{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-25T06:38:26.196172Z",
     "start_time": "2024-09-25T06:38:24.325188Z"
    }
   },
   "source": [
    "import os\n",
    "import mnist_loader as ml\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import math\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T06:38:26.200607Z",
     "start_time": "2024-09-25T06:38:26.197562Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class NetSimple(nn.Module):\n",
    "    def __init__(self, c):\n",
    "        super(NetSimple, self).__init__()\n",
    "        self.conv = nn.Conv2d(3, 16, 3, 1, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.linear = nn.Linear(14*14*16, c)\n",
    "    def forward(self, x):\n",
    "        conv_out = self.conv(x)\n",
    "        relu_out = self.relu(conv_out)\n",
    "        pool_out = self.pool(relu_out)\n",
    "        res = pool_out.view(pool_out.size(0), -1)\n",
    "        out = self.linear(res)\n",
    "        return out"
   ],
   "id": "e4bcad8f89c2fd8a",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def train(dp, bs, epc, cuda):\n",
    "    os.makedirs('./output', exist_ok=True)\n",
    "    # os.makedirs 创建一个名为 output 的目录，如果已经存在则不抛出异常。\n",
    "    if True: #not os.path.exists('output/total.txt'):\n",
    "        ml.image_list(dp, 'output/total.txt')\n",
    "        # 从指定的数据路径生成一个包含图像文件和标签的列表文件。\n",
    "        ml.shuffle_split('output/total.txt', 'output/train.txt', 'output/val.txt')\n",
    "\n",
    "    train_data = ml.MyDataset(txt='output/train.txt', transform=transforms.ToTensor())\n",
    "    val_data = ml.MyDataset(txt='output/val.txt', transform=transforms.ToTensor())\n",
    "    # transforms.ToTensor() 将图像数据转换为 PyTorch 的张量格式。\n",
    "    train_loader = DataLoader(dataset=train_data, batch_size=bs, shuffle=True)\n",
    "    val_loader = DataLoader(dataset=val_data, batch_size=bs)\n",
    "    # DataLoader 将数据集包装为可迭代的数据加载器，支持批处理和打乱数据。\n",
    "\n",
    "    model = NetSimple(10)\n",
    "    #model = models.vgg16(num_classes=10)\n",
    "    #model = models.resnet18(num_classes=10)  # 调用内置模型\n",
    "    #model.load_state_dict(torch.load('./output/params_10.pth'))\n",
    "    from torchsummary import summary\n",
    "    summary(model, (3, 28, 28))\n",
    "    # 3 -> RGB 3 channels, 28 -> height, width\n",
    "\n",
    "    if cuda:\n",
    "        print('training with cuda')\n",
    "        model.cuda()\n",
    "        # 检查是否可以使用 CUDA（GPU 加速），如果可以则将模型移动到 GPU\n",
    "        \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=1e-3)\n",
    "    # 初始化 Adam 优化器，设置学习率和权重衰减\n",
    "    # Adam自动调整学习率\n",
    "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, [20, 30], 0.1)\n",
    "    # 在特定的训练轮次（20 和 30）调整学习率，变为原来的10%（0.1）\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "    # 交叉熵损失函数\n",
    "\n",
    "    for epoch in range(epc):\n",
    "        # training-----------------------------------\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_acc = 0\n",
    "        for batch, (batch_data, batch_label) in enumerate(train_loader):\n",
    "            # 使用 enumerate 来迭代训练数据加载器（train_loader），每次获取一个批次的数据和标签。\n",
    "            # 迭代时自动进行getitem方法，将img和label返回给batch_data和batch_label\n",
    "            # batch_data 是当前批次的输入数据，通常是一个张量，包含多个样本\n",
    "            # batch_label 是当前批次的标签，也通常是一个张量，包含与 batch_data 对应的标签\n",
    "            if cuda:\n",
    "                batch_data, batch_label = Variable(batch_data.cuda()), Variable(batch_label.cuda())\n",
    "            else:\n",
    "                batch_data, batch_label = Variable(batch_data), Variable(batch_label)\n",
    "            # 根据是否使用 CUDA 将数据移动到 GPU 或保留在 CPU 上\n",
    "\n",
    "            out = model(batch_data)  # 256x3x28x28  out 256x10\n",
    "            # 将输入批次（batch_data）传入模型，得到输出（out）。注释说明输入是 256 张 28x28 的 RGB 图像，输出是 256 个类别的预测。\n",
    "            \n",
    "            loss = loss_func(out, batch_label)\n",
    "            # 计算输出与真实标签之间的损失，使用交叉熵损失函数（loss_func）。\n",
    "            train_loss += loss.item()\n",
    "            # 将当前批次的损失添加到总损失中。\n",
    "            \n",
    "            pred = torch.max(out, 1)[1]\n",
    "            # torch.max(out, 1)[1] 计算预测的类别。\n",
    "            train_correct = (pred == batch_label).sum()\n",
    "            # (pred == batch_y).sum() 计算正确预测的数量。\n",
    "            train_acc += train_correct.item()\n",
    "            # 将正确预测的数量累加到总准确率中。\n",
    "            \n",
    "            print('epoch: %2d/%d batch %3d/%d  Train Loss: %.3f, Acc: %.3f'\n",
    "                  % (epoch + 1, epc, batch, math.ceil(len(train_data) / bs),\n",
    "                     loss.item(), train_correct.item() / len(batch_data)))\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            # 在进行反向传播之前，先将优化器中的梯度清零。\n",
    "            loss.backward()\n",
    "            # 反向传播\n",
    "            optimizer.step()\n",
    "            # 更新参数\n",
    "            \n",
    "        scheduler.step()  # 更新learning rate\n",
    "        print('Train Loss: %.6f, Acc: %.3f' % (train_loss / (math.ceil(len(train_data) / bs)), train_acc / (len(train_data))))\n",
    "\n",
    "        # evaluation--------------------------------\n",
    "        model.eval()\n",
    "        eval_loss = 0\n",
    "        eval_acc = 0\n",
    "        for batch_data, batch_label in val_loader:\n",
    "            if cuda:\n",
    "                batch_data, batch_label = Variable(batch_data.cuda()), Variable(batch_label.cuda())\n",
    "            else:\n",
    "                batch_data, batch_label = Variable(batch_data), Variable(batch_label)\n",
    "\n",
    "            out = model(batch_data)\n",
    "            loss = loss_func(out, batch_label)\n",
    "            eval_loss += loss.item()\n",
    "            pred = torch.max(out, 1)[1]\n",
    "            num_correct = (pred == batch_label).sum()\n",
    "            eval_acc += num_correct.item()\n",
    "        print('Val Loss: %.6f, Acc: %.3f' % (eval_loss / (math.ceil(len(val_data) / bs)), eval_acc / (len(val_data))))\n",
    "        # 保存模型。每隔多少帧存模型，此处可修改------------\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            # torch.save(model, 'output/model_' + str(epoch+1) + '.pth')\n",
    "            torch.save(model.state_dict(), 'output/params_' + str(epoch + 1) + '.pth')\n",
    "        # 每个 epoch 保存一次模型参数，方便后续加载和继续训练"
   ],
   "id": "fb4bee9aee790bb6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T08:04:39.218098Z",
     "start_time": "2024-09-25T06:38:26.209458Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 设置参数\n",
    "datapath = '/Users/sunyuliang/Desktop/CV/Python/n_imgs/train_images'\n",
    "batch_size = 256\n",
    "epochs = 300\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "# 调用训练函数\n",
    "train(datapath, batch_size, epochs, use_cuda)"
   ],
   "id": "1207c07c7f057ef1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 16, 28, 28]             448\n",
      "              ReLU-2           [-1, 16, 28, 28]               0\n",
      "         MaxPool2d-3           [-1, 16, 14, 14]               0\n",
      "            Linear-4                   [-1, 10]          31,370\n",
      "================================================================\n",
      "Total params: 31,818\n",
      "Trainable params: 31,818\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.22\n",
      "Params size (MB): 0.12\n",
      "Estimated Total Size (MB): 0.35\n",
      "----------------------------------------------------------------\n",
      "epoch:  1/300 batch   0/188  Train Loss: 2.311, Acc: 0.102\n",
      "epoch:  1/300 batch   1/188  Train Loss: 3.386, Acc: 0.090\n",
      "epoch:  1/300 batch   2/188  Train Loss: 1.835, Acc: 0.375\n",
      "epoch:  1/300 batch   3/188  Train Loss: 1.800, Acc: 0.527\n",
      "epoch:  1/300 batch   4/188  Train Loss: 1.681, Acc: 0.543\n",
      "epoch:  1/300 batch   5/188  Train Loss: 1.731, Acc: 0.645\n",
      "epoch:  1/300 batch   6/188  Train Loss: 1.583, Acc: 0.695\n",
      "epoch:  1/300 batch   7/188  Train Loss: 1.474, Acc: 0.672\n",
      "epoch:  1/300 batch   8/188  Train Loss: 1.159, Acc: 0.719\n",
      "epoch:  1/300 batch   9/188  Train Loss: 1.190, Acc: 0.715\n",
      "epoch:  1/300 batch  10/188  Train Loss: 1.044, Acc: 0.715\n",
      "epoch:  1/300 batch  11/188  Train Loss: 0.958, Acc: 0.758\n",
      "epoch:  1/300 batch  12/188  Train Loss: 0.722, Acc: 0.777\n",
      "epoch:  1/300 batch  13/188  Train Loss: 0.576, Acc: 0.816\n",
      "epoch:  1/300 batch  14/188  Train Loss: 0.538, Acc: 0.836\n",
      "epoch:  1/300 batch  15/188  Train Loss: 0.660, Acc: 0.777\n",
      "epoch:  1/300 batch  16/188  Train Loss: 0.569, Acc: 0.797\n",
      "epoch:  1/300 batch  17/188  Train Loss: 0.482, Acc: 0.859\n",
      "epoch:  1/300 batch  18/188  Train Loss: 0.388, Acc: 0.859\n",
      "epoch:  1/300 batch  19/188  Train Loss: 0.438, Acc: 0.867\n",
      "epoch:  1/300 batch  20/188  Train Loss: 0.380, Acc: 0.879\n",
      "epoch:  1/300 batch  21/188  Train Loss: 0.519, Acc: 0.840\n",
      "epoch:  1/300 batch  22/188  Train Loss: 0.451, Acc: 0.836\n",
      "epoch:  1/300 batch  23/188  Train Loss: 0.374, Acc: 0.871\n",
      "epoch:  1/300 batch  24/188  Train Loss: 0.416, Acc: 0.871\n",
      "epoch:  1/300 batch  25/188  Train Loss: 0.395, Acc: 0.887\n",
      "epoch:  1/300 batch  26/188  Train Loss: 0.434, Acc: 0.855\n",
      "epoch:  1/300 batch  27/188  Train Loss: 0.314, Acc: 0.914\n",
      "epoch:  1/300 batch  28/188  Train Loss: 0.362, Acc: 0.867\n",
      "epoch:  1/300 batch  29/188  Train Loss: 0.378, Acc: 0.902\n",
      "epoch:  1/300 batch  30/188  Train Loss: 0.283, Acc: 0.922\n",
      "epoch:  1/300 batch  31/188  Train Loss: 0.373, Acc: 0.902\n",
      "epoch:  1/300 batch  32/188  Train Loss: 0.338, Acc: 0.906\n",
      "epoch:  1/300 batch  33/188  Train Loss: 0.291, Acc: 0.910\n",
      "epoch:  1/300 batch  34/188  Train Loss: 0.307, Acc: 0.914\n",
      "epoch:  1/300 batch  35/188  Train Loss: 0.300, Acc: 0.902\n",
      "epoch:  1/300 batch  36/188  Train Loss: 0.331, Acc: 0.891\n",
      "epoch:  1/300 batch  37/188  Train Loss: 0.320, Acc: 0.914\n",
      "epoch:  1/300 batch  38/188  Train Loss: 0.206, Acc: 0.930\n",
      "epoch:  1/300 batch  39/188  Train Loss: 0.292, Acc: 0.906\n",
      "epoch:  1/300 batch  40/188  Train Loss: 0.244, Acc: 0.914\n",
      "epoch:  1/300 batch  41/188  Train Loss: 0.388, Acc: 0.887\n",
      "epoch:  1/300 batch  42/188  Train Loss: 0.199, Acc: 0.930\n",
      "epoch:  1/300 batch  43/188  Train Loss: 0.292, Acc: 0.906\n",
      "epoch:  1/300 batch  44/188  Train Loss: 0.380, Acc: 0.871\n",
      "epoch:  1/300 batch  45/188  Train Loss: 0.299, Acc: 0.906\n",
      "epoch:  1/300 batch  46/188  Train Loss: 0.221, Acc: 0.934\n",
      "epoch:  1/300 batch  47/188  Train Loss: 0.336, Acc: 0.898\n",
      "epoch:  1/300 batch  48/188  Train Loss: 0.248, Acc: 0.930\n",
      "epoch:  1/300 batch  49/188  Train Loss: 0.175, Acc: 0.949\n",
      "epoch:  1/300 batch  50/188  Train Loss: 0.218, Acc: 0.926\n",
      "epoch:  1/300 batch  51/188  Train Loss: 0.258, Acc: 0.906\n",
      "epoch:  1/300 batch  52/188  Train Loss: 0.314, Acc: 0.910\n",
      "epoch:  1/300 batch  53/188  Train Loss: 0.190, Acc: 0.938\n",
      "epoch:  1/300 batch  54/188  Train Loss: 0.232, Acc: 0.922\n",
      "epoch:  1/300 batch  55/188  Train Loss: 0.178, Acc: 0.949\n",
      "epoch:  1/300 batch  56/188  Train Loss: 0.186, Acc: 0.941\n",
      "epoch:  1/300 batch  57/188  Train Loss: 0.255, Acc: 0.934\n",
      "epoch:  1/300 batch  58/188  Train Loss: 0.191, Acc: 0.945\n",
      "epoch:  1/300 batch  59/188  Train Loss: 0.215, Acc: 0.930\n",
      "epoch:  1/300 batch  60/188  Train Loss: 0.203, Acc: 0.934\n",
      "epoch:  1/300 batch  61/188  Train Loss: 0.275, Acc: 0.906\n",
      "epoch:  1/300 batch  62/188  Train Loss: 0.264, Acc: 0.938\n",
      "epoch:  1/300 batch  63/188  Train Loss: 0.166, Acc: 0.938\n",
      "epoch:  1/300 batch  64/188  Train Loss: 0.297, Acc: 0.910\n",
      "epoch:  1/300 batch  65/188  Train Loss: 0.290, Acc: 0.938\n",
      "epoch:  1/300 batch  66/188  Train Loss: 0.222, Acc: 0.926\n",
      "epoch:  1/300 batch  67/188  Train Loss: 0.199, Acc: 0.961\n",
      "epoch:  1/300 batch  68/188  Train Loss: 0.273, Acc: 0.918\n",
      "epoch:  1/300 batch  69/188  Train Loss: 0.189, Acc: 0.930\n",
      "epoch:  1/300 batch  70/188  Train Loss: 0.244, Acc: 0.934\n",
      "epoch:  1/300 batch  71/188  Train Loss: 0.275, Acc: 0.918\n",
      "epoch:  1/300 batch  72/188  Train Loss: 0.229, Acc: 0.938\n",
      "epoch:  1/300 batch  73/188  Train Loss: 0.300, Acc: 0.922\n",
      "epoch:  1/300 batch  74/188  Train Loss: 0.136, Acc: 0.969\n",
      "epoch:  1/300 batch  75/188  Train Loss: 0.259, Acc: 0.926\n",
      "epoch:  1/300 batch  76/188  Train Loss: 0.152, Acc: 0.949\n",
      "epoch:  1/300 batch  77/188  Train Loss: 0.154, Acc: 0.957\n",
      "epoch:  1/300 batch  78/188  Train Loss: 0.261, Acc: 0.930\n",
      "epoch:  1/300 batch  79/188  Train Loss: 0.155, Acc: 0.965\n",
      "epoch:  1/300 batch  80/188  Train Loss: 0.161, Acc: 0.961\n",
      "epoch:  1/300 batch  81/188  Train Loss: 0.133, Acc: 0.949\n",
      "epoch:  1/300 batch  82/188  Train Loss: 0.226, Acc: 0.941\n",
      "epoch:  1/300 batch  83/188  Train Loss: 0.224, Acc: 0.934\n",
      "epoch:  1/300 batch  84/188  Train Loss: 0.164, Acc: 0.961\n",
      "epoch:  1/300 batch  85/188  Train Loss: 0.246, Acc: 0.941\n",
      "epoch:  1/300 batch  86/188  Train Loss: 0.173, Acc: 0.945\n",
      "epoch:  1/300 batch  87/188  Train Loss: 0.151, Acc: 0.957\n",
      "epoch:  1/300 batch  88/188  Train Loss: 0.117, Acc: 0.969\n",
      "epoch:  1/300 batch  89/188  Train Loss: 0.192, Acc: 0.918\n",
      "epoch:  1/300 batch  90/188  Train Loss: 0.158, Acc: 0.957\n",
      "epoch:  1/300 batch  91/188  Train Loss: 0.096, Acc: 0.973\n",
      "epoch:  1/300 batch  92/188  Train Loss: 0.206, Acc: 0.934\n",
      "epoch:  1/300 batch  93/188  Train Loss: 0.147, Acc: 0.949\n",
      "epoch:  1/300 batch  94/188  Train Loss: 0.139, Acc: 0.961\n",
      "epoch:  1/300 batch  95/188  Train Loss: 0.130, Acc: 0.973\n",
      "epoch:  1/300 batch  96/188  Train Loss: 0.188, Acc: 0.953\n",
      "epoch:  1/300 batch  97/188  Train Loss: 0.121, Acc: 0.977\n",
      "epoch:  1/300 batch  98/188  Train Loss: 0.126, Acc: 0.965\n",
      "epoch:  1/300 batch  99/188  Train Loss: 0.113, Acc: 0.969\n",
      "epoch:  1/300 batch 100/188  Train Loss: 0.156, Acc: 0.945\n",
      "epoch:  1/300 batch 101/188  Train Loss: 0.176, Acc: 0.961\n",
      "epoch:  1/300 batch 102/188  Train Loss: 0.144, Acc: 0.949\n",
      "epoch:  1/300 batch 103/188  Train Loss: 0.121, Acc: 0.969\n",
      "epoch:  1/300 batch 104/188  Train Loss: 0.114, Acc: 0.973\n",
      "epoch:  1/300 batch 105/188  Train Loss: 0.208, Acc: 0.941\n",
      "epoch:  1/300 batch 106/188  Train Loss: 0.102, Acc: 0.973\n",
      "epoch:  1/300 batch 107/188  Train Loss: 0.178, Acc: 0.945\n",
      "epoch:  1/300 batch 108/188  Train Loss: 0.133, Acc: 0.957\n",
      "epoch:  1/300 batch 109/188  Train Loss: 0.190, Acc: 0.945\n",
      "epoch:  1/300 batch 110/188  Train Loss: 0.078, Acc: 0.984\n",
      "epoch:  1/300 batch 111/188  Train Loss: 0.155, Acc: 0.957\n",
      "epoch:  1/300 batch 112/188  Train Loss: 0.107, Acc: 0.969\n",
      "epoch:  1/300 batch 113/188  Train Loss: 0.194, Acc: 0.941\n",
      "epoch:  1/300 batch 114/188  Train Loss: 0.132, Acc: 0.969\n",
      "epoch:  1/300 batch 115/188  Train Loss: 0.138, Acc: 0.965\n",
      "epoch:  1/300 batch 116/188  Train Loss: 0.131, Acc: 0.945\n",
      "epoch:  1/300 batch 117/188  Train Loss: 0.109, Acc: 0.973\n",
      "epoch:  1/300 batch 118/188  Train Loss: 0.132, Acc: 0.961\n",
      "epoch:  1/300 batch 119/188  Train Loss: 0.111, Acc: 0.973\n",
      "epoch:  1/300 batch 120/188  Train Loss: 0.114, Acc: 0.965\n",
      "epoch:  1/300 batch 121/188  Train Loss: 0.190, Acc: 0.934\n",
      "epoch:  1/300 batch 122/188  Train Loss: 0.157, Acc: 0.957\n",
      "epoch:  1/300 batch 123/188  Train Loss: 0.127, Acc: 0.961\n",
      "epoch:  1/300 batch 124/188  Train Loss: 0.093, Acc: 0.969\n",
      "epoch:  1/300 batch 125/188  Train Loss: 0.096, Acc: 0.961\n",
      "epoch:  1/300 batch 126/188  Train Loss: 0.125, Acc: 0.965\n",
      "epoch:  1/300 batch 127/188  Train Loss: 0.110, Acc: 0.961\n",
      "epoch:  1/300 batch 128/188  Train Loss: 0.148, Acc: 0.957\n",
      "epoch:  1/300 batch 129/188  Train Loss: 0.119, Acc: 0.965\n",
      "epoch:  1/300 batch 130/188  Train Loss: 0.245, Acc: 0.945\n",
      "epoch:  1/300 batch 131/188  Train Loss: 0.106, Acc: 0.969\n",
      "epoch:  1/300 batch 132/188  Train Loss: 0.168, Acc: 0.945\n",
      "epoch:  1/300 batch 133/188  Train Loss: 0.119, Acc: 0.965\n",
      "epoch:  1/300 batch 134/188  Train Loss: 0.108, Acc: 0.965\n",
      "epoch:  1/300 batch 135/188  Train Loss: 0.123, Acc: 0.965\n",
      "epoch:  1/300 batch 136/188  Train Loss: 0.189, Acc: 0.949\n",
      "epoch:  1/300 batch 137/188  Train Loss: 0.204, Acc: 0.945\n",
      "epoch:  1/300 batch 138/188  Train Loss: 0.087, Acc: 0.973\n",
      "epoch:  1/300 batch 139/188  Train Loss: 0.099, Acc: 0.965\n",
      "epoch:  1/300 batch 140/188  Train Loss: 0.097, Acc: 0.980\n",
      "epoch:  1/300 batch 141/188  Train Loss: 0.110, Acc: 0.969\n",
      "epoch:  1/300 batch 142/188  Train Loss: 0.123, Acc: 0.961\n",
      "epoch:  1/300 batch 143/188  Train Loss: 0.142, Acc: 0.957\n",
      "epoch:  1/300 batch 144/188  Train Loss: 0.093, Acc: 0.969\n",
      "epoch:  1/300 batch 145/188  Train Loss: 0.088, Acc: 0.969\n",
      "epoch:  1/300 batch 146/188  Train Loss: 0.102, Acc: 0.969\n",
      "epoch:  1/300 batch 147/188  Train Loss: 0.110, Acc: 0.969\n",
      "epoch:  1/300 batch 148/188  Train Loss: 0.103, Acc: 0.965\n",
      "epoch:  1/300 batch 149/188  Train Loss: 0.107, Acc: 0.980\n",
      "epoch:  1/300 batch 150/188  Train Loss: 0.115, Acc: 0.949\n",
      "epoch:  1/300 batch 151/188  Train Loss: 0.091, Acc: 0.969\n",
      "epoch:  1/300 batch 152/188  Train Loss: 0.109, Acc: 0.977\n",
      "epoch:  1/300 batch 153/188  Train Loss: 0.129, Acc: 0.953\n",
      "epoch:  1/300 batch 154/188  Train Loss: 0.112, Acc: 0.969\n",
      "epoch:  1/300 batch 155/188  Train Loss: 0.110, Acc: 0.953\n",
      "epoch:  1/300 batch 156/188  Train Loss: 0.159, Acc: 0.961\n",
      "epoch:  1/300 batch 157/188  Train Loss: 0.112, Acc: 0.957\n",
      "epoch:  1/300 batch 158/188  Train Loss: 0.105, Acc: 0.961\n",
      "epoch:  1/300 batch 159/188  Train Loss: 0.069, Acc: 0.984\n",
      "epoch:  1/300 batch 160/188  Train Loss: 0.120, Acc: 0.973\n",
      "epoch:  1/300 batch 161/188  Train Loss: 0.120, Acc: 0.957\n",
      "epoch:  1/300 batch 162/188  Train Loss: 0.082, Acc: 0.965\n",
      "epoch:  1/300 batch 163/188  Train Loss: 0.103, Acc: 0.973\n",
      "epoch:  1/300 batch 164/188  Train Loss: 0.169, Acc: 0.957\n",
      "epoch:  1/300 batch 165/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch:  1/300 batch 166/188  Train Loss: 0.054, Acc: 0.996\n",
      "epoch:  1/300 batch 167/188  Train Loss: 0.143, Acc: 0.961\n",
      "epoch:  1/300 batch 168/188  Train Loss: 0.091, Acc: 0.977\n",
      "epoch:  1/300 batch 169/188  Train Loss: 0.064, Acc: 0.980\n",
      "epoch:  1/300 batch 170/188  Train Loss: 0.083, Acc: 0.980\n",
      "epoch:  1/300 batch 171/188  Train Loss: 0.116, Acc: 0.973\n",
      "epoch:  1/300 batch 172/188  Train Loss: 0.080, Acc: 0.984\n",
      "epoch:  1/300 batch 173/188  Train Loss: 0.099, Acc: 0.965\n",
      "epoch:  1/300 batch 174/188  Train Loss: 0.130, Acc: 0.957\n",
      "epoch:  1/300 batch 175/188  Train Loss: 0.130, Acc: 0.973\n",
      "epoch:  1/300 batch 176/188  Train Loss: 0.096, Acc: 0.973\n",
      "epoch:  1/300 batch 177/188  Train Loss: 0.129, Acc: 0.969\n",
      "epoch:  1/300 batch 178/188  Train Loss: 0.132, Acc: 0.961\n",
      "epoch:  1/300 batch 179/188  Train Loss: 0.111, Acc: 0.984\n",
      "epoch:  1/300 batch 180/188  Train Loss: 0.122, Acc: 0.957\n",
      "epoch:  1/300 batch 181/188  Train Loss: 0.130, Acc: 0.965\n",
      "epoch:  1/300 batch 182/188  Train Loss: 0.118, Acc: 0.957\n",
      "epoch:  1/300 batch 183/188  Train Loss: 0.103, Acc: 0.965\n",
      "epoch:  1/300 batch 184/188  Train Loss: 0.124, Acc: 0.957\n",
      "epoch:  1/300 batch 185/188  Train Loss: 0.070, Acc: 0.980\n",
      "epoch:  1/300 batch 186/188  Train Loss: 0.079, Acc: 0.977\n",
      "epoch:  1/300 batch 187/188  Train Loss: 0.086, Acc: 0.977\n",
      "Train Loss: 0.292602, Acc: 0.915\n",
      "Val Loss: 0.107262, Acc: 0.968\n",
      "epoch:  2/300 batch   0/188  Train Loss: 0.090, Acc: 0.977\n",
      "epoch:  2/300 batch   1/188  Train Loss: 0.076, Acc: 0.977\n",
      "epoch:  2/300 batch   2/188  Train Loss: 0.118, Acc: 0.957\n",
      "epoch:  2/300 batch   3/188  Train Loss: 0.058, Acc: 0.988\n",
      "epoch:  2/300 batch   4/188  Train Loss: 0.110, Acc: 0.961\n",
      "epoch:  2/300 batch   5/188  Train Loss: 0.097, Acc: 0.969\n",
      "epoch:  2/300 batch   6/188  Train Loss: 0.139, Acc: 0.945\n",
      "epoch:  2/300 batch   7/188  Train Loss: 0.146, Acc: 0.957\n",
      "epoch:  2/300 batch   8/188  Train Loss: 0.070, Acc: 0.980\n",
      "epoch:  2/300 batch   9/188  Train Loss: 0.094, Acc: 0.969\n",
      "epoch:  2/300 batch  10/188  Train Loss: 0.154, Acc: 0.961\n",
      "epoch:  2/300 batch  11/188  Train Loss: 0.058, Acc: 0.977\n",
      "epoch:  2/300 batch  12/188  Train Loss: 0.100, Acc: 0.977\n",
      "epoch:  2/300 batch  13/188  Train Loss: 0.097, Acc: 0.980\n",
      "epoch:  2/300 batch  14/188  Train Loss: 0.101, Acc: 0.973\n",
      "epoch:  2/300 batch  15/188  Train Loss: 0.088, Acc: 0.977\n",
      "epoch:  2/300 batch  16/188  Train Loss: 0.106, Acc: 0.965\n",
      "epoch:  2/300 batch  17/188  Train Loss: 0.076, Acc: 0.977\n",
      "epoch:  2/300 batch  18/188  Train Loss: 0.071, Acc: 0.988\n",
      "epoch:  2/300 batch  19/188  Train Loss: 0.090, Acc: 0.977\n",
      "epoch:  2/300 batch  20/188  Train Loss: 0.086, Acc: 0.980\n",
      "epoch:  2/300 batch  21/188  Train Loss: 0.092, Acc: 0.977\n",
      "epoch:  2/300 batch  22/188  Train Loss: 0.077, Acc: 0.977\n",
      "epoch:  2/300 batch  23/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch:  2/300 batch  24/188  Train Loss: 0.062, Acc: 0.980\n",
      "epoch:  2/300 batch  25/188  Train Loss: 0.077, Acc: 0.980\n",
      "epoch:  2/300 batch  26/188  Train Loss: 0.121, Acc: 0.965\n",
      "epoch:  2/300 batch  27/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch:  2/300 batch  28/188  Train Loss: 0.076, Acc: 0.984\n",
      "epoch:  2/300 batch  29/188  Train Loss: 0.145, Acc: 0.953\n",
      "epoch:  2/300 batch  30/188  Train Loss: 0.055, Acc: 0.977\n",
      "epoch:  2/300 batch  31/188  Train Loss: 0.115, Acc: 0.961\n",
      "epoch:  2/300 batch  32/188  Train Loss: 0.068, Acc: 0.980\n",
      "epoch:  2/300 batch  33/188  Train Loss: 0.101, Acc: 0.984\n",
      "epoch:  2/300 batch  34/188  Train Loss: 0.086, Acc: 0.961\n",
      "epoch:  2/300 batch  35/188  Train Loss: 0.042, Acc: 0.996\n",
      "epoch:  2/300 batch  36/188  Train Loss: 0.115, Acc: 0.973\n",
      "epoch:  2/300 batch  37/188  Train Loss: 0.103, Acc: 0.969\n",
      "epoch:  2/300 batch  38/188  Train Loss: 0.105, Acc: 0.973\n",
      "epoch:  2/300 batch  39/188  Train Loss: 0.114, Acc: 0.977\n",
      "epoch:  2/300 batch  40/188  Train Loss: 0.067, Acc: 0.973\n",
      "epoch:  2/300 batch  41/188  Train Loss: 0.157, Acc: 0.961\n",
      "epoch:  2/300 batch  42/188  Train Loss: 0.086, Acc: 0.977\n",
      "epoch:  2/300 batch  43/188  Train Loss: 0.153, Acc: 0.945\n",
      "epoch:  2/300 batch  44/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch:  2/300 batch  45/188  Train Loss: 0.093, Acc: 0.973\n",
      "epoch:  2/300 batch  46/188  Train Loss: 0.126, Acc: 0.965\n",
      "epoch:  2/300 batch  47/188  Train Loss: 0.148, Acc: 0.961\n",
      "epoch:  2/300 batch  48/188  Train Loss: 0.093, Acc: 0.965\n",
      "epoch:  2/300 batch  49/188  Train Loss: 0.136, Acc: 0.961\n",
      "epoch:  2/300 batch  50/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch:  2/300 batch  51/188  Train Loss: 0.092, Acc: 0.973\n",
      "epoch:  2/300 batch  52/188  Train Loss: 0.104, Acc: 0.973\n",
      "epoch:  2/300 batch  53/188  Train Loss: 0.086, Acc: 0.977\n",
      "epoch:  2/300 batch  54/188  Train Loss: 0.092, Acc: 0.965\n",
      "epoch:  2/300 batch  55/188  Train Loss: 0.134, Acc: 0.961\n",
      "epoch:  2/300 batch  56/188  Train Loss: 0.098, Acc: 0.961\n",
      "epoch:  2/300 batch  57/188  Train Loss: 0.078, Acc: 0.969\n",
      "epoch:  2/300 batch  58/188  Train Loss: 0.160, Acc: 0.953\n",
      "epoch:  2/300 batch  59/188  Train Loss: 0.073, Acc: 0.992\n",
      "epoch:  2/300 batch  60/188  Train Loss: 0.059, Acc: 0.984\n",
      "epoch:  2/300 batch  61/188  Train Loss: 0.114, Acc: 0.961\n",
      "epoch:  2/300 batch  62/188  Train Loss: 0.092, Acc: 0.961\n",
      "epoch:  2/300 batch  63/188  Train Loss: 0.079, Acc: 0.969\n",
      "epoch:  2/300 batch  64/188  Train Loss: 0.154, Acc: 0.957\n",
      "epoch:  2/300 batch  65/188  Train Loss: 0.103, Acc: 0.969\n",
      "epoch:  2/300 batch  66/188  Train Loss: 0.073, Acc: 0.980\n",
      "epoch:  2/300 batch  67/188  Train Loss: 0.104, Acc: 0.969\n",
      "epoch:  2/300 batch  68/188  Train Loss: 0.169, Acc: 0.957\n",
      "epoch:  2/300 batch  69/188  Train Loss: 0.082, Acc: 0.980\n",
      "epoch:  2/300 batch  70/188  Train Loss: 0.102, Acc: 0.984\n",
      "epoch:  2/300 batch  71/188  Train Loss: 0.135, Acc: 0.977\n",
      "epoch:  2/300 batch  72/188  Train Loss: 0.085, Acc: 0.980\n",
      "epoch:  2/300 batch  73/188  Train Loss: 0.086, Acc: 0.980\n",
      "epoch:  2/300 batch  74/188  Train Loss: 0.080, Acc: 0.980\n",
      "epoch:  2/300 batch  75/188  Train Loss: 0.072, Acc: 0.984\n",
      "epoch:  2/300 batch  76/188  Train Loss: 0.056, Acc: 0.992\n",
      "epoch:  2/300 batch  77/188  Train Loss: 0.110, Acc: 0.969\n",
      "epoch:  2/300 batch  78/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch:  2/300 batch  79/188  Train Loss: 0.089, Acc: 0.980\n",
      "epoch:  2/300 batch  80/188  Train Loss: 0.090, Acc: 0.969\n",
      "epoch:  2/300 batch  81/188  Train Loss: 0.094, Acc: 0.977\n",
      "epoch:  2/300 batch  82/188  Train Loss: 0.132, Acc: 0.961\n",
      "epoch:  2/300 batch  83/188  Train Loss: 0.121, Acc: 0.969\n",
      "epoch:  2/300 batch  84/188  Train Loss: 0.154, Acc: 0.977\n",
      "epoch:  2/300 batch  85/188  Train Loss: 0.090, Acc: 0.969\n",
      "epoch:  2/300 batch  86/188  Train Loss: 0.095, Acc: 0.980\n",
      "epoch:  2/300 batch  87/188  Train Loss: 0.096, Acc: 0.965\n",
      "epoch:  2/300 batch  88/188  Train Loss: 0.081, Acc: 0.988\n",
      "epoch:  2/300 batch  89/188  Train Loss: 0.087, Acc: 0.973\n",
      "epoch:  2/300 batch  90/188  Train Loss: 0.080, Acc: 0.973\n",
      "epoch:  2/300 batch  91/188  Train Loss: 0.122, Acc: 0.961\n",
      "epoch:  2/300 batch  92/188  Train Loss: 0.150, Acc: 0.949\n",
      "epoch:  2/300 batch  93/188  Train Loss: 0.100, Acc: 0.965\n",
      "epoch:  2/300 batch  94/188  Train Loss: 0.083, Acc: 0.980\n",
      "epoch:  2/300 batch  95/188  Train Loss: 0.120, Acc: 0.961\n",
      "epoch:  2/300 batch  96/188  Train Loss: 0.084, Acc: 0.992\n",
      "epoch:  2/300 batch  97/188  Train Loss: 0.087, Acc: 0.977\n",
      "epoch:  2/300 batch  98/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch:  2/300 batch  99/188  Train Loss: 0.062, Acc: 0.980\n",
      "epoch:  2/300 batch 100/188  Train Loss: 0.079, Acc: 0.988\n",
      "epoch:  2/300 batch 101/188  Train Loss: 0.093, Acc: 0.980\n",
      "epoch:  2/300 batch 102/188  Train Loss: 0.079, Acc: 0.973\n",
      "epoch:  2/300 batch 103/188  Train Loss: 0.071, Acc: 0.973\n",
      "epoch:  2/300 batch 104/188  Train Loss: 0.058, Acc: 0.988\n",
      "epoch:  2/300 batch 105/188  Train Loss: 0.064, Acc: 0.984\n",
      "epoch:  2/300 batch 106/188  Train Loss: 0.089, Acc: 0.980\n",
      "epoch:  2/300 batch 107/188  Train Loss: 0.065, Acc: 0.980\n",
      "epoch:  2/300 batch 108/188  Train Loss: 0.085, Acc: 0.980\n",
      "epoch:  2/300 batch 109/188  Train Loss: 0.102, Acc: 0.957\n",
      "epoch:  2/300 batch 110/188  Train Loss: 0.092, Acc: 0.973\n",
      "epoch:  2/300 batch 111/188  Train Loss: 0.063, Acc: 0.980\n",
      "epoch:  2/300 batch 112/188  Train Loss: 0.169, Acc: 0.961\n",
      "epoch:  2/300 batch 113/188  Train Loss: 0.107, Acc: 0.965\n",
      "epoch:  2/300 batch 114/188  Train Loss: 0.089, Acc: 0.977\n",
      "epoch:  2/300 batch 115/188  Train Loss: 0.091, Acc: 0.977\n",
      "epoch:  2/300 batch 116/188  Train Loss: 0.098, Acc: 0.973\n",
      "epoch:  2/300 batch 117/188  Train Loss: 0.111, Acc: 0.977\n",
      "epoch:  2/300 batch 118/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch:  2/300 batch 119/188  Train Loss: 0.071, Acc: 0.977\n",
      "epoch:  2/300 batch 120/188  Train Loss: 0.102, Acc: 0.961\n",
      "epoch:  2/300 batch 121/188  Train Loss: 0.085, Acc: 0.961\n",
      "epoch:  2/300 batch 122/188  Train Loss: 0.092, Acc: 0.957\n",
      "epoch:  2/300 batch 123/188  Train Loss: 0.063, Acc: 0.988\n",
      "epoch:  2/300 batch 124/188  Train Loss: 0.079, Acc: 0.969\n",
      "epoch:  2/300 batch 125/188  Train Loss: 0.156, Acc: 0.945\n",
      "epoch:  2/300 batch 126/188  Train Loss: 0.120, Acc: 0.953\n",
      "epoch:  2/300 batch 127/188  Train Loss: 0.054, Acc: 0.980\n",
      "epoch:  2/300 batch 128/188  Train Loss: 0.085, Acc: 0.973\n",
      "epoch:  2/300 batch 129/188  Train Loss: 0.127, Acc: 0.969\n",
      "epoch:  2/300 batch 130/188  Train Loss: 0.109, Acc: 0.957\n",
      "epoch:  2/300 batch 131/188  Train Loss: 0.113, Acc: 0.969\n",
      "epoch:  2/300 batch 132/188  Train Loss: 0.111, Acc: 0.965\n",
      "epoch:  2/300 batch 133/188  Train Loss: 0.142, Acc: 0.949\n",
      "epoch:  2/300 batch 134/188  Train Loss: 0.142, Acc: 0.977\n",
      "epoch:  2/300 batch 135/188  Train Loss: 0.147, Acc: 0.965\n",
      "epoch:  2/300 batch 136/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch:  2/300 batch 137/188  Train Loss: 0.099, Acc: 0.969\n",
      "epoch:  2/300 batch 138/188  Train Loss: 0.074, Acc: 0.980\n",
      "epoch:  2/300 batch 139/188  Train Loss: 0.119, Acc: 0.969\n",
      "epoch:  2/300 batch 140/188  Train Loss: 0.131, Acc: 0.961\n",
      "epoch:  2/300 batch 141/188  Train Loss: 0.077, Acc: 0.977\n",
      "epoch:  2/300 batch 142/188  Train Loss: 0.145, Acc: 0.965\n",
      "epoch:  2/300 batch 143/188  Train Loss: 0.108, Acc: 0.969\n",
      "epoch:  2/300 batch 144/188  Train Loss: 0.088, Acc: 0.973\n",
      "epoch:  2/300 batch 145/188  Train Loss: 0.093, Acc: 0.977\n",
      "epoch:  2/300 batch 146/188  Train Loss: 0.097, Acc: 0.977\n",
      "epoch:  2/300 batch 147/188  Train Loss: 0.081, Acc: 0.973\n",
      "epoch:  2/300 batch 148/188  Train Loss: 0.073, Acc: 0.977\n",
      "epoch:  2/300 batch 149/188  Train Loss: 0.088, Acc: 0.973\n",
      "epoch:  2/300 batch 150/188  Train Loss: 0.094, Acc: 0.969\n",
      "epoch:  2/300 batch 151/188  Train Loss: 0.085, Acc: 0.973\n",
      "epoch:  2/300 batch 152/188  Train Loss: 0.201, Acc: 0.953\n",
      "epoch:  2/300 batch 153/188  Train Loss: 0.161, Acc: 0.949\n",
      "epoch:  2/300 batch 154/188  Train Loss: 0.192, Acc: 0.949\n",
      "epoch:  2/300 batch 155/188  Train Loss: 0.075, Acc: 0.980\n",
      "epoch:  2/300 batch 156/188  Train Loss: 0.122, Acc: 0.957\n",
      "epoch:  2/300 batch 157/188  Train Loss: 0.080, Acc: 0.973\n",
      "epoch:  2/300 batch 158/188  Train Loss: 0.107, Acc: 0.973\n",
      "epoch:  2/300 batch 159/188  Train Loss: 0.113, Acc: 0.965\n",
      "epoch:  2/300 batch 160/188  Train Loss: 0.104, Acc: 0.973\n",
      "epoch:  2/300 batch 161/188  Train Loss: 0.104, Acc: 0.969\n",
      "epoch:  2/300 batch 162/188  Train Loss: 0.129, Acc: 0.969\n",
      "epoch:  2/300 batch 163/188  Train Loss: 0.129, Acc: 0.957\n",
      "epoch:  2/300 batch 164/188  Train Loss: 0.081, Acc: 0.984\n",
      "epoch:  2/300 batch 165/188  Train Loss: 0.088, Acc: 0.969\n",
      "epoch:  2/300 batch 166/188  Train Loss: 0.085, Acc: 0.965\n",
      "epoch:  2/300 batch 167/188  Train Loss: 0.112, Acc: 0.973\n",
      "epoch:  2/300 batch 168/188  Train Loss: 0.097, Acc: 0.973\n",
      "epoch:  2/300 batch 169/188  Train Loss: 0.110, Acc: 0.977\n",
      "epoch:  2/300 batch 170/188  Train Loss: 0.079, Acc: 0.969\n",
      "epoch:  2/300 batch 171/188  Train Loss: 0.143, Acc: 0.961\n",
      "epoch:  2/300 batch 172/188  Train Loss: 0.114, Acc: 0.949\n",
      "epoch:  2/300 batch 173/188  Train Loss: 0.081, Acc: 0.973\n",
      "epoch:  2/300 batch 174/188  Train Loss: 0.173, Acc: 0.957\n",
      "epoch:  2/300 batch 175/188  Train Loss: 0.140, Acc: 0.949\n",
      "epoch:  2/300 batch 176/188  Train Loss: 0.070, Acc: 0.977\n",
      "epoch:  2/300 batch 177/188  Train Loss: 0.049, Acc: 0.996\n",
      "epoch:  2/300 batch 178/188  Train Loss: 0.185, Acc: 0.930\n",
      "epoch:  2/300 batch 179/188  Train Loss: 0.110, Acc: 0.965\n",
      "epoch:  2/300 batch 180/188  Train Loss: 0.100, Acc: 0.973\n",
      "epoch:  2/300 batch 181/188  Train Loss: 0.076, Acc: 0.973\n",
      "epoch:  2/300 batch 182/188  Train Loss: 0.054, Acc: 0.992\n",
      "epoch:  2/300 batch 183/188  Train Loss: 0.099, Acc: 0.969\n",
      "epoch:  2/300 batch 184/188  Train Loss: 0.125, Acc: 0.969\n",
      "epoch:  2/300 batch 185/188  Train Loss: 0.107, Acc: 0.949\n",
      "epoch:  2/300 batch 186/188  Train Loss: 0.144, Acc: 0.949\n",
      "epoch:  2/300 batch 187/188  Train Loss: 0.047, Acc: 0.984\n",
      "Train Loss: 0.098589, Acc: 0.971\n",
      "Val Loss: 0.086768, Acc: 0.974\n",
      "epoch:  3/300 batch   0/188  Train Loss: 0.052, Acc: 0.996\n",
      "epoch:  3/300 batch   1/188  Train Loss: 0.078, Acc: 0.977\n",
      "epoch:  3/300 batch   2/188  Train Loss: 0.133, Acc: 0.961\n",
      "epoch:  3/300 batch   3/188  Train Loss: 0.091, Acc: 0.977\n",
      "epoch:  3/300 batch   4/188  Train Loss: 0.100, Acc: 0.969\n",
      "epoch:  3/300 batch   5/188  Train Loss: 0.098, Acc: 0.961\n",
      "epoch:  3/300 batch   6/188  Train Loss: 0.058, Acc: 0.980\n",
      "epoch:  3/300 batch   7/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch:  3/300 batch   8/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch:  3/300 batch   9/188  Train Loss: 0.159, Acc: 0.965\n",
      "epoch:  3/300 batch  10/188  Train Loss: 0.118, Acc: 0.953\n",
      "epoch:  3/300 batch  11/188  Train Loss: 0.064, Acc: 0.984\n",
      "epoch:  3/300 batch  12/188  Train Loss: 0.067, Acc: 0.984\n",
      "epoch:  3/300 batch  13/188  Train Loss: 0.064, Acc: 0.977\n",
      "epoch:  3/300 batch  14/188  Train Loss: 0.114, Acc: 0.973\n",
      "epoch:  3/300 batch  15/188  Train Loss: 0.098, Acc: 0.969\n",
      "epoch:  3/300 batch  16/188  Train Loss: 0.128, Acc: 0.953\n",
      "epoch:  3/300 batch  17/188  Train Loss: 0.147, Acc: 0.965\n",
      "epoch:  3/300 batch  18/188  Train Loss: 0.084, Acc: 0.977\n",
      "epoch:  3/300 batch  19/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch:  3/300 batch  20/188  Train Loss: 0.098, Acc: 0.980\n",
      "epoch:  3/300 batch  21/188  Train Loss: 0.108, Acc: 0.973\n",
      "epoch:  3/300 batch  22/188  Train Loss: 0.078, Acc: 0.969\n",
      "epoch:  3/300 batch  23/188  Train Loss: 0.103, Acc: 0.965\n",
      "epoch:  3/300 batch  24/188  Train Loss: 0.115, Acc: 0.973\n",
      "epoch:  3/300 batch  25/188  Train Loss: 0.090, Acc: 0.969\n",
      "epoch:  3/300 batch  26/188  Train Loss: 0.106, Acc: 0.977\n",
      "epoch:  3/300 batch  27/188  Train Loss: 0.077, Acc: 0.973\n",
      "epoch:  3/300 batch  28/188  Train Loss: 0.087, Acc: 0.973\n",
      "epoch:  3/300 batch  29/188  Train Loss: 0.084, Acc: 0.977\n",
      "epoch:  3/300 batch  30/188  Train Loss: 0.064, Acc: 0.984\n",
      "epoch:  3/300 batch  31/188  Train Loss: 0.098, Acc: 0.980\n",
      "epoch:  3/300 batch  32/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch:  3/300 batch  33/188  Train Loss: 0.147, Acc: 0.953\n",
      "epoch:  3/300 batch  34/188  Train Loss: 0.122, Acc: 0.965\n",
      "epoch:  3/300 batch  35/188  Train Loss: 0.102, Acc: 0.957\n",
      "epoch:  3/300 batch  36/188  Train Loss: 0.064, Acc: 0.988\n",
      "epoch:  3/300 batch  37/188  Train Loss: 0.114, Acc: 0.961\n",
      "epoch:  3/300 batch  38/188  Train Loss: 0.077, Acc: 0.980\n",
      "epoch:  3/300 batch  39/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch:  3/300 batch  40/188  Train Loss: 0.128, Acc: 0.969\n",
      "epoch:  3/300 batch  41/188  Train Loss: 0.099, Acc: 0.969\n",
      "epoch:  3/300 batch  42/188  Train Loss: 0.077, Acc: 0.977\n",
      "epoch:  3/300 batch  43/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch:  3/300 batch  44/188  Train Loss: 0.100, Acc: 0.957\n",
      "epoch:  3/300 batch  45/188  Train Loss: 0.151, Acc: 0.953\n",
      "epoch:  3/300 batch  46/188  Train Loss: 0.113, Acc: 0.949\n",
      "epoch:  3/300 batch  47/188  Train Loss: 0.088, Acc: 0.969\n",
      "epoch:  3/300 batch  48/188  Train Loss: 0.090, Acc: 0.973\n",
      "epoch:  3/300 batch  49/188  Train Loss: 0.099, Acc: 0.965\n",
      "epoch:  3/300 batch  50/188  Train Loss: 0.113, Acc: 0.973\n",
      "epoch:  3/300 batch  51/188  Train Loss: 0.146, Acc: 0.957\n",
      "epoch:  3/300 batch  52/188  Train Loss: 0.065, Acc: 0.977\n",
      "epoch:  3/300 batch  53/188  Train Loss: 0.110, Acc: 0.969\n",
      "epoch:  3/300 batch  54/188  Train Loss: 0.074, Acc: 0.977\n",
      "epoch:  3/300 batch  55/188  Train Loss: 0.065, Acc: 0.969\n",
      "epoch:  3/300 batch  56/188  Train Loss: 0.104, Acc: 0.969\n",
      "epoch:  3/300 batch  57/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch:  3/300 batch  58/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch:  3/300 batch  59/188  Train Loss: 0.089, Acc: 0.973\n",
      "epoch:  3/300 batch  60/188  Train Loss: 0.066, Acc: 0.977\n",
      "epoch:  3/300 batch  61/188  Train Loss: 0.067, Acc: 0.984\n",
      "epoch:  3/300 batch  62/188  Train Loss: 0.087, Acc: 0.969\n",
      "epoch:  3/300 batch  63/188  Train Loss: 0.077, Acc: 0.984\n",
      "epoch:  3/300 batch  64/188  Train Loss: 0.108, Acc: 0.965\n",
      "epoch:  3/300 batch  65/188  Train Loss: 0.122, Acc: 0.953\n",
      "epoch:  3/300 batch  66/188  Train Loss: 0.077, Acc: 0.977\n",
      "epoch:  3/300 batch  67/188  Train Loss: 0.051, Acc: 0.980\n",
      "epoch:  3/300 batch  68/188  Train Loss: 0.094, Acc: 0.980\n",
      "epoch:  3/300 batch  69/188  Train Loss: 0.161, Acc: 0.957\n",
      "epoch:  3/300 batch  70/188  Train Loss: 0.137, Acc: 0.961\n",
      "epoch:  3/300 batch  71/188  Train Loss: 0.098, Acc: 0.973\n",
      "epoch:  3/300 batch  72/188  Train Loss: 0.108, Acc: 0.973\n",
      "epoch:  3/300 batch  73/188  Train Loss: 0.137, Acc: 0.961\n",
      "epoch:  3/300 batch  74/188  Train Loss: 0.052, Acc: 0.980\n",
      "epoch:  3/300 batch  75/188  Train Loss: 0.179, Acc: 0.941\n",
      "epoch:  3/300 batch  76/188  Train Loss: 0.134, Acc: 0.961\n",
      "epoch:  3/300 batch  77/188  Train Loss: 0.078, Acc: 0.980\n",
      "epoch:  3/300 batch  78/188  Train Loss: 0.072, Acc: 0.984\n",
      "epoch:  3/300 batch  79/188  Train Loss: 0.067, Acc: 0.980\n",
      "epoch:  3/300 batch  80/188  Train Loss: 0.090, Acc: 0.977\n",
      "epoch:  3/300 batch  81/188  Train Loss: 0.087, Acc: 0.969\n",
      "epoch:  3/300 batch  82/188  Train Loss: 0.050, Acc: 0.996\n",
      "epoch:  3/300 batch  83/188  Train Loss: 0.086, Acc: 0.977\n",
      "epoch:  3/300 batch  84/188  Train Loss: 0.064, Acc: 0.980\n",
      "epoch:  3/300 batch  85/188  Train Loss: 0.079, Acc: 0.973\n",
      "epoch:  3/300 batch  86/188  Train Loss: 0.087, Acc: 0.977\n",
      "epoch:  3/300 batch  87/188  Train Loss: 0.075, Acc: 0.980\n",
      "epoch:  3/300 batch  88/188  Train Loss: 0.126, Acc: 0.969\n",
      "epoch:  3/300 batch  89/188  Train Loss: 0.095, Acc: 0.965\n",
      "epoch:  3/300 batch  90/188  Train Loss: 0.091, Acc: 0.980\n",
      "epoch:  3/300 batch  91/188  Train Loss: 0.083, Acc: 0.973\n",
      "epoch:  3/300 batch  92/188  Train Loss: 0.087, Acc: 0.977\n",
      "epoch:  3/300 batch  93/188  Train Loss: 0.101, Acc: 0.969\n",
      "epoch:  3/300 batch  94/188  Train Loss: 0.120, Acc: 0.973\n",
      "epoch:  3/300 batch  95/188  Train Loss: 0.135, Acc: 0.957\n",
      "epoch:  3/300 batch  96/188  Train Loss: 0.087, Acc: 0.977\n",
      "epoch:  3/300 batch  97/188  Train Loss: 0.071, Acc: 0.984\n",
      "epoch:  3/300 batch  98/188  Train Loss: 0.092, Acc: 0.965\n",
      "epoch:  3/300 batch  99/188  Train Loss: 0.080, Acc: 0.973\n",
      "epoch:  3/300 batch 100/188  Train Loss: 0.111, Acc: 0.965\n",
      "epoch:  3/300 batch 101/188  Train Loss: 0.096, Acc: 0.961\n",
      "epoch:  3/300 batch 102/188  Train Loss: 0.065, Acc: 0.980\n",
      "epoch:  3/300 batch 103/188  Train Loss: 0.087, Acc: 0.984\n",
      "epoch:  3/300 batch 104/188  Train Loss: 0.171, Acc: 0.965\n",
      "epoch:  3/300 batch 105/188  Train Loss: 0.062, Acc: 0.988\n",
      "epoch:  3/300 batch 106/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch:  3/300 batch 107/188  Train Loss: 0.090, Acc: 0.977\n",
      "epoch:  3/300 batch 108/188  Train Loss: 0.082, Acc: 0.980\n",
      "epoch:  3/300 batch 109/188  Train Loss: 0.118, Acc: 0.977\n",
      "epoch:  3/300 batch 110/188  Train Loss: 0.145, Acc: 0.961\n",
      "epoch:  3/300 batch 111/188  Train Loss: 0.120, Acc: 0.965\n",
      "epoch:  3/300 batch 112/188  Train Loss: 0.082, Acc: 0.980\n",
      "epoch:  3/300 batch 113/188  Train Loss: 0.106, Acc: 0.965\n",
      "epoch:  3/300 batch 114/188  Train Loss: 0.116, Acc: 0.973\n",
      "epoch:  3/300 batch 115/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch:  3/300 batch 116/188  Train Loss: 0.105, Acc: 0.969\n",
      "epoch:  3/300 batch 117/188  Train Loss: 0.076, Acc: 0.969\n",
      "epoch:  3/300 batch 118/188  Train Loss: 0.056, Acc: 0.980\n",
      "epoch:  3/300 batch 119/188  Train Loss: 0.098, Acc: 0.961\n",
      "epoch:  3/300 batch 120/188  Train Loss: 0.108, Acc: 0.965\n",
      "epoch:  3/300 batch 121/188  Train Loss: 0.117, Acc: 0.980\n",
      "epoch:  3/300 batch 122/188  Train Loss: 0.107, Acc: 0.961\n",
      "epoch:  3/300 batch 123/188  Train Loss: 0.072, Acc: 0.977\n",
      "epoch:  3/300 batch 124/188  Train Loss: 0.115, Acc: 0.961\n",
      "epoch:  3/300 batch 125/188  Train Loss: 0.080, Acc: 0.980\n",
      "epoch:  3/300 batch 126/188  Train Loss: 0.080, Acc: 0.973\n",
      "epoch:  3/300 batch 127/188  Train Loss: 0.081, Acc: 0.969\n",
      "epoch:  3/300 batch 128/188  Train Loss: 0.077, Acc: 0.969\n",
      "epoch:  3/300 batch 129/188  Train Loss: 0.063, Acc: 0.980\n",
      "epoch:  3/300 batch 130/188  Train Loss: 0.072, Acc: 0.977\n",
      "epoch:  3/300 batch 131/188  Train Loss: 0.122, Acc: 0.949\n",
      "epoch:  3/300 batch 132/188  Train Loss: 0.070, Acc: 0.973\n",
      "epoch:  3/300 batch 133/188  Train Loss: 0.080, Acc: 0.969\n",
      "epoch:  3/300 batch 134/188  Train Loss: 0.061, Acc: 0.977\n",
      "epoch:  3/300 batch 135/188  Train Loss: 0.066, Acc: 0.980\n",
      "epoch:  3/300 batch 136/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch:  3/300 batch 137/188  Train Loss: 0.156, Acc: 0.953\n",
      "epoch:  3/300 batch 138/188  Train Loss: 0.084, Acc: 0.977\n",
      "epoch:  3/300 batch 139/188  Train Loss: 0.107, Acc: 0.961\n",
      "epoch:  3/300 batch 140/188  Train Loss: 0.102, Acc: 0.973\n",
      "epoch:  3/300 batch 141/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch:  3/300 batch 142/188  Train Loss: 0.115, Acc: 0.965\n",
      "epoch:  3/300 batch 143/188  Train Loss: 0.099, Acc: 0.969\n",
      "epoch:  3/300 batch 144/188  Train Loss: 0.082, Acc: 0.977\n",
      "epoch:  3/300 batch 145/188  Train Loss: 0.151, Acc: 0.953\n",
      "epoch:  3/300 batch 146/188  Train Loss: 0.096, Acc: 0.977\n",
      "epoch:  3/300 batch 147/188  Train Loss: 0.069, Acc: 0.977\n",
      "epoch:  3/300 batch 148/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch:  3/300 batch 149/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch:  3/300 batch 150/188  Train Loss: 0.084, Acc: 0.977\n",
      "epoch:  3/300 batch 151/188  Train Loss: 0.062, Acc: 0.980\n",
      "epoch:  3/300 batch 152/188  Train Loss: 0.109, Acc: 0.969\n",
      "epoch:  3/300 batch 153/188  Train Loss: 0.081, Acc: 0.984\n",
      "epoch:  3/300 batch 154/188  Train Loss: 0.072, Acc: 0.973\n",
      "epoch:  3/300 batch 155/188  Train Loss: 0.090, Acc: 0.969\n",
      "epoch:  3/300 batch 156/188  Train Loss: 0.086, Acc: 0.965\n",
      "epoch:  3/300 batch 157/188  Train Loss: 0.097, Acc: 0.969\n",
      "epoch:  3/300 batch 158/188  Train Loss: 0.118, Acc: 0.973\n",
      "epoch:  3/300 batch 159/188  Train Loss: 0.070, Acc: 0.988\n",
      "epoch:  3/300 batch 160/188  Train Loss: 0.063, Acc: 0.984\n",
      "epoch:  3/300 batch 161/188  Train Loss: 0.099, Acc: 0.977\n",
      "epoch:  3/300 batch 162/188  Train Loss: 0.080, Acc: 0.977\n",
      "epoch:  3/300 batch 163/188  Train Loss: 0.104, Acc: 0.965\n",
      "epoch:  3/300 batch 164/188  Train Loss: 0.108, Acc: 0.953\n",
      "epoch:  3/300 batch 165/188  Train Loss: 0.094, Acc: 0.969\n",
      "epoch:  3/300 batch 166/188  Train Loss: 0.142, Acc: 0.965\n",
      "epoch:  3/300 batch 167/188  Train Loss: 0.113, Acc: 0.980\n",
      "epoch:  3/300 batch 168/188  Train Loss: 0.061, Acc: 0.996\n",
      "epoch:  3/300 batch 169/188  Train Loss: 0.122, Acc: 0.969\n",
      "epoch:  3/300 batch 170/188  Train Loss: 0.093, Acc: 0.965\n",
      "epoch:  3/300 batch 171/188  Train Loss: 0.105, Acc: 0.965\n",
      "epoch:  3/300 batch 172/188  Train Loss: 0.110, Acc: 0.957\n",
      "epoch:  3/300 batch 173/188  Train Loss: 0.115, Acc: 0.961\n",
      "epoch:  3/300 batch 174/188  Train Loss: 0.070, Acc: 0.984\n",
      "epoch:  3/300 batch 175/188  Train Loss: 0.061, Acc: 0.984\n",
      "epoch:  3/300 batch 176/188  Train Loss: 0.059, Acc: 0.988\n",
      "epoch:  3/300 batch 177/188  Train Loss: 0.134, Acc: 0.961\n",
      "epoch:  3/300 batch 178/188  Train Loss: 0.101, Acc: 0.949\n",
      "epoch:  3/300 batch 179/188  Train Loss: 0.113, Acc: 0.969\n",
      "epoch:  3/300 batch 180/188  Train Loss: 0.083, Acc: 0.969\n",
      "epoch:  3/300 batch 181/188  Train Loss: 0.089, Acc: 0.973\n",
      "epoch:  3/300 batch 182/188  Train Loss: 0.117, Acc: 0.973\n",
      "epoch:  3/300 batch 183/188  Train Loss: 0.097, Acc: 0.965\n",
      "epoch:  3/300 batch 184/188  Train Loss: 0.093, Acc: 0.973\n",
      "epoch:  3/300 batch 185/188  Train Loss: 0.129, Acc: 0.973\n",
      "epoch:  3/300 batch 186/188  Train Loss: 0.101, Acc: 0.969\n",
      "epoch:  3/300 batch 187/188  Train Loss: 0.190, Acc: 0.922\n",
      "Train Loss: 0.093042, Acc: 0.972\n",
      "Val Loss: 0.094320, Acc: 0.973\n",
      "epoch:  4/300 batch   0/188  Train Loss: 0.076, Acc: 0.980\n",
      "epoch:  4/300 batch   1/188  Train Loss: 0.090, Acc: 0.965\n",
      "epoch:  4/300 batch   2/188  Train Loss: 0.062, Acc: 0.988\n",
      "epoch:  4/300 batch   3/188  Train Loss: 0.080, Acc: 0.977\n",
      "epoch:  4/300 batch   4/188  Train Loss: 0.085, Acc: 0.969\n",
      "epoch:  4/300 batch   5/188  Train Loss: 0.109, Acc: 0.961\n",
      "epoch:  4/300 batch   6/188  Train Loss: 0.101, Acc: 0.965\n",
      "epoch:  4/300 batch   7/188  Train Loss: 0.059, Acc: 0.980\n",
      "epoch:  4/300 batch   8/188  Train Loss: 0.121, Acc: 0.949\n",
      "epoch:  4/300 batch   9/188  Train Loss: 0.080, Acc: 0.977\n",
      "epoch:  4/300 batch  10/188  Train Loss: 0.091, Acc: 0.973\n",
      "epoch:  4/300 batch  11/188  Train Loss: 0.142, Acc: 0.949\n",
      "epoch:  4/300 batch  12/188  Train Loss: 0.104, Acc: 0.961\n",
      "epoch:  4/300 batch  13/188  Train Loss: 0.091, Acc: 0.965\n",
      "epoch:  4/300 batch  14/188  Train Loss: 0.092, Acc: 0.961\n",
      "epoch:  4/300 batch  15/188  Train Loss: 0.097, Acc: 0.973\n",
      "epoch:  4/300 batch  16/188  Train Loss: 0.053, Acc: 0.992\n",
      "epoch:  4/300 batch  17/188  Train Loss: 0.105, Acc: 0.969\n",
      "epoch:  4/300 batch  18/188  Train Loss: 0.036, Acc: 1.000\n",
      "epoch:  4/300 batch  19/188  Train Loss: 0.137, Acc: 0.961\n",
      "epoch:  4/300 batch  20/188  Train Loss: 0.095, Acc: 0.973\n",
      "epoch:  4/300 batch  21/188  Train Loss: 0.062, Acc: 0.984\n",
      "epoch:  4/300 batch  22/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch:  4/300 batch  23/188  Train Loss: 0.059, Acc: 0.984\n",
      "epoch:  4/300 batch  24/188  Train Loss: 0.060, Acc: 0.984\n",
      "epoch:  4/300 batch  25/188  Train Loss: 0.075, Acc: 0.973\n",
      "epoch:  4/300 batch  26/188  Train Loss: 0.080, Acc: 0.980\n",
      "epoch:  4/300 batch  27/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch:  4/300 batch  28/188  Train Loss: 0.122, Acc: 0.957\n",
      "epoch:  4/300 batch  29/188  Train Loss: 0.088, Acc: 0.980\n",
      "epoch:  4/300 batch  30/188  Train Loss: 0.176, Acc: 0.969\n",
      "epoch:  4/300 batch  31/188  Train Loss: 0.127, Acc: 0.973\n",
      "epoch:  4/300 batch  32/188  Train Loss: 0.125, Acc: 0.965\n",
      "epoch:  4/300 batch  33/188  Train Loss: 0.084, Acc: 0.984\n",
      "epoch:  4/300 batch  34/188  Train Loss: 0.065, Acc: 0.980\n",
      "epoch:  4/300 batch  35/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch:  4/300 batch  36/188  Train Loss: 0.100, Acc: 0.965\n",
      "epoch:  4/300 batch  37/188  Train Loss: 0.123, Acc: 0.969\n",
      "epoch:  4/300 batch  38/188  Train Loss: 0.102, Acc: 0.980\n",
      "epoch:  4/300 batch  39/188  Train Loss: 0.073, Acc: 0.973\n",
      "epoch:  4/300 batch  40/188  Train Loss: 0.119, Acc: 0.953\n",
      "epoch:  4/300 batch  41/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch:  4/300 batch  42/188  Train Loss: 0.088, Acc: 0.961\n",
      "epoch:  4/300 batch  43/188  Train Loss: 0.155, Acc: 0.957\n",
      "epoch:  4/300 batch  44/188  Train Loss: 0.149, Acc: 0.957\n",
      "epoch:  4/300 batch  45/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch:  4/300 batch  46/188  Train Loss: 0.097, Acc: 0.980\n",
      "epoch:  4/300 batch  47/188  Train Loss: 0.082, Acc: 0.977\n",
      "epoch:  4/300 batch  48/188  Train Loss: 0.111, Acc: 0.965\n",
      "epoch:  4/300 batch  49/188  Train Loss: 0.069, Acc: 0.965\n",
      "epoch:  4/300 batch  50/188  Train Loss: 0.104, Acc: 0.977\n",
      "epoch:  4/300 batch  51/188  Train Loss: 0.082, Acc: 0.973\n",
      "epoch:  4/300 batch  52/188  Train Loss: 0.066, Acc: 0.977\n",
      "epoch:  4/300 batch  53/188  Train Loss: 0.172, Acc: 0.953\n",
      "epoch:  4/300 batch  54/188  Train Loss: 0.033, Acc: 1.000\n",
      "epoch:  4/300 batch  55/188  Train Loss: 0.065, Acc: 0.977\n",
      "epoch:  4/300 batch  56/188  Train Loss: 0.073, Acc: 0.973\n",
      "epoch:  4/300 batch  57/188  Train Loss: 0.108, Acc: 0.965\n",
      "epoch:  4/300 batch  58/188  Train Loss: 0.181, Acc: 0.934\n",
      "epoch:  4/300 batch  59/188  Train Loss: 0.083, Acc: 0.977\n",
      "epoch:  4/300 batch  60/188  Train Loss: 0.107, Acc: 0.969\n",
      "epoch:  4/300 batch  61/188  Train Loss: 0.095, Acc: 0.973\n",
      "epoch:  4/300 batch  62/188  Train Loss: 0.103, Acc: 0.969\n",
      "epoch:  4/300 batch  63/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch:  4/300 batch  64/188  Train Loss: 0.085, Acc: 0.980\n",
      "epoch:  4/300 batch  65/188  Train Loss: 0.100, Acc: 0.961\n",
      "epoch:  4/300 batch  66/188  Train Loss: 0.102, Acc: 0.957\n",
      "epoch:  4/300 batch  67/188  Train Loss: 0.162, Acc: 0.949\n",
      "epoch:  4/300 batch  68/188  Train Loss: 0.067, Acc: 0.980\n",
      "epoch:  4/300 batch  69/188  Train Loss: 0.104, Acc: 0.973\n",
      "epoch:  4/300 batch  70/188  Train Loss: 0.062, Acc: 0.984\n",
      "epoch:  4/300 batch  71/188  Train Loss: 0.116, Acc: 0.965\n",
      "epoch:  4/300 batch  72/188  Train Loss: 0.122, Acc: 0.965\n",
      "epoch:  4/300 batch  73/188  Train Loss: 0.064, Acc: 0.973\n",
      "epoch:  4/300 batch  74/188  Train Loss: 0.100, Acc: 0.973\n",
      "epoch:  4/300 batch  75/188  Train Loss: 0.096, Acc: 0.973\n",
      "epoch:  4/300 batch  76/188  Train Loss: 0.068, Acc: 0.973\n",
      "epoch:  4/300 batch  77/188  Train Loss: 0.106, Acc: 0.969\n",
      "epoch:  4/300 batch  78/188  Train Loss: 0.101, Acc: 0.969\n",
      "epoch:  4/300 batch  79/188  Train Loss: 0.078, Acc: 0.980\n",
      "epoch:  4/300 batch  80/188  Train Loss: 0.108, Acc: 0.961\n",
      "epoch:  4/300 batch  81/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch:  4/300 batch  82/188  Train Loss: 0.077, Acc: 0.969\n",
      "epoch:  4/300 batch  83/188  Train Loss: 0.110, Acc: 0.969\n",
      "epoch:  4/300 batch  84/188  Train Loss: 0.067, Acc: 0.992\n",
      "epoch:  4/300 batch  85/188  Train Loss: 0.113, Acc: 0.977\n",
      "epoch:  4/300 batch  86/188  Train Loss: 0.079, Acc: 0.977\n",
      "epoch:  4/300 batch  87/188  Train Loss: 0.116, Acc: 0.977\n",
      "epoch:  4/300 batch  88/188  Train Loss: 0.056, Acc: 0.980\n",
      "epoch:  4/300 batch  89/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch:  4/300 batch  90/188  Train Loss: 0.069, Acc: 0.973\n",
      "epoch:  4/300 batch  91/188  Train Loss: 0.125, Acc: 0.965\n",
      "epoch:  4/300 batch  92/188  Train Loss: 0.077, Acc: 0.977\n",
      "epoch:  4/300 batch  93/188  Train Loss: 0.090, Acc: 0.977\n",
      "epoch:  4/300 batch  94/188  Train Loss: 0.066, Acc: 0.988\n",
      "epoch:  4/300 batch  95/188  Train Loss: 0.088, Acc: 0.973\n",
      "epoch:  4/300 batch  96/188  Train Loss: 0.071, Acc: 0.980\n",
      "epoch:  4/300 batch  97/188  Train Loss: 0.062, Acc: 0.973\n",
      "epoch:  4/300 batch  98/188  Train Loss: 0.081, Acc: 0.984\n",
      "epoch:  4/300 batch  99/188  Train Loss: 0.076, Acc: 0.977\n",
      "epoch:  4/300 batch 100/188  Train Loss: 0.064, Acc: 0.984\n",
      "epoch:  4/300 batch 101/188  Train Loss: 0.078, Acc: 0.980\n",
      "epoch:  4/300 batch 102/188  Train Loss: 0.125, Acc: 0.957\n",
      "epoch:  4/300 batch 103/188  Train Loss: 0.109, Acc: 0.973\n",
      "epoch:  4/300 batch 104/188  Train Loss: 0.075, Acc: 0.984\n",
      "epoch:  4/300 batch 105/188  Train Loss: 0.114, Acc: 0.961\n",
      "epoch:  4/300 batch 106/188  Train Loss: 0.094, Acc: 0.977\n",
      "epoch:  4/300 batch 107/188  Train Loss: 0.067, Acc: 0.977\n",
      "epoch:  4/300 batch 108/188  Train Loss: 0.104, Acc: 0.977\n",
      "epoch:  4/300 batch 109/188  Train Loss: 0.094, Acc: 0.953\n",
      "epoch:  4/300 batch 110/188  Train Loss: 0.086, Acc: 0.977\n",
      "epoch:  4/300 batch 111/188  Train Loss: 0.080, Acc: 0.984\n",
      "epoch:  4/300 batch 112/188  Train Loss: 0.069, Acc: 0.992\n",
      "epoch:  4/300 batch 113/188  Train Loss: 0.067, Acc: 0.984\n",
      "epoch:  4/300 batch 114/188  Train Loss: 0.111, Acc: 0.973\n",
      "epoch:  4/300 batch 115/188  Train Loss: 0.069, Acc: 0.980\n",
      "epoch:  4/300 batch 116/188  Train Loss: 0.136, Acc: 0.953\n",
      "epoch:  4/300 batch 117/188  Train Loss: 0.088, Acc: 0.977\n",
      "epoch:  4/300 batch 118/188  Train Loss: 0.123, Acc: 0.973\n",
      "epoch:  4/300 batch 119/188  Train Loss: 0.070, Acc: 0.980\n",
      "epoch:  4/300 batch 120/188  Train Loss: 0.127, Acc: 0.969\n",
      "epoch:  4/300 batch 121/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch:  4/300 batch 122/188  Train Loss: 0.075, Acc: 0.977\n",
      "epoch:  4/300 batch 123/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch:  4/300 batch 124/188  Train Loss: 0.063, Acc: 0.980\n",
      "epoch:  4/300 batch 125/188  Train Loss: 0.131, Acc: 0.961\n",
      "epoch:  4/300 batch 126/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch:  4/300 batch 127/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch:  4/300 batch 128/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch:  4/300 batch 129/188  Train Loss: 0.101, Acc: 0.957\n",
      "epoch:  4/300 batch 130/188  Train Loss: 0.126, Acc: 0.969\n",
      "epoch:  4/300 batch 131/188  Train Loss: 0.107, Acc: 0.961\n",
      "epoch:  4/300 batch 132/188  Train Loss: 0.085, Acc: 0.977\n",
      "epoch:  4/300 batch 133/188  Train Loss: 0.081, Acc: 0.980\n",
      "epoch:  4/300 batch 134/188  Train Loss: 0.111, Acc: 0.969\n",
      "epoch:  4/300 batch 135/188  Train Loss: 0.074, Acc: 0.977\n",
      "epoch:  4/300 batch 136/188  Train Loss: 0.121, Acc: 0.969\n",
      "epoch:  4/300 batch 137/188  Train Loss: 0.094, Acc: 0.965\n",
      "epoch:  4/300 batch 138/188  Train Loss: 0.068, Acc: 0.977\n",
      "epoch:  4/300 batch 139/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch:  4/300 batch 140/188  Train Loss: 0.088, Acc: 0.977\n",
      "epoch:  4/300 batch 141/188  Train Loss: 0.112, Acc: 0.965\n",
      "epoch:  4/300 batch 142/188  Train Loss: 0.111, Acc: 0.977\n",
      "epoch:  4/300 batch 143/188  Train Loss: 0.089, Acc: 0.977\n",
      "epoch:  4/300 batch 144/188  Train Loss: 0.082, Acc: 0.973\n",
      "epoch:  4/300 batch 145/188  Train Loss: 0.079, Acc: 0.984\n",
      "epoch:  4/300 batch 146/188  Train Loss: 0.113, Acc: 0.969\n",
      "epoch:  4/300 batch 147/188  Train Loss: 0.087, Acc: 0.977\n",
      "epoch:  4/300 batch 148/188  Train Loss: 0.066, Acc: 0.977\n",
      "epoch:  4/300 batch 149/188  Train Loss: 0.129, Acc: 0.953\n",
      "epoch:  4/300 batch 150/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch:  4/300 batch 151/188  Train Loss: 0.083, Acc: 0.977\n",
      "epoch:  4/300 batch 152/188  Train Loss: 0.071, Acc: 0.969\n",
      "epoch:  4/300 batch 153/188  Train Loss: 0.108, Acc: 0.945\n",
      "epoch:  4/300 batch 154/188  Train Loss: 0.138, Acc: 0.969\n",
      "epoch:  4/300 batch 155/188  Train Loss: 0.074, Acc: 0.977\n",
      "epoch:  4/300 batch 156/188  Train Loss: 0.070, Acc: 0.977\n",
      "epoch:  4/300 batch 157/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch:  4/300 batch 158/188  Train Loss: 0.146, Acc: 0.965\n",
      "epoch:  4/300 batch 159/188  Train Loss: 0.079, Acc: 0.973\n",
      "epoch:  4/300 batch 160/188  Train Loss: 0.082, Acc: 0.980\n",
      "epoch:  4/300 batch 161/188  Train Loss: 0.115, Acc: 0.969\n",
      "epoch:  4/300 batch 162/188  Train Loss: 0.099, Acc: 0.969\n",
      "epoch:  4/300 batch 163/188  Train Loss: 0.128, Acc: 0.953\n",
      "epoch:  4/300 batch 164/188  Train Loss: 0.131, Acc: 0.973\n",
      "epoch:  4/300 batch 165/188  Train Loss: 0.059, Acc: 0.988\n",
      "epoch:  4/300 batch 166/188  Train Loss: 0.082, Acc: 0.980\n",
      "epoch:  4/300 batch 167/188  Train Loss: 0.067, Acc: 0.980\n",
      "epoch:  4/300 batch 168/188  Train Loss: 0.119, Acc: 0.969\n",
      "epoch:  4/300 batch 169/188  Train Loss: 0.082, Acc: 0.965\n",
      "epoch:  4/300 batch 170/188  Train Loss: 0.074, Acc: 0.973\n",
      "epoch:  4/300 batch 171/188  Train Loss: 0.126, Acc: 0.953\n",
      "epoch:  4/300 batch 172/188  Train Loss: 0.115, Acc: 0.965\n",
      "epoch:  4/300 batch 173/188  Train Loss: 0.156, Acc: 0.949\n",
      "epoch:  4/300 batch 174/188  Train Loss: 0.061, Acc: 0.984\n",
      "epoch:  4/300 batch 175/188  Train Loss: 0.058, Acc: 0.977\n",
      "epoch:  4/300 batch 176/188  Train Loss: 0.125, Acc: 0.961\n",
      "epoch:  4/300 batch 177/188  Train Loss: 0.099, Acc: 0.977\n",
      "epoch:  4/300 batch 178/188  Train Loss: 0.070, Acc: 0.973\n",
      "epoch:  4/300 batch 179/188  Train Loss: 0.076, Acc: 0.969\n",
      "epoch:  4/300 batch 180/188  Train Loss: 0.077, Acc: 0.965\n",
      "epoch:  4/300 batch 181/188  Train Loss: 0.117, Acc: 0.973\n",
      "epoch:  4/300 batch 182/188  Train Loss: 0.074, Acc: 0.969\n",
      "epoch:  4/300 batch 183/188  Train Loss: 0.074, Acc: 0.980\n",
      "epoch:  4/300 batch 184/188  Train Loss: 0.111, Acc: 0.965\n",
      "epoch:  4/300 batch 185/188  Train Loss: 0.063, Acc: 0.977\n",
      "epoch:  4/300 batch 186/188  Train Loss: 0.080, Acc: 0.980\n",
      "epoch:  4/300 batch 187/188  Train Loss: 0.096, Acc: 0.961\n",
      "Train Loss: 0.090006, Acc: 0.973\n",
      "Val Loss: 0.090441, Acc: 0.973\n",
      "epoch:  5/300 batch   0/188  Train Loss: 0.065, Acc: 0.977\n",
      "epoch:  5/300 batch   1/188  Train Loss: 0.068, Acc: 0.984\n",
      "epoch:  5/300 batch   2/188  Train Loss: 0.107, Acc: 0.965\n",
      "epoch:  5/300 batch   3/188  Train Loss: 0.063, Acc: 0.977\n",
      "epoch:  5/300 batch   4/188  Train Loss: 0.108, Acc: 0.973\n",
      "epoch:  5/300 batch   5/188  Train Loss: 0.082, Acc: 0.969\n",
      "epoch:  5/300 batch   6/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch:  5/300 batch   7/188  Train Loss: 0.094, Acc: 0.969\n",
      "epoch:  5/300 batch   8/188  Train Loss: 0.064, Acc: 0.973\n",
      "epoch:  5/300 batch   9/188  Train Loss: 0.065, Acc: 0.977\n",
      "epoch:  5/300 batch  10/188  Train Loss: 0.082, Acc: 0.984\n",
      "epoch:  5/300 batch  11/188  Train Loss: 0.057, Acc: 0.988\n",
      "epoch:  5/300 batch  12/188  Train Loss: 0.074, Acc: 0.984\n",
      "epoch:  5/300 batch  13/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch:  5/300 batch  14/188  Train Loss: 0.083, Acc: 0.973\n",
      "epoch:  5/300 batch  15/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch:  5/300 batch  16/188  Train Loss: 0.101, Acc: 0.973\n",
      "epoch:  5/300 batch  17/188  Train Loss: 0.095, Acc: 0.973\n",
      "epoch:  5/300 batch  18/188  Train Loss: 0.076, Acc: 0.973\n",
      "epoch:  5/300 batch  19/188  Train Loss: 0.078, Acc: 0.977\n",
      "epoch:  5/300 batch  20/188  Train Loss: 0.075, Acc: 0.984\n",
      "epoch:  5/300 batch  21/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch:  5/300 batch  22/188  Train Loss: 0.076, Acc: 0.973\n",
      "epoch:  5/300 batch  23/188  Train Loss: 0.055, Acc: 0.973\n",
      "epoch:  5/300 batch  24/188  Train Loss: 0.074, Acc: 0.980\n",
      "epoch:  5/300 batch  25/188  Train Loss: 0.061, Acc: 0.988\n",
      "epoch:  5/300 batch  26/188  Train Loss: 0.131, Acc: 0.949\n",
      "epoch:  5/300 batch  27/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch:  5/300 batch  28/188  Train Loss: 0.073, Acc: 0.988\n",
      "epoch:  5/300 batch  29/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch:  5/300 batch  30/188  Train Loss: 0.133, Acc: 0.965\n",
      "epoch:  5/300 batch  31/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch:  5/300 batch  32/188  Train Loss: 0.059, Acc: 0.980\n",
      "epoch:  5/300 batch  33/188  Train Loss: 0.053, Acc: 0.980\n",
      "epoch:  5/300 batch  34/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch:  5/300 batch  35/188  Train Loss: 0.058, Acc: 0.992\n",
      "epoch:  5/300 batch  36/188  Train Loss: 0.090, Acc: 0.973\n",
      "epoch:  5/300 batch  37/188  Train Loss: 0.084, Acc: 0.973\n",
      "epoch:  5/300 batch  38/188  Train Loss: 0.097, Acc: 0.969\n",
      "epoch:  5/300 batch  39/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch:  5/300 batch  40/188  Train Loss: 0.104, Acc: 0.977\n",
      "epoch:  5/300 batch  41/188  Train Loss: 0.137, Acc: 0.969\n",
      "epoch:  5/300 batch  42/188  Train Loss: 0.098, Acc: 0.977\n",
      "epoch:  5/300 batch  43/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch:  5/300 batch  44/188  Train Loss: 0.078, Acc: 0.973\n",
      "epoch:  5/300 batch  45/188  Train Loss: 0.060, Acc: 0.980\n",
      "epoch:  5/300 batch  46/188  Train Loss: 0.074, Acc: 0.969\n",
      "epoch:  5/300 batch  47/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch:  5/300 batch  48/188  Train Loss: 0.067, Acc: 0.988\n",
      "epoch:  5/300 batch  49/188  Train Loss: 0.076, Acc: 0.973\n",
      "epoch:  5/300 batch  50/188  Train Loss: 0.075, Acc: 0.980\n",
      "epoch:  5/300 batch  51/188  Train Loss: 0.101, Acc: 0.965\n",
      "epoch:  5/300 batch  52/188  Train Loss: 0.066, Acc: 0.980\n",
      "epoch:  5/300 batch  53/188  Train Loss: 0.064, Acc: 0.984\n",
      "epoch:  5/300 batch  54/188  Train Loss: 0.105, Acc: 0.984\n",
      "epoch:  5/300 batch  55/188  Train Loss: 0.082, Acc: 0.988\n",
      "epoch:  5/300 batch  56/188  Train Loss: 0.136, Acc: 0.969\n",
      "epoch:  5/300 batch  57/188  Train Loss: 0.061, Acc: 0.984\n",
      "epoch:  5/300 batch  58/188  Train Loss: 0.088, Acc: 0.961\n",
      "epoch:  5/300 batch  59/188  Train Loss: 0.103, Acc: 0.961\n",
      "epoch:  5/300 batch  60/188  Train Loss: 0.135, Acc: 0.953\n",
      "epoch:  5/300 batch  61/188  Train Loss: 0.113, Acc: 0.969\n",
      "epoch:  5/300 batch  62/188  Train Loss: 0.070, Acc: 0.980\n",
      "epoch:  5/300 batch  63/188  Train Loss: 0.065, Acc: 0.980\n",
      "epoch:  5/300 batch  64/188  Train Loss: 0.075, Acc: 0.980\n",
      "epoch:  5/300 batch  65/188  Train Loss: 0.081, Acc: 0.980\n",
      "epoch:  5/300 batch  66/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch:  5/300 batch  67/188  Train Loss: 0.124, Acc: 0.965\n",
      "epoch:  5/300 batch  68/188  Train Loss: 0.140, Acc: 0.953\n",
      "epoch:  5/300 batch  69/188  Train Loss: 0.115, Acc: 0.973\n",
      "epoch:  5/300 batch  70/188  Train Loss: 0.057, Acc: 0.988\n",
      "epoch:  5/300 batch  71/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch:  5/300 batch  72/188  Train Loss: 0.088, Acc: 0.977\n",
      "epoch:  5/300 batch  73/188  Train Loss: 0.084, Acc: 0.965\n",
      "epoch:  5/300 batch  74/188  Train Loss: 0.103, Acc: 0.973\n",
      "epoch:  5/300 batch  75/188  Train Loss: 0.085, Acc: 0.973\n",
      "epoch:  5/300 batch  76/188  Train Loss: 0.101, Acc: 0.973\n",
      "epoch:  5/300 batch  77/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch:  5/300 batch  78/188  Train Loss: 0.079, Acc: 0.969\n",
      "epoch:  5/300 batch  79/188  Train Loss: 0.063, Acc: 0.977\n",
      "epoch:  5/300 batch  80/188  Train Loss: 0.069, Acc: 0.988\n",
      "epoch:  5/300 batch  81/188  Train Loss: 0.071, Acc: 0.980\n",
      "epoch:  5/300 batch  82/188  Train Loss: 0.073, Acc: 0.980\n",
      "epoch:  5/300 batch  83/188  Train Loss: 0.104, Acc: 0.969\n",
      "epoch:  5/300 batch  84/188  Train Loss: 0.109, Acc: 0.969\n",
      "epoch:  5/300 batch  85/188  Train Loss: 0.090, Acc: 0.973\n",
      "epoch:  5/300 batch  86/188  Train Loss: 0.061, Acc: 0.984\n",
      "epoch:  5/300 batch  87/188  Train Loss: 0.059, Acc: 0.992\n",
      "epoch:  5/300 batch  88/188  Train Loss: 0.067, Acc: 0.977\n",
      "epoch:  5/300 batch  89/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch:  5/300 batch  90/188  Train Loss: 0.068, Acc: 0.973\n",
      "epoch:  5/300 batch  91/188  Train Loss: 0.059, Acc: 0.984\n",
      "epoch:  5/300 batch  92/188  Train Loss: 0.052, Acc: 0.977\n",
      "epoch:  5/300 batch  93/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch:  5/300 batch  94/188  Train Loss: 0.117, Acc: 0.965\n",
      "epoch:  5/300 batch  95/188  Train Loss: 0.097, Acc: 0.980\n",
      "epoch:  5/300 batch  96/188  Train Loss: 0.090, Acc: 0.969\n",
      "epoch:  5/300 batch  97/188  Train Loss: 0.121, Acc: 0.953\n",
      "epoch:  5/300 batch  98/188  Train Loss: 0.091, Acc: 0.969\n",
      "epoch:  5/300 batch  99/188  Train Loss: 0.056, Acc: 0.977\n",
      "epoch:  5/300 batch 100/188  Train Loss: 0.065, Acc: 0.977\n",
      "epoch:  5/300 batch 101/188  Train Loss: 0.082, Acc: 0.977\n",
      "epoch:  5/300 batch 102/188  Train Loss: 0.083, Acc: 0.973\n",
      "epoch:  5/300 batch 103/188  Train Loss: 0.073, Acc: 0.973\n",
      "epoch:  5/300 batch 104/188  Train Loss: 0.101, Acc: 0.973\n",
      "epoch:  5/300 batch 105/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch:  5/300 batch 106/188  Train Loss: 0.076, Acc: 0.977\n",
      "epoch:  5/300 batch 107/188  Train Loss: 0.063, Acc: 0.988\n",
      "epoch:  5/300 batch 108/188  Train Loss: 0.067, Acc: 0.973\n",
      "epoch:  5/300 batch 109/188  Train Loss: 0.082, Acc: 0.977\n",
      "epoch:  5/300 batch 110/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch:  5/300 batch 111/188  Train Loss: 0.117, Acc: 0.961\n",
      "epoch:  5/300 batch 112/188  Train Loss: 0.141, Acc: 0.961\n",
      "epoch:  5/300 batch 113/188  Train Loss: 0.181, Acc: 0.945\n",
      "epoch:  5/300 batch 114/188  Train Loss: 0.073, Acc: 0.980\n",
      "epoch:  5/300 batch 115/188  Train Loss: 0.100, Acc: 0.969\n",
      "epoch:  5/300 batch 116/188  Train Loss: 0.065, Acc: 0.984\n",
      "epoch:  5/300 batch 117/188  Train Loss: 0.147, Acc: 0.965\n",
      "epoch:  5/300 batch 118/188  Train Loss: 0.115, Acc: 0.977\n",
      "epoch:  5/300 batch 119/188  Train Loss: 0.081, Acc: 0.965\n",
      "epoch:  5/300 batch 120/188  Train Loss: 0.137, Acc: 0.961\n",
      "epoch:  5/300 batch 121/188  Train Loss: 0.091, Acc: 0.969\n",
      "epoch:  5/300 batch 122/188  Train Loss: 0.165, Acc: 0.953\n",
      "epoch:  5/300 batch 123/188  Train Loss: 0.133, Acc: 0.957\n",
      "epoch:  5/300 batch 124/188  Train Loss: 0.090, Acc: 0.969\n",
      "epoch:  5/300 batch 125/188  Train Loss: 0.106, Acc: 0.973\n",
      "epoch:  5/300 batch 126/188  Train Loss: 0.115, Acc: 0.953\n",
      "epoch:  5/300 batch 127/188  Train Loss: 0.126, Acc: 0.973\n",
      "epoch:  5/300 batch 128/188  Train Loss: 0.114, Acc: 0.969\n",
      "epoch:  5/300 batch 129/188  Train Loss: 0.086, Acc: 0.977\n",
      "epoch:  5/300 batch 130/188  Train Loss: 0.087, Acc: 0.977\n",
      "epoch:  5/300 batch 131/188  Train Loss: 0.154, Acc: 0.949\n",
      "epoch:  5/300 batch 132/188  Train Loss: 0.114, Acc: 0.953\n",
      "epoch:  5/300 batch 133/188  Train Loss: 0.111, Acc: 0.969\n",
      "epoch:  5/300 batch 134/188  Train Loss: 0.067, Acc: 0.980\n",
      "epoch:  5/300 batch 135/188  Train Loss: 0.097, Acc: 0.965\n",
      "epoch:  5/300 batch 136/188  Train Loss: 0.087, Acc: 0.977\n",
      "epoch:  5/300 batch 137/188  Train Loss: 0.162, Acc: 0.957\n",
      "epoch:  5/300 batch 138/188  Train Loss: 0.072, Acc: 0.977\n",
      "epoch:  5/300 batch 139/188  Train Loss: 0.076, Acc: 0.969\n",
      "epoch:  5/300 batch 140/188  Train Loss: 0.046, Acc: 0.980\n",
      "epoch:  5/300 batch 141/188  Train Loss: 0.074, Acc: 0.988\n",
      "epoch:  5/300 batch 142/188  Train Loss: 0.085, Acc: 0.969\n",
      "epoch:  5/300 batch 143/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch:  5/300 batch 144/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch:  5/300 batch 145/188  Train Loss: 0.088, Acc: 0.973\n",
      "epoch:  5/300 batch 146/188  Train Loss: 0.064, Acc: 0.980\n",
      "epoch:  5/300 batch 147/188  Train Loss: 0.071, Acc: 0.969\n",
      "epoch:  5/300 batch 148/188  Train Loss: 0.096, Acc: 0.969\n",
      "epoch:  5/300 batch 149/188  Train Loss: 0.125, Acc: 0.957\n",
      "epoch:  5/300 batch 150/188  Train Loss: 0.127, Acc: 0.965\n",
      "epoch:  5/300 batch 151/188  Train Loss: 0.057, Acc: 0.988\n",
      "epoch:  5/300 batch 152/188  Train Loss: 0.066, Acc: 0.977\n",
      "epoch:  5/300 batch 153/188  Train Loss: 0.055, Acc: 0.980\n",
      "epoch:  5/300 batch 154/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch:  5/300 batch 155/188  Train Loss: 0.077, Acc: 0.973\n",
      "epoch:  5/300 batch 156/188  Train Loss: 0.117, Acc: 0.973\n",
      "epoch:  5/300 batch 157/188  Train Loss: 0.095, Acc: 0.965\n",
      "epoch:  5/300 batch 158/188  Train Loss: 0.067, Acc: 0.980\n",
      "epoch:  5/300 batch 159/188  Train Loss: 0.143, Acc: 0.965\n",
      "epoch:  5/300 batch 160/188  Train Loss: 0.105, Acc: 0.973\n",
      "epoch:  5/300 batch 161/188  Train Loss: 0.105, Acc: 0.977\n",
      "epoch:  5/300 batch 162/188  Train Loss: 0.101, Acc: 0.977\n",
      "epoch:  5/300 batch 163/188  Train Loss: 0.077, Acc: 0.973\n",
      "epoch:  5/300 batch 164/188  Train Loss: 0.077, Acc: 0.977\n",
      "epoch:  5/300 batch 165/188  Train Loss: 0.087, Acc: 0.973\n",
      "epoch:  5/300 batch 166/188  Train Loss: 0.098, Acc: 0.969\n",
      "epoch:  5/300 batch 167/188  Train Loss: 0.067, Acc: 0.977\n",
      "epoch:  5/300 batch 168/188  Train Loss: 0.112, Acc: 0.965\n",
      "epoch:  5/300 batch 169/188  Train Loss: 0.094, Acc: 0.977\n",
      "epoch:  5/300 batch 170/188  Train Loss: 0.113, Acc: 0.965\n",
      "epoch:  5/300 batch 171/188  Train Loss: 0.133, Acc: 0.961\n",
      "epoch:  5/300 batch 172/188  Train Loss: 0.121, Acc: 0.969\n",
      "epoch:  5/300 batch 173/188  Train Loss: 0.124, Acc: 0.965\n",
      "epoch:  5/300 batch 174/188  Train Loss: 0.087, Acc: 0.973\n",
      "epoch:  5/300 batch 175/188  Train Loss: 0.117, Acc: 0.973\n",
      "epoch:  5/300 batch 176/188  Train Loss: 0.133, Acc: 0.953\n",
      "epoch:  5/300 batch 177/188  Train Loss: 0.096, Acc: 0.961\n",
      "epoch:  5/300 batch 178/188  Train Loss: 0.090, Acc: 0.977\n",
      "epoch:  5/300 batch 179/188  Train Loss: 0.071, Acc: 0.969\n",
      "epoch:  5/300 batch 180/188  Train Loss: 0.088, Acc: 0.977\n",
      "epoch:  5/300 batch 181/188  Train Loss: 0.072, Acc: 0.977\n",
      "epoch:  5/300 batch 182/188  Train Loss: 0.075, Acc: 0.973\n",
      "epoch:  5/300 batch 183/188  Train Loss: 0.153, Acc: 0.953\n",
      "epoch:  5/300 batch 184/188  Train Loss: 0.075, Acc: 0.977\n",
      "epoch:  5/300 batch 185/188  Train Loss: 0.099, Acc: 0.965\n",
      "epoch:  5/300 batch 186/188  Train Loss: 0.117, Acc: 0.980\n",
      "epoch:  5/300 batch 187/188  Train Loss: 0.065, Acc: 0.992\n",
      "Train Loss: 0.085943, Acc: 0.975\n",
      "Val Loss: 0.090973, Acc: 0.972\n",
      "epoch:  6/300 batch   0/188  Train Loss: 0.074, Acc: 0.969\n",
      "epoch:  6/300 batch   1/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch:  6/300 batch   2/188  Train Loss: 0.081, Acc: 0.980\n",
      "epoch:  6/300 batch   3/188  Train Loss: 0.095, Acc: 0.969\n",
      "epoch:  6/300 batch   4/188  Train Loss: 0.108, Acc: 0.977\n",
      "epoch:  6/300 batch   5/188  Train Loss: 0.061, Acc: 0.984\n",
      "epoch:  6/300 batch   6/188  Train Loss: 0.067, Acc: 0.980\n",
      "epoch:  6/300 batch   7/188  Train Loss: 0.076, Acc: 0.980\n",
      "epoch:  6/300 batch   8/188  Train Loss: 0.068, Acc: 0.984\n",
      "epoch:  6/300 batch   9/188  Train Loss: 0.082, Acc: 0.988\n",
      "epoch:  6/300 batch  10/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch:  6/300 batch  11/188  Train Loss: 0.088, Acc: 0.973\n",
      "epoch:  6/300 batch  12/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch:  6/300 batch  13/188  Train Loss: 0.054, Acc: 0.980\n",
      "epoch:  6/300 batch  14/188  Train Loss: 0.068, Acc: 0.984\n",
      "epoch:  6/300 batch  15/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch:  6/300 batch  16/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch:  6/300 batch  17/188  Train Loss: 0.066, Acc: 0.980\n",
      "epoch:  6/300 batch  18/188  Train Loss: 0.054, Acc: 0.980\n",
      "epoch:  6/300 batch  19/188  Train Loss: 0.105, Acc: 0.965\n",
      "epoch:  6/300 batch  20/188  Train Loss: 0.130, Acc: 0.977\n",
      "epoch:  6/300 batch  21/188  Train Loss: 0.063, Acc: 0.977\n",
      "epoch:  6/300 batch  22/188  Train Loss: 0.098, Acc: 0.977\n",
      "epoch:  6/300 batch  23/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch:  6/300 batch  24/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch:  6/300 batch  25/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch:  6/300 batch  26/188  Train Loss: 0.074, Acc: 0.977\n",
      "epoch:  6/300 batch  27/188  Train Loss: 0.094, Acc: 0.973\n",
      "epoch:  6/300 batch  28/188  Train Loss: 0.127, Acc: 0.969\n",
      "epoch:  6/300 batch  29/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch:  6/300 batch  30/188  Train Loss: 0.103, Acc: 0.969\n",
      "epoch:  6/300 batch  31/188  Train Loss: 0.092, Acc: 0.969\n",
      "epoch:  6/300 batch  32/188  Train Loss: 0.074, Acc: 0.984\n",
      "epoch:  6/300 batch  33/188  Train Loss: 0.068, Acc: 0.988\n",
      "epoch:  6/300 batch  34/188  Train Loss: 0.057, Acc: 0.977\n",
      "epoch:  6/300 batch  35/188  Train Loss: 0.106, Acc: 0.977\n",
      "epoch:  6/300 batch  36/188  Train Loss: 0.069, Acc: 0.988\n",
      "epoch:  6/300 batch  37/188  Train Loss: 0.064, Acc: 0.980\n",
      "epoch:  6/300 batch  38/188  Train Loss: 0.091, Acc: 0.977\n",
      "epoch:  6/300 batch  39/188  Train Loss: 0.075, Acc: 0.988\n",
      "epoch:  6/300 batch  40/188  Train Loss: 0.060, Acc: 0.984\n",
      "epoch:  6/300 batch  41/188  Train Loss: 0.068, Acc: 0.984\n",
      "epoch:  6/300 batch  42/188  Train Loss: 0.079, Acc: 0.973\n",
      "epoch:  6/300 batch  43/188  Train Loss: 0.084, Acc: 0.977\n",
      "epoch:  6/300 batch  44/188  Train Loss: 0.123, Acc: 0.969\n",
      "epoch:  6/300 batch  45/188  Train Loss: 0.141, Acc: 0.945\n",
      "epoch:  6/300 batch  46/188  Train Loss: 0.073, Acc: 0.980\n",
      "epoch:  6/300 batch  47/188  Train Loss: 0.066, Acc: 0.980\n",
      "epoch:  6/300 batch  48/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch:  6/300 batch  49/188  Train Loss: 0.145, Acc: 0.945\n",
      "epoch:  6/300 batch  50/188  Train Loss: 0.105, Acc: 0.969\n",
      "epoch:  6/300 batch  51/188  Train Loss: 0.079, Acc: 0.969\n",
      "epoch:  6/300 batch  52/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch:  6/300 batch  53/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch:  6/300 batch  54/188  Train Loss: 0.107, Acc: 0.969\n",
      "epoch:  6/300 batch  55/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch:  6/300 batch  56/188  Train Loss: 0.119, Acc: 0.953\n",
      "epoch:  6/300 batch  57/188  Train Loss: 0.097, Acc: 0.957\n",
      "epoch:  6/300 batch  58/188  Train Loss: 0.089, Acc: 0.973\n",
      "epoch:  6/300 batch  59/188  Train Loss: 0.113, Acc: 0.965\n",
      "epoch:  6/300 batch  60/188  Train Loss: 0.090, Acc: 0.977\n",
      "epoch:  6/300 batch  61/188  Train Loss: 0.089, Acc: 0.977\n",
      "epoch:  6/300 batch  62/188  Train Loss: 0.111, Acc: 0.973\n",
      "epoch:  6/300 batch  63/188  Train Loss: 0.074, Acc: 0.980\n",
      "epoch:  6/300 batch  64/188  Train Loss: 0.080, Acc: 0.973\n",
      "epoch:  6/300 batch  65/188  Train Loss: 0.071, Acc: 0.977\n",
      "epoch:  6/300 batch  66/188  Train Loss: 0.077, Acc: 0.969\n",
      "epoch:  6/300 batch  67/188  Train Loss: 0.102, Acc: 0.965\n",
      "epoch:  6/300 batch  68/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch:  6/300 batch  69/188  Train Loss: 0.107, Acc: 0.973\n",
      "epoch:  6/300 batch  70/188  Train Loss: 0.063, Acc: 0.984\n",
      "epoch:  6/300 batch  71/188  Train Loss: 0.125, Acc: 0.949\n",
      "epoch:  6/300 batch  72/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch:  6/300 batch  73/188  Train Loss: 0.104, Acc: 0.977\n",
      "epoch:  6/300 batch  74/188  Train Loss: 0.066, Acc: 0.980\n",
      "epoch:  6/300 batch  75/188  Train Loss: 0.083, Acc: 0.984\n",
      "epoch:  6/300 batch  76/188  Train Loss: 0.101, Acc: 0.961\n",
      "epoch:  6/300 batch  77/188  Train Loss: 0.127, Acc: 0.957\n",
      "epoch:  6/300 batch  78/188  Train Loss: 0.105, Acc: 0.969\n",
      "epoch:  6/300 batch  79/188  Train Loss: 0.086, Acc: 0.973\n",
      "epoch:  6/300 batch  80/188  Train Loss: 0.049, Acc: 0.980\n",
      "epoch:  6/300 batch  81/188  Train Loss: 0.103, Acc: 0.965\n",
      "epoch:  6/300 batch  82/188  Train Loss: 0.142, Acc: 0.965\n",
      "epoch:  6/300 batch  83/188  Train Loss: 0.096, Acc: 0.977\n",
      "epoch:  6/300 batch  84/188  Train Loss: 0.105, Acc: 0.980\n",
      "epoch:  6/300 batch  85/188  Train Loss: 0.097, Acc: 0.965\n",
      "epoch:  6/300 batch  86/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch:  6/300 batch  87/188  Train Loss: 0.144, Acc: 0.957\n",
      "epoch:  6/300 batch  88/188  Train Loss: 0.066, Acc: 0.984\n",
      "epoch:  6/300 batch  89/188  Train Loss: 0.082, Acc: 0.973\n",
      "epoch:  6/300 batch  90/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch:  6/300 batch  91/188  Train Loss: 0.070, Acc: 0.961\n",
      "epoch:  6/300 batch  92/188  Train Loss: 0.094, Acc: 0.973\n",
      "epoch:  6/300 batch  93/188  Train Loss: 0.084, Acc: 0.977\n",
      "epoch:  6/300 batch  94/188  Train Loss: 0.061, Acc: 0.988\n",
      "epoch:  6/300 batch  95/188  Train Loss: 0.119, Acc: 0.961\n",
      "epoch:  6/300 batch  96/188  Train Loss: 0.115, Acc: 0.977\n",
      "epoch:  6/300 batch  97/188  Train Loss: 0.116, Acc: 0.969\n",
      "epoch:  6/300 batch  98/188  Train Loss: 0.057, Acc: 0.980\n",
      "epoch:  6/300 batch  99/188  Train Loss: 0.112, Acc: 0.961\n",
      "epoch:  6/300 batch 100/188  Train Loss: 0.079, Acc: 0.969\n",
      "epoch:  6/300 batch 101/188  Train Loss: 0.109, Acc: 0.969\n",
      "epoch:  6/300 batch 102/188  Train Loss: 0.155, Acc: 0.953\n",
      "epoch:  6/300 batch 103/188  Train Loss: 0.123, Acc: 0.965\n",
      "epoch:  6/300 batch 104/188  Train Loss: 0.130, Acc: 0.953\n",
      "epoch:  6/300 batch 105/188  Train Loss: 0.118, Acc: 0.961\n",
      "epoch:  6/300 batch 106/188  Train Loss: 0.096, Acc: 0.977\n",
      "epoch:  6/300 batch 107/188  Train Loss: 0.115, Acc: 0.961\n",
      "epoch:  6/300 batch 108/188  Train Loss: 0.075, Acc: 0.980\n",
      "epoch:  6/300 batch 109/188  Train Loss: 0.142, Acc: 0.945\n",
      "epoch:  6/300 batch 110/188  Train Loss: 0.103, Acc: 0.973\n",
      "epoch:  6/300 batch 111/188  Train Loss: 0.119, Acc: 0.961\n",
      "epoch:  6/300 batch 112/188  Train Loss: 0.060, Acc: 0.980\n",
      "epoch:  6/300 batch 113/188  Train Loss: 0.072, Acc: 0.977\n",
      "epoch:  6/300 batch 114/188  Train Loss: 0.130, Acc: 0.961\n",
      "epoch:  6/300 batch 115/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch:  6/300 batch 116/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch:  6/300 batch 117/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch:  6/300 batch 118/188  Train Loss: 0.060, Acc: 0.984\n",
      "epoch:  6/300 batch 119/188  Train Loss: 0.112, Acc: 0.965\n",
      "epoch:  6/300 batch 120/188  Train Loss: 0.067, Acc: 0.984\n",
      "epoch:  6/300 batch 121/188  Train Loss: 0.064, Acc: 0.977\n",
      "epoch:  6/300 batch 122/188  Train Loss: 0.059, Acc: 0.984\n",
      "epoch:  6/300 batch 123/188  Train Loss: 0.099, Acc: 0.973\n",
      "epoch:  6/300 batch 124/188  Train Loss: 0.085, Acc: 0.969\n",
      "epoch:  6/300 batch 125/188  Train Loss: 0.160, Acc: 0.965\n",
      "epoch:  6/300 batch 126/188  Train Loss: 0.085, Acc: 0.957\n",
      "epoch:  6/300 batch 127/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch:  6/300 batch 128/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch:  6/300 batch 129/188  Train Loss: 0.123, Acc: 0.973\n",
      "epoch:  6/300 batch 130/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch:  6/300 batch 131/188  Train Loss: 0.096, Acc: 0.965\n",
      "epoch:  6/300 batch 132/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch:  6/300 batch 133/188  Train Loss: 0.098, Acc: 0.969\n",
      "epoch:  6/300 batch 134/188  Train Loss: 0.112, Acc: 0.965\n",
      "epoch:  6/300 batch 135/188  Train Loss: 0.051, Acc: 0.980\n",
      "epoch:  6/300 batch 136/188  Train Loss: 0.150, Acc: 0.965\n",
      "epoch:  6/300 batch 137/188  Train Loss: 0.115, Acc: 0.961\n",
      "epoch:  6/300 batch 138/188  Train Loss: 0.075, Acc: 0.980\n",
      "epoch:  6/300 batch 139/188  Train Loss: 0.073, Acc: 0.980\n",
      "epoch:  6/300 batch 140/188  Train Loss: 0.100, Acc: 0.973\n",
      "epoch:  6/300 batch 141/188  Train Loss: 0.070, Acc: 0.977\n",
      "epoch:  6/300 batch 142/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch:  6/300 batch 143/188  Train Loss: 0.082, Acc: 0.957\n",
      "epoch:  6/300 batch 144/188  Train Loss: 0.122, Acc: 0.949\n",
      "epoch:  6/300 batch 145/188  Train Loss: 0.092, Acc: 0.973\n",
      "epoch:  6/300 batch 146/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch:  6/300 batch 147/188  Train Loss: 0.056, Acc: 0.980\n",
      "epoch:  6/300 batch 148/188  Train Loss: 0.062, Acc: 0.980\n",
      "epoch:  6/300 batch 149/188  Train Loss: 0.083, Acc: 0.977\n",
      "epoch:  6/300 batch 150/188  Train Loss: 0.127, Acc: 0.953\n",
      "epoch:  6/300 batch 151/188  Train Loss: 0.088, Acc: 0.977\n",
      "epoch:  6/300 batch 152/188  Train Loss: 0.058, Acc: 0.980\n",
      "epoch:  6/300 batch 153/188  Train Loss: 0.113, Acc: 0.969\n",
      "epoch:  6/300 batch 154/188  Train Loss: 0.061, Acc: 0.980\n",
      "epoch:  6/300 batch 155/188  Train Loss: 0.112, Acc: 0.961\n",
      "epoch:  6/300 batch 156/188  Train Loss: 0.058, Acc: 0.977\n",
      "epoch:  6/300 batch 157/188  Train Loss: 0.071, Acc: 0.980\n",
      "epoch:  6/300 batch 158/188  Train Loss: 0.057, Acc: 0.980\n",
      "epoch:  6/300 batch 159/188  Train Loss: 0.062, Acc: 0.977\n",
      "epoch:  6/300 batch 160/188  Train Loss: 0.065, Acc: 0.984\n",
      "epoch:  6/300 batch 161/188  Train Loss: 0.077, Acc: 0.977\n",
      "epoch:  6/300 batch 162/188  Train Loss: 0.130, Acc: 0.961\n",
      "epoch:  6/300 batch 163/188  Train Loss: 0.093, Acc: 0.953\n",
      "epoch:  6/300 batch 164/188  Train Loss: 0.116, Acc: 0.965\n",
      "epoch:  6/300 batch 165/188  Train Loss: 0.097, Acc: 0.973\n",
      "epoch:  6/300 batch 166/188  Train Loss: 0.058, Acc: 0.980\n",
      "epoch:  6/300 batch 167/188  Train Loss: 0.072, Acc: 0.980\n",
      "epoch:  6/300 batch 168/188  Train Loss: 0.135, Acc: 0.953\n",
      "epoch:  6/300 batch 169/188  Train Loss: 0.055, Acc: 0.980\n",
      "epoch:  6/300 batch 170/188  Train Loss: 0.071, Acc: 0.988\n",
      "epoch:  6/300 batch 171/188  Train Loss: 0.118, Acc: 0.973\n",
      "epoch:  6/300 batch 172/188  Train Loss: 0.102, Acc: 0.969\n",
      "epoch:  6/300 batch 173/188  Train Loss: 0.045, Acc: 0.980\n",
      "epoch:  6/300 batch 174/188  Train Loss: 0.074, Acc: 0.980\n",
      "epoch:  6/300 batch 175/188  Train Loss: 0.117, Acc: 0.965\n",
      "epoch:  6/300 batch 176/188  Train Loss: 0.067, Acc: 0.980\n",
      "epoch:  6/300 batch 177/188  Train Loss: 0.086, Acc: 0.973\n",
      "epoch:  6/300 batch 178/188  Train Loss: 0.120, Acc: 0.957\n",
      "epoch:  6/300 batch 179/188  Train Loss: 0.084, Acc: 0.984\n",
      "epoch:  6/300 batch 180/188  Train Loss: 0.079, Acc: 0.965\n",
      "epoch:  6/300 batch 181/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch:  6/300 batch 182/188  Train Loss: 0.076, Acc: 0.973\n",
      "epoch:  6/300 batch 183/188  Train Loss: 0.107, Acc: 0.969\n",
      "epoch:  6/300 batch 184/188  Train Loss: 0.097, Acc: 0.977\n",
      "epoch:  6/300 batch 185/188  Train Loss: 0.104, Acc: 0.957\n",
      "epoch:  6/300 batch 186/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch:  6/300 batch 187/188  Train Loss: 0.055, Acc: 0.984\n",
      "Train Loss: 0.083972, Acc: 0.975\n",
      "Val Loss: 0.088269, Acc: 0.973\n",
      "epoch:  7/300 batch   0/188  Train Loss: 0.106, Acc: 0.973\n",
      "epoch:  7/300 batch   1/188  Train Loss: 0.064, Acc: 0.984\n",
      "epoch:  7/300 batch   2/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch:  7/300 batch   3/188  Train Loss: 0.096, Acc: 0.977\n",
      "epoch:  7/300 batch   4/188  Train Loss: 0.067, Acc: 0.988\n",
      "epoch:  7/300 batch   5/188  Train Loss: 0.063, Acc: 0.980\n",
      "epoch:  7/300 batch   6/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch:  7/300 batch   7/188  Train Loss: 0.045, Acc: 0.980\n",
      "epoch:  7/300 batch   8/188  Train Loss: 0.062, Acc: 0.984\n",
      "epoch:  7/300 batch   9/188  Train Loss: 0.059, Acc: 0.977\n",
      "epoch:  7/300 batch  10/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch:  7/300 batch  11/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch:  7/300 batch  12/188  Train Loss: 0.084, Acc: 0.973\n",
      "epoch:  7/300 batch  13/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch:  7/300 batch  14/188  Train Loss: 0.080, Acc: 0.969\n",
      "epoch:  7/300 batch  15/188  Train Loss: 0.101, Acc: 0.977\n",
      "epoch:  7/300 batch  16/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch:  7/300 batch  17/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch:  7/300 batch  18/188  Train Loss: 0.115, Acc: 0.969\n",
      "epoch:  7/300 batch  19/188  Train Loss: 0.107, Acc: 0.969\n",
      "epoch:  7/300 batch  20/188  Train Loss: 0.089, Acc: 0.969\n",
      "epoch:  7/300 batch  21/188  Train Loss: 0.063, Acc: 0.984\n",
      "epoch:  7/300 batch  22/188  Train Loss: 0.071, Acc: 0.965\n",
      "epoch:  7/300 batch  23/188  Train Loss: 0.102, Acc: 0.973\n",
      "epoch:  7/300 batch  24/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch:  7/300 batch  25/188  Train Loss: 0.072, Acc: 0.977\n",
      "epoch:  7/300 batch  26/188  Train Loss: 0.058, Acc: 0.980\n",
      "epoch:  7/300 batch  27/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch:  7/300 batch  28/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch:  7/300 batch  29/188  Train Loss: 0.063, Acc: 0.984\n",
      "epoch:  7/300 batch  30/188  Train Loss: 0.063, Acc: 0.973\n",
      "epoch:  7/300 batch  31/188  Train Loss: 0.062, Acc: 0.984\n",
      "epoch:  7/300 batch  32/188  Train Loss: 0.086, Acc: 0.980\n",
      "epoch:  7/300 batch  33/188  Train Loss: 0.113, Acc: 0.973\n",
      "epoch:  7/300 batch  34/188  Train Loss: 0.094, Acc: 0.965\n",
      "epoch:  7/300 batch  35/188  Train Loss: 0.076, Acc: 0.973\n",
      "epoch:  7/300 batch  36/188  Train Loss: 0.082, Acc: 0.984\n",
      "epoch:  7/300 batch  37/188  Train Loss: 0.066, Acc: 0.980\n",
      "epoch:  7/300 batch  38/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch:  7/300 batch  39/188  Train Loss: 0.098, Acc: 0.977\n",
      "epoch:  7/300 batch  40/188  Train Loss: 0.061, Acc: 0.984\n",
      "epoch:  7/300 batch  41/188  Train Loss: 0.074, Acc: 0.973\n",
      "epoch:  7/300 batch  42/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch:  7/300 batch  43/188  Train Loss: 0.060, Acc: 0.984\n",
      "epoch:  7/300 batch  44/188  Train Loss: 0.138, Acc: 0.949\n",
      "epoch:  7/300 batch  45/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch:  7/300 batch  46/188  Train Loss: 0.071, Acc: 0.980\n",
      "epoch:  7/300 batch  47/188  Train Loss: 0.079, Acc: 0.980\n",
      "epoch:  7/300 batch  48/188  Train Loss: 0.110, Acc: 0.977\n",
      "epoch:  7/300 batch  49/188  Train Loss: 0.073, Acc: 0.984\n",
      "epoch:  7/300 batch  50/188  Train Loss: 0.076, Acc: 0.973\n",
      "epoch:  7/300 batch  51/188  Train Loss: 0.115, Acc: 0.961\n",
      "epoch:  7/300 batch  52/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch:  7/300 batch  53/188  Train Loss: 0.048, Acc: 0.996\n",
      "epoch:  7/300 batch  54/188  Train Loss: 0.093, Acc: 0.969\n",
      "epoch:  7/300 batch  55/188  Train Loss: 0.074, Acc: 0.977\n",
      "epoch:  7/300 batch  56/188  Train Loss: 0.063, Acc: 0.977\n",
      "epoch:  7/300 batch  57/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch:  7/300 batch  58/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch:  7/300 batch  59/188  Train Loss: 0.101, Acc: 0.973\n",
      "epoch:  7/300 batch  60/188  Train Loss: 0.063, Acc: 0.980\n",
      "epoch:  7/300 batch  61/188  Train Loss: 0.158, Acc: 0.961\n",
      "epoch:  7/300 batch  62/188  Train Loss: 0.060, Acc: 0.977\n",
      "epoch:  7/300 batch  63/188  Train Loss: 0.054, Acc: 0.980\n",
      "epoch:  7/300 batch  64/188  Train Loss: 0.107, Acc: 0.965\n",
      "epoch:  7/300 batch  65/188  Train Loss: 0.059, Acc: 0.980\n",
      "epoch:  7/300 batch  66/188  Train Loss: 0.120, Acc: 0.961\n",
      "epoch:  7/300 batch  67/188  Train Loss: 0.144, Acc: 0.961\n",
      "epoch:  7/300 batch  68/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch:  7/300 batch  69/188  Train Loss: 0.073, Acc: 0.977\n",
      "epoch:  7/300 batch  70/188  Train Loss: 0.053, Acc: 0.980\n",
      "epoch:  7/300 batch  71/188  Train Loss: 0.114, Acc: 0.965\n",
      "epoch:  7/300 batch  72/188  Train Loss: 0.045, Acc: 0.980\n",
      "epoch:  7/300 batch  73/188  Train Loss: 0.107, Acc: 0.969\n",
      "epoch:  7/300 batch  74/188  Train Loss: 0.115, Acc: 0.961\n",
      "epoch:  7/300 batch  75/188  Train Loss: 0.075, Acc: 0.977\n",
      "epoch:  7/300 batch  76/188  Train Loss: 0.103, Acc: 0.973\n",
      "epoch:  7/300 batch  77/188  Train Loss: 0.069, Acc: 0.980\n",
      "epoch:  7/300 batch  78/188  Train Loss: 0.133, Acc: 0.969\n",
      "epoch:  7/300 batch  79/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch:  7/300 batch  80/188  Train Loss: 0.128, Acc: 0.949\n",
      "epoch:  7/300 batch  81/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch:  7/300 batch  82/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch:  7/300 batch  83/188  Train Loss: 0.092, Acc: 0.969\n",
      "epoch:  7/300 batch  84/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch:  7/300 batch  85/188  Train Loss: 0.077, Acc: 0.977\n",
      "epoch:  7/300 batch  86/188  Train Loss: 0.083, Acc: 0.969\n",
      "epoch:  7/300 batch  87/188  Train Loss: 0.078, Acc: 0.973\n",
      "epoch:  7/300 batch  88/188  Train Loss: 0.066, Acc: 0.980\n",
      "epoch:  7/300 batch  89/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch:  7/300 batch  90/188  Train Loss: 0.059, Acc: 0.980\n",
      "epoch:  7/300 batch  91/188  Train Loss: 0.087, Acc: 0.969\n",
      "epoch:  7/300 batch  92/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch:  7/300 batch  93/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch:  7/300 batch  94/188  Train Loss: 0.128, Acc: 0.957\n",
      "epoch:  7/300 batch  95/188  Train Loss: 0.085, Acc: 0.969\n",
      "epoch:  7/300 batch  96/188  Train Loss: 0.091, Acc: 0.973\n",
      "epoch:  7/300 batch  97/188  Train Loss: 0.055, Acc: 0.977\n",
      "epoch:  7/300 batch  98/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch:  7/300 batch  99/188  Train Loss: 0.095, Acc: 0.980\n",
      "epoch:  7/300 batch 100/188  Train Loss: 0.136, Acc: 0.953\n",
      "epoch:  7/300 batch 101/188  Train Loss: 0.069, Acc: 0.988\n",
      "epoch:  7/300 batch 102/188  Train Loss: 0.072, Acc: 0.973\n",
      "epoch:  7/300 batch 103/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch:  7/300 batch 104/188  Train Loss: 0.066, Acc: 0.988\n",
      "epoch:  7/300 batch 105/188  Train Loss: 0.110, Acc: 0.969\n",
      "epoch:  7/300 batch 106/188  Train Loss: 0.084, Acc: 0.977\n",
      "epoch:  7/300 batch 107/188  Train Loss: 0.104, Acc: 0.969\n",
      "epoch:  7/300 batch 108/188  Train Loss: 0.104, Acc: 0.953\n",
      "epoch:  7/300 batch 109/188  Train Loss: 0.118, Acc: 0.965\n",
      "epoch:  7/300 batch 110/188  Train Loss: 0.095, Acc: 0.969\n",
      "epoch:  7/300 batch 111/188  Train Loss: 0.103, Acc: 0.965\n",
      "epoch:  7/300 batch 112/188  Train Loss: 0.123, Acc: 0.965\n",
      "epoch:  7/300 batch 113/188  Train Loss: 0.061, Acc: 0.977\n",
      "epoch:  7/300 batch 114/188  Train Loss: 0.098, Acc: 0.969\n",
      "epoch:  7/300 batch 115/188  Train Loss: 0.067, Acc: 0.984\n",
      "epoch:  7/300 batch 116/188  Train Loss: 0.157, Acc: 0.961\n",
      "epoch:  7/300 batch 117/188  Train Loss: 0.100, Acc: 0.965\n",
      "epoch:  7/300 batch 118/188  Train Loss: 0.086, Acc: 0.977\n",
      "epoch:  7/300 batch 119/188  Train Loss: 0.128, Acc: 0.965\n",
      "epoch:  7/300 batch 120/188  Train Loss: 0.091, Acc: 0.965\n",
      "epoch:  7/300 batch 121/188  Train Loss: 0.064, Acc: 0.980\n",
      "epoch:  7/300 batch 122/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch:  7/300 batch 123/188  Train Loss: 0.077, Acc: 0.969\n",
      "epoch:  7/300 batch 124/188  Train Loss: 0.147, Acc: 0.965\n",
      "epoch:  7/300 batch 125/188  Train Loss: 0.087, Acc: 0.969\n",
      "epoch:  7/300 batch 126/188  Train Loss: 0.060, Acc: 0.973\n",
      "epoch:  7/300 batch 127/188  Train Loss: 0.104, Acc: 0.973\n",
      "epoch:  7/300 batch 128/188  Train Loss: 0.114, Acc: 0.949\n",
      "epoch:  7/300 batch 129/188  Train Loss: 0.086, Acc: 0.973\n",
      "epoch:  7/300 batch 130/188  Train Loss: 0.124, Acc: 0.965\n",
      "epoch:  7/300 batch 131/188  Train Loss: 0.094, Acc: 0.965\n",
      "epoch:  7/300 batch 132/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch:  7/300 batch 133/188  Train Loss: 0.098, Acc: 0.977\n",
      "epoch:  7/300 batch 134/188  Train Loss: 0.099, Acc: 0.965\n",
      "epoch:  7/300 batch 135/188  Train Loss: 0.084, Acc: 0.977\n",
      "epoch:  7/300 batch 136/188  Train Loss: 0.086, Acc: 0.973\n",
      "epoch:  7/300 batch 137/188  Train Loss: 0.077, Acc: 0.980\n",
      "epoch:  7/300 batch 138/188  Train Loss: 0.083, Acc: 0.977\n",
      "epoch:  7/300 batch 139/188  Train Loss: 0.116, Acc: 0.973\n",
      "epoch:  7/300 batch 140/188  Train Loss: 0.065, Acc: 0.980\n",
      "epoch:  7/300 batch 141/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch:  7/300 batch 142/188  Train Loss: 0.087, Acc: 0.977\n",
      "epoch:  7/300 batch 143/188  Train Loss: 0.120, Acc: 0.961\n",
      "epoch:  7/300 batch 144/188  Train Loss: 0.062, Acc: 0.977\n",
      "epoch:  7/300 batch 145/188  Train Loss: 0.081, Acc: 0.973\n",
      "epoch:  7/300 batch 146/188  Train Loss: 0.104, Acc: 0.961\n",
      "epoch:  7/300 batch 147/188  Train Loss: 0.132, Acc: 0.969\n",
      "epoch:  7/300 batch 148/188  Train Loss: 0.061, Acc: 0.980\n",
      "epoch:  7/300 batch 149/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch:  7/300 batch 150/188  Train Loss: 0.126, Acc: 0.969\n",
      "epoch:  7/300 batch 151/188  Train Loss: 0.127, Acc: 0.957\n",
      "epoch:  7/300 batch 152/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch:  7/300 batch 153/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch:  7/300 batch 154/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch:  7/300 batch 155/188  Train Loss: 0.127, Acc: 0.965\n",
      "epoch:  7/300 batch 156/188  Train Loss: 0.080, Acc: 0.977\n",
      "epoch:  7/300 batch 157/188  Train Loss: 0.066, Acc: 0.984\n",
      "epoch:  7/300 batch 158/188  Train Loss: 0.112, Acc: 0.969\n",
      "epoch:  7/300 batch 159/188  Train Loss: 0.065, Acc: 0.977\n",
      "epoch:  7/300 batch 160/188  Train Loss: 0.117, Acc: 0.965\n",
      "epoch:  7/300 batch 161/188  Train Loss: 0.095, Acc: 0.961\n",
      "epoch:  7/300 batch 162/188  Train Loss: 0.088, Acc: 0.977\n",
      "epoch:  7/300 batch 163/188  Train Loss: 0.097, Acc: 0.961\n",
      "epoch:  7/300 batch 164/188  Train Loss: 0.126, Acc: 0.973\n",
      "epoch:  7/300 batch 165/188  Train Loss: 0.108, Acc: 0.973\n",
      "epoch:  7/300 batch 166/188  Train Loss: 0.081, Acc: 0.973\n",
      "epoch:  7/300 batch 167/188  Train Loss: 0.094, Acc: 0.961\n",
      "epoch:  7/300 batch 168/188  Train Loss: 0.101, Acc: 0.969\n",
      "epoch:  7/300 batch 169/188  Train Loss: 0.074, Acc: 0.977\n",
      "epoch:  7/300 batch 170/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch:  7/300 batch 171/188  Train Loss: 0.108, Acc: 0.965\n",
      "epoch:  7/300 batch 172/188  Train Loss: 0.081, Acc: 0.969\n",
      "epoch:  7/300 batch 173/188  Train Loss: 0.143, Acc: 0.953\n",
      "epoch:  7/300 batch 174/188  Train Loss: 0.118, Acc: 0.961\n",
      "epoch:  7/300 batch 175/188  Train Loss: 0.103, Acc: 0.969\n",
      "epoch:  7/300 batch 176/188  Train Loss: 0.120, Acc: 0.977\n",
      "epoch:  7/300 batch 177/188  Train Loss: 0.088, Acc: 0.961\n",
      "epoch:  7/300 batch 178/188  Train Loss: 0.117, Acc: 0.961\n",
      "epoch:  7/300 batch 179/188  Train Loss: 0.131, Acc: 0.965\n",
      "epoch:  7/300 batch 180/188  Train Loss: 0.137, Acc: 0.945\n",
      "epoch:  7/300 batch 181/188  Train Loss: 0.143, Acc: 0.973\n",
      "epoch:  7/300 batch 182/188  Train Loss: 0.111, Acc: 0.965\n",
      "epoch:  7/300 batch 183/188  Train Loss: 0.071, Acc: 0.973\n",
      "epoch:  7/300 batch 184/188  Train Loss: 0.087, Acc: 0.965\n",
      "epoch:  7/300 batch 185/188  Train Loss: 0.057, Acc: 0.980\n",
      "epoch:  7/300 batch 186/188  Train Loss: 0.117, Acc: 0.961\n",
      "epoch:  7/300 batch 187/188  Train Loss: 0.131, Acc: 0.945\n",
      "Train Loss: 0.083327, Acc: 0.975\n",
      "Val Loss: 0.098983, Acc: 0.970\n",
      "epoch:  8/300 batch   0/188  Train Loss: 0.080, Acc: 0.973\n",
      "epoch:  8/300 batch   1/188  Train Loss: 0.108, Acc: 0.969\n",
      "epoch:  8/300 batch   2/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch:  8/300 batch   3/188  Train Loss: 0.088, Acc: 0.977\n",
      "epoch:  8/300 batch   4/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch:  8/300 batch   5/188  Train Loss: 0.037, Acc: 1.000\n",
      "epoch:  8/300 batch   6/188  Train Loss: 0.083, Acc: 0.977\n",
      "epoch:  8/300 batch   7/188  Train Loss: 0.121, Acc: 0.969\n",
      "epoch:  8/300 batch   8/188  Train Loss: 0.068, Acc: 0.977\n",
      "epoch:  8/300 batch   9/188  Train Loss: 0.067, Acc: 0.969\n",
      "epoch:  8/300 batch  10/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch:  8/300 batch  11/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch:  8/300 batch  12/188  Train Loss: 0.062, Acc: 0.984\n",
      "epoch:  8/300 batch  13/188  Train Loss: 0.089, Acc: 0.977\n",
      "epoch:  8/300 batch  14/188  Train Loss: 0.074, Acc: 0.977\n",
      "epoch:  8/300 batch  15/188  Train Loss: 0.083, Acc: 0.969\n",
      "epoch:  8/300 batch  16/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch:  8/300 batch  17/188  Train Loss: 0.059, Acc: 0.973\n",
      "epoch:  8/300 batch  18/188  Train Loss: 0.103, Acc: 0.969\n",
      "epoch:  8/300 batch  19/188  Train Loss: 0.066, Acc: 0.977\n",
      "epoch:  8/300 batch  20/188  Train Loss: 0.070, Acc: 0.980\n",
      "epoch:  8/300 batch  21/188  Train Loss: 0.064, Acc: 0.980\n",
      "epoch:  8/300 batch  22/188  Train Loss: 0.057, Acc: 0.980\n",
      "epoch:  8/300 batch  23/188  Train Loss: 0.079, Acc: 0.973\n",
      "epoch:  8/300 batch  24/188  Train Loss: 0.062, Acc: 0.992\n",
      "epoch:  8/300 batch  25/188  Train Loss: 0.076, Acc: 0.980\n",
      "epoch:  8/300 batch  26/188  Train Loss: 0.077, Acc: 0.965\n",
      "epoch:  8/300 batch  27/188  Train Loss: 0.067, Acc: 0.969\n",
      "epoch:  8/300 batch  28/188  Train Loss: 0.068, Acc: 0.984\n",
      "epoch:  8/300 batch  29/188  Train Loss: 0.081, Acc: 0.969\n",
      "epoch:  8/300 batch  30/188  Train Loss: 0.053, Acc: 0.973\n",
      "epoch:  8/300 batch  31/188  Train Loss: 0.080, Acc: 0.973\n",
      "epoch:  8/300 batch  32/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch:  8/300 batch  33/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch:  8/300 batch  34/188  Train Loss: 0.079, Acc: 0.980\n",
      "epoch:  8/300 batch  35/188  Train Loss: 0.090, Acc: 0.973\n",
      "epoch:  8/300 batch  36/188  Train Loss: 0.107, Acc: 0.973\n",
      "epoch:  8/300 batch  37/188  Train Loss: 0.090, Acc: 0.973\n",
      "epoch:  8/300 batch  38/188  Train Loss: 0.112, Acc: 0.977\n",
      "epoch:  8/300 batch  39/188  Train Loss: 0.096, Acc: 0.973\n",
      "epoch:  8/300 batch  40/188  Train Loss: 0.050, Acc: 0.980\n",
      "epoch:  8/300 batch  41/188  Train Loss: 0.149, Acc: 0.965\n",
      "epoch:  8/300 batch  42/188  Train Loss: 0.077, Acc: 0.980\n",
      "epoch:  8/300 batch  43/188  Train Loss: 0.096, Acc: 0.969\n",
      "epoch:  8/300 batch  44/188  Train Loss: 0.062, Acc: 0.980\n",
      "epoch:  8/300 batch  45/188  Train Loss: 0.122, Acc: 0.953\n",
      "epoch:  8/300 batch  46/188  Train Loss: 0.116, Acc: 0.969\n",
      "epoch:  8/300 batch  47/188  Train Loss: 0.083, Acc: 0.984\n",
      "epoch:  8/300 batch  48/188  Train Loss: 0.093, Acc: 0.965\n",
      "epoch:  8/300 batch  49/188  Train Loss: 0.077, Acc: 0.980\n",
      "epoch:  8/300 batch  50/188  Train Loss: 0.093, Acc: 0.980\n",
      "epoch:  8/300 batch  51/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch:  8/300 batch  52/188  Train Loss: 0.075, Acc: 0.977\n",
      "epoch:  8/300 batch  53/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch:  8/300 batch  54/188  Train Loss: 0.069, Acc: 0.977\n",
      "epoch:  8/300 batch  55/188  Train Loss: 0.085, Acc: 0.977\n",
      "epoch:  8/300 batch  56/188  Train Loss: 0.097, Acc: 0.965\n",
      "epoch:  8/300 batch  57/188  Train Loss: 0.057, Acc: 0.992\n",
      "epoch:  8/300 batch  58/188  Train Loss: 0.137, Acc: 0.965\n",
      "epoch:  8/300 batch  59/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch:  8/300 batch  60/188  Train Loss: 0.056, Acc: 0.980\n",
      "epoch:  8/300 batch  61/188  Train Loss: 0.054, Acc: 0.980\n",
      "epoch:  8/300 batch  62/188  Train Loss: 0.078, Acc: 0.965\n",
      "epoch:  8/300 batch  63/188  Train Loss: 0.102, Acc: 0.973\n",
      "epoch:  8/300 batch  64/188  Train Loss: 0.072, Acc: 0.980\n",
      "epoch:  8/300 batch  65/188  Train Loss: 0.043, Acc: 0.980\n",
      "epoch:  8/300 batch  66/188  Train Loss: 0.081, Acc: 0.973\n",
      "epoch:  8/300 batch  67/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch:  8/300 batch  68/188  Train Loss: 0.099, Acc: 0.969\n",
      "epoch:  8/300 batch  69/188  Train Loss: 0.085, Acc: 0.969\n",
      "epoch:  8/300 batch  70/188  Train Loss: 0.091, Acc: 0.965\n",
      "epoch:  8/300 batch  71/188  Train Loss: 0.068, Acc: 0.973\n",
      "epoch:  8/300 batch  72/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch:  8/300 batch  73/188  Train Loss: 0.069, Acc: 0.980\n",
      "epoch:  8/300 batch  74/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch:  8/300 batch  75/188  Train Loss: 0.106, Acc: 0.973\n",
      "epoch:  8/300 batch  76/188  Train Loss: 0.134, Acc: 0.957\n",
      "epoch:  8/300 batch  77/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch:  8/300 batch  78/188  Train Loss: 0.085, Acc: 0.977\n",
      "epoch:  8/300 batch  79/188  Train Loss: 0.106, Acc: 0.965\n",
      "epoch:  8/300 batch  80/188  Train Loss: 0.063, Acc: 0.988\n",
      "epoch:  8/300 batch  81/188  Train Loss: 0.057, Acc: 0.980\n",
      "epoch:  8/300 batch  82/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch:  8/300 batch  83/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch:  8/300 batch  84/188  Train Loss: 0.085, Acc: 0.969\n",
      "epoch:  8/300 batch  85/188  Train Loss: 0.108, Acc: 0.961\n",
      "epoch:  8/300 batch  86/188  Train Loss: 0.088, Acc: 0.977\n",
      "epoch:  8/300 batch  87/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch:  8/300 batch  88/188  Train Loss: 0.084, Acc: 0.973\n",
      "epoch:  8/300 batch  89/188  Train Loss: 0.092, Acc: 0.973\n",
      "epoch:  8/300 batch  90/188  Train Loss: 0.076, Acc: 0.980\n",
      "epoch:  8/300 batch  91/188  Train Loss: 0.067, Acc: 0.977\n",
      "epoch:  8/300 batch  92/188  Train Loss: 0.059, Acc: 0.988\n",
      "epoch:  8/300 batch  93/188  Train Loss: 0.068, Acc: 0.980\n",
      "epoch:  8/300 batch  94/188  Train Loss: 0.071, Acc: 0.980\n",
      "epoch:  8/300 batch  95/188  Train Loss: 0.064, Acc: 0.992\n",
      "epoch:  8/300 batch  96/188  Train Loss: 0.079, Acc: 0.980\n",
      "epoch:  8/300 batch  97/188  Train Loss: 0.076, Acc: 0.977\n",
      "epoch:  8/300 batch  98/188  Train Loss: 0.088, Acc: 0.977\n",
      "epoch:  8/300 batch  99/188  Train Loss: 0.121, Acc: 0.953\n",
      "epoch:  8/300 batch 100/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch:  8/300 batch 101/188  Train Loss: 0.089, Acc: 0.965\n",
      "epoch:  8/300 batch 102/188  Train Loss: 0.146, Acc: 0.949\n",
      "epoch:  8/300 batch 103/188  Train Loss: 0.112, Acc: 0.973\n",
      "epoch:  8/300 batch 104/188  Train Loss: 0.061, Acc: 0.980\n",
      "epoch:  8/300 batch 105/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch:  8/300 batch 106/188  Train Loss: 0.070, Acc: 0.977\n",
      "epoch:  8/300 batch 107/188  Train Loss: 0.135, Acc: 0.957\n",
      "epoch:  8/300 batch 108/188  Train Loss: 0.081, Acc: 0.973\n",
      "epoch:  8/300 batch 109/188  Train Loss: 0.064, Acc: 0.980\n",
      "epoch:  8/300 batch 110/188  Train Loss: 0.080, Acc: 0.984\n",
      "epoch:  8/300 batch 111/188  Train Loss: 0.078, Acc: 0.984\n",
      "epoch:  8/300 batch 112/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch:  8/300 batch 113/188  Train Loss: 0.084, Acc: 0.977\n",
      "epoch:  8/300 batch 114/188  Train Loss: 0.089, Acc: 0.973\n",
      "epoch:  8/300 batch 115/188  Train Loss: 0.082, Acc: 0.969\n",
      "epoch:  8/300 batch 116/188  Train Loss: 0.079, Acc: 0.969\n",
      "epoch:  8/300 batch 117/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch:  8/300 batch 118/188  Train Loss: 0.103, Acc: 0.973\n",
      "epoch:  8/300 batch 119/188  Train Loss: 0.088, Acc: 0.957\n",
      "epoch:  8/300 batch 120/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch:  8/300 batch 121/188  Train Loss: 0.109, Acc: 0.961\n",
      "epoch:  8/300 batch 122/188  Train Loss: 0.109, Acc: 0.957\n",
      "epoch:  8/300 batch 123/188  Train Loss: 0.081, Acc: 0.969\n",
      "epoch:  8/300 batch 124/188  Train Loss: 0.070, Acc: 0.980\n",
      "epoch:  8/300 batch 125/188  Train Loss: 0.081, Acc: 0.973\n",
      "epoch:  8/300 batch 126/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch:  8/300 batch 127/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch:  8/300 batch 128/188  Train Loss: 0.116, Acc: 0.969\n",
      "epoch:  8/300 batch 129/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch:  8/300 batch 130/188  Train Loss: 0.081, Acc: 0.973\n",
      "epoch:  8/300 batch 131/188  Train Loss: 0.068, Acc: 0.984\n",
      "epoch:  8/300 batch 132/188  Train Loss: 0.057, Acc: 0.977\n",
      "epoch:  8/300 batch 133/188  Train Loss: 0.122, Acc: 0.961\n",
      "epoch:  8/300 batch 134/188  Train Loss: 0.063, Acc: 0.977\n",
      "epoch:  8/300 batch 135/188  Train Loss: 0.073, Acc: 0.980\n",
      "epoch:  8/300 batch 136/188  Train Loss: 0.085, Acc: 0.957\n",
      "epoch:  8/300 batch 137/188  Train Loss: 0.089, Acc: 0.973\n",
      "epoch:  8/300 batch 138/188  Train Loss: 0.100, Acc: 0.965\n",
      "epoch:  8/300 batch 139/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch:  8/300 batch 140/188  Train Loss: 0.066, Acc: 0.984\n",
      "epoch:  8/300 batch 141/188  Train Loss: 0.075, Acc: 0.977\n",
      "epoch:  8/300 batch 142/188  Train Loss: 0.065, Acc: 0.980\n",
      "epoch:  8/300 batch 143/188  Train Loss: 0.076, Acc: 0.980\n",
      "epoch:  8/300 batch 144/188  Train Loss: 0.063, Acc: 0.973\n",
      "epoch:  8/300 batch 145/188  Train Loss: 0.134, Acc: 0.961\n",
      "epoch:  8/300 batch 146/188  Train Loss: 0.073, Acc: 0.984\n",
      "epoch:  8/300 batch 147/188  Train Loss: 0.077, Acc: 0.969\n",
      "epoch:  8/300 batch 148/188  Train Loss: 0.079, Acc: 0.973\n",
      "epoch:  8/300 batch 149/188  Train Loss: 0.095, Acc: 0.977\n",
      "epoch:  8/300 batch 150/188  Train Loss: 0.144, Acc: 0.953\n",
      "epoch:  8/300 batch 151/188  Train Loss: 0.060, Acc: 0.988\n",
      "epoch:  8/300 batch 152/188  Train Loss: 0.093, Acc: 0.965\n",
      "epoch:  8/300 batch 153/188  Train Loss: 0.088, Acc: 0.969\n",
      "epoch:  8/300 batch 154/188  Train Loss: 0.097, Acc: 0.977\n",
      "epoch:  8/300 batch 155/188  Train Loss: 0.076, Acc: 0.977\n",
      "epoch:  8/300 batch 156/188  Train Loss: 0.115, Acc: 0.969\n",
      "epoch:  8/300 batch 157/188  Train Loss: 0.114, Acc: 0.965\n",
      "epoch:  8/300 batch 158/188  Train Loss: 0.101, Acc: 0.965\n",
      "epoch:  8/300 batch 159/188  Train Loss: 0.077, Acc: 0.980\n",
      "epoch:  8/300 batch 160/188  Train Loss: 0.088, Acc: 0.980\n",
      "epoch:  8/300 batch 161/188  Train Loss: 0.069, Acc: 0.980\n",
      "epoch:  8/300 batch 162/188  Train Loss: 0.132, Acc: 0.969\n",
      "epoch:  8/300 batch 163/188  Train Loss: 0.111, Acc: 0.953\n",
      "epoch:  8/300 batch 164/188  Train Loss: 0.082, Acc: 0.977\n",
      "epoch:  8/300 batch 165/188  Train Loss: 0.085, Acc: 0.969\n",
      "epoch:  8/300 batch 166/188  Train Loss: 0.077, Acc: 0.980\n",
      "epoch:  8/300 batch 167/188  Train Loss: 0.147, Acc: 0.957\n",
      "epoch:  8/300 batch 168/188  Train Loss: 0.099, Acc: 0.965\n",
      "epoch:  8/300 batch 169/188  Train Loss: 0.074, Acc: 0.984\n",
      "epoch:  8/300 batch 170/188  Train Loss: 0.088, Acc: 0.969\n",
      "epoch:  8/300 batch 171/188  Train Loss: 0.125, Acc: 0.961\n",
      "epoch:  8/300 batch 172/188  Train Loss: 0.071, Acc: 0.988\n",
      "epoch:  8/300 batch 173/188  Train Loss: 0.109, Acc: 0.965\n",
      "epoch:  8/300 batch 174/188  Train Loss: 0.067, Acc: 0.988\n",
      "epoch:  8/300 batch 175/188  Train Loss: 0.115, Acc: 0.973\n",
      "epoch:  8/300 batch 176/188  Train Loss: 0.074, Acc: 0.977\n",
      "epoch:  8/300 batch 177/188  Train Loss: 0.101, Acc: 0.965\n",
      "epoch:  8/300 batch 178/188  Train Loss: 0.066, Acc: 0.969\n",
      "epoch:  8/300 batch 179/188  Train Loss: 0.089, Acc: 0.969\n",
      "epoch:  8/300 batch 180/188  Train Loss: 0.111, Acc: 0.977\n",
      "epoch:  8/300 batch 181/188  Train Loss: 0.110, Acc: 0.977\n",
      "epoch:  8/300 batch 182/188  Train Loss: 0.067, Acc: 0.977\n",
      "epoch:  8/300 batch 183/188  Train Loss: 0.147, Acc: 0.961\n",
      "epoch:  8/300 batch 184/188  Train Loss: 0.061, Acc: 0.973\n",
      "epoch:  8/300 batch 185/188  Train Loss: 0.075, Acc: 0.973\n",
      "epoch:  8/300 batch 186/188  Train Loss: 0.198, Acc: 0.961\n",
      "epoch:  8/300 batch 187/188  Train Loss: 0.070, Acc: 0.977\n",
      "Train Loss: 0.081077, Acc: 0.975\n",
      "Val Loss: 0.082705, Acc: 0.976\n",
      "epoch:  9/300 batch   0/188  Train Loss: 0.053, Acc: 0.992\n",
      "epoch:  9/300 batch   1/188  Train Loss: 0.068, Acc: 0.980\n",
      "epoch:  9/300 batch   2/188  Train Loss: 0.079, Acc: 0.977\n",
      "epoch:  9/300 batch   3/188  Train Loss: 0.076, Acc: 0.988\n",
      "epoch:  9/300 batch   4/188  Train Loss: 0.076, Acc: 0.969\n",
      "epoch:  9/300 batch   5/188  Train Loss: 0.058, Acc: 0.980\n",
      "epoch:  9/300 batch   6/188  Train Loss: 0.093, Acc: 0.977\n",
      "epoch:  9/300 batch   7/188  Train Loss: 0.071, Acc: 0.980\n",
      "epoch:  9/300 batch   8/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch:  9/300 batch   9/188  Train Loss: 0.099, Acc: 0.973\n",
      "epoch:  9/300 batch  10/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch:  9/300 batch  11/188  Train Loss: 0.097, Acc: 0.969\n",
      "epoch:  9/300 batch  12/188  Train Loss: 0.066, Acc: 0.980\n",
      "epoch:  9/300 batch  13/188  Train Loss: 0.056, Acc: 0.980\n",
      "epoch:  9/300 batch  14/188  Train Loss: 0.074, Acc: 0.988\n",
      "epoch:  9/300 batch  15/188  Train Loss: 0.094, Acc: 0.969\n",
      "epoch:  9/300 batch  16/188  Train Loss: 0.084, Acc: 0.984\n",
      "epoch:  9/300 batch  17/188  Train Loss: 0.090, Acc: 0.969\n",
      "epoch:  9/300 batch  18/188  Train Loss: 0.087, Acc: 0.969\n",
      "epoch:  9/300 batch  19/188  Train Loss: 0.082, Acc: 0.984\n",
      "epoch:  9/300 batch  20/188  Train Loss: 0.067, Acc: 0.977\n",
      "epoch:  9/300 batch  21/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch:  9/300 batch  22/188  Train Loss: 0.089, Acc: 0.965\n",
      "epoch:  9/300 batch  23/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch:  9/300 batch  24/188  Train Loss: 0.109, Acc: 0.965\n",
      "epoch:  9/300 batch  25/188  Train Loss: 0.098, Acc: 0.977\n",
      "epoch:  9/300 batch  26/188  Train Loss: 0.076, Acc: 0.969\n",
      "epoch:  9/300 batch  27/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch:  9/300 batch  28/188  Train Loss: 0.061, Acc: 0.984\n",
      "epoch:  9/300 batch  29/188  Train Loss: 0.089, Acc: 0.973\n",
      "epoch:  9/300 batch  30/188  Train Loss: 0.059, Acc: 0.984\n",
      "epoch:  9/300 batch  31/188  Train Loss: 0.105, Acc: 0.973\n",
      "epoch:  9/300 batch  32/188  Train Loss: 0.083, Acc: 0.977\n",
      "epoch:  9/300 batch  33/188  Train Loss: 0.092, Acc: 0.965\n",
      "epoch:  9/300 batch  34/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch:  9/300 batch  35/188  Train Loss: 0.106, Acc: 0.980\n",
      "epoch:  9/300 batch  36/188  Train Loss: 0.089, Acc: 0.969\n",
      "epoch:  9/300 batch  37/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch:  9/300 batch  38/188  Train Loss: 0.078, Acc: 0.980\n",
      "epoch:  9/300 batch  39/188  Train Loss: 0.099, Acc: 0.965\n",
      "epoch:  9/300 batch  40/188  Train Loss: 0.102, Acc: 0.973\n",
      "epoch:  9/300 batch  41/188  Train Loss: 0.100, Acc: 0.973\n",
      "epoch:  9/300 batch  42/188  Train Loss: 0.063, Acc: 0.977\n",
      "epoch:  9/300 batch  43/188  Train Loss: 0.079, Acc: 0.965\n",
      "epoch:  9/300 batch  44/188  Train Loss: 0.116, Acc: 0.961\n",
      "epoch:  9/300 batch  45/188  Train Loss: 0.105, Acc: 0.969\n",
      "epoch:  9/300 batch  46/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch:  9/300 batch  47/188  Train Loss: 0.072, Acc: 0.988\n",
      "epoch:  9/300 batch  48/188  Train Loss: 0.121, Acc: 0.980\n",
      "epoch:  9/300 batch  49/188  Train Loss: 0.078, Acc: 0.980\n",
      "epoch:  9/300 batch  50/188  Train Loss: 0.090, Acc: 0.977\n",
      "epoch:  9/300 batch  51/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch:  9/300 batch  52/188  Train Loss: 0.069, Acc: 0.973\n",
      "epoch:  9/300 batch  53/188  Train Loss: 0.094, Acc: 0.969\n",
      "epoch:  9/300 batch  54/188  Train Loss: 0.081, Acc: 0.969\n",
      "epoch:  9/300 batch  55/188  Train Loss: 0.118, Acc: 0.957\n",
      "epoch:  9/300 batch  56/188  Train Loss: 0.099, Acc: 0.953\n",
      "epoch:  9/300 batch  57/188  Train Loss: 0.091, Acc: 0.977\n",
      "epoch:  9/300 batch  58/188  Train Loss: 0.075, Acc: 0.977\n",
      "epoch:  9/300 batch  59/188  Train Loss: 0.048, Acc: 0.980\n",
      "epoch:  9/300 batch  60/188  Train Loss: 0.060, Acc: 0.980\n",
      "epoch:  9/300 batch  61/188  Train Loss: 0.060, Acc: 0.988\n",
      "epoch:  9/300 batch  62/188  Train Loss: 0.091, Acc: 0.957\n",
      "epoch:  9/300 batch  63/188  Train Loss: 0.106, Acc: 0.965\n",
      "epoch:  9/300 batch  64/188  Train Loss: 0.100, Acc: 0.973\n",
      "epoch:  9/300 batch  65/188  Train Loss: 0.108, Acc: 0.973\n",
      "epoch:  9/300 batch  66/188  Train Loss: 0.107, Acc: 0.961\n",
      "epoch:  9/300 batch  67/188  Train Loss: 0.073, Acc: 0.984\n",
      "epoch:  9/300 batch  68/188  Train Loss: 0.121, Acc: 0.965\n",
      "epoch:  9/300 batch  69/188  Train Loss: 0.108, Acc: 0.973\n",
      "epoch:  9/300 batch  70/188  Train Loss: 0.089, Acc: 0.984\n",
      "epoch:  9/300 batch  71/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch:  9/300 batch  72/188  Train Loss: 0.064, Acc: 0.980\n",
      "epoch:  9/300 batch  73/188  Train Loss: 0.112, Acc: 0.961\n",
      "epoch:  9/300 batch  74/188  Train Loss: 0.097, Acc: 0.961\n",
      "epoch:  9/300 batch  75/188  Train Loss: 0.064, Acc: 0.988\n",
      "epoch:  9/300 batch  76/188  Train Loss: 0.074, Acc: 0.977\n",
      "epoch:  9/300 batch  77/188  Train Loss: 0.042, Acc: 0.996\n",
      "epoch:  9/300 batch  78/188  Train Loss: 0.072, Acc: 0.965\n",
      "epoch:  9/300 batch  79/188  Train Loss: 0.071, Acc: 0.973\n",
      "epoch:  9/300 batch  80/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch:  9/300 batch  81/188  Train Loss: 0.122, Acc: 0.957\n",
      "epoch:  9/300 batch  82/188  Train Loss: 0.082, Acc: 0.969\n",
      "epoch:  9/300 batch  83/188  Train Loss: 0.125, Acc: 0.961\n",
      "epoch:  9/300 batch  84/188  Train Loss: 0.050, Acc: 0.980\n",
      "epoch:  9/300 batch  85/188  Train Loss: 0.066, Acc: 0.984\n",
      "epoch:  9/300 batch  86/188  Train Loss: 0.071, Acc: 0.984\n",
      "epoch:  9/300 batch  87/188  Train Loss: 0.078, Acc: 0.961\n",
      "epoch:  9/300 batch  88/188  Train Loss: 0.057, Acc: 0.992\n",
      "epoch:  9/300 batch  89/188  Train Loss: 0.131, Acc: 0.961\n",
      "epoch:  9/300 batch  90/188  Train Loss: 0.094, Acc: 0.980\n",
      "epoch:  9/300 batch  91/188  Train Loss: 0.066, Acc: 0.984\n",
      "epoch:  9/300 batch  92/188  Train Loss: 0.118, Acc: 0.953\n",
      "epoch:  9/300 batch  93/188  Train Loss: 0.082, Acc: 0.977\n",
      "epoch:  9/300 batch  94/188  Train Loss: 0.156, Acc: 0.957\n",
      "epoch:  9/300 batch  95/188  Train Loss: 0.135, Acc: 0.957\n",
      "epoch:  9/300 batch  96/188  Train Loss: 0.137, Acc: 0.957\n",
      "epoch:  9/300 batch  97/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch:  9/300 batch  98/188  Train Loss: 0.081, Acc: 0.977\n",
      "epoch:  9/300 batch  99/188  Train Loss: 0.046, Acc: 0.980\n",
      "epoch:  9/300 batch 100/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch:  9/300 batch 101/188  Train Loss: 0.095, Acc: 0.953\n",
      "epoch:  9/300 batch 102/188  Train Loss: 0.100, Acc: 0.969\n",
      "epoch:  9/300 batch 103/188  Train Loss: 0.097, Acc: 0.965\n",
      "epoch:  9/300 batch 104/188  Train Loss: 0.133, Acc: 0.965\n",
      "epoch:  9/300 batch 105/188  Train Loss: 0.074, Acc: 0.965\n",
      "epoch:  9/300 batch 106/188  Train Loss: 0.093, Acc: 0.973\n",
      "epoch:  9/300 batch 107/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch:  9/300 batch 108/188  Train Loss: 0.132, Acc: 0.965\n",
      "epoch:  9/300 batch 109/188  Train Loss: 0.063, Acc: 0.980\n",
      "epoch:  9/300 batch 110/188  Train Loss: 0.081, Acc: 0.977\n",
      "epoch:  9/300 batch 111/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch:  9/300 batch 112/188  Train Loss: 0.068, Acc: 0.973\n",
      "epoch:  9/300 batch 113/188  Train Loss: 0.110, Acc: 0.961\n",
      "epoch:  9/300 batch 114/188  Train Loss: 0.077, Acc: 0.969\n",
      "epoch:  9/300 batch 115/188  Train Loss: 0.112, Acc: 0.965\n",
      "epoch:  9/300 batch 116/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch:  9/300 batch 117/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch:  9/300 batch 118/188  Train Loss: 0.109, Acc: 0.957\n",
      "epoch:  9/300 batch 119/188  Train Loss: 0.106, Acc: 0.965\n",
      "epoch:  9/300 batch 120/188  Train Loss: 0.085, Acc: 0.977\n",
      "epoch:  9/300 batch 121/188  Train Loss: 0.117, Acc: 0.965\n",
      "epoch:  9/300 batch 122/188  Train Loss: 0.091, Acc: 0.984\n",
      "epoch:  9/300 batch 123/188  Train Loss: 0.076, Acc: 0.977\n",
      "epoch:  9/300 batch 124/188  Train Loss: 0.084, Acc: 0.973\n",
      "epoch:  9/300 batch 125/188  Train Loss: 0.075, Acc: 0.973\n",
      "epoch:  9/300 batch 126/188  Train Loss: 0.064, Acc: 0.984\n",
      "epoch:  9/300 batch 127/188  Train Loss: 0.137, Acc: 0.945\n",
      "epoch:  9/300 batch 128/188  Train Loss: 0.078, Acc: 0.969\n",
      "epoch:  9/300 batch 129/188  Train Loss: 0.087, Acc: 0.969\n",
      "epoch:  9/300 batch 130/188  Train Loss: 0.091, Acc: 0.969\n",
      "epoch:  9/300 batch 131/188  Train Loss: 0.112, Acc: 0.953\n",
      "epoch:  9/300 batch 132/188  Train Loss: 0.071, Acc: 0.977\n",
      "epoch:  9/300 batch 133/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch:  9/300 batch 134/188  Train Loss: 0.077, Acc: 0.980\n",
      "epoch:  9/300 batch 135/188  Train Loss: 0.093, Acc: 0.969\n",
      "epoch:  9/300 batch 136/188  Train Loss: 0.058, Acc: 0.992\n",
      "epoch:  9/300 batch 137/188  Train Loss: 0.091, Acc: 0.965\n",
      "epoch:  9/300 batch 138/188  Train Loss: 0.093, Acc: 0.977\n",
      "epoch:  9/300 batch 139/188  Train Loss: 0.068, Acc: 0.977\n",
      "epoch:  9/300 batch 140/188  Train Loss: 0.075, Acc: 0.969\n",
      "epoch:  9/300 batch 141/188  Train Loss: 0.085, Acc: 0.977\n",
      "epoch:  9/300 batch 142/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch:  9/300 batch 143/188  Train Loss: 0.061, Acc: 0.984\n",
      "epoch:  9/300 batch 144/188  Train Loss: 0.122, Acc: 0.980\n",
      "epoch:  9/300 batch 145/188  Train Loss: 0.098, Acc: 0.973\n",
      "epoch:  9/300 batch 146/188  Train Loss: 0.074, Acc: 0.973\n",
      "epoch:  9/300 batch 147/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch:  9/300 batch 148/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch:  9/300 batch 149/188  Train Loss: 0.133, Acc: 0.961\n",
      "epoch:  9/300 batch 150/188  Train Loss: 0.095, Acc: 0.961\n",
      "epoch:  9/300 batch 151/188  Train Loss: 0.064, Acc: 0.984\n",
      "epoch:  9/300 batch 152/188  Train Loss: 0.097, Acc: 0.969\n",
      "epoch:  9/300 batch 153/188  Train Loss: 0.075, Acc: 0.973\n",
      "epoch:  9/300 batch 154/188  Train Loss: 0.086, Acc: 0.969\n",
      "epoch:  9/300 batch 155/188  Train Loss: 0.106, Acc: 0.973\n",
      "epoch:  9/300 batch 156/188  Train Loss: 0.066, Acc: 0.980\n",
      "epoch:  9/300 batch 157/188  Train Loss: 0.051, Acc: 0.992\n",
      "epoch:  9/300 batch 158/188  Train Loss: 0.103, Acc: 0.961\n",
      "epoch:  9/300 batch 159/188  Train Loss: 0.078, Acc: 0.980\n",
      "epoch:  9/300 batch 160/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch:  9/300 batch 161/188  Train Loss: 0.137, Acc: 0.949\n",
      "epoch:  9/300 batch 162/188  Train Loss: 0.080, Acc: 0.980\n",
      "epoch:  9/300 batch 163/188  Train Loss: 0.071, Acc: 0.980\n",
      "epoch:  9/300 batch 164/188  Train Loss: 0.086, Acc: 0.969\n",
      "epoch:  9/300 batch 165/188  Train Loss: 0.086, Acc: 0.980\n",
      "epoch:  9/300 batch 166/188  Train Loss: 0.090, Acc: 0.973\n",
      "epoch:  9/300 batch 167/188  Train Loss: 0.067, Acc: 0.988\n",
      "epoch:  9/300 batch 168/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch:  9/300 batch 169/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch:  9/300 batch 170/188  Train Loss: 0.079, Acc: 0.965\n",
      "epoch:  9/300 batch 171/188  Train Loss: 0.061, Acc: 0.988\n",
      "epoch:  9/300 batch 172/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch:  9/300 batch 173/188  Train Loss: 0.128, Acc: 0.961\n",
      "epoch:  9/300 batch 174/188  Train Loss: 0.117, Acc: 0.969\n",
      "epoch:  9/300 batch 175/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch:  9/300 batch 176/188  Train Loss: 0.058, Acc: 0.980\n",
      "epoch:  9/300 batch 177/188  Train Loss: 0.087, Acc: 0.973\n",
      "epoch:  9/300 batch 178/188  Train Loss: 0.123, Acc: 0.969\n",
      "epoch:  9/300 batch 179/188  Train Loss: 0.115, Acc: 0.977\n",
      "epoch:  9/300 batch 180/188  Train Loss: 0.079, Acc: 0.969\n",
      "epoch:  9/300 batch 181/188  Train Loss: 0.077, Acc: 0.980\n",
      "epoch:  9/300 batch 182/188  Train Loss: 0.068, Acc: 0.984\n",
      "epoch:  9/300 batch 183/188  Train Loss: 0.055, Acc: 0.980\n",
      "epoch:  9/300 batch 184/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch:  9/300 batch 185/188  Train Loss: 0.079, Acc: 0.973\n",
      "epoch:  9/300 batch 186/188  Train Loss: 0.090, Acc: 0.977\n",
      "epoch:  9/300 batch 187/188  Train Loss: 0.049, Acc: 0.992\n",
      "Train Loss: 0.081322, Acc: 0.975\n",
      "Val Loss: 0.081009, Acc: 0.976\n",
      "epoch: 10/300 batch   0/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 10/300 batch   1/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 10/300 batch   2/188  Train Loss: 0.078, Acc: 0.984\n",
      "epoch: 10/300 batch   3/188  Train Loss: 0.058, Acc: 0.980\n",
      "epoch: 10/300 batch   4/188  Train Loss: 0.062, Acc: 0.992\n",
      "epoch: 10/300 batch   5/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 10/300 batch   6/188  Train Loss: 0.063, Acc: 0.980\n",
      "epoch: 10/300 batch   7/188  Train Loss: 0.078, Acc: 0.965\n",
      "epoch: 10/300 batch   8/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 10/300 batch   9/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 10/300 batch  10/188  Train Loss: 0.083, Acc: 0.980\n",
      "epoch: 10/300 batch  11/188  Train Loss: 0.056, Acc: 0.980\n",
      "epoch: 10/300 batch  12/188  Train Loss: 0.076, Acc: 0.980\n",
      "epoch: 10/300 batch  13/188  Train Loss: 0.067, Acc: 0.977\n",
      "epoch: 10/300 batch  14/188  Train Loss: 0.067, Acc: 0.984\n",
      "epoch: 10/300 batch  15/188  Train Loss: 0.080, Acc: 0.969\n",
      "epoch: 10/300 batch  16/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 10/300 batch  17/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 10/300 batch  18/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 10/300 batch  19/188  Train Loss: 0.087, Acc: 0.980\n",
      "epoch: 10/300 batch  20/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 10/300 batch  21/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 10/300 batch  22/188  Train Loss: 0.078, Acc: 0.984\n",
      "epoch: 10/300 batch  23/188  Train Loss: 0.056, Acc: 0.988\n",
      "epoch: 10/300 batch  24/188  Train Loss: 0.106, Acc: 0.973\n",
      "epoch: 10/300 batch  25/188  Train Loss: 0.056, Acc: 0.980\n",
      "epoch: 10/300 batch  26/188  Train Loss: 0.061, Acc: 0.988\n",
      "epoch: 10/300 batch  27/188  Train Loss: 0.090, Acc: 0.969\n",
      "epoch: 10/300 batch  28/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 10/300 batch  29/188  Train Loss: 0.071, Acc: 0.984\n",
      "epoch: 10/300 batch  30/188  Train Loss: 0.164, Acc: 0.965\n",
      "epoch: 10/300 batch  31/188  Train Loss: 0.070, Acc: 0.980\n",
      "epoch: 10/300 batch  32/188  Train Loss: 0.085, Acc: 0.977\n",
      "epoch: 10/300 batch  33/188  Train Loss: 0.058, Acc: 0.977\n",
      "epoch: 10/300 batch  34/188  Train Loss: 0.089, Acc: 0.973\n",
      "epoch: 10/300 batch  35/188  Train Loss: 0.069, Acc: 0.977\n",
      "epoch: 10/300 batch  36/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 10/300 batch  37/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 10/300 batch  38/188  Train Loss: 0.065, Acc: 0.977\n",
      "epoch: 10/300 batch  39/188  Train Loss: 0.110, Acc: 0.961\n",
      "epoch: 10/300 batch  40/188  Train Loss: 0.091, Acc: 0.969\n",
      "epoch: 10/300 batch  41/188  Train Loss: 0.077, Acc: 0.977\n",
      "epoch: 10/300 batch  42/188  Train Loss: 0.065, Acc: 0.984\n",
      "epoch: 10/300 batch  43/188  Train Loss: 0.050, Acc: 0.980\n",
      "epoch: 10/300 batch  44/188  Train Loss: 0.071, Acc: 0.980\n",
      "epoch: 10/300 batch  45/188  Train Loss: 0.101, Acc: 0.973\n",
      "epoch: 10/300 batch  46/188  Train Loss: 0.123, Acc: 0.977\n",
      "epoch: 10/300 batch  47/188  Train Loss: 0.070, Acc: 0.977\n",
      "epoch: 10/300 batch  48/188  Train Loss: 0.066, Acc: 0.980\n",
      "epoch: 10/300 batch  49/188  Train Loss: 0.099, Acc: 0.965\n",
      "epoch: 10/300 batch  50/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 10/300 batch  51/188  Train Loss: 0.105, Acc: 0.961\n",
      "epoch: 10/300 batch  52/188  Train Loss: 0.070, Acc: 0.973\n",
      "epoch: 10/300 batch  53/188  Train Loss: 0.069, Acc: 0.977\n",
      "epoch: 10/300 batch  54/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 10/300 batch  55/188  Train Loss: 0.074, Acc: 0.965\n",
      "epoch: 10/300 batch  56/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 10/300 batch  57/188  Train Loss: 0.084, Acc: 0.965\n",
      "epoch: 10/300 batch  58/188  Train Loss: 0.093, Acc: 0.969\n",
      "epoch: 10/300 batch  59/188  Train Loss: 0.076, Acc: 0.980\n",
      "epoch: 10/300 batch  60/188  Train Loss: 0.071, Acc: 0.977\n",
      "epoch: 10/300 batch  61/188  Train Loss: 0.106, Acc: 0.957\n",
      "epoch: 10/300 batch  62/188  Train Loss: 0.059, Acc: 0.988\n",
      "epoch: 10/300 batch  63/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 10/300 batch  64/188  Train Loss: 0.070, Acc: 0.973\n",
      "epoch: 10/300 batch  65/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 10/300 batch  66/188  Train Loss: 0.062, Acc: 0.973\n",
      "epoch: 10/300 batch  67/188  Train Loss: 0.087, Acc: 0.977\n",
      "epoch: 10/300 batch  68/188  Train Loss: 0.078, Acc: 0.980\n",
      "epoch: 10/300 batch  69/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 10/300 batch  70/188  Train Loss: 0.107, Acc: 0.965\n",
      "epoch: 10/300 batch  71/188  Train Loss: 0.120, Acc: 0.957\n",
      "epoch: 10/300 batch  72/188  Train Loss: 0.091, Acc: 0.984\n",
      "epoch: 10/300 batch  73/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 10/300 batch  74/188  Train Loss: 0.074, Acc: 0.977\n",
      "epoch: 10/300 batch  75/188  Train Loss: 0.134, Acc: 0.980\n",
      "epoch: 10/300 batch  76/188  Train Loss: 0.158, Acc: 0.957\n",
      "epoch: 10/300 batch  77/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 10/300 batch  78/188  Train Loss: 0.083, Acc: 0.977\n",
      "epoch: 10/300 batch  79/188  Train Loss: 0.082, Acc: 0.973\n",
      "epoch: 10/300 batch  80/188  Train Loss: 0.087, Acc: 0.969\n",
      "epoch: 10/300 batch  81/188  Train Loss: 0.094, Acc: 0.969\n",
      "epoch: 10/300 batch  82/188  Train Loss: 0.120, Acc: 0.953\n",
      "epoch: 10/300 batch  83/188  Train Loss: 0.094, Acc: 0.965\n",
      "epoch: 10/300 batch  84/188  Train Loss: 0.082, Acc: 0.961\n",
      "epoch: 10/300 batch  85/188  Train Loss: 0.088, Acc: 0.977\n",
      "epoch: 10/300 batch  86/188  Train Loss: 0.070, Acc: 0.977\n",
      "epoch: 10/300 batch  87/188  Train Loss: 0.144, Acc: 0.957\n",
      "epoch: 10/300 batch  88/188  Train Loss: 0.062, Acc: 0.980\n",
      "epoch: 10/300 batch  89/188  Train Loss: 0.072, Acc: 0.980\n",
      "epoch: 10/300 batch  90/188  Train Loss: 0.119, Acc: 0.973\n",
      "epoch: 10/300 batch  91/188  Train Loss: 0.151, Acc: 0.957\n",
      "epoch: 10/300 batch  92/188  Train Loss: 0.090, Acc: 0.969\n",
      "epoch: 10/300 batch  93/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 10/300 batch  94/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 10/300 batch  95/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 10/300 batch  96/188  Train Loss: 0.075, Acc: 0.973\n",
      "epoch: 10/300 batch  97/188  Train Loss: 0.121, Acc: 0.957\n",
      "epoch: 10/300 batch  98/188  Train Loss: 0.054, Acc: 0.980\n",
      "epoch: 10/300 batch  99/188  Train Loss: 0.071, Acc: 0.965\n",
      "epoch: 10/300 batch 100/188  Train Loss: 0.071, Acc: 0.977\n",
      "epoch: 10/300 batch 101/188  Train Loss: 0.080, Acc: 0.977\n",
      "epoch: 10/300 batch 102/188  Train Loss: 0.138, Acc: 0.969\n",
      "epoch: 10/300 batch 103/188  Train Loss: 0.085, Acc: 0.969\n",
      "epoch: 10/300 batch 104/188  Train Loss: 0.071, Acc: 0.977\n",
      "epoch: 10/300 batch 105/188  Train Loss: 0.120, Acc: 0.973\n",
      "epoch: 10/300 batch 106/188  Train Loss: 0.079, Acc: 0.980\n",
      "epoch: 10/300 batch 107/188  Train Loss: 0.106, Acc: 0.969\n",
      "epoch: 10/300 batch 108/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 10/300 batch 109/188  Train Loss: 0.144, Acc: 0.961\n",
      "epoch: 10/300 batch 110/188  Train Loss: 0.084, Acc: 0.965\n",
      "epoch: 10/300 batch 111/188  Train Loss: 0.078, Acc: 0.973\n",
      "epoch: 10/300 batch 112/188  Train Loss: 0.068, Acc: 0.969\n",
      "epoch: 10/300 batch 113/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 10/300 batch 114/188  Train Loss: 0.061, Acc: 0.980\n",
      "epoch: 10/300 batch 115/188  Train Loss: 0.098, Acc: 0.973\n",
      "epoch: 10/300 batch 116/188  Train Loss: 0.093, Acc: 0.969\n",
      "epoch: 10/300 batch 117/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 10/300 batch 118/188  Train Loss: 0.085, Acc: 0.973\n",
      "epoch: 10/300 batch 119/188  Train Loss: 0.137, Acc: 0.961\n",
      "epoch: 10/300 batch 120/188  Train Loss: 0.110, Acc: 0.969\n",
      "epoch: 10/300 batch 121/188  Train Loss: 0.096, Acc: 0.973\n",
      "epoch: 10/300 batch 122/188  Train Loss: 0.102, Acc: 0.973\n",
      "epoch: 10/300 batch 123/188  Train Loss: 0.156, Acc: 0.957\n",
      "epoch: 10/300 batch 124/188  Train Loss: 0.080, Acc: 0.973\n",
      "epoch: 10/300 batch 125/188  Train Loss: 0.075, Acc: 0.973\n",
      "epoch: 10/300 batch 126/188  Train Loss: 0.117, Acc: 0.957\n",
      "epoch: 10/300 batch 127/188  Train Loss: 0.068, Acc: 0.984\n",
      "epoch: 10/300 batch 128/188  Train Loss: 0.059, Acc: 0.988\n",
      "epoch: 10/300 batch 129/188  Train Loss: 0.084, Acc: 0.977\n",
      "epoch: 10/300 batch 130/188  Train Loss: 0.091, Acc: 0.980\n",
      "epoch: 10/300 batch 131/188  Train Loss: 0.109, Acc: 0.965\n",
      "epoch: 10/300 batch 132/188  Train Loss: 0.101, Acc: 0.977\n",
      "epoch: 10/300 batch 133/188  Train Loss: 0.086, Acc: 0.973\n",
      "epoch: 10/300 batch 134/188  Train Loss: 0.149, Acc: 0.961\n",
      "epoch: 10/300 batch 135/188  Train Loss: 0.125, Acc: 0.965\n",
      "epoch: 10/300 batch 136/188  Train Loss: 0.093, Acc: 0.969\n",
      "epoch: 10/300 batch 137/188  Train Loss: 0.060, Acc: 0.980\n",
      "epoch: 10/300 batch 138/188  Train Loss: 0.085, Acc: 0.980\n",
      "epoch: 10/300 batch 139/188  Train Loss: 0.096, Acc: 0.969\n",
      "epoch: 10/300 batch 140/188  Train Loss: 0.069, Acc: 0.988\n",
      "epoch: 10/300 batch 141/188  Train Loss: 0.117, Acc: 0.953\n",
      "epoch: 10/300 batch 142/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 10/300 batch 143/188  Train Loss: 0.094, Acc: 0.973\n",
      "epoch: 10/300 batch 144/188  Train Loss: 0.101, Acc: 0.961\n",
      "epoch: 10/300 batch 145/188  Train Loss: 0.076, Acc: 0.977\n",
      "epoch: 10/300 batch 146/188  Train Loss: 0.068, Acc: 0.973\n",
      "epoch: 10/300 batch 147/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 10/300 batch 148/188  Train Loss: 0.090, Acc: 0.980\n",
      "epoch: 10/300 batch 149/188  Train Loss: 0.077, Acc: 0.977\n",
      "epoch: 10/300 batch 150/188  Train Loss: 0.075, Acc: 0.973\n",
      "epoch: 10/300 batch 151/188  Train Loss: 0.106, Acc: 0.965\n",
      "epoch: 10/300 batch 152/188  Train Loss: 0.119, Acc: 0.949\n",
      "epoch: 10/300 batch 153/188  Train Loss: 0.058, Acc: 0.977\n",
      "epoch: 10/300 batch 154/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 10/300 batch 155/188  Train Loss: 0.097, Acc: 0.965\n",
      "epoch: 10/300 batch 156/188  Train Loss: 0.116, Acc: 0.977\n",
      "epoch: 10/300 batch 157/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 10/300 batch 158/188  Train Loss: 0.140, Acc: 0.973\n",
      "epoch: 10/300 batch 159/188  Train Loss: 0.094, Acc: 0.969\n",
      "epoch: 10/300 batch 160/188  Train Loss: 0.064, Acc: 0.984\n",
      "epoch: 10/300 batch 161/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 10/300 batch 162/188  Train Loss: 0.062, Acc: 0.961\n",
      "epoch: 10/300 batch 163/188  Train Loss: 0.132, Acc: 0.957\n",
      "epoch: 10/300 batch 164/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 10/300 batch 165/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 10/300 batch 166/188  Train Loss: 0.060, Acc: 0.980\n",
      "epoch: 10/300 batch 167/188  Train Loss: 0.072, Acc: 0.973\n",
      "epoch: 10/300 batch 168/188  Train Loss: 0.056, Acc: 0.977\n",
      "epoch: 10/300 batch 169/188  Train Loss: 0.083, Acc: 0.973\n",
      "epoch: 10/300 batch 170/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 10/300 batch 171/188  Train Loss: 0.066, Acc: 0.980\n",
      "epoch: 10/300 batch 172/188  Train Loss: 0.101, Acc: 0.965\n",
      "epoch: 10/300 batch 173/188  Train Loss: 0.101, Acc: 0.961\n",
      "epoch: 10/300 batch 174/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 10/300 batch 175/188  Train Loss: 0.112, Acc: 0.965\n",
      "epoch: 10/300 batch 176/188  Train Loss: 0.065, Acc: 0.969\n",
      "epoch: 10/300 batch 177/188  Train Loss: 0.110, Acc: 0.965\n",
      "epoch: 10/300 batch 178/188  Train Loss: 0.105, Acc: 0.965\n",
      "epoch: 10/300 batch 179/188  Train Loss: 0.083, Acc: 0.977\n",
      "epoch: 10/300 batch 180/188  Train Loss: 0.059, Acc: 0.984\n",
      "epoch: 10/300 batch 181/188  Train Loss: 0.140, Acc: 0.953\n",
      "epoch: 10/300 batch 182/188  Train Loss: 0.092, Acc: 0.973\n",
      "epoch: 10/300 batch 183/188  Train Loss: 0.068, Acc: 0.977\n",
      "epoch: 10/300 batch 184/188  Train Loss: 0.100, Acc: 0.953\n",
      "epoch: 10/300 batch 185/188  Train Loss: 0.085, Acc: 0.961\n",
      "epoch: 10/300 batch 186/188  Train Loss: 0.110, Acc: 0.965\n",
      "epoch: 10/300 batch 187/188  Train Loss: 0.106, Acc: 0.961\n",
      "Train Loss: 0.080501, Acc: 0.975\n",
      "Val Loss: 0.082079, Acc: 0.975\n",
      "epoch: 11/300 batch   0/188  Train Loss: 0.068, Acc: 0.980\n",
      "epoch: 11/300 batch   1/188  Train Loss: 0.082, Acc: 0.977\n",
      "epoch: 11/300 batch   2/188  Train Loss: 0.087, Acc: 0.980\n",
      "epoch: 11/300 batch   3/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 11/300 batch   4/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 11/300 batch   5/188  Train Loss: 0.078, Acc: 0.984\n",
      "epoch: 11/300 batch   6/188  Train Loss: 0.060, Acc: 0.977\n",
      "epoch: 11/300 batch   7/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 11/300 batch   8/188  Train Loss: 0.066, Acc: 0.988\n",
      "epoch: 11/300 batch   9/188  Train Loss: 0.054, Acc: 0.996\n",
      "epoch: 11/300 batch  10/188  Train Loss: 0.061, Acc: 0.984\n",
      "epoch: 11/300 batch  11/188  Train Loss: 0.078, Acc: 0.977\n",
      "epoch: 11/300 batch  12/188  Train Loss: 0.067, Acc: 0.988\n",
      "epoch: 11/300 batch  13/188  Train Loss: 0.082, Acc: 0.977\n",
      "epoch: 11/300 batch  14/188  Train Loss: 0.084, Acc: 0.965\n",
      "epoch: 11/300 batch  15/188  Train Loss: 0.088, Acc: 0.977\n",
      "epoch: 11/300 batch  16/188  Train Loss: 0.066, Acc: 0.984\n",
      "epoch: 11/300 batch  17/188  Train Loss: 0.068, Acc: 0.984\n",
      "epoch: 11/300 batch  18/188  Train Loss: 0.054, Acc: 0.980\n",
      "epoch: 11/300 batch  19/188  Train Loss: 0.056, Acc: 0.977\n",
      "epoch: 11/300 batch  20/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 11/300 batch  21/188  Train Loss: 0.061, Acc: 0.977\n",
      "epoch: 11/300 batch  22/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 11/300 batch  23/188  Train Loss: 0.097, Acc: 0.973\n",
      "epoch: 11/300 batch  24/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 11/300 batch  25/188  Train Loss: 0.060, Acc: 0.977\n",
      "epoch: 11/300 batch  26/188  Train Loss: 0.104, Acc: 0.969\n",
      "epoch: 11/300 batch  27/188  Train Loss: 0.054, Acc: 0.980\n",
      "epoch: 11/300 batch  28/188  Train Loss: 0.076, Acc: 0.973\n",
      "epoch: 11/300 batch  29/188  Train Loss: 0.093, Acc: 0.965\n",
      "epoch: 11/300 batch  30/188  Train Loss: 0.099, Acc: 0.973\n",
      "epoch: 11/300 batch  31/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 11/300 batch  32/188  Train Loss: 0.085, Acc: 0.984\n",
      "epoch: 11/300 batch  33/188  Train Loss: 0.103, Acc: 0.965\n",
      "epoch: 11/300 batch  34/188  Train Loss: 0.081, Acc: 0.977\n",
      "epoch: 11/300 batch  35/188  Train Loss: 0.070, Acc: 0.977\n",
      "epoch: 11/300 batch  36/188  Train Loss: 0.104, Acc: 0.961\n",
      "epoch: 11/300 batch  37/188  Train Loss: 0.089, Acc: 0.973\n",
      "epoch: 11/300 batch  38/188  Train Loss: 0.082, Acc: 0.977\n",
      "epoch: 11/300 batch  39/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 11/300 batch  40/188  Train Loss: 0.093, Acc: 0.969\n",
      "epoch: 11/300 batch  41/188  Train Loss: 0.089, Acc: 0.988\n",
      "epoch: 11/300 batch  42/188  Train Loss: 0.057, Acc: 0.988\n",
      "epoch: 11/300 batch  43/188  Train Loss: 0.054, Acc: 0.977\n",
      "epoch: 11/300 batch  44/188  Train Loss: 0.062, Acc: 0.988\n",
      "epoch: 11/300 batch  45/188  Train Loss: 0.101, Acc: 0.961\n",
      "epoch: 11/300 batch  46/188  Train Loss: 0.099, Acc: 0.973\n",
      "epoch: 11/300 batch  47/188  Train Loss: 0.069, Acc: 0.977\n",
      "epoch: 11/300 batch  48/188  Train Loss: 0.080, Acc: 0.977\n",
      "epoch: 11/300 batch  49/188  Train Loss: 0.102, Acc: 0.969\n",
      "epoch: 11/300 batch  50/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 11/300 batch  51/188  Train Loss: 0.091, Acc: 0.965\n",
      "epoch: 11/300 batch  52/188  Train Loss: 0.063, Acc: 0.980\n",
      "epoch: 11/300 batch  53/188  Train Loss: 0.089, Acc: 0.965\n",
      "epoch: 11/300 batch  54/188  Train Loss: 0.102, Acc: 0.977\n",
      "epoch: 11/300 batch  55/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 11/300 batch  56/188  Train Loss: 0.058, Acc: 0.980\n",
      "epoch: 11/300 batch  57/188  Train Loss: 0.067, Acc: 0.973\n",
      "epoch: 11/300 batch  58/188  Train Loss: 0.120, Acc: 0.961\n",
      "epoch: 11/300 batch  59/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 11/300 batch  60/188  Train Loss: 0.068, Acc: 0.980\n",
      "epoch: 11/300 batch  61/188  Train Loss: 0.129, Acc: 0.969\n",
      "epoch: 11/300 batch  62/188  Train Loss: 0.128, Acc: 0.965\n",
      "epoch: 11/300 batch  63/188  Train Loss: 0.055, Acc: 0.980\n",
      "epoch: 11/300 batch  64/188  Train Loss: 0.096, Acc: 0.984\n",
      "epoch: 11/300 batch  65/188  Train Loss: 0.070, Acc: 0.973\n",
      "epoch: 11/300 batch  66/188  Train Loss: 0.085, Acc: 0.984\n",
      "epoch: 11/300 batch  67/188  Train Loss: 0.061, Acc: 0.984\n",
      "epoch: 11/300 batch  68/188  Train Loss: 0.061, Acc: 0.988\n",
      "epoch: 11/300 batch  69/188  Train Loss: 0.088, Acc: 0.980\n",
      "epoch: 11/300 batch  70/188  Train Loss: 0.118, Acc: 0.961\n",
      "epoch: 11/300 batch  71/188  Train Loss: 0.078, Acc: 0.969\n",
      "epoch: 11/300 batch  72/188  Train Loss: 0.078, Acc: 0.984\n",
      "epoch: 11/300 batch  73/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 11/300 batch  74/188  Train Loss: 0.073, Acc: 0.984\n",
      "epoch: 11/300 batch  75/188  Train Loss: 0.057, Acc: 0.980\n",
      "epoch: 11/300 batch  76/188  Train Loss: 0.061, Acc: 0.984\n",
      "epoch: 11/300 batch  77/188  Train Loss: 0.078, Acc: 0.980\n",
      "epoch: 11/300 batch  78/188  Train Loss: 0.104, Acc: 0.965\n",
      "epoch: 11/300 batch  79/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 11/300 batch  80/188  Train Loss: 0.104, Acc: 0.965\n",
      "epoch: 11/300 batch  81/188  Train Loss: 0.056, Acc: 0.988\n",
      "epoch: 11/300 batch  82/188  Train Loss: 0.081, Acc: 0.973\n",
      "epoch: 11/300 batch  83/188  Train Loss: 0.102, Acc: 0.969\n",
      "epoch: 11/300 batch  84/188  Train Loss: 0.068, Acc: 0.984\n",
      "epoch: 11/300 batch  85/188  Train Loss: 0.069, Acc: 0.969\n",
      "epoch: 11/300 batch  86/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 11/300 batch  87/188  Train Loss: 0.099, Acc: 0.961\n",
      "epoch: 11/300 batch  88/188  Train Loss: 0.064, Acc: 0.973\n",
      "epoch: 11/300 batch  89/188  Train Loss: 0.093, Acc: 0.973\n",
      "epoch: 11/300 batch  90/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 11/300 batch  91/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 11/300 batch  92/188  Train Loss: 0.078, Acc: 0.977\n",
      "epoch: 11/300 batch  93/188  Train Loss: 0.132, Acc: 0.957\n",
      "epoch: 11/300 batch  94/188  Train Loss: 0.099, Acc: 0.965\n",
      "epoch: 11/300 batch  95/188  Train Loss: 0.047, Acc: 0.980\n",
      "epoch: 11/300 batch  96/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 11/300 batch  97/188  Train Loss: 0.107, Acc: 0.961\n",
      "epoch: 11/300 batch  98/188  Train Loss: 0.097, Acc: 0.969\n",
      "epoch: 11/300 batch  99/188  Train Loss: 0.110, Acc: 0.973\n",
      "epoch: 11/300 batch 100/188  Train Loss: 0.058, Acc: 0.965\n",
      "epoch: 11/300 batch 101/188  Train Loss: 0.068, Acc: 0.992\n",
      "epoch: 11/300 batch 102/188  Train Loss: 0.073, Acc: 0.977\n",
      "epoch: 11/300 batch 103/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 11/300 batch 104/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 11/300 batch 105/188  Train Loss: 0.072, Acc: 0.980\n",
      "epoch: 11/300 batch 106/188  Train Loss: 0.087, Acc: 0.965\n",
      "epoch: 11/300 batch 107/188  Train Loss: 0.080, Acc: 0.973\n",
      "epoch: 11/300 batch 108/188  Train Loss: 0.097, Acc: 0.973\n",
      "epoch: 11/300 batch 109/188  Train Loss: 0.063, Acc: 0.977\n",
      "epoch: 11/300 batch 110/188  Train Loss: 0.099, Acc: 0.957\n",
      "epoch: 11/300 batch 111/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 11/300 batch 112/188  Train Loss: 0.063, Acc: 0.984\n",
      "epoch: 11/300 batch 113/188  Train Loss: 0.065, Acc: 0.980\n",
      "epoch: 11/300 batch 114/188  Train Loss: 0.073, Acc: 0.969\n",
      "epoch: 11/300 batch 115/188  Train Loss: 0.069, Acc: 0.969\n",
      "epoch: 11/300 batch 116/188  Train Loss: 0.080, Acc: 0.980\n",
      "epoch: 11/300 batch 117/188  Train Loss: 0.083, Acc: 0.977\n",
      "epoch: 11/300 batch 118/188  Train Loss: 0.051, Acc: 0.980\n",
      "epoch: 11/300 batch 119/188  Train Loss: 0.067, Acc: 0.973\n",
      "epoch: 11/300 batch 120/188  Train Loss: 0.063, Acc: 0.980\n",
      "epoch: 11/300 batch 121/188  Train Loss: 0.086, Acc: 0.980\n",
      "epoch: 11/300 batch 122/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 11/300 batch 123/188  Train Loss: 0.059, Acc: 0.984\n",
      "epoch: 11/300 batch 124/188  Train Loss: 0.089, Acc: 0.973\n",
      "epoch: 11/300 batch 125/188  Train Loss: 0.125, Acc: 0.965\n",
      "epoch: 11/300 batch 126/188  Train Loss: 0.112, Acc: 0.965\n",
      "epoch: 11/300 batch 127/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 11/300 batch 128/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 11/300 batch 129/188  Train Loss: 0.121, Acc: 0.961\n",
      "epoch: 11/300 batch 130/188  Train Loss: 0.084, Acc: 0.977\n",
      "epoch: 11/300 batch 131/188  Train Loss: 0.110, Acc: 0.988\n",
      "epoch: 11/300 batch 132/188  Train Loss: 0.097, Acc: 0.977\n",
      "epoch: 11/300 batch 133/188  Train Loss: 0.054, Acc: 0.980\n",
      "epoch: 11/300 batch 134/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 11/300 batch 135/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 11/300 batch 136/188  Train Loss: 0.138, Acc: 0.965\n",
      "epoch: 11/300 batch 137/188  Train Loss: 0.081, Acc: 0.973\n",
      "epoch: 11/300 batch 138/188  Train Loss: 0.153, Acc: 0.961\n",
      "epoch: 11/300 batch 139/188  Train Loss: 0.123, Acc: 0.961\n",
      "epoch: 11/300 batch 140/188  Train Loss: 0.072, Acc: 0.973\n",
      "epoch: 11/300 batch 141/188  Train Loss: 0.075, Acc: 0.977\n",
      "epoch: 11/300 batch 142/188  Train Loss: 0.058, Acc: 0.992\n",
      "epoch: 11/300 batch 143/188  Train Loss: 0.109, Acc: 0.953\n",
      "epoch: 11/300 batch 144/188  Train Loss: 0.069, Acc: 0.977\n",
      "epoch: 11/300 batch 145/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 11/300 batch 146/188  Train Loss: 0.051, Acc: 0.996\n",
      "epoch: 11/300 batch 147/188  Train Loss: 0.106, Acc: 0.961\n",
      "epoch: 11/300 batch 148/188  Train Loss: 0.074, Acc: 0.984\n",
      "epoch: 11/300 batch 149/188  Train Loss: 0.052, Acc: 0.992\n",
      "epoch: 11/300 batch 150/188  Train Loss: 0.078, Acc: 0.977\n",
      "epoch: 11/300 batch 151/188  Train Loss: 0.100, Acc: 0.969\n",
      "epoch: 11/300 batch 152/188  Train Loss: 0.061, Acc: 0.977\n",
      "epoch: 11/300 batch 153/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 11/300 batch 154/188  Train Loss: 0.087, Acc: 0.957\n",
      "epoch: 11/300 batch 155/188  Train Loss: 0.130, Acc: 0.961\n",
      "epoch: 11/300 batch 156/188  Train Loss: 0.079, Acc: 0.977\n",
      "epoch: 11/300 batch 157/188  Train Loss: 0.063, Acc: 0.977\n",
      "epoch: 11/300 batch 158/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 11/300 batch 159/188  Train Loss: 0.121, Acc: 0.965\n",
      "epoch: 11/300 batch 160/188  Train Loss: 0.097, Acc: 0.980\n",
      "epoch: 11/300 batch 161/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 11/300 batch 162/188  Train Loss: 0.099, Acc: 0.969\n",
      "epoch: 11/300 batch 163/188  Train Loss: 0.081, Acc: 0.984\n",
      "epoch: 11/300 batch 164/188  Train Loss: 0.066, Acc: 0.980\n",
      "epoch: 11/300 batch 165/188  Train Loss: 0.104, Acc: 0.965\n",
      "epoch: 11/300 batch 166/188  Train Loss: 0.077, Acc: 0.977\n",
      "epoch: 11/300 batch 167/188  Train Loss: 0.069, Acc: 0.980\n",
      "epoch: 11/300 batch 168/188  Train Loss: 0.093, Acc: 0.977\n",
      "epoch: 11/300 batch 169/188  Train Loss: 0.099, Acc: 0.973\n",
      "epoch: 11/300 batch 170/188  Train Loss: 0.095, Acc: 0.969\n",
      "epoch: 11/300 batch 171/188  Train Loss: 0.101, Acc: 0.961\n",
      "epoch: 11/300 batch 172/188  Train Loss: 0.088, Acc: 0.969\n",
      "epoch: 11/300 batch 173/188  Train Loss: 0.062, Acc: 0.984\n",
      "epoch: 11/300 batch 174/188  Train Loss: 0.053, Acc: 0.977\n",
      "epoch: 11/300 batch 175/188  Train Loss: 0.083, Acc: 0.969\n",
      "epoch: 11/300 batch 176/188  Train Loss: 0.103, Acc: 0.965\n",
      "epoch: 11/300 batch 177/188  Train Loss: 0.111, Acc: 0.977\n",
      "epoch: 11/300 batch 178/188  Train Loss: 0.124, Acc: 0.973\n",
      "epoch: 11/300 batch 179/188  Train Loss: 0.137, Acc: 0.965\n",
      "epoch: 11/300 batch 180/188  Train Loss: 0.064, Acc: 0.977\n",
      "epoch: 11/300 batch 181/188  Train Loss: 0.125, Acc: 0.957\n",
      "epoch: 11/300 batch 182/188  Train Loss: 0.061, Acc: 0.980\n",
      "epoch: 11/300 batch 183/188  Train Loss: 0.138, Acc: 0.945\n",
      "epoch: 11/300 batch 184/188  Train Loss: 0.073, Acc: 0.973\n",
      "epoch: 11/300 batch 185/188  Train Loss: 0.073, Acc: 0.984\n",
      "epoch: 11/300 batch 186/188  Train Loss: 0.102, Acc: 0.965\n",
      "epoch: 11/300 batch 187/188  Train Loss: 0.147, Acc: 0.969\n",
      "Train Loss: 0.078476, Acc: 0.976\n",
      "Val Loss: 0.085081, Acc: 0.975\n",
      "epoch: 12/300 batch   0/188  Train Loss: 0.066, Acc: 0.980\n",
      "epoch: 12/300 batch   1/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 12/300 batch   2/188  Train Loss: 0.033, Acc: 1.000\n",
      "epoch: 12/300 batch   3/188  Train Loss: 0.071, Acc: 0.977\n",
      "epoch: 12/300 batch   4/188  Train Loss: 0.067, Acc: 0.980\n",
      "epoch: 12/300 batch   5/188  Train Loss: 0.080, Acc: 0.969\n",
      "epoch: 12/300 batch   6/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 12/300 batch   7/188  Train Loss: 0.108, Acc: 0.973\n",
      "epoch: 12/300 batch   8/188  Train Loss: 0.096, Acc: 0.969\n",
      "epoch: 12/300 batch   9/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 12/300 batch  10/188  Train Loss: 0.060, Acc: 0.984\n",
      "epoch: 12/300 batch  11/188  Train Loss: 0.101, Acc: 0.969\n",
      "epoch: 12/300 batch  12/188  Train Loss: 0.071, Acc: 0.977\n",
      "epoch: 12/300 batch  13/188  Train Loss: 0.108, Acc: 0.965\n",
      "epoch: 12/300 batch  14/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 12/300 batch  15/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 12/300 batch  16/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 12/300 batch  17/188  Train Loss: 0.085, Acc: 0.969\n",
      "epoch: 12/300 batch  18/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 12/300 batch  19/188  Train Loss: 0.073, Acc: 0.977\n",
      "epoch: 12/300 batch  20/188  Train Loss: 0.097, Acc: 0.965\n",
      "epoch: 12/300 batch  21/188  Train Loss: 0.066, Acc: 0.969\n",
      "epoch: 12/300 batch  22/188  Train Loss: 0.062, Acc: 0.977\n",
      "epoch: 12/300 batch  23/188  Train Loss: 0.090, Acc: 0.973\n",
      "epoch: 12/300 batch  24/188  Train Loss: 0.066, Acc: 0.984\n",
      "epoch: 12/300 batch  25/188  Train Loss: 0.054, Acc: 0.980\n",
      "epoch: 12/300 batch  26/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 12/300 batch  27/188  Train Loss: 0.067, Acc: 0.980\n",
      "epoch: 12/300 batch  28/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 12/300 batch  29/188  Train Loss: 0.063, Acc: 0.980\n",
      "epoch: 12/300 batch  30/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 12/300 batch  31/188  Train Loss: 0.074, Acc: 0.980\n",
      "epoch: 12/300 batch  32/188  Train Loss: 0.100, Acc: 0.977\n",
      "epoch: 12/300 batch  33/188  Train Loss: 0.079, Acc: 0.973\n",
      "epoch: 12/300 batch  34/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 12/300 batch  35/188  Train Loss: 0.064, Acc: 0.980\n",
      "epoch: 12/300 batch  36/188  Train Loss: 0.066, Acc: 0.973\n",
      "epoch: 12/300 batch  37/188  Train Loss: 0.077, Acc: 0.969\n",
      "epoch: 12/300 batch  38/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 12/300 batch  39/188  Train Loss: 0.075, Acc: 0.988\n",
      "epoch: 12/300 batch  40/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 12/300 batch  41/188  Train Loss: 0.057, Acc: 0.988\n",
      "epoch: 12/300 batch  42/188  Train Loss: 0.093, Acc: 0.969\n",
      "epoch: 12/300 batch  43/188  Train Loss: 0.082, Acc: 0.961\n",
      "epoch: 12/300 batch  44/188  Train Loss: 0.185, Acc: 0.957\n",
      "epoch: 12/300 batch  45/188  Train Loss: 0.057, Acc: 0.980\n",
      "epoch: 12/300 batch  46/188  Train Loss: 0.107, Acc: 0.980\n",
      "epoch: 12/300 batch  47/188  Train Loss: 0.097, Acc: 0.969\n",
      "epoch: 12/300 batch  48/188  Train Loss: 0.061, Acc: 0.973\n",
      "epoch: 12/300 batch  49/188  Train Loss: 0.085, Acc: 0.969\n",
      "epoch: 12/300 batch  50/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 12/300 batch  51/188  Train Loss: 0.091, Acc: 0.965\n",
      "epoch: 12/300 batch  52/188  Train Loss: 0.071, Acc: 0.984\n",
      "epoch: 12/300 batch  53/188  Train Loss: 0.077, Acc: 0.969\n",
      "epoch: 12/300 batch  54/188  Train Loss: 0.098, Acc: 0.969\n",
      "epoch: 12/300 batch  55/188  Train Loss: 0.080, Acc: 0.980\n",
      "epoch: 12/300 batch  56/188  Train Loss: 0.075, Acc: 0.969\n",
      "epoch: 12/300 batch  57/188  Train Loss: 0.081, Acc: 0.977\n",
      "epoch: 12/300 batch  58/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 12/300 batch  59/188  Train Loss: 0.053, Acc: 0.992\n",
      "epoch: 12/300 batch  60/188  Train Loss: 0.076, Acc: 0.980\n",
      "epoch: 12/300 batch  61/188  Train Loss: 0.064, Acc: 0.980\n",
      "epoch: 12/300 batch  62/188  Train Loss: 0.049, Acc: 0.980\n",
      "epoch: 12/300 batch  63/188  Train Loss: 0.055, Acc: 0.977\n",
      "epoch: 12/300 batch  64/188  Train Loss: 0.083, Acc: 0.973\n",
      "epoch: 12/300 batch  65/188  Train Loss: 0.061, Acc: 0.980\n",
      "epoch: 12/300 batch  66/188  Train Loss: 0.076, Acc: 0.980\n",
      "epoch: 12/300 batch  67/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 12/300 batch  68/188  Train Loss: 0.047, Acc: 0.980\n",
      "epoch: 12/300 batch  69/188  Train Loss: 0.080, Acc: 0.984\n",
      "epoch: 12/300 batch  70/188  Train Loss: 0.094, Acc: 0.980\n",
      "epoch: 12/300 batch  71/188  Train Loss: 0.080, Acc: 0.980\n",
      "epoch: 12/300 batch  72/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 12/300 batch  73/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 12/300 batch  74/188  Train Loss: 0.082, Acc: 0.977\n",
      "epoch: 12/300 batch  75/188  Train Loss: 0.078, Acc: 0.984\n",
      "epoch: 12/300 batch  76/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 12/300 batch  77/188  Train Loss: 0.066, Acc: 0.984\n",
      "epoch: 12/300 batch  78/188  Train Loss: 0.075, Acc: 0.977\n",
      "epoch: 12/300 batch  79/188  Train Loss: 0.059, Acc: 0.980\n",
      "epoch: 12/300 batch  80/188  Train Loss: 0.051, Acc: 0.980\n",
      "epoch: 12/300 batch  81/188  Train Loss: 0.078, Acc: 0.980\n",
      "epoch: 12/300 batch  82/188  Train Loss: 0.095, Acc: 0.965\n",
      "epoch: 12/300 batch  83/188  Train Loss: 0.070, Acc: 0.984\n",
      "epoch: 12/300 batch  84/188  Train Loss: 0.068, Acc: 0.984\n",
      "epoch: 12/300 batch  85/188  Train Loss: 0.095, Acc: 0.969\n",
      "epoch: 12/300 batch  86/188  Train Loss: 0.122, Acc: 0.965\n",
      "epoch: 12/300 batch  87/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 12/300 batch  88/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 12/300 batch  89/188  Train Loss: 0.135, Acc: 0.953\n",
      "epoch: 12/300 batch  90/188  Train Loss: 0.084, Acc: 0.965\n",
      "epoch: 12/300 batch  91/188  Train Loss: 0.098, Acc: 0.965\n",
      "epoch: 12/300 batch  92/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 12/300 batch  93/188  Train Loss: 0.112, Acc: 0.977\n",
      "epoch: 12/300 batch  94/188  Train Loss: 0.074, Acc: 0.973\n",
      "epoch: 12/300 batch  95/188  Train Loss: 0.050, Acc: 0.980\n",
      "epoch: 12/300 batch  96/188  Train Loss: 0.122, Acc: 0.980\n",
      "epoch: 12/300 batch  97/188  Train Loss: 0.078, Acc: 0.984\n",
      "epoch: 12/300 batch  98/188  Train Loss: 0.064, Acc: 0.988\n",
      "epoch: 12/300 batch  99/188  Train Loss: 0.093, Acc: 0.965\n",
      "epoch: 12/300 batch 100/188  Train Loss: 0.144, Acc: 0.957\n",
      "epoch: 12/300 batch 101/188  Train Loss: 0.081, Acc: 0.961\n",
      "epoch: 12/300 batch 102/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 12/300 batch 103/188  Train Loss: 0.100, Acc: 0.969\n",
      "epoch: 12/300 batch 104/188  Train Loss: 0.158, Acc: 0.945\n",
      "epoch: 12/300 batch 105/188  Train Loss: 0.103, Acc: 0.973\n",
      "epoch: 12/300 batch 106/188  Train Loss: 0.074, Acc: 0.980\n",
      "epoch: 12/300 batch 107/188  Train Loss: 0.117, Acc: 0.965\n",
      "epoch: 12/300 batch 108/188  Train Loss: 0.111, Acc: 0.965\n",
      "epoch: 12/300 batch 109/188  Train Loss: 0.151, Acc: 0.973\n",
      "epoch: 12/300 batch 110/188  Train Loss: 0.044, Acc: 0.980\n",
      "epoch: 12/300 batch 111/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 12/300 batch 112/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 12/300 batch 113/188  Train Loss: 0.064, Acc: 0.977\n",
      "epoch: 12/300 batch 114/188  Train Loss: 0.097, Acc: 0.980\n",
      "epoch: 12/300 batch 115/188  Train Loss: 0.071, Acc: 0.969\n",
      "epoch: 12/300 batch 116/188  Train Loss: 0.117, Acc: 0.973\n",
      "epoch: 12/300 batch 117/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 12/300 batch 118/188  Train Loss: 0.080, Acc: 0.973\n",
      "epoch: 12/300 batch 119/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 12/300 batch 120/188  Train Loss: 0.066, Acc: 0.988\n",
      "epoch: 12/300 batch 121/188  Train Loss: 0.058, Acc: 0.980\n",
      "epoch: 12/300 batch 122/188  Train Loss: 0.089, Acc: 0.977\n",
      "epoch: 12/300 batch 123/188  Train Loss: 0.113, Acc: 0.973\n",
      "epoch: 12/300 batch 124/188  Train Loss: 0.098, Acc: 0.969\n",
      "epoch: 12/300 batch 125/188  Train Loss: 0.065, Acc: 0.980\n",
      "epoch: 12/300 batch 126/188  Train Loss: 0.074, Acc: 0.988\n",
      "epoch: 12/300 batch 127/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 12/300 batch 128/188  Train Loss: 0.079, Acc: 0.980\n",
      "epoch: 12/300 batch 129/188  Train Loss: 0.064, Acc: 0.980\n",
      "epoch: 12/300 batch 130/188  Train Loss: 0.059, Acc: 0.988\n",
      "epoch: 12/300 batch 131/188  Train Loss: 0.069, Acc: 0.977\n",
      "epoch: 12/300 batch 132/188  Train Loss: 0.125, Acc: 0.977\n",
      "epoch: 12/300 batch 133/188  Train Loss: 0.092, Acc: 0.973\n",
      "epoch: 12/300 batch 134/188  Train Loss: 0.117, Acc: 0.961\n",
      "epoch: 12/300 batch 135/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 12/300 batch 136/188  Train Loss: 0.062, Acc: 0.977\n",
      "epoch: 12/300 batch 137/188  Train Loss: 0.081, Acc: 0.973\n",
      "epoch: 12/300 batch 138/188  Train Loss: 0.083, Acc: 0.965\n",
      "epoch: 12/300 batch 139/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 12/300 batch 140/188  Train Loss: 0.071, Acc: 0.980\n",
      "epoch: 12/300 batch 141/188  Train Loss: 0.089, Acc: 0.977\n",
      "epoch: 12/300 batch 142/188  Train Loss: 0.084, Acc: 0.977\n",
      "epoch: 12/300 batch 143/188  Train Loss: 0.140, Acc: 0.957\n",
      "epoch: 12/300 batch 144/188  Train Loss: 0.062, Acc: 0.977\n",
      "epoch: 12/300 batch 145/188  Train Loss: 0.100, Acc: 0.969\n",
      "epoch: 12/300 batch 146/188  Train Loss: 0.090, Acc: 0.973\n",
      "epoch: 12/300 batch 147/188  Train Loss: 0.097, Acc: 0.965\n",
      "epoch: 12/300 batch 148/188  Train Loss: 0.095, Acc: 0.980\n",
      "epoch: 12/300 batch 149/188  Train Loss: 0.083, Acc: 0.965\n",
      "epoch: 12/300 batch 150/188  Train Loss: 0.109, Acc: 0.957\n",
      "epoch: 12/300 batch 151/188  Train Loss: 0.135, Acc: 0.977\n",
      "epoch: 12/300 batch 152/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 12/300 batch 153/188  Train Loss: 0.087, Acc: 0.980\n",
      "epoch: 12/300 batch 154/188  Train Loss: 0.059, Acc: 0.988\n",
      "epoch: 12/300 batch 155/188  Train Loss: 0.067, Acc: 0.980\n",
      "epoch: 12/300 batch 156/188  Train Loss: 0.095, Acc: 0.965\n",
      "epoch: 12/300 batch 157/188  Train Loss: 0.158, Acc: 0.945\n",
      "epoch: 12/300 batch 158/188  Train Loss: 0.048, Acc: 0.980\n",
      "epoch: 12/300 batch 159/188  Train Loss: 0.099, Acc: 0.969\n",
      "epoch: 12/300 batch 160/188  Train Loss: 0.059, Acc: 0.984\n",
      "epoch: 12/300 batch 161/188  Train Loss: 0.084, Acc: 0.965\n",
      "epoch: 12/300 batch 162/188  Train Loss: 0.122, Acc: 0.969\n",
      "epoch: 12/300 batch 163/188  Train Loss: 0.071, Acc: 0.988\n",
      "epoch: 12/300 batch 164/188  Train Loss: 0.092, Acc: 0.969\n",
      "epoch: 12/300 batch 165/188  Train Loss: 0.070, Acc: 0.965\n",
      "epoch: 12/300 batch 166/188  Train Loss: 0.128, Acc: 0.957\n",
      "epoch: 12/300 batch 167/188  Train Loss: 0.069, Acc: 0.977\n",
      "epoch: 12/300 batch 168/188  Train Loss: 0.108, Acc: 0.965\n",
      "epoch: 12/300 batch 169/188  Train Loss: 0.081, Acc: 0.977\n",
      "epoch: 12/300 batch 170/188  Train Loss: 0.093, Acc: 0.977\n",
      "epoch: 12/300 batch 171/188  Train Loss: 0.101, Acc: 0.977\n",
      "epoch: 12/300 batch 172/188  Train Loss: 0.111, Acc: 0.953\n",
      "epoch: 12/300 batch 173/188  Train Loss: 0.115, Acc: 0.965\n",
      "epoch: 12/300 batch 174/188  Train Loss: 0.073, Acc: 0.977\n",
      "epoch: 12/300 batch 175/188  Train Loss: 0.070, Acc: 0.977\n",
      "epoch: 12/300 batch 176/188  Train Loss: 0.071, Acc: 0.977\n",
      "epoch: 12/300 batch 177/188  Train Loss: 0.087, Acc: 0.969\n",
      "epoch: 12/300 batch 178/188  Train Loss: 0.145, Acc: 0.973\n",
      "epoch: 12/300 batch 179/188  Train Loss: 0.071, Acc: 0.980\n",
      "epoch: 12/300 batch 180/188  Train Loss: 0.083, Acc: 0.977\n",
      "epoch: 12/300 batch 181/188  Train Loss: 0.081, Acc: 0.980\n",
      "epoch: 12/300 batch 182/188  Train Loss: 0.082, Acc: 0.977\n",
      "epoch: 12/300 batch 183/188  Train Loss: 0.085, Acc: 0.973\n",
      "epoch: 12/300 batch 184/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 12/300 batch 185/188  Train Loss: 0.086, Acc: 0.973\n",
      "epoch: 12/300 batch 186/188  Train Loss: 0.082, Acc: 0.969\n",
      "epoch: 12/300 batch 187/188  Train Loss: 0.066, Acc: 0.984\n",
      "Train Loss: 0.078186, Acc: 0.977\n",
      "Val Loss: 0.092040, Acc: 0.972\n",
      "epoch: 13/300 batch   0/188  Train Loss: 0.066, Acc: 0.980\n",
      "epoch: 13/300 batch   1/188  Train Loss: 0.099, Acc: 0.973\n",
      "epoch: 13/300 batch   2/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 13/300 batch   3/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 13/300 batch   4/188  Train Loss: 0.085, Acc: 0.965\n",
      "epoch: 13/300 batch   5/188  Train Loss: 0.064, Acc: 0.980\n",
      "epoch: 13/300 batch   6/188  Train Loss: 0.080, Acc: 0.980\n",
      "epoch: 13/300 batch   7/188  Train Loss: 0.087, Acc: 0.977\n",
      "epoch: 13/300 batch   8/188  Train Loss: 0.061, Acc: 0.973\n",
      "epoch: 13/300 batch   9/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 13/300 batch  10/188  Train Loss: 0.102, Acc: 0.965\n",
      "epoch: 13/300 batch  11/188  Train Loss: 0.074, Acc: 0.980\n",
      "epoch: 13/300 batch  12/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 13/300 batch  13/188  Train Loss: 0.064, Acc: 0.965\n",
      "epoch: 13/300 batch  14/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 13/300 batch  15/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 13/300 batch  16/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 13/300 batch  17/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 13/300 batch  18/188  Train Loss: 0.075, Acc: 0.977\n",
      "epoch: 13/300 batch  19/188  Train Loss: 0.076, Acc: 0.984\n",
      "epoch: 13/300 batch  20/188  Train Loss: 0.064, Acc: 0.980\n",
      "epoch: 13/300 batch  21/188  Train Loss: 0.059, Acc: 0.977\n",
      "epoch: 13/300 batch  22/188  Train Loss: 0.096, Acc: 0.977\n",
      "epoch: 13/300 batch  23/188  Train Loss: 0.057, Acc: 0.992\n",
      "epoch: 13/300 batch  24/188  Train Loss: 0.080, Acc: 0.980\n",
      "epoch: 13/300 batch  25/188  Train Loss: 0.073, Acc: 0.980\n",
      "epoch: 13/300 batch  26/188  Train Loss: 0.079, Acc: 0.969\n",
      "epoch: 13/300 batch  27/188  Train Loss: 0.062, Acc: 0.988\n",
      "epoch: 13/300 batch  28/188  Train Loss: 0.068, Acc: 0.977\n",
      "epoch: 13/300 batch  29/188  Train Loss: 0.078, Acc: 0.980\n",
      "epoch: 13/300 batch  30/188  Train Loss: 0.080, Acc: 0.980\n",
      "epoch: 13/300 batch  31/188  Train Loss: 0.071, Acc: 0.980\n",
      "epoch: 13/300 batch  32/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 13/300 batch  33/188  Train Loss: 0.046, Acc: 0.980\n",
      "epoch: 13/300 batch  34/188  Train Loss: 0.089, Acc: 0.973\n",
      "epoch: 13/300 batch  35/188  Train Loss: 0.093, Acc: 0.977\n",
      "epoch: 13/300 batch  36/188  Train Loss: 0.092, Acc: 0.969\n",
      "epoch: 13/300 batch  37/188  Train Loss: 0.043, Acc: 0.996\n",
      "epoch: 13/300 batch  38/188  Train Loss: 0.084, Acc: 0.969\n",
      "epoch: 13/300 batch  39/188  Train Loss: 0.073, Acc: 0.965\n",
      "epoch: 13/300 batch  40/188  Train Loss: 0.083, Acc: 0.980\n",
      "epoch: 13/300 batch  41/188  Train Loss: 0.054, Acc: 0.980\n",
      "epoch: 13/300 batch  42/188  Train Loss: 0.068, Acc: 0.973\n",
      "epoch: 13/300 batch  43/188  Train Loss: 0.084, Acc: 0.969\n",
      "epoch: 13/300 batch  44/188  Train Loss: 0.105, Acc: 0.965\n",
      "epoch: 13/300 batch  45/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 13/300 batch  46/188  Train Loss: 0.076, Acc: 0.984\n",
      "epoch: 13/300 batch  47/188  Train Loss: 0.089, Acc: 0.973\n",
      "epoch: 13/300 batch  48/188  Train Loss: 0.092, Acc: 0.977\n",
      "epoch: 13/300 batch  49/188  Train Loss: 0.066, Acc: 0.980\n",
      "epoch: 13/300 batch  50/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 13/300 batch  51/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 13/300 batch  52/188  Train Loss: 0.079, Acc: 0.977\n",
      "epoch: 13/300 batch  53/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 13/300 batch  54/188  Train Loss: 0.079, Acc: 0.977\n",
      "epoch: 13/300 batch  55/188  Train Loss: 0.065, Acc: 0.980\n",
      "epoch: 13/300 batch  56/188  Train Loss: 0.124, Acc: 0.961\n",
      "epoch: 13/300 batch  57/188  Train Loss: 0.052, Acc: 0.980\n",
      "epoch: 13/300 batch  58/188  Train Loss: 0.083, Acc: 0.977\n",
      "epoch: 13/300 batch  59/188  Train Loss: 0.083, Acc: 0.980\n",
      "epoch: 13/300 batch  60/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 13/300 batch  61/188  Train Loss: 0.058, Acc: 0.980\n",
      "epoch: 13/300 batch  62/188  Train Loss: 0.070, Acc: 0.984\n",
      "epoch: 13/300 batch  63/188  Train Loss: 0.096, Acc: 0.957\n",
      "epoch: 13/300 batch  64/188  Train Loss: 0.055, Acc: 0.977\n",
      "epoch: 13/300 batch  65/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 13/300 batch  66/188  Train Loss: 0.067, Acc: 0.973\n",
      "epoch: 13/300 batch  67/188  Train Loss: 0.089, Acc: 0.980\n",
      "epoch: 13/300 batch  68/188  Train Loss: 0.086, Acc: 0.988\n",
      "epoch: 13/300 batch  69/188  Train Loss: 0.073, Acc: 0.984\n",
      "epoch: 13/300 batch  70/188  Train Loss: 0.076, Acc: 0.980\n",
      "epoch: 13/300 batch  71/188  Train Loss: 0.127, Acc: 0.965\n",
      "epoch: 13/300 batch  72/188  Train Loss: 0.087, Acc: 0.969\n",
      "epoch: 13/300 batch  73/188  Train Loss: 0.102, Acc: 0.977\n",
      "epoch: 13/300 batch  74/188  Train Loss: 0.078, Acc: 0.977\n",
      "epoch: 13/300 batch  75/188  Train Loss: 0.081, Acc: 0.980\n",
      "epoch: 13/300 batch  76/188  Train Loss: 0.093, Acc: 0.969\n",
      "epoch: 13/300 batch  77/188  Train Loss: 0.101, Acc: 0.957\n",
      "epoch: 13/300 batch  78/188  Train Loss: 0.094, Acc: 0.980\n",
      "epoch: 13/300 batch  79/188  Train Loss: 0.078, Acc: 0.973\n",
      "epoch: 13/300 batch  80/188  Train Loss: 0.072, Acc: 0.984\n",
      "epoch: 13/300 batch  81/188  Train Loss: 0.097, Acc: 0.980\n",
      "epoch: 13/300 batch  82/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 13/300 batch  83/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 13/300 batch  84/188  Train Loss: 0.080, Acc: 0.977\n",
      "epoch: 13/300 batch  85/188  Train Loss: 0.110, Acc: 0.973\n",
      "epoch: 13/300 batch  86/188  Train Loss: 0.077, Acc: 0.961\n",
      "epoch: 13/300 batch  87/188  Train Loss: 0.127, Acc: 0.969\n",
      "epoch: 13/300 batch  88/188  Train Loss: 0.067, Acc: 0.988\n",
      "epoch: 13/300 batch  89/188  Train Loss: 0.088, Acc: 0.980\n",
      "epoch: 13/300 batch  90/188  Train Loss: 0.056, Acc: 0.980\n",
      "epoch: 13/300 batch  91/188  Train Loss: 0.055, Acc: 0.980\n",
      "epoch: 13/300 batch  92/188  Train Loss: 0.079, Acc: 0.977\n",
      "epoch: 13/300 batch  93/188  Train Loss: 0.073, Acc: 0.973\n",
      "epoch: 13/300 batch  94/188  Train Loss: 0.089, Acc: 0.965\n",
      "epoch: 13/300 batch  95/188  Train Loss: 0.071, Acc: 0.980\n",
      "epoch: 13/300 batch  96/188  Train Loss: 0.102, Acc: 0.977\n",
      "epoch: 13/300 batch  97/188  Train Loss: 0.054, Acc: 0.980\n",
      "epoch: 13/300 batch  98/188  Train Loss: 0.057, Acc: 0.996\n",
      "epoch: 13/300 batch  99/188  Train Loss: 0.121, Acc: 0.961\n",
      "epoch: 13/300 batch 100/188  Train Loss: 0.090, Acc: 0.988\n",
      "epoch: 13/300 batch 101/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 13/300 batch 102/188  Train Loss: 0.097, Acc: 0.980\n",
      "epoch: 13/300 batch 103/188  Train Loss: 0.078, Acc: 0.977\n",
      "epoch: 13/300 batch 104/188  Train Loss: 0.071, Acc: 0.977\n",
      "epoch: 13/300 batch 105/188  Train Loss: 0.111, Acc: 0.961\n",
      "epoch: 13/300 batch 106/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 13/300 batch 107/188  Train Loss: 0.127, Acc: 0.973\n",
      "epoch: 13/300 batch 108/188  Train Loss: 0.091, Acc: 0.973\n",
      "epoch: 13/300 batch 109/188  Train Loss: 0.109, Acc: 0.945\n",
      "epoch: 13/300 batch 110/188  Train Loss: 0.139, Acc: 0.957\n",
      "epoch: 13/300 batch 111/188  Train Loss: 0.094, Acc: 0.969\n",
      "epoch: 13/300 batch 112/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 13/300 batch 113/188  Train Loss: 0.064, Acc: 0.973\n",
      "epoch: 13/300 batch 114/188  Train Loss: 0.082, Acc: 0.984\n",
      "epoch: 13/300 batch 115/188  Train Loss: 0.101, Acc: 0.957\n",
      "epoch: 13/300 batch 116/188  Train Loss: 0.117, Acc: 0.969\n",
      "epoch: 13/300 batch 117/188  Train Loss: 0.144, Acc: 0.945\n",
      "epoch: 13/300 batch 118/188  Train Loss: 0.100, Acc: 0.973\n",
      "epoch: 13/300 batch 119/188  Train Loss: 0.116, Acc: 0.973\n",
      "epoch: 13/300 batch 120/188  Train Loss: 0.064, Acc: 0.980\n",
      "epoch: 13/300 batch 121/188  Train Loss: 0.097, Acc: 0.973\n",
      "epoch: 13/300 batch 122/188  Train Loss: 0.099, Acc: 0.969\n",
      "epoch: 13/300 batch 123/188  Train Loss: 0.088, Acc: 0.973\n",
      "epoch: 13/300 batch 124/188  Train Loss: 0.117, Acc: 0.965\n",
      "epoch: 13/300 batch 125/188  Train Loss: 0.076, Acc: 0.961\n",
      "epoch: 13/300 batch 126/188  Train Loss: 0.073, Acc: 0.988\n",
      "epoch: 13/300 batch 127/188  Train Loss: 0.156, Acc: 0.953\n",
      "epoch: 13/300 batch 128/188  Train Loss: 0.048, Acc: 0.980\n",
      "epoch: 13/300 batch 129/188  Train Loss: 0.149, Acc: 0.949\n",
      "epoch: 13/300 batch 130/188  Train Loss: 0.097, Acc: 0.973\n",
      "epoch: 13/300 batch 131/188  Train Loss: 0.062, Acc: 0.984\n",
      "epoch: 13/300 batch 132/188  Train Loss: 0.080, Acc: 0.984\n",
      "epoch: 13/300 batch 133/188  Train Loss: 0.061, Acc: 0.977\n",
      "epoch: 13/300 batch 134/188  Train Loss: 0.080, Acc: 0.969\n",
      "epoch: 13/300 batch 135/188  Train Loss: 0.100, Acc: 0.973\n",
      "epoch: 13/300 batch 136/188  Train Loss: 0.072, Acc: 0.984\n",
      "epoch: 13/300 batch 137/188  Train Loss: 0.069, Acc: 0.980\n",
      "epoch: 13/300 batch 138/188  Train Loss: 0.098, Acc: 0.973\n",
      "epoch: 13/300 batch 139/188  Train Loss: 0.065, Acc: 0.977\n",
      "epoch: 13/300 batch 140/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 13/300 batch 141/188  Train Loss: 0.061, Acc: 0.984\n",
      "epoch: 13/300 batch 142/188  Train Loss: 0.070, Acc: 0.973\n",
      "epoch: 13/300 batch 143/188  Train Loss: 0.092, Acc: 0.965\n",
      "epoch: 13/300 batch 144/188  Train Loss: 0.162, Acc: 0.965\n",
      "epoch: 13/300 batch 145/188  Train Loss: 0.063, Acc: 0.988\n",
      "epoch: 13/300 batch 146/188  Train Loss: 0.089, Acc: 0.973\n",
      "epoch: 13/300 batch 147/188  Train Loss: 0.070, Acc: 0.973\n",
      "epoch: 13/300 batch 148/188  Train Loss: 0.074, Acc: 0.977\n",
      "epoch: 13/300 batch 149/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 13/300 batch 150/188  Train Loss: 0.142, Acc: 0.965\n",
      "epoch: 13/300 batch 151/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 13/300 batch 152/188  Train Loss: 0.094, Acc: 0.969\n",
      "epoch: 13/300 batch 153/188  Train Loss: 0.090, Acc: 0.977\n",
      "epoch: 13/300 batch 154/188  Train Loss: 0.113, Acc: 0.984\n",
      "epoch: 13/300 batch 155/188  Train Loss: 0.071, Acc: 0.980\n",
      "epoch: 13/300 batch 156/188  Train Loss: 0.076, Acc: 0.984\n",
      "epoch: 13/300 batch 157/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 13/300 batch 158/188  Train Loss: 0.083, Acc: 0.984\n",
      "epoch: 13/300 batch 159/188  Train Loss: 0.066, Acc: 0.977\n",
      "epoch: 13/300 batch 160/188  Train Loss: 0.126, Acc: 0.965\n",
      "epoch: 13/300 batch 161/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 13/300 batch 162/188  Train Loss: 0.085, Acc: 0.969\n",
      "epoch: 13/300 batch 163/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 13/300 batch 164/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 13/300 batch 165/188  Train Loss: 0.111, Acc: 0.973\n",
      "epoch: 13/300 batch 166/188  Train Loss: 0.119, Acc: 0.953\n",
      "epoch: 13/300 batch 167/188  Train Loss: 0.083, Acc: 0.977\n",
      "epoch: 13/300 batch 168/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 13/300 batch 169/188  Train Loss: 0.101, Acc: 0.969\n",
      "epoch: 13/300 batch 170/188  Train Loss: 0.127, Acc: 0.965\n",
      "epoch: 13/300 batch 171/188  Train Loss: 0.092, Acc: 0.980\n",
      "epoch: 13/300 batch 172/188  Train Loss: 0.064, Acc: 0.977\n",
      "epoch: 13/300 batch 173/188  Train Loss: 0.099, Acc: 0.961\n",
      "epoch: 13/300 batch 174/188  Train Loss: 0.063, Acc: 0.988\n",
      "epoch: 13/300 batch 175/188  Train Loss: 0.105, Acc: 0.965\n",
      "epoch: 13/300 batch 176/188  Train Loss: 0.104, Acc: 0.969\n",
      "epoch: 13/300 batch 177/188  Train Loss: 0.071, Acc: 0.969\n",
      "epoch: 13/300 batch 178/188  Train Loss: 0.075, Acc: 0.977\n",
      "epoch: 13/300 batch 179/188  Train Loss: 0.127, Acc: 0.969\n",
      "epoch: 13/300 batch 180/188  Train Loss: 0.070, Acc: 0.977\n",
      "epoch: 13/300 batch 181/188  Train Loss: 0.069, Acc: 0.977\n",
      "epoch: 13/300 batch 182/188  Train Loss: 0.108, Acc: 0.957\n",
      "epoch: 13/300 batch 183/188  Train Loss: 0.054, Acc: 0.980\n",
      "epoch: 13/300 batch 184/188  Train Loss: 0.073, Acc: 0.973\n",
      "epoch: 13/300 batch 185/188  Train Loss: 0.087, Acc: 0.969\n",
      "epoch: 13/300 batch 186/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 13/300 batch 187/188  Train Loss: 0.032, Acc: 0.984\n",
      "Train Loss: 0.078979, Acc: 0.977\n",
      "Val Loss: 0.082229, Acc: 0.976\n",
      "epoch: 14/300 batch   0/188  Train Loss: 0.059, Acc: 0.984\n",
      "epoch: 14/300 batch   1/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 14/300 batch   2/188  Train Loss: 0.050, Acc: 0.980\n",
      "epoch: 14/300 batch   3/188  Train Loss: 0.065, Acc: 0.984\n",
      "epoch: 14/300 batch   4/188  Train Loss: 0.057, Acc: 0.980\n",
      "epoch: 14/300 batch   5/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 14/300 batch   6/188  Train Loss: 0.056, Acc: 0.977\n",
      "epoch: 14/300 batch   7/188  Train Loss: 0.061, Acc: 0.988\n",
      "epoch: 14/300 batch   8/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 14/300 batch   9/188  Train Loss: 0.064, Acc: 0.988\n",
      "epoch: 14/300 batch  10/188  Train Loss: 0.070, Acc: 0.980\n",
      "epoch: 14/300 batch  11/188  Train Loss: 0.060, Acc: 0.984\n",
      "epoch: 14/300 batch  12/188  Train Loss: 0.049, Acc: 0.980\n",
      "epoch: 14/300 batch  13/188  Train Loss: 0.064, Acc: 0.988\n",
      "epoch: 14/300 batch  14/188  Train Loss: 0.065, Acc: 0.988\n",
      "epoch: 14/300 batch  15/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 14/300 batch  16/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 14/300 batch  17/188  Train Loss: 0.064, Acc: 0.984\n",
      "epoch: 14/300 batch  18/188  Train Loss: 0.056, Acc: 0.977\n",
      "epoch: 14/300 batch  19/188  Train Loss: 0.057, Acc: 0.980\n",
      "epoch: 14/300 batch  20/188  Train Loss: 0.057, Acc: 0.980\n",
      "epoch: 14/300 batch  21/188  Train Loss: 0.089, Acc: 0.980\n",
      "epoch: 14/300 batch  22/188  Train Loss: 0.084, Acc: 0.980\n",
      "epoch: 14/300 batch  23/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 14/300 batch  24/188  Train Loss: 0.075, Acc: 0.973\n",
      "epoch: 14/300 batch  25/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 14/300 batch  26/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 14/300 batch  27/188  Train Loss: 0.081, Acc: 0.977\n",
      "epoch: 14/300 batch  28/188  Train Loss: 0.107, Acc: 0.969\n",
      "epoch: 14/300 batch  29/188  Train Loss: 0.071, Acc: 0.973\n",
      "epoch: 14/300 batch  30/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 14/300 batch  31/188  Train Loss: 0.092, Acc: 0.965\n",
      "epoch: 14/300 batch  32/188  Train Loss: 0.062, Acc: 0.984\n",
      "epoch: 14/300 batch  33/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 14/300 batch  34/188  Train Loss: 0.061, Acc: 0.984\n",
      "epoch: 14/300 batch  35/188  Train Loss: 0.072, Acc: 0.980\n",
      "epoch: 14/300 batch  36/188  Train Loss: 0.074, Acc: 0.977\n",
      "epoch: 14/300 batch  37/188  Train Loss: 0.064, Acc: 0.980\n",
      "epoch: 14/300 batch  38/188  Train Loss: 0.134, Acc: 0.973\n",
      "epoch: 14/300 batch  39/188  Train Loss: 0.055, Acc: 0.977\n",
      "epoch: 14/300 batch  40/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 14/300 batch  41/188  Train Loss: 0.080, Acc: 0.977\n",
      "epoch: 14/300 batch  42/188  Train Loss: 0.101, Acc: 0.965\n",
      "epoch: 14/300 batch  43/188  Train Loss: 0.087, Acc: 0.973\n",
      "epoch: 14/300 batch  44/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 14/300 batch  45/188  Train Loss: 0.070, Acc: 0.973\n",
      "epoch: 14/300 batch  46/188  Train Loss: 0.098, Acc: 0.965\n",
      "epoch: 14/300 batch  47/188  Train Loss: 0.098, Acc: 0.969\n",
      "epoch: 14/300 batch  48/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 14/300 batch  49/188  Train Loss: 0.085, Acc: 0.969\n",
      "epoch: 14/300 batch  50/188  Train Loss: 0.075, Acc: 0.980\n",
      "epoch: 14/300 batch  51/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 14/300 batch  52/188  Train Loss: 0.073, Acc: 0.980\n",
      "epoch: 14/300 batch  53/188  Train Loss: 0.086, Acc: 0.980\n",
      "epoch: 14/300 batch  54/188  Train Loss: 0.112, Acc: 0.957\n",
      "epoch: 14/300 batch  55/188  Train Loss: 0.056, Acc: 0.980\n",
      "epoch: 14/300 batch  56/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 14/300 batch  57/188  Train Loss: 0.086, Acc: 0.957\n",
      "epoch: 14/300 batch  58/188  Train Loss: 0.095, Acc: 0.973\n",
      "epoch: 14/300 batch  59/188  Train Loss: 0.085, Acc: 0.973\n",
      "epoch: 14/300 batch  60/188  Train Loss: 0.058, Acc: 0.980\n",
      "epoch: 14/300 batch  61/188  Train Loss: 0.064, Acc: 0.984\n",
      "epoch: 14/300 batch  62/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 14/300 batch  63/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 14/300 batch  64/188  Train Loss: 0.133, Acc: 0.953\n",
      "epoch: 14/300 batch  65/188  Train Loss: 0.127, Acc: 0.961\n",
      "epoch: 14/300 batch  66/188  Train Loss: 0.078, Acc: 0.973\n",
      "epoch: 14/300 batch  67/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 14/300 batch  68/188  Train Loss: 0.096, Acc: 0.969\n",
      "epoch: 14/300 batch  69/188  Train Loss: 0.102, Acc: 0.973\n",
      "epoch: 14/300 batch  70/188  Train Loss: 0.073, Acc: 0.977\n",
      "epoch: 14/300 batch  71/188  Train Loss: 0.073, Acc: 0.980\n",
      "epoch: 14/300 batch  72/188  Train Loss: 0.068, Acc: 0.977\n",
      "epoch: 14/300 batch  73/188  Train Loss: 0.063, Acc: 0.977\n",
      "epoch: 14/300 batch  74/188  Train Loss: 0.075, Acc: 0.973\n",
      "epoch: 14/300 batch  75/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 14/300 batch  76/188  Train Loss: 0.061, Acc: 0.984\n",
      "epoch: 14/300 batch  77/188  Train Loss: 0.060, Acc: 0.988\n",
      "epoch: 14/300 batch  78/188  Train Loss: 0.067, Acc: 0.984\n",
      "epoch: 14/300 batch  79/188  Train Loss: 0.097, Acc: 0.980\n",
      "epoch: 14/300 batch  80/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 14/300 batch  81/188  Train Loss: 0.080, Acc: 0.977\n",
      "epoch: 14/300 batch  82/188  Train Loss: 0.099, Acc: 0.977\n",
      "epoch: 14/300 batch  83/188  Train Loss: 0.066, Acc: 0.977\n",
      "epoch: 14/300 batch  84/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 14/300 batch  85/188  Train Loss: 0.110, Acc: 0.977\n",
      "epoch: 14/300 batch  86/188  Train Loss: 0.043, Acc: 0.980\n",
      "epoch: 14/300 batch  87/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 14/300 batch  88/188  Train Loss: 0.092, Acc: 0.969\n",
      "epoch: 14/300 batch  89/188  Train Loss: 0.073, Acc: 0.980\n",
      "epoch: 14/300 batch  90/188  Train Loss: 0.063, Acc: 0.977\n",
      "epoch: 14/300 batch  91/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 14/300 batch  92/188  Train Loss: 0.121, Acc: 0.977\n",
      "epoch: 14/300 batch  93/188  Train Loss: 0.086, Acc: 0.973\n",
      "epoch: 14/300 batch  94/188  Train Loss: 0.092, Acc: 0.969\n",
      "epoch: 14/300 batch  95/188  Train Loss: 0.061, Acc: 0.980\n",
      "epoch: 14/300 batch  96/188  Train Loss: 0.050, Acc: 0.980\n",
      "epoch: 14/300 batch  97/188  Train Loss: 0.052, Acc: 0.977\n",
      "epoch: 14/300 batch  98/188  Train Loss: 0.074, Acc: 0.965\n",
      "epoch: 14/300 batch  99/188  Train Loss: 0.058, Acc: 0.992\n",
      "epoch: 14/300 batch 100/188  Train Loss: 0.121, Acc: 0.953\n",
      "epoch: 14/300 batch 101/188  Train Loss: 0.065, Acc: 0.992\n",
      "epoch: 14/300 batch 102/188  Train Loss: 0.057, Acc: 0.988\n",
      "epoch: 14/300 batch 103/188  Train Loss: 0.068, Acc: 0.977\n",
      "epoch: 14/300 batch 104/188  Train Loss: 0.085, Acc: 0.969\n",
      "epoch: 14/300 batch 105/188  Train Loss: 0.063, Acc: 0.980\n",
      "epoch: 14/300 batch 106/188  Train Loss: 0.083, Acc: 0.980\n",
      "epoch: 14/300 batch 107/188  Train Loss: 0.085, Acc: 0.965\n",
      "epoch: 14/300 batch 108/188  Train Loss: 0.059, Acc: 0.980\n",
      "epoch: 14/300 batch 109/188  Train Loss: 0.061, Acc: 0.984\n",
      "epoch: 14/300 batch 110/188  Train Loss: 0.090, Acc: 0.980\n",
      "epoch: 14/300 batch 111/188  Train Loss: 0.091, Acc: 0.980\n",
      "epoch: 14/300 batch 112/188  Train Loss: 0.071, Acc: 0.977\n",
      "epoch: 14/300 batch 113/188  Train Loss: 0.086, Acc: 0.973\n",
      "epoch: 14/300 batch 114/188  Train Loss: 0.085, Acc: 0.980\n",
      "epoch: 14/300 batch 115/188  Train Loss: 0.090, Acc: 0.969\n",
      "epoch: 14/300 batch 116/188  Train Loss: 0.080, Acc: 0.980\n",
      "epoch: 14/300 batch 117/188  Train Loss: 0.068, Acc: 0.973\n",
      "epoch: 14/300 batch 118/188  Train Loss: 0.101, Acc: 0.973\n",
      "epoch: 14/300 batch 119/188  Train Loss: 0.080, Acc: 0.984\n",
      "epoch: 14/300 batch 120/188  Train Loss: 0.105, Acc: 0.977\n",
      "epoch: 14/300 batch 121/188  Train Loss: 0.122, Acc: 0.969\n",
      "epoch: 14/300 batch 122/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 14/300 batch 123/188  Train Loss: 0.111, Acc: 0.965\n",
      "epoch: 14/300 batch 124/188  Train Loss: 0.125, Acc: 0.973\n",
      "epoch: 14/300 batch 125/188  Train Loss: 0.098, Acc: 0.969\n",
      "epoch: 14/300 batch 126/188  Train Loss: 0.083, Acc: 0.965\n",
      "epoch: 14/300 batch 127/188  Train Loss: 0.137, Acc: 0.953\n",
      "epoch: 14/300 batch 128/188  Train Loss: 0.139, Acc: 0.965\n",
      "epoch: 14/300 batch 129/188  Train Loss: 0.084, Acc: 0.973\n",
      "epoch: 14/300 batch 130/188  Train Loss: 0.072, Acc: 0.980\n",
      "epoch: 14/300 batch 131/188  Train Loss: 0.062, Acc: 0.973\n",
      "epoch: 14/300 batch 132/188  Train Loss: 0.081, Acc: 0.980\n",
      "epoch: 14/300 batch 133/188  Train Loss: 0.062, Acc: 0.980\n",
      "epoch: 14/300 batch 134/188  Train Loss: 0.074, Acc: 0.969\n",
      "epoch: 14/300 batch 135/188  Train Loss: 0.060, Acc: 0.988\n",
      "epoch: 14/300 batch 136/188  Train Loss: 0.068, Acc: 0.984\n",
      "epoch: 14/300 batch 137/188  Train Loss: 0.068, Acc: 0.980\n",
      "epoch: 14/300 batch 138/188  Train Loss: 0.089, Acc: 0.973\n",
      "epoch: 14/300 batch 139/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 14/300 batch 140/188  Train Loss: 0.093, Acc: 0.961\n",
      "epoch: 14/300 batch 141/188  Train Loss: 0.054, Acc: 0.977\n",
      "epoch: 14/300 batch 142/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 14/300 batch 143/188  Train Loss: 0.084, Acc: 0.980\n",
      "epoch: 14/300 batch 144/188  Train Loss: 0.057, Acc: 0.988\n",
      "epoch: 14/300 batch 145/188  Train Loss: 0.081, Acc: 0.969\n",
      "epoch: 14/300 batch 146/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 14/300 batch 147/188  Train Loss: 0.067, Acc: 0.980\n",
      "epoch: 14/300 batch 148/188  Train Loss: 0.085, Acc: 0.977\n",
      "epoch: 14/300 batch 149/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 14/300 batch 150/188  Train Loss: 0.095, Acc: 0.984\n",
      "epoch: 14/300 batch 151/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 14/300 batch 152/188  Train Loss: 0.095, Acc: 0.977\n",
      "epoch: 14/300 batch 153/188  Train Loss: 0.166, Acc: 0.953\n",
      "epoch: 14/300 batch 154/188  Train Loss: 0.069, Acc: 0.980\n",
      "epoch: 14/300 batch 155/188  Train Loss: 0.120, Acc: 0.965\n",
      "epoch: 14/300 batch 156/188  Train Loss: 0.102, Acc: 0.969\n",
      "epoch: 14/300 batch 157/188  Train Loss: 0.120, Acc: 0.957\n",
      "epoch: 14/300 batch 158/188  Train Loss: 0.143, Acc: 0.961\n",
      "epoch: 14/300 batch 159/188  Train Loss: 0.090, Acc: 0.969\n",
      "epoch: 14/300 batch 160/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 14/300 batch 161/188  Train Loss: 0.081, Acc: 0.965\n",
      "epoch: 14/300 batch 162/188  Train Loss: 0.092, Acc: 0.980\n",
      "epoch: 14/300 batch 163/188  Train Loss: 0.060, Acc: 0.977\n",
      "epoch: 14/300 batch 164/188  Train Loss: 0.101, Acc: 0.969\n",
      "epoch: 14/300 batch 165/188  Train Loss: 0.120, Acc: 0.965\n",
      "epoch: 14/300 batch 166/188  Train Loss: 0.086, Acc: 0.984\n",
      "epoch: 14/300 batch 167/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 14/300 batch 168/188  Train Loss: 0.071, Acc: 0.977\n",
      "epoch: 14/300 batch 169/188  Train Loss: 0.079, Acc: 0.973\n",
      "epoch: 14/300 batch 170/188  Train Loss: 0.100, Acc: 0.977\n",
      "epoch: 14/300 batch 171/188  Train Loss: 0.123, Acc: 0.961\n",
      "epoch: 14/300 batch 172/188  Train Loss: 0.079, Acc: 0.977\n",
      "epoch: 14/300 batch 173/188  Train Loss: 0.108, Acc: 0.969\n",
      "epoch: 14/300 batch 174/188  Train Loss: 0.097, Acc: 0.973\n",
      "epoch: 14/300 batch 175/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 14/300 batch 176/188  Train Loss: 0.192, Acc: 0.969\n",
      "epoch: 14/300 batch 177/188  Train Loss: 0.114, Acc: 0.961\n",
      "epoch: 14/300 batch 178/188  Train Loss: 0.086, Acc: 0.969\n",
      "epoch: 14/300 batch 179/188  Train Loss: 0.097, Acc: 0.969\n",
      "epoch: 14/300 batch 180/188  Train Loss: 0.108, Acc: 0.973\n",
      "epoch: 14/300 batch 181/188  Train Loss: 0.086, Acc: 0.980\n",
      "epoch: 14/300 batch 182/188  Train Loss: 0.051, Acc: 0.980\n",
      "epoch: 14/300 batch 183/188  Train Loss: 0.138, Acc: 0.965\n",
      "epoch: 14/300 batch 184/188  Train Loss: 0.067, Acc: 0.977\n",
      "epoch: 14/300 batch 185/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 14/300 batch 186/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 14/300 batch 187/188  Train Loss: 0.105, Acc: 0.961\n",
      "Train Loss: 0.077025, Acc: 0.977\n",
      "Val Loss: 0.077015, Acc: 0.978\n",
      "epoch: 15/300 batch   0/188  Train Loss: 0.063, Acc: 0.984\n",
      "epoch: 15/300 batch   1/188  Train Loss: 0.064, Acc: 0.980\n",
      "epoch: 15/300 batch   2/188  Train Loss: 0.058, Acc: 0.980\n",
      "epoch: 15/300 batch   3/188  Train Loss: 0.082, Acc: 0.977\n",
      "epoch: 15/300 batch   4/188  Train Loss: 0.114, Acc: 0.969\n",
      "epoch: 15/300 batch   5/188  Train Loss: 0.112, Acc: 0.973\n",
      "epoch: 15/300 batch   6/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 15/300 batch   7/188  Train Loss: 0.100, Acc: 0.977\n",
      "epoch: 15/300 batch   8/188  Train Loss: 0.081, Acc: 0.973\n",
      "epoch: 15/300 batch   9/188  Train Loss: 0.095, Acc: 0.965\n",
      "epoch: 15/300 batch  10/188  Train Loss: 0.075, Acc: 0.973\n",
      "epoch: 15/300 batch  11/188  Train Loss: 0.094, Acc: 0.961\n",
      "epoch: 15/300 batch  12/188  Train Loss: 0.085, Acc: 0.961\n",
      "epoch: 15/300 batch  13/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 15/300 batch  14/188  Train Loss: 0.063, Acc: 0.980\n",
      "epoch: 15/300 batch  15/188  Train Loss: 0.080, Acc: 0.977\n",
      "epoch: 15/300 batch  16/188  Train Loss: 0.065, Acc: 0.980\n",
      "epoch: 15/300 batch  17/188  Train Loss: 0.068, Acc: 0.973\n",
      "epoch: 15/300 batch  18/188  Train Loss: 0.052, Acc: 0.992\n",
      "epoch: 15/300 batch  19/188  Train Loss: 0.062, Acc: 0.980\n",
      "epoch: 15/300 batch  20/188  Train Loss: 0.074, Acc: 0.973\n",
      "epoch: 15/300 batch  21/188  Train Loss: 0.071, Acc: 0.977\n",
      "epoch: 15/300 batch  22/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 15/300 batch  23/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 15/300 batch  24/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 15/300 batch  25/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 15/300 batch  26/188  Train Loss: 0.088, Acc: 0.980\n",
      "epoch: 15/300 batch  27/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 15/300 batch  28/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 15/300 batch  29/188  Train Loss: 0.053, Acc: 0.980\n",
      "epoch: 15/300 batch  30/188  Train Loss: 0.061, Acc: 0.977\n",
      "epoch: 15/300 batch  31/188  Train Loss: 0.060, Acc: 0.988\n",
      "epoch: 15/300 batch  32/188  Train Loss: 0.079, Acc: 0.977\n",
      "epoch: 15/300 batch  33/188  Train Loss: 0.088, Acc: 0.969\n",
      "epoch: 15/300 batch  34/188  Train Loss: 0.068, Acc: 0.988\n",
      "epoch: 15/300 batch  35/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 15/300 batch  36/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 15/300 batch  37/188  Train Loss: 0.082, Acc: 0.980\n",
      "epoch: 15/300 batch  38/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 15/300 batch  39/188  Train Loss: 0.059, Acc: 0.973\n",
      "epoch: 15/300 batch  40/188  Train Loss: 0.101, Acc: 0.973\n",
      "epoch: 15/300 batch  41/188  Train Loss: 0.082, Acc: 0.973\n",
      "epoch: 15/300 batch  42/188  Train Loss: 0.074, Acc: 0.980\n",
      "epoch: 15/300 batch  43/188  Train Loss: 0.086, Acc: 0.977\n",
      "epoch: 15/300 batch  44/188  Train Loss: 0.099, Acc: 0.965\n",
      "epoch: 15/300 batch  45/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 15/300 batch  46/188  Train Loss: 0.100, Acc: 0.957\n",
      "epoch: 15/300 batch  47/188  Train Loss: 0.105, Acc: 0.961\n",
      "epoch: 15/300 batch  48/188  Train Loss: 0.061, Acc: 0.980\n",
      "epoch: 15/300 batch  49/188  Train Loss: 0.068, Acc: 0.977\n",
      "epoch: 15/300 batch  50/188  Train Loss: 0.078, Acc: 0.969\n",
      "epoch: 15/300 batch  51/188  Train Loss: 0.086, Acc: 0.980\n",
      "epoch: 15/300 batch  52/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 15/300 batch  53/188  Train Loss: 0.080, Acc: 0.977\n",
      "epoch: 15/300 batch  54/188  Train Loss: 0.108, Acc: 0.977\n",
      "epoch: 15/300 batch  55/188  Train Loss: 0.047, Acc: 0.980\n",
      "epoch: 15/300 batch  56/188  Train Loss: 0.098, Acc: 0.977\n",
      "epoch: 15/300 batch  57/188  Train Loss: 0.077, Acc: 0.980\n",
      "epoch: 15/300 batch  58/188  Train Loss: 0.087, Acc: 0.988\n",
      "epoch: 15/300 batch  59/188  Train Loss: 0.078, Acc: 0.973\n",
      "epoch: 15/300 batch  60/188  Train Loss: 0.103, Acc: 0.984\n",
      "epoch: 15/300 batch  61/188  Train Loss: 0.068, Acc: 0.980\n",
      "epoch: 15/300 batch  62/188  Train Loss: 0.161, Acc: 0.949\n",
      "epoch: 15/300 batch  63/188  Train Loss: 0.078, Acc: 0.980\n",
      "epoch: 15/300 batch  64/188  Train Loss: 0.087, Acc: 0.973\n",
      "epoch: 15/300 batch  65/188  Train Loss: 0.088, Acc: 0.969\n",
      "epoch: 15/300 batch  66/188  Train Loss: 0.127, Acc: 0.953\n",
      "epoch: 15/300 batch  67/188  Train Loss: 0.089, Acc: 0.965\n",
      "epoch: 15/300 batch  68/188  Train Loss: 0.103, Acc: 0.961\n",
      "epoch: 15/300 batch  69/188  Train Loss: 0.078, Acc: 0.980\n",
      "epoch: 15/300 batch  70/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 15/300 batch  71/188  Train Loss: 0.085, Acc: 0.977\n",
      "epoch: 15/300 batch  72/188  Train Loss: 0.074, Acc: 0.984\n",
      "epoch: 15/300 batch  73/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 15/300 batch  74/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 15/300 batch  75/188  Train Loss: 0.119, Acc: 0.969\n",
      "epoch: 15/300 batch  76/188  Train Loss: 0.068, Acc: 0.977\n",
      "epoch: 15/300 batch  77/188  Train Loss: 0.093, Acc: 0.973\n",
      "epoch: 15/300 batch  78/188  Train Loss: 0.095, Acc: 0.973\n",
      "epoch: 15/300 batch  79/188  Train Loss: 0.119, Acc: 0.961\n",
      "epoch: 15/300 batch  80/188  Train Loss: 0.122, Acc: 0.969\n",
      "epoch: 15/300 batch  81/188  Train Loss: 0.063, Acc: 0.980\n",
      "epoch: 15/300 batch  82/188  Train Loss: 0.170, Acc: 0.953\n",
      "epoch: 15/300 batch  83/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 15/300 batch  84/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 15/300 batch  85/188  Train Loss: 0.066, Acc: 0.980\n",
      "epoch: 15/300 batch  86/188  Train Loss: 0.074, Acc: 0.973\n",
      "epoch: 15/300 batch  87/188  Train Loss: 0.069, Acc: 0.969\n",
      "epoch: 15/300 batch  88/188  Train Loss: 0.098, Acc: 0.980\n",
      "epoch: 15/300 batch  89/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 15/300 batch  90/188  Train Loss: 0.084, Acc: 0.977\n",
      "epoch: 15/300 batch  91/188  Train Loss: 0.064, Acc: 0.988\n",
      "epoch: 15/300 batch  92/188  Train Loss: 0.075, Acc: 0.969\n",
      "epoch: 15/300 batch  93/188  Train Loss: 0.064, Acc: 0.977\n",
      "epoch: 15/300 batch  94/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 15/300 batch  95/188  Train Loss: 0.063, Acc: 0.980\n",
      "epoch: 15/300 batch  96/188  Train Loss: 0.067, Acc: 0.969\n",
      "epoch: 15/300 batch  97/188  Train Loss: 0.128, Acc: 0.953\n",
      "epoch: 15/300 batch  98/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 15/300 batch  99/188  Train Loss: 0.101, Acc: 0.969\n",
      "epoch: 15/300 batch 100/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 15/300 batch 101/188  Train Loss: 0.084, Acc: 0.977\n",
      "epoch: 15/300 batch 102/188  Train Loss: 0.094, Acc: 0.973\n",
      "epoch: 15/300 batch 103/188  Train Loss: 0.094, Acc: 0.973\n",
      "epoch: 15/300 batch 104/188  Train Loss: 0.078, Acc: 0.969\n",
      "epoch: 15/300 batch 105/188  Train Loss: 0.090, Acc: 0.969\n",
      "epoch: 15/300 batch 106/188  Train Loss: 0.073, Acc: 0.977\n",
      "epoch: 15/300 batch 107/188  Train Loss: 0.061, Acc: 0.977\n",
      "epoch: 15/300 batch 108/188  Train Loss: 0.114, Acc: 0.961\n",
      "epoch: 15/300 batch 109/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 15/300 batch 110/188  Train Loss: 0.084, Acc: 0.969\n",
      "epoch: 15/300 batch 111/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 15/300 batch 112/188  Train Loss: 0.061, Acc: 0.969\n",
      "epoch: 15/300 batch 113/188  Train Loss: 0.095, Acc: 0.969\n",
      "epoch: 15/300 batch 114/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 15/300 batch 115/188  Train Loss: 0.066, Acc: 0.980\n",
      "epoch: 15/300 batch 116/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 15/300 batch 117/188  Train Loss: 0.056, Acc: 0.988\n",
      "epoch: 15/300 batch 118/188  Train Loss: 0.040, Acc: 0.980\n",
      "epoch: 15/300 batch 119/188  Train Loss: 0.077, Acc: 0.977\n",
      "epoch: 15/300 batch 120/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 15/300 batch 121/188  Train Loss: 0.072, Acc: 0.977\n",
      "epoch: 15/300 batch 122/188  Train Loss: 0.065, Acc: 0.977\n",
      "epoch: 15/300 batch 123/188  Train Loss: 0.103, Acc: 0.977\n",
      "epoch: 15/300 batch 124/188  Train Loss: 0.097, Acc: 0.984\n",
      "epoch: 15/300 batch 125/188  Train Loss: 0.087, Acc: 0.969\n",
      "epoch: 15/300 batch 126/188  Train Loss: 0.085, Acc: 0.973\n",
      "epoch: 15/300 batch 127/188  Train Loss: 0.130, Acc: 0.965\n",
      "epoch: 15/300 batch 128/188  Train Loss: 0.091, Acc: 0.965\n",
      "epoch: 15/300 batch 129/188  Train Loss: 0.075, Acc: 0.977\n",
      "epoch: 15/300 batch 130/188  Train Loss: 0.097, Acc: 0.973\n",
      "epoch: 15/300 batch 131/188  Train Loss: 0.088, Acc: 0.973\n",
      "epoch: 15/300 batch 132/188  Train Loss: 0.062, Acc: 0.977\n",
      "epoch: 15/300 batch 133/188  Train Loss: 0.088, Acc: 0.980\n",
      "epoch: 15/300 batch 134/188  Train Loss: 0.075, Acc: 0.980\n",
      "epoch: 15/300 batch 135/188  Train Loss: 0.092, Acc: 0.961\n",
      "epoch: 15/300 batch 136/188  Train Loss: 0.104, Acc: 0.969\n",
      "epoch: 15/300 batch 137/188  Train Loss: 0.118, Acc: 0.957\n",
      "epoch: 15/300 batch 138/188  Train Loss: 0.090, Acc: 0.969\n",
      "epoch: 15/300 batch 139/188  Train Loss: 0.129, Acc: 0.965\n",
      "epoch: 15/300 batch 140/188  Train Loss: 0.078, Acc: 0.977\n",
      "epoch: 15/300 batch 141/188  Train Loss: 0.111, Acc: 0.969\n",
      "epoch: 15/300 batch 142/188  Train Loss: 0.076, Acc: 0.973\n",
      "epoch: 15/300 batch 143/188  Train Loss: 0.056, Acc: 0.977\n",
      "epoch: 15/300 batch 144/188  Train Loss: 0.109, Acc: 0.961\n",
      "epoch: 15/300 batch 145/188  Train Loss: 0.090, Acc: 0.984\n",
      "epoch: 15/300 batch 146/188  Train Loss: 0.068, Acc: 0.977\n",
      "epoch: 15/300 batch 147/188  Train Loss: 0.162, Acc: 0.965\n",
      "epoch: 15/300 batch 148/188  Train Loss: 0.087, Acc: 0.973\n",
      "epoch: 15/300 batch 149/188  Train Loss: 0.087, Acc: 0.969\n",
      "epoch: 15/300 batch 150/188  Train Loss: 0.081, Acc: 0.977\n",
      "epoch: 15/300 batch 151/188  Train Loss: 0.103, Acc: 0.953\n",
      "epoch: 15/300 batch 152/188  Train Loss: 0.079, Acc: 0.969\n",
      "epoch: 15/300 batch 153/188  Train Loss: 0.058, Acc: 0.980\n",
      "epoch: 15/300 batch 154/188  Train Loss: 0.112, Acc: 0.965\n",
      "epoch: 15/300 batch 155/188  Train Loss: 0.088, Acc: 0.977\n",
      "epoch: 15/300 batch 156/188  Train Loss: 0.106, Acc: 0.969\n",
      "epoch: 15/300 batch 157/188  Train Loss: 0.089, Acc: 0.973\n",
      "epoch: 15/300 batch 158/188  Train Loss: 0.113, Acc: 0.965\n",
      "epoch: 15/300 batch 159/188  Train Loss: 0.080, Acc: 0.984\n",
      "epoch: 15/300 batch 160/188  Train Loss: 0.085, Acc: 0.953\n",
      "epoch: 15/300 batch 161/188  Train Loss: 0.061, Acc: 0.980\n",
      "epoch: 15/300 batch 162/188  Train Loss: 0.085, Acc: 0.988\n",
      "epoch: 15/300 batch 163/188  Train Loss: 0.080, Acc: 0.980\n",
      "epoch: 15/300 batch 164/188  Train Loss: 0.073, Acc: 0.980\n",
      "epoch: 15/300 batch 165/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 15/300 batch 166/188  Train Loss: 0.067, Acc: 0.980\n",
      "epoch: 15/300 batch 167/188  Train Loss: 0.060, Acc: 0.988\n",
      "epoch: 15/300 batch 168/188  Train Loss: 0.083, Acc: 0.980\n",
      "epoch: 15/300 batch 169/188  Train Loss: 0.095, Acc: 0.980\n",
      "epoch: 15/300 batch 170/188  Train Loss: 0.098, Acc: 0.980\n",
      "epoch: 15/300 batch 171/188  Train Loss: 0.083, Acc: 0.973\n",
      "epoch: 15/300 batch 172/188  Train Loss: 0.089, Acc: 0.980\n",
      "epoch: 15/300 batch 173/188  Train Loss: 0.085, Acc: 0.973\n",
      "epoch: 15/300 batch 174/188  Train Loss: 0.112, Acc: 0.969\n",
      "epoch: 15/300 batch 175/188  Train Loss: 0.070, Acc: 0.980\n",
      "epoch: 15/300 batch 176/188  Train Loss: 0.065, Acc: 0.977\n",
      "epoch: 15/300 batch 177/188  Train Loss: 0.088, Acc: 0.980\n",
      "epoch: 15/300 batch 178/188  Train Loss: 0.066, Acc: 0.977\n",
      "epoch: 15/300 batch 179/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 15/300 batch 180/188  Train Loss: 0.077, Acc: 0.973\n",
      "epoch: 15/300 batch 181/188  Train Loss: 0.082, Acc: 0.973\n",
      "epoch: 15/300 batch 182/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 15/300 batch 183/188  Train Loss: 0.140, Acc: 0.949\n",
      "epoch: 15/300 batch 184/188  Train Loss: 0.080, Acc: 0.984\n",
      "epoch: 15/300 batch 185/188  Train Loss: 0.070, Acc: 0.984\n",
      "epoch: 15/300 batch 186/188  Train Loss: 0.064, Acc: 0.980\n",
      "epoch: 15/300 batch 187/188  Train Loss: 0.069, Acc: 0.961\n",
      "Train Loss: 0.078520, Acc: 0.976\n",
      "Val Loss: 0.083052, Acc: 0.974\n",
      "epoch: 16/300 batch   0/188  Train Loss: 0.120, Acc: 0.965\n",
      "epoch: 16/300 batch   1/188  Train Loss: 0.082, Acc: 0.977\n",
      "epoch: 16/300 batch   2/188  Train Loss: 0.065, Acc: 0.973\n",
      "epoch: 16/300 batch   3/188  Train Loss: 0.104, Acc: 0.980\n",
      "epoch: 16/300 batch   4/188  Train Loss: 0.042, Acc: 0.996\n",
      "epoch: 16/300 batch   5/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 16/300 batch   6/188  Train Loss: 0.079, Acc: 0.980\n",
      "epoch: 16/300 batch   7/188  Train Loss: 0.032, Acc: 1.000\n",
      "epoch: 16/300 batch   8/188  Train Loss: 0.086, Acc: 0.961\n",
      "epoch: 16/300 batch   9/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 16/300 batch  10/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 16/300 batch  11/188  Train Loss: 0.059, Acc: 0.973\n",
      "epoch: 16/300 batch  12/188  Train Loss: 0.056, Acc: 0.980\n",
      "epoch: 16/300 batch  13/188  Train Loss: 0.079, Acc: 0.973\n",
      "epoch: 16/300 batch  14/188  Train Loss: 0.069, Acc: 0.973\n",
      "epoch: 16/300 batch  15/188  Train Loss: 0.131, Acc: 0.957\n",
      "epoch: 16/300 batch  16/188  Train Loss: 0.060, Acc: 0.980\n",
      "epoch: 16/300 batch  17/188  Train Loss: 0.090, Acc: 0.973\n",
      "epoch: 16/300 batch  18/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 16/300 batch  19/188  Train Loss: 0.115, Acc: 0.977\n",
      "epoch: 16/300 batch  20/188  Train Loss: 0.073, Acc: 0.977\n",
      "epoch: 16/300 batch  21/188  Train Loss: 0.116, Acc: 0.969\n",
      "epoch: 16/300 batch  22/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 16/300 batch  23/188  Train Loss: 0.051, Acc: 0.973\n",
      "epoch: 16/300 batch  24/188  Train Loss: 0.081, Acc: 0.973\n",
      "epoch: 16/300 batch  25/188  Train Loss: 0.087, Acc: 0.969\n",
      "epoch: 16/300 batch  26/188  Train Loss: 0.092, Acc: 0.973\n",
      "epoch: 16/300 batch  27/188  Train Loss: 0.065, Acc: 0.980\n",
      "epoch: 16/300 batch  28/188  Train Loss: 0.077, Acc: 0.980\n",
      "epoch: 16/300 batch  29/188  Train Loss: 0.060, Acc: 0.988\n",
      "epoch: 16/300 batch  30/188  Train Loss: 0.063, Acc: 0.980\n",
      "epoch: 16/300 batch  31/188  Train Loss: 0.082, Acc: 0.980\n",
      "epoch: 16/300 batch  32/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 16/300 batch  33/188  Train Loss: 0.057, Acc: 0.977\n",
      "epoch: 16/300 batch  34/188  Train Loss: 0.095, Acc: 0.973\n",
      "epoch: 16/300 batch  35/188  Train Loss: 0.096, Acc: 0.973\n",
      "epoch: 16/300 batch  36/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 16/300 batch  37/188  Train Loss: 0.072, Acc: 0.969\n",
      "epoch: 16/300 batch  38/188  Train Loss: 0.067, Acc: 0.965\n",
      "epoch: 16/300 batch  39/188  Train Loss: 0.076, Acc: 0.980\n",
      "epoch: 16/300 batch  40/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 16/300 batch  41/188  Train Loss: 0.063, Acc: 0.973\n",
      "epoch: 16/300 batch  42/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 16/300 batch  43/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 16/300 batch  44/188  Train Loss: 0.076, Acc: 0.969\n",
      "epoch: 16/300 batch  45/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 16/300 batch  46/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 16/300 batch  47/188  Train Loss: 0.126, Acc: 0.957\n",
      "epoch: 16/300 batch  48/188  Train Loss: 0.073, Acc: 0.980\n",
      "epoch: 16/300 batch  49/188  Train Loss: 0.110, Acc: 0.965\n",
      "epoch: 16/300 batch  50/188  Train Loss: 0.093, Acc: 0.965\n",
      "epoch: 16/300 batch  51/188  Train Loss: 0.071, Acc: 0.965\n",
      "epoch: 16/300 batch  52/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 16/300 batch  53/188  Train Loss: 0.076, Acc: 0.984\n",
      "epoch: 16/300 batch  54/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 16/300 batch  55/188  Train Loss: 0.068, Acc: 0.980\n",
      "epoch: 16/300 batch  56/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 16/300 batch  57/188  Train Loss: 0.064, Acc: 0.969\n",
      "epoch: 16/300 batch  58/188  Train Loss: 0.078, Acc: 0.973\n",
      "epoch: 16/300 batch  59/188  Train Loss: 0.092, Acc: 0.965\n",
      "epoch: 16/300 batch  60/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 16/300 batch  61/188  Train Loss: 0.063, Acc: 0.980\n",
      "epoch: 16/300 batch  62/188  Train Loss: 0.105, Acc: 0.965\n",
      "epoch: 16/300 batch  63/188  Train Loss: 0.047, Acc: 0.980\n",
      "epoch: 16/300 batch  64/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 16/300 batch  65/188  Train Loss: 0.070, Acc: 0.973\n",
      "epoch: 16/300 batch  66/188  Train Loss: 0.118, Acc: 0.961\n",
      "epoch: 16/300 batch  67/188  Train Loss: 0.079, Acc: 0.980\n",
      "epoch: 16/300 batch  68/188  Train Loss: 0.065, Acc: 0.984\n",
      "epoch: 16/300 batch  69/188  Train Loss: 0.090, Acc: 0.969\n",
      "epoch: 16/300 batch  70/188  Train Loss: 0.106, Acc: 0.969\n",
      "epoch: 16/300 batch  71/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 16/300 batch  72/188  Train Loss: 0.085, Acc: 0.980\n",
      "epoch: 16/300 batch  73/188  Train Loss: 0.124, Acc: 0.961\n",
      "epoch: 16/300 batch  74/188  Train Loss: 0.086, Acc: 0.969\n",
      "epoch: 16/300 batch  75/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 16/300 batch  76/188  Train Loss: 0.121, Acc: 0.977\n",
      "epoch: 16/300 batch  77/188  Train Loss: 0.140, Acc: 0.969\n",
      "epoch: 16/300 batch  78/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 16/300 batch  79/188  Train Loss: 0.093, Acc: 0.973\n",
      "epoch: 16/300 batch  80/188  Train Loss: 0.101, Acc: 0.969\n",
      "epoch: 16/300 batch  81/188  Train Loss: 0.076, Acc: 0.980\n",
      "epoch: 16/300 batch  82/188  Train Loss: 0.046, Acc: 0.980\n",
      "epoch: 16/300 batch  83/188  Train Loss: 0.058, Acc: 0.977\n",
      "epoch: 16/300 batch  84/188  Train Loss: 0.115, Acc: 0.957\n",
      "epoch: 16/300 batch  85/188  Train Loss: 0.093, Acc: 0.965\n",
      "epoch: 16/300 batch  86/188  Train Loss: 0.065, Acc: 0.980\n",
      "epoch: 16/300 batch  87/188  Train Loss: 0.063, Acc: 0.980\n",
      "epoch: 16/300 batch  88/188  Train Loss: 0.093, Acc: 0.973\n",
      "epoch: 16/300 batch  89/188  Train Loss: 0.068, Acc: 0.977\n",
      "epoch: 16/300 batch  90/188  Train Loss: 0.063, Acc: 0.980\n",
      "epoch: 16/300 batch  91/188  Train Loss: 0.078, Acc: 0.977\n",
      "epoch: 16/300 batch  92/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 16/300 batch  93/188  Train Loss: 0.104, Acc: 0.969\n",
      "epoch: 16/300 batch  94/188  Train Loss: 0.072, Acc: 0.977\n",
      "epoch: 16/300 batch  95/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 16/300 batch  96/188  Train Loss: 0.087, Acc: 0.984\n",
      "epoch: 16/300 batch  97/188  Train Loss: 0.074, Acc: 0.984\n",
      "epoch: 16/300 batch  98/188  Train Loss: 0.115, Acc: 0.965\n",
      "epoch: 16/300 batch  99/188  Train Loss: 0.074, Acc: 0.980\n",
      "epoch: 16/300 batch 100/188  Train Loss: 0.085, Acc: 0.969\n",
      "epoch: 16/300 batch 101/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 16/300 batch 102/188  Train Loss: 0.076, Acc: 0.977\n",
      "epoch: 16/300 batch 103/188  Train Loss: 0.075, Acc: 0.973\n",
      "epoch: 16/300 batch 104/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 16/300 batch 105/188  Train Loss: 0.051, Acc: 0.992\n",
      "epoch: 16/300 batch 106/188  Train Loss: 0.070, Acc: 0.977\n",
      "epoch: 16/300 batch 107/188  Train Loss: 0.074, Acc: 0.977\n",
      "epoch: 16/300 batch 108/188  Train Loss: 0.083, Acc: 0.977\n",
      "epoch: 16/300 batch 109/188  Train Loss: 0.096, Acc: 0.973\n",
      "epoch: 16/300 batch 110/188  Train Loss: 0.071, Acc: 0.973\n",
      "epoch: 16/300 batch 111/188  Train Loss: 0.096, Acc: 0.980\n",
      "epoch: 16/300 batch 112/188  Train Loss: 0.147, Acc: 0.957\n",
      "epoch: 16/300 batch 113/188  Train Loss: 0.104, Acc: 0.973\n",
      "epoch: 16/300 batch 114/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 16/300 batch 115/188  Train Loss: 0.069, Acc: 0.977\n",
      "epoch: 16/300 batch 116/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 16/300 batch 117/188  Train Loss: 0.101, Acc: 0.965\n",
      "epoch: 16/300 batch 118/188  Train Loss: 0.120, Acc: 0.973\n",
      "epoch: 16/300 batch 119/188  Train Loss: 0.064, Acc: 0.980\n",
      "epoch: 16/300 batch 120/188  Train Loss: 0.091, Acc: 0.969\n",
      "epoch: 16/300 batch 121/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 16/300 batch 122/188  Train Loss: 0.079, Acc: 0.973\n",
      "epoch: 16/300 batch 123/188  Train Loss: 0.116, Acc: 0.973\n",
      "epoch: 16/300 batch 124/188  Train Loss: 0.107, Acc: 0.965\n",
      "epoch: 16/300 batch 125/188  Train Loss: 0.139, Acc: 0.953\n",
      "epoch: 16/300 batch 126/188  Train Loss: 0.093, Acc: 0.973\n",
      "epoch: 16/300 batch 127/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 16/300 batch 128/188  Train Loss: 0.063, Acc: 0.988\n",
      "epoch: 16/300 batch 129/188  Train Loss: 0.085, Acc: 0.969\n",
      "epoch: 16/300 batch 130/188  Train Loss: 0.082, Acc: 0.980\n",
      "epoch: 16/300 batch 131/188  Train Loss: 0.068, Acc: 0.973\n",
      "epoch: 16/300 batch 132/188  Train Loss: 0.044, Acc: 0.980\n",
      "epoch: 16/300 batch 133/188  Train Loss: 0.079, Acc: 0.977\n",
      "epoch: 16/300 batch 134/188  Train Loss: 0.072, Acc: 0.977\n",
      "epoch: 16/300 batch 135/188  Train Loss: 0.062, Acc: 0.980\n",
      "epoch: 16/300 batch 136/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 16/300 batch 137/188  Train Loss: 0.109, Acc: 0.965\n",
      "epoch: 16/300 batch 138/188  Train Loss: 0.060, Acc: 0.977\n",
      "epoch: 16/300 batch 139/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 16/300 batch 140/188  Train Loss: 0.073, Acc: 0.984\n",
      "epoch: 16/300 batch 141/188  Train Loss: 0.132, Acc: 0.957\n",
      "epoch: 16/300 batch 142/188  Train Loss: 0.064, Acc: 0.977\n",
      "epoch: 16/300 batch 143/188  Train Loss: 0.099, Acc: 0.969\n",
      "epoch: 16/300 batch 144/188  Train Loss: 0.097, Acc: 0.980\n",
      "epoch: 16/300 batch 145/188  Train Loss: 0.074, Acc: 0.973\n",
      "epoch: 16/300 batch 146/188  Train Loss: 0.101, Acc: 0.965\n",
      "epoch: 16/300 batch 147/188  Train Loss: 0.094, Acc: 0.961\n",
      "epoch: 16/300 batch 148/188  Train Loss: 0.052, Acc: 0.977\n",
      "epoch: 16/300 batch 149/188  Train Loss: 0.081, Acc: 0.969\n",
      "epoch: 16/300 batch 150/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 16/300 batch 151/188  Train Loss: 0.114, Acc: 0.977\n",
      "epoch: 16/300 batch 152/188  Train Loss: 0.091, Acc: 0.977\n",
      "epoch: 16/300 batch 153/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 16/300 batch 154/188  Train Loss: 0.100, Acc: 0.969\n",
      "epoch: 16/300 batch 155/188  Train Loss: 0.059, Acc: 0.980\n",
      "epoch: 16/300 batch 156/188  Train Loss: 0.086, Acc: 0.973\n",
      "epoch: 16/300 batch 157/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 16/300 batch 158/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 16/300 batch 159/188  Train Loss: 0.088, Acc: 0.980\n",
      "epoch: 16/300 batch 160/188  Train Loss: 0.102, Acc: 0.961\n",
      "epoch: 16/300 batch 161/188  Train Loss: 0.093, Acc: 0.980\n",
      "epoch: 16/300 batch 162/188  Train Loss: 0.068, Acc: 0.980\n",
      "epoch: 16/300 batch 163/188  Train Loss: 0.076, Acc: 0.984\n",
      "epoch: 16/300 batch 164/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 16/300 batch 165/188  Train Loss: 0.099, Acc: 0.977\n",
      "epoch: 16/300 batch 166/188  Train Loss: 0.064, Acc: 0.988\n",
      "epoch: 16/300 batch 167/188  Train Loss: 0.063, Acc: 0.977\n",
      "epoch: 16/300 batch 168/188  Train Loss: 0.119, Acc: 0.957\n",
      "epoch: 16/300 batch 169/188  Train Loss: 0.086, Acc: 0.969\n",
      "epoch: 16/300 batch 170/188  Train Loss: 0.064, Acc: 0.980\n",
      "epoch: 16/300 batch 171/188  Train Loss: 0.067, Acc: 0.984\n",
      "epoch: 16/300 batch 172/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 16/300 batch 173/188  Train Loss: 0.098, Acc: 0.957\n",
      "epoch: 16/300 batch 174/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 16/300 batch 175/188  Train Loss: 0.059, Acc: 0.992\n",
      "epoch: 16/300 batch 176/188  Train Loss: 0.124, Acc: 0.969\n",
      "epoch: 16/300 batch 177/188  Train Loss: 0.065, Acc: 0.984\n",
      "epoch: 16/300 batch 178/188  Train Loss: 0.051, Acc: 0.980\n",
      "epoch: 16/300 batch 179/188  Train Loss: 0.085, Acc: 0.965\n",
      "epoch: 16/300 batch 180/188  Train Loss: 0.113, Acc: 0.965\n",
      "epoch: 16/300 batch 181/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 16/300 batch 182/188  Train Loss: 0.108, Acc: 0.977\n",
      "epoch: 16/300 batch 183/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 16/300 batch 184/188  Train Loss: 0.089, Acc: 0.973\n",
      "epoch: 16/300 batch 185/188  Train Loss: 0.069, Acc: 0.973\n",
      "epoch: 16/300 batch 186/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 16/300 batch 187/188  Train Loss: 0.072, Acc: 0.992\n",
      "Train Loss: 0.075343, Acc: 0.977\n",
      "Val Loss: 0.084319, Acc: 0.974\n",
      "epoch: 17/300 batch   0/188  Train Loss: 0.056, Acc: 0.988\n",
      "epoch: 17/300 batch   1/188  Train Loss: 0.102, Acc: 0.965\n",
      "epoch: 17/300 batch   2/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 17/300 batch   3/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 17/300 batch   4/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 17/300 batch   5/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 17/300 batch   6/188  Train Loss: 0.133, Acc: 0.965\n",
      "epoch: 17/300 batch   7/188  Train Loss: 0.072, Acc: 0.988\n",
      "epoch: 17/300 batch   8/188  Train Loss: 0.078, Acc: 0.965\n",
      "epoch: 17/300 batch   9/188  Train Loss: 0.105, Acc: 0.965\n",
      "epoch: 17/300 batch  10/188  Train Loss: 0.084, Acc: 0.977\n",
      "epoch: 17/300 batch  11/188  Train Loss: 0.084, Acc: 0.957\n",
      "epoch: 17/300 batch  12/188  Train Loss: 0.060, Acc: 0.973\n",
      "epoch: 17/300 batch  13/188  Train Loss: 0.093, Acc: 0.973\n",
      "epoch: 17/300 batch  14/188  Train Loss: 0.088, Acc: 0.969\n",
      "epoch: 17/300 batch  15/188  Train Loss: 0.065, Acc: 0.973\n",
      "epoch: 17/300 batch  16/188  Train Loss: 0.092, Acc: 0.965\n",
      "epoch: 17/300 batch  17/188  Train Loss: 0.149, Acc: 0.961\n",
      "epoch: 17/300 batch  18/188  Train Loss: 0.068, Acc: 0.973\n",
      "epoch: 17/300 batch  19/188  Train Loss: 0.112, Acc: 0.973\n",
      "epoch: 17/300 batch  20/188  Train Loss: 0.109, Acc: 0.980\n",
      "epoch: 17/300 batch  21/188  Train Loss: 0.073, Acc: 0.984\n",
      "epoch: 17/300 batch  22/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 17/300 batch  23/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 17/300 batch  24/188  Train Loss: 0.068, Acc: 0.973\n",
      "epoch: 17/300 batch  25/188  Train Loss: 0.104, Acc: 0.969\n",
      "epoch: 17/300 batch  26/188  Train Loss: 0.081, Acc: 0.969\n",
      "epoch: 17/300 batch  27/188  Train Loss: 0.069, Acc: 0.980\n",
      "epoch: 17/300 batch  28/188  Train Loss: 0.087, Acc: 0.973\n",
      "epoch: 17/300 batch  29/188  Train Loss: 0.060, Acc: 0.984\n",
      "epoch: 17/300 batch  30/188  Train Loss: 0.067, Acc: 0.973\n",
      "epoch: 17/300 batch  31/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 17/300 batch  32/188  Train Loss: 0.115, Acc: 0.965\n",
      "epoch: 17/300 batch  33/188  Train Loss: 0.057, Acc: 0.980\n",
      "epoch: 17/300 batch  34/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 17/300 batch  35/188  Train Loss: 0.100, Acc: 0.957\n",
      "epoch: 17/300 batch  36/188  Train Loss: 0.065, Acc: 0.980\n",
      "epoch: 17/300 batch  37/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 17/300 batch  38/188  Train Loss: 0.072, Acc: 0.973\n",
      "epoch: 17/300 batch  39/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 17/300 batch  40/188  Train Loss: 0.055, Acc: 0.977\n",
      "epoch: 17/300 batch  41/188  Train Loss: 0.061, Acc: 0.977\n",
      "epoch: 17/300 batch  42/188  Train Loss: 0.073, Acc: 0.973\n",
      "epoch: 17/300 batch  43/188  Train Loss: 0.136, Acc: 0.961\n",
      "epoch: 17/300 batch  44/188  Train Loss: 0.089, Acc: 0.977\n",
      "epoch: 17/300 batch  45/188  Train Loss: 0.047, Acc: 0.980\n",
      "epoch: 17/300 batch  46/188  Train Loss: 0.130, Acc: 0.953\n",
      "epoch: 17/300 batch  47/188  Train Loss: 0.070, Acc: 0.984\n",
      "epoch: 17/300 batch  48/188  Train Loss: 0.090, Acc: 0.965\n",
      "epoch: 17/300 batch  49/188  Train Loss: 0.107, Acc: 0.973\n",
      "epoch: 17/300 batch  50/188  Train Loss: 0.063, Acc: 0.980\n",
      "epoch: 17/300 batch  51/188  Train Loss: 0.096, Acc: 0.969\n",
      "epoch: 17/300 batch  52/188  Train Loss: 0.067, Acc: 0.973\n",
      "epoch: 17/300 batch  53/188  Train Loss: 0.073, Acc: 0.988\n",
      "epoch: 17/300 batch  54/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 17/300 batch  55/188  Train Loss: 0.076, Acc: 0.977\n",
      "epoch: 17/300 batch  56/188  Train Loss: 0.070, Acc: 0.977\n",
      "epoch: 17/300 batch  57/188  Train Loss: 0.102, Acc: 0.969\n",
      "epoch: 17/300 batch  58/188  Train Loss: 0.138, Acc: 0.949\n",
      "epoch: 17/300 batch  59/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 17/300 batch  60/188  Train Loss: 0.066, Acc: 0.988\n",
      "epoch: 17/300 batch  61/188  Train Loss: 0.074, Acc: 0.984\n",
      "epoch: 17/300 batch  62/188  Train Loss: 0.065, Acc: 0.988\n",
      "epoch: 17/300 batch  63/188  Train Loss: 0.078, Acc: 0.980\n",
      "epoch: 17/300 batch  64/188  Train Loss: 0.097, Acc: 0.973\n",
      "epoch: 17/300 batch  65/188  Train Loss: 0.124, Acc: 0.965\n",
      "epoch: 17/300 batch  66/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 17/300 batch  67/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 17/300 batch  68/188  Train Loss: 0.074, Acc: 0.980\n",
      "epoch: 17/300 batch  69/188  Train Loss: 0.050, Acc: 0.980\n",
      "epoch: 17/300 batch  70/188  Train Loss: 0.071, Acc: 0.980\n",
      "epoch: 17/300 batch  71/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 17/300 batch  72/188  Train Loss: 0.141, Acc: 0.949\n",
      "epoch: 17/300 batch  73/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 17/300 batch  74/188  Train Loss: 0.079, Acc: 0.980\n",
      "epoch: 17/300 batch  75/188  Train Loss: 0.108, Acc: 0.961\n",
      "epoch: 17/300 batch  76/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 17/300 batch  77/188  Train Loss: 0.079, Acc: 0.977\n",
      "epoch: 17/300 batch  78/188  Train Loss: 0.092, Acc: 0.969\n",
      "epoch: 17/300 batch  79/188  Train Loss: 0.067, Acc: 0.980\n",
      "epoch: 17/300 batch  80/188  Train Loss: 0.070, Acc: 0.977\n",
      "epoch: 17/300 batch  81/188  Train Loss: 0.063, Acc: 0.977\n",
      "epoch: 17/300 batch  82/188  Train Loss: 0.058, Acc: 0.992\n",
      "epoch: 17/300 batch  83/188  Train Loss: 0.090, Acc: 0.965\n",
      "epoch: 17/300 batch  84/188  Train Loss: 0.066, Acc: 0.980\n",
      "epoch: 17/300 batch  85/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 17/300 batch  86/188  Train Loss: 0.072, Acc: 0.977\n",
      "epoch: 17/300 batch  87/188  Train Loss: 0.073, Acc: 0.984\n",
      "epoch: 17/300 batch  88/188  Train Loss: 0.097, Acc: 0.965\n",
      "epoch: 17/300 batch  89/188  Train Loss: 0.059, Acc: 0.980\n",
      "epoch: 17/300 batch  90/188  Train Loss: 0.062, Acc: 0.973\n",
      "epoch: 17/300 batch  91/188  Train Loss: 0.079, Acc: 0.980\n",
      "epoch: 17/300 batch  92/188  Train Loss: 0.073, Acc: 0.973\n",
      "epoch: 17/300 batch  93/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 17/300 batch  94/188  Train Loss: 0.054, Acc: 0.980\n",
      "epoch: 17/300 batch  95/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 17/300 batch  96/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 17/300 batch  97/188  Train Loss: 0.070, Acc: 0.977\n",
      "epoch: 17/300 batch  98/188  Train Loss: 0.101, Acc: 0.965\n",
      "epoch: 17/300 batch  99/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 17/300 batch 100/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 17/300 batch 101/188  Train Loss: 0.104, Acc: 0.973\n",
      "epoch: 17/300 batch 102/188  Train Loss: 0.061, Acc: 0.980\n",
      "epoch: 17/300 batch 103/188  Train Loss: 0.084, Acc: 0.980\n",
      "epoch: 17/300 batch 104/188  Train Loss: 0.067, Acc: 0.980\n",
      "epoch: 17/300 batch 105/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 17/300 batch 106/188  Train Loss: 0.101, Acc: 0.969\n",
      "epoch: 17/300 batch 107/188  Train Loss: 0.076, Acc: 0.977\n",
      "epoch: 17/300 batch 108/188  Train Loss: 0.078, Acc: 0.977\n",
      "epoch: 17/300 batch 109/188  Train Loss: 0.057, Acc: 0.977\n",
      "epoch: 17/300 batch 110/188  Train Loss: 0.068, Acc: 0.977\n",
      "epoch: 17/300 batch 111/188  Train Loss: 0.067, Acc: 0.980\n",
      "epoch: 17/300 batch 112/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 17/300 batch 113/188  Train Loss: 0.061, Acc: 0.980\n",
      "epoch: 17/300 batch 114/188  Train Loss: 0.084, Acc: 0.973\n",
      "epoch: 17/300 batch 115/188  Train Loss: 0.069, Acc: 0.980\n",
      "epoch: 17/300 batch 116/188  Train Loss: 0.131, Acc: 0.957\n",
      "epoch: 17/300 batch 117/188  Train Loss: 0.070, Acc: 0.980\n",
      "epoch: 17/300 batch 118/188  Train Loss: 0.084, Acc: 0.965\n",
      "epoch: 17/300 batch 119/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 17/300 batch 120/188  Train Loss: 0.101, Acc: 0.973\n",
      "epoch: 17/300 batch 121/188  Train Loss: 0.099, Acc: 0.973\n",
      "epoch: 17/300 batch 122/188  Train Loss: 0.114, Acc: 0.965\n",
      "epoch: 17/300 batch 123/188  Train Loss: 0.065, Acc: 0.977\n",
      "epoch: 17/300 batch 124/188  Train Loss: 0.122, Acc: 0.961\n",
      "epoch: 17/300 batch 125/188  Train Loss: 0.071, Acc: 0.977\n",
      "epoch: 17/300 batch 126/188  Train Loss: 0.092, Acc: 0.969\n",
      "epoch: 17/300 batch 127/188  Train Loss: 0.137, Acc: 0.969\n",
      "epoch: 17/300 batch 128/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 17/300 batch 129/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 17/300 batch 130/188  Train Loss: 0.066, Acc: 0.973\n",
      "epoch: 17/300 batch 131/188  Train Loss: 0.058, Acc: 0.980\n",
      "epoch: 17/300 batch 132/188  Train Loss: 0.090, Acc: 0.973\n",
      "epoch: 17/300 batch 133/188  Train Loss: 0.084, Acc: 0.977\n",
      "epoch: 17/300 batch 134/188  Train Loss: 0.069, Acc: 0.980\n",
      "epoch: 17/300 batch 135/188  Train Loss: 0.062, Acc: 0.977\n",
      "epoch: 17/300 batch 136/188  Train Loss: 0.097, Acc: 0.973\n",
      "epoch: 17/300 batch 137/188  Train Loss: 0.071, Acc: 0.969\n",
      "epoch: 17/300 batch 138/188  Train Loss: 0.102, Acc: 0.969\n",
      "epoch: 17/300 batch 139/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 17/300 batch 140/188  Train Loss: 0.091, Acc: 0.988\n",
      "epoch: 17/300 batch 141/188  Train Loss: 0.092, Acc: 0.965\n",
      "epoch: 17/300 batch 142/188  Train Loss: 0.080, Acc: 0.969\n",
      "epoch: 17/300 batch 143/188  Train Loss: 0.096, Acc: 0.961\n",
      "epoch: 17/300 batch 144/188  Train Loss: 0.072, Acc: 0.980\n",
      "epoch: 17/300 batch 145/188  Train Loss: 0.070, Acc: 0.969\n",
      "epoch: 17/300 batch 146/188  Train Loss: 0.139, Acc: 0.957\n",
      "epoch: 17/300 batch 147/188  Train Loss: 0.066, Acc: 0.977\n",
      "epoch: 17/300 batch 148/188  Train Loss: 0.084, Acc: 0.961\n",
      "epoch: 17/300 batch 149/188  Train Loss: 0.085, Acc: 0.984\n",
      "epoch: 17/300 batch 150/188  Train Loss: 0.170, Acc: 0.945\n",
      "epoch: 17/300 batch 151/188  Train Loss: 0.106, Acc: 0.965\n",
      "epoch: 17/300 batch 152/188  Train Loss: 0.070, Acc: 0.977\n",
      "epoch: 17/300 batch 153/188  Train Loss: 0.064, Acc: 0.980\n",
      "epoch: 17/300 batch 154/188  Train Loss: 0.057, Acc: 0.980\n",
      "epoch: 17/300 batch 155/188  Train Loss: 0.063, Acc: 0.988\n",
      "epoch: 17/300 batch 156/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 17/300 batch 157/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 17/300 batch 158/188  Train Loss: 0.056, Acc: 0.977\n",
      "epoch: 17/300 batch 159/188  Train Loss: 0.069, Acc: 0.977\n",
      "epoch: 17/300 batch 160/188  Train Loss: 0.056, Acc: 0.980\n",
      "epoch: 17/300 batch 161/188  Train Loss: 0.139, Acc: 0.977\n",
      "epoch: 17/300 batch 162/188  Train Loss: 0.066, Acc: 0.980\n",
      "epoch: 17/300 batch 163/188  Train Loss: 0.060, Acc: 0.973\n",
      "epoch: 17/300 batch 164/188  Train Loss: 0.069, Acc: 0.977\n",
      "epoch: 17/300 batch 165/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 17/300 batch 166/188  Train Loss: 0.068, Acc: 0.984\n",
      "epoch: 17/300 batch 167/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 17/300 batch 168/188  Train Loss: 0.082, Acc: 0.980\n",
      "epoch: 17/300 batch 169/188  Train Loss: 0.080, Acc: 0.980\n",
      "epoch: 17/300 batch 170/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 17/300 batch 171/188  Train Loss: 0.077, Acc: 0.969\n",
      "epoch: 17/300 batch 172/188  Train Loss: 0.139, Acc: 0.965\n",
      "epoch: 17/300 batch 173/188  Train Loss: 0.099, Acc: 0.977\n",
      "epoch: 17/300 batch 174/188  Train Loss: 0.115, Acc: 0.965\n",
      "epoch: 17/300 batch 175/188  Train Loss: 0.073, Acc: 0.988\n",
      "epoch: 17/300 batch 176/188  Train Loss: 0.076, Acc: 0.977\n",
      "epoch: 17/300 batch 177/188  Train Loss: 0.118, Acc: 0.969\n",
      "epoch: 17/300 batch 178/188  Train Loss: 0.097, Acc: 0.977\n",
      "epoch: 17/300 batch 179/188  Train Loss: 0.056, Acc: 0.980\n",
      "epoch: 17/300 batch 180/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 17/300 batch 181/188  Train Loss: 0.102, Acc: 0.965\n",
      "epoch: 17/300 batch 182/188  Train Loss: 0.069, Acc: 0.977\n",
      "epoch: 17/300 batch 183/188  Train Loss: 0.118, Acc: 0.949\n",
      "epoch: 17/300 batch 184/188  Train Loss: 0.160, Acc: 0.965\n",
      "epoch: 17/300 batch 185/188  Train Loss: 0.103, Acc: 0.961\n",
      "epoch: 17/300 batch 186/188  Train Loss: 0.099, Acc: 0.977\n",
      "epoch: 17/300 batch 187/188  Train Loss: 0.043, Acc: 0.984\n",
      "Train Loss: 0.077314, Acc: 0.976\n",
      "Val Loss: 0.079723, Acc: 0.977\n",
      "epoch: 18/300 batch   0/188  Train Loss: 0.093, Acc: 0.977\n",
      "epoch: 18/300 batch   1/188  Train Loss: 0.053, Acc: 0.992\n",
      "epoch: 18/300 batch   2/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 18/300 batch   3/188  Train Loss: 0.075, Acc: 0.969\n",
      "epoch: 18/300 batch   4/188  Train Loss: 0.099, Acc: 0.969\n",
      "epoch: 18/300 batch   5/188  Train Loss: 0.061, Acc: 0.980\n",
      "epoch: 18/300 batch   6/188  Train Loss: 0.089, Acc: 0.973\n",
      "epoch: 18/300 batch   7/188  Train Loss: 0.105, Acc: 0.980\n",
      "epoch: 18/300 batch   8/188  Train Loss: 0.080, Acc: 0.973\n",
      "epoch: 18/300 batch   9/188  Train Loss: 0.096, Acc: 0.957\n",
      "epoch: 18/300 batch  10/188  Train Loss: 0.055, Acc: 0.980\n",
      "epoch: 18/300 batch  11/188  Train Loss: 0.061, Acc: 0.984\n",
      "epoch: 18/300 batch  12/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 18/300 batch  13/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 18/300 batch  14/188  Train Loss: 0.059, Acc: 0.980\n",
      "epoch: 18/300 batch  15/188  Train Loss: 0.052, Acc: 0.980\n",
      "epoch: 18/300 batch  16/188  Train Loss: 0.090, Acc: 0.977\n",
      "epoch: 18/300 batch  17/188  Train Loss: 0.082, Acc: 0.980\n",
      "epoch: 18/300 batch  18/188  Train Loss: 0.071, Acc: 0.973\n",
      "epoch: 18/300 batch  19/188  Train Loss: 0.059, Acc: 0.984\n",
      "epoch: 18/300 batch  20/188  Train Loss: 0.062, Acc: 0.984\n",
      "epoch: 18/300 batch  21/188  Train Loss: 0.080, Acc: 0.977\n",
      "epoch: 18/300 batch  22/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 18/300 batch  23/188  Train Loss: 0.076, Acc: 0.977\n",
      "epoch: 18/300 batch  24/188  Train Loss: 0.108, Acc: 0.980\n",
      "epoch: 18/300 batch  25/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 18/300 batch  26/188  Train Loss: 0.059, Acc: 0.980\n",
      "epoch: 18/300 batch  27/188  Train Loss: 0.064, Acc: 0.977\n",
      "epoch: 18/300 batch  28/188  Train Loss: 0.082, Acc: 0.969\n",
      "epoch: 18/300 batch  29/188  Train Loss: 0.066, Acc: 0.988\n",
      "epoch: 18/300 batch  30/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 18/300 batch  31/188  Train Loss: 0.087, Acc: 0.977\n",
      "epoch: 18/300 batch  32/188  Train Loss: 0.051, Acc: 0.973\n",
      "epoch: 18/300 batch  33/188  Train Loss: 0.073, Acc: 0.977\n",
      "epoch: 18/300 batch  34/188  Train Loss: 0.068, Acc: 0.980\n",
      "epoch: 18/300 batch  35/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 18/300 batch  36/188  Train Loss: 0.060, Acc: 0.988\n",
      "epoch: 18/300 batch  37/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 18/300 batch  38/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 18/300 batch  39/188  Train Loss: 0.050, Acc: 0.980\n",
      "epoch: 18/300 batch  40/188  Train Loss: 0.065, Acc: 0.980\n",
      "epoch: 18/300 batch  41/188  Train Loss: 0.062, Acc: 0.984\n",
      "epoch: 18/300 batch  42/188  Train Loss: 0.051, Acc: 0.980\n",
      "epoch: 18/300 batch  43/188  Train Loss: 0.087, Acc: 0.969\n",
      "epoch: 18/300 batch  44/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 18/300 batch  45/188  Train Loss: 0.129, Acc: 0.969\n",
      "epoch: 18/300 batch  46/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 18/300 batch  47/188  Train Loss: 0.068, Acc: 0.980\n",
      "epoch: 18/300 batch  48/188  Train Loss: 0.042, Acc: 0.996\n",
      "epoch: 18/300 batch  49/188  Train Loss: 0.070, Acc: 0.980\n",
      "epoch: 18/300 batch  50/188  Train Loss: 0.075, Acc: 0.980\n",
      "epoch: 18/300 batch  51/188  Train Loss: 0.073, Acc: 0.969\n",
      "epoch: 18/300 batch  52/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 18/300 batch  53/188  Train Loss: 0.076, Acc: 0.973\n",
      "epoch: 18/300 batch  54/188  Train Loss: 0.096, Acc: 0.961\n",
      "epoch: 18/300 batch  55/188  Train Loss: 0.072, Acc: 0.977\n",
      "epoch: 18/300 batch  56/188  Train Loss: 0.081, Acc: 0.977\n",
      "epoch: 18/300 batch  57/188  Train Loss: 0.075, Acc: 0.977\n",
      "epoch: 18/300 batch  58/188  Train Loss: 0.115, Acc: 0.953\n",
      "epoch: 18/300 batch  59/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 18/300 batch  60/188  Train Loss: 0.103, Acc: 0.973\n",
      "epoch: 18/300 batch  61/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 18/300 batch  62/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 18/300 batch  63/188  Train Loss: 0.090, Acc: 0.977\n",
      "epoch: 18/300 batch  64/188  Train Loss: 0.072, Acc: 0.977\n",
      "epoch: 18/300 batch  65/188  Train Loss: 0.091, Acc: 0.977\n",
      "epoch: 18/300 batch  66/188  Train Loss: 0.089, Acc: 0.973\n",
      "epoch: 18/300 batch  67/188  Train Loss: 0.066, Acc: 0.984\n",
      "epoch: 18/300 batch  68/188  Train Loss: 0.064, Acc: 0.984\n",
      "epoch: 18/300 batch  69/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 18/300 batch  70/188  Train Loss: 0.068, Acc: 0.984\n",
      "epoch: 18/300 batch  71/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 18/300 batch  72/188  Train Loss: 0.060, Acc: 0.992\n",
      "epoch: 18/300 batch  73/188  Train Loss: 0.115, Acc: 0.977\n",
      "epoch: 18/300 batch  74/188  Train Loss: 0.081, Acc: 0.969\n",
      "epoch: 18/300 batch  75/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 18/300 batch  76/188  Train Loss: 0.075, Acc: 0.965\n",
      "epoch: 18/300 batch  77/188  Train Loss: 0.095, Acc: 0.977\n",
      "epoch: 18/300 batch  78/188  Train Loss: 0.054, Acc: 0.977\n",
      "epoch: 18/300 batch  79/188  Train Loss: 0.088, Acc: 0.973\n",
      "epoch: 18/300 batch  80/188  Train Loss: 0.093, Acc: 0.969\n",
      "epoch: 18/300 batch  81/188  Train Loss: 0.119, Acc: 0.977\n",
      "epoch: 18/300 batch  82/188  Train Loss: 0.061, Acc: 0.984\n",
      "epoch: 18/300 batch  83/188  Train Loss: 0.079, Acc: 0.980\n",
      "epoch: 18/300 batch  84/188  Train Loss: 0.079, Acc: 0.969\n",
      "epoch: 18/300 batch  85/188  Train Loss: 0.069, Acc: 0.977\n",
      "epoch: 18/300 batch  86/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 18/300 batch  87/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 18/300 batch  88/188  Train Loss: 0.069, Acc: 0.980\n",
      "epoch: 18/300 batch  89/188  Train Loss: 0.112, Acc: 0.973\n",
      "epoch: 18/300 batch  90/188  Train Loss: 0.083, Acc: 0.984\n",
      "epoch: 18/300 batch  91/188  Train Loss: 0.073, Acc: 0.980\n",
      "epoch: 18/300 batch  92/188  Train Loss: 0.111, Acc: 0.977\n",
      "epoch: 18/300 batch  93/188  Train Loss: 0.090, Acc: 0.977\n",
      "epoch: 18/300 batch  94/188  Train Loss: 0.102, Acc: 0.973\n",
      "epoch: 18/300 batch  95/188  Train Loss: 0.108, Acc: 0.977\n",
      "epoch: 18/300 batch  96/188  Train Loss: 0.070, Acc: 0.977\n",
      "epoch: 18/300 batch  97/188  Train Loss: 0.079, Acc: 0.973\n",
      "epoch: 18/300 batch  98/188  Train Loss: 0.106, Acc: 0.957\n",
      "epoch: 18/300 batch  99/188  Train Loss: 0.126, Acc: 0.949\n",
      "epoch: 18/300 batch 100/188  Train Loss: 0.119, Acc: 0.957\n",
      "epoch: 18/300 batch 101/188  Train Loss: 0.075, Acc: 0.980\n",
      "epoch: 18/300 batch 102/188  Train Loss: 0.079, Acc: 0.980\n",
      "epoch: 18/300 batch 103/188  Train Loss: 0.103, Acc: 0.969\n",
      "epoch: 18/300 batch 104/188  Train Loss: 0.091, Acc: 0.969\n",
      "epoch: 18/300 batch 105/188  Train Loss: 0.066, Acc: 0.973\n",
      "epoch: 18/300 batch 106/188  Train Loss: 0.092, Acc: 0.984\n",
      "epoch: 18/300 batch 107/188  Train Loss: 0.122, Acc: 0.969\n",
      "epoch: 18/300 batch 108/188  Train Loss: 0.087, Acc: 0.961\n",
      "epoch: 18/300 batch 109/188  Train Loss: 0.081, Acc: 0.973\n",
      "epoch: 18/300 batch 110/188  Train Loss: 0.081, Acc: 0.980\n",
      "epoch: 18/300 batch 111/188  Train Loss: 0.096, Acc: 0.965\n",
      "epoch: 18/300 batch 112/188  Train Loss: 0.096, Acc: 0.969\n",
      "epoch: 18/300 batch 113/188  Train Loss: 0.149, Acc: 0.953\n",
      "epoch: 18/300 batch 114/188  Train Loss: 0.091, Acc: 0.973\n",
      "epoch: 18/300 batch 115/188  Train Loss: 0.061, Acc: 0.980\n",
      "epoch: 18/300 batch 116/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 18/300 batch 117/188  Train Loss: 0.102, Acc: 0.965\n",
      "epoch: 18/300 batch 118/188  Train Loss: 0.052, Acc: 0.992\n",
      "epoch: 18/300 batch 119/188  Train Loss: 0.109, Acc: 0.977\n",
      "epoch: 18/300 batch 120/188  Train Loss: 0.078, Acc: 0.977\n",
      "epoch: 18/300 batch 121/188  Train Loss: 0.074, Acc: 0.977\n",
      "epoch: 18/300 batch 122/188  Train Loss: 0.083, Acc: 0.977\n",
      "epoch: 18/300 batch 123/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 18/300 batch 124/188  Train Loss: 0.059, Acc: 0.984\n",
      "epoch: 18/300 batch 125/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 18/300 batch 126/188  Train Loss: 0.071, Acc: 0.969\n",
      "epoch: 18/300 batch 127/188  Train Loss: 0.080, Acc: 0.965\n",
      "epoch: 18/300 batch 128/188  Train Loss: 0.063, Acc: 0.984\n",
      "epoch: 18/300 batch 129/188  Train Loss: 0.075, Acc: 0.977\n",
      "epoch: 18/300 batch 130/188  Train Loss: 0.109, Acc: 0.957\n",
      "epoch: 18/300 batch 131/188  Train Loss: 0.064, Acc: 0.973\n",
      "epoch: 18/300 batch 132/188  Train Loss: 0.078, Acc: 0.969\n",
      "epoch: 18/300 batch 133/188  Train Loss: 0.092, Acc: 0.973\n",
      "epoch: 18/300 batch 134/188  Train Loss: 0.074, Acc: 0.965\n",
      "epoch: 18/300 batch 135/188  Train Loss: 0.080, Acc: 0.973\n",
      "epoch: 18/300 batch 136/188  Train Loss: 0.056, Acc: 0.977\n",
      "epoch: 18/300 batch 137/188  Train Loss: 0.065, Acc: 0.969\n",
      "epoch: 18/300 batch 138/188  Train Loss: 0.120, Acc: 0.969\n",
      "epoch: 18/300 batch 139/188  Train Loss: 0.135, Acc: 0.961\n",
      "epoch: 18/300 batch 140/188  Train Loss: 0.053, Acc: 0.980\n",
      "epoch: 18/300 batch 141/188  Train Loss: 0.062, Acc: 0.977\n",
      "epoch: 18/300 batch 142/188  Train Loss: 0.095, Acc: 0.961\n",
      "epoch: 18/300 batch 143/188  Train Loss: 0.086, Acc: 0.965\n",
      "epoch: 18/300 batch 144/188  Train Loss: 0.043, Acc: 0.996\n",
      "epoch: 18/300 batch 145/188  Train Loss: 0.060, Acc: 0.977\n",
      "epoch: 18/300 batch 146/188  Train Loss: 0.081, Acc: 0.969\n",
      "epoch: 18/300 batch 147/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 18/300 batch 148/188  Train Loss: 0.072, Acc: 0.973\n",
      "epoch: 18/300 batch 149/188  Train Loss: 0.093, Acc: 0.969\n",
      "epoch: 18/300 batch 150/188  Train Loss: 0.054, Acc: 0.992\n",
      "epoch: 18/300 batch 151/188  Train Loss: 0.087, Acc: 0.969\n",
      "epoch: 18/300 batch 152/188  Train Loss: 0.111, Acc: 0.961\n",
      "epoch: 18/300 batch 153/188  Train Loss: 0.105, Acc: 0.961\n",
      "epoch: 18/300 batch 154/188  Train Loss: 0.073, Acc: 0.984\n",
      "epoch: 18/300 batch 155/188  Train Loss: 0.096, Acc: 0.965\n",
      "epoch: 18/300 batch 156/188  Train Loss: 0.123, Acc: 0.973\n",
      "epoch: 18/300 batch 157/188  Train Loss: 0.100, Acc: 0.969\n",
      "epoch: 18/300 batch 158/188  Train Loss: 0.094, Acc: 0.969\n",
      "epoch: 18/300 batch 159/188  Train Loss: 0.051, Acc: 0.980\n",
      "epoch: 18/300 batch 160/188  Train Loss: 0.093, Acc: 0.973\n",
      "epoch: 18/300 batch 161/188  Train Loss: 0.094, Acc: 0.980\n",
      "epoch: 18/300 batch 162/188  Train Loss: 0.134, Acc: 0.973\n",
      "epoch: 18/300 batch 163/188  Train Loss: 0.114, Acc: 0.969\n",
      "epoch: 18/300 batch 164/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 18/300 batch 165/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 18/300 batch 166/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 18/300 batch 167/188  Train Loss: 0.070, Acc: 0.977\n",
      "epoch: 18/300 batch 168/188  Train Loss: 0.130, Acc: 0.965\n",
      "epoch: 18/300 batch 169/188  Train Loss: 0.110, Acc: 0.973\n",
      "epoch: 18/300 batch 170/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 18/300 batch 171/188  Train Loss: 0.067, Acc: 0.980\n",
      "epoch: 18/300 batch 172/188  Train Loss: 0.085, Acc: 0.977\n",
      "epoch: 18/300 batch 173/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 18/300 batch 174/188  Train Loss: 0.094, Acc: 0.980\n",
      "epoch: 18/300 batch 175/188  Train Loss: 0.096, Acc: 0.973\n",
      "epoch: 18/300 batch 176/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 18/300 batch 177/188  Train Loss: 0.139, Acc: 0.969\n",
      "epoch: 18/300 batch 178/188  Train Loss: 0.107, Acc: 0.965\n",
      "epoch: 18/300 batch 179/188  Train Loss: 0.099, Acc: 0.969\n",
      "epoch: 18/300 batch 180/188  Train Loss: 0.062, Acc: 0.980\n",
      "epoch: 18/300 batch 181/188  Train Loss: 0.062, Acc: 0.980\n",
      "epoch: 18/300 batch 182/188  Train Loss: 0.103, Acc: 0.973\n",
      "epoch: 18/300 batch 183/188  Train Loss: 0.084, Acc: 0.977\n",
      "epoch: 18/300 batch 184/188  Train Loss: 0.103, Acc: 0.969\n",
      "epoch: 18/300 batch 185/188  Train Loss: 0.074, Acc: 0.984\n",
      "epoch: 18/300 batch 186/188  Train Loss: 0.105, Acc: 0.973\n",
      "epoch: 18/300 batch 187/188  Train Loss: 0.061, Acc: 0.977\n",
      "Train Loss: 0.077084, Acc: 0.977\n",
      "Val Loss: 0.079924, Acc: 0.975\n",
      "epoch: 19/300 batch   0/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 19/300 batch   1/188  Train Loss: 0.064, Acc: 0.977\n",
      "epoch: 19/300 batch   2/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 19/300 batch   3/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 19/300 batch   4/188  Train Loss: 0.053, Acc: 0.977\n",
      "epoch: 19/300 batch   5/188  Train Loss: 0.099, Acc: 0.969\n",
      "epoch: 19/300 batch   6/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 19/300 batch   7/188  Train Loss: 0.074, Acc: 0.977\n",
      "epoch: 19/300 batch   8/188  Train Loss: 0.088, Acc: 0.969\n",
      "epoch: 19/300 batch   9/188  Train Loss: 0.106, Acc: 0.969\n",
      "epoch: 19/300 batch  10/188  Train Loss: 0.069, Acc: 0.977\n",
      "epoch: 19/300 batch  11/188  Train Loss: 0.066, Acc: 0.977\n",
      "epoch: 19/300 batch  12/188  Train Loss: 0.089, Acc: 0.977\n",
      "epoch: 19/300 batch  13/188  Train Loss: 0.075, Acc: 0.984\n",
      "epoch: 19/300 batch  14/188  Train Loss: 0.098, Acc: 0.973\n",
      "epoch: 19/300 batch  15/188  Train Loss: 0.050, Acc: 0.980\n",
      "epoch: 19/300 batch  16/188  Train Loss: 0.052, Acc: 0.992\n",
      "epoch: 19/300 batch  17/188  Train Loss: 0.106, Acc: 0.969\n",
      "epoch: 19/300 batch  18/188  Train Loss: 0.066, Acc: 0.988\n",
      "epoch: 19/300 batch  19/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 19/300 batch  20/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 19/300 batch  21/188  Train Loss: 0.047, Acc: 0.980\n",
      "epoch: 19/300 batch  22/188  Train Loss: 0.065, Acc: 0.973\n",
      "epoch: 19/300 batch  23/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 19/300 batch  24/188  Train Loss: 0.061, Acc: 0.984\n",
      "epoch: 19/300 batch  25/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 19/300 batch  26/188  Train Loss: 0.056, Acc: 0.973\n",
      "epoch: 19/300 batch  27/188  Train Loss: 0.083, Acc: 0.977\n",
      "epoch: 19/300 batch  28/188  Train Loss: 0.063, Acc: 0.984\n",
      "epoch: 19/300 batch  29/188  Train Loss: 0.110, Acc: 0.965\n",
      "epoch: 19/300 batch  30/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 19/300 batch  31/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 19/300 batch  32/188  Train Loss: 0.070, Acc: 0.977\n",
      "epoch: 19/300 batch  33/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 19/300 batch  34/188  Train Loss: 0.059, Acc: 0.980\n",
      "epoch: 19/300 batch  35/188  Train Loss: 0.076, Acc: 0.984\n",
      "epoch: 19/300 batch  36/188  Train Loss: 0.065, Acc: 0.977\n",
      "epoch: 19/300 batch  37/188  Train Loss: 0.087, Acc: 0.984\n",
      "epoch: 19/300 batch  38/188  Train Loss: 0.104, Acc: 0.969\n",
      "epoch: 19/300 batch  39/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 19/300 batch  40/188  Train Loss: 0.093, Acc: 0.980\n",
      "epoch: 19/300 batch  41/188  Train Loss: 0.061, Acc: 0.980\n",
      "epoch: 19/300 batch  42/188  Train Loss: 0.108, Acc: 0.973\n",
      "epoch: 19/300 batch  43/188  Train Loss: 0.072, Acc: 0.977\n",
      "epoch: 19/300 batch  44/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 19/300 batch  45/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 19/300 batch  46/188  Train Loss: 0.089, Acc: 0.965\n",
      "epoch: 19/300 batch  47/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 19/300 batch  48/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 19/300 batch  49/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 19/300 batch  50/188  Train Loss: 0.083, Acc: 0.973\n",
      "epoch: 19/300 batch  51/188  Train Loss: 0.061, Acc: 0.980\n",
      "epoch: 19/300 batch  52/188  Train Loss: 0.072, Acc: 0.973\n",
      "epoch: 19/300 batch  53/188  Train Loss: 0.092, Acc: 0.977\n",
      "epoch: 19/300 batch  54/188  Train Loss: 0.066, Acc: 0.977\n",
      "epoch: 19/300 batch  55/188  Train Loss: 0.080, Acc: 0.980\n",
      "epoch: 19/300 batch  56/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 19/300 batch  57/188  Train Loss: 0.123, Acc: 0.969\n",
      "epoch: 19/300 batch  58/188  Train Loss: 0.088, Acc: 0.973\n",
      "epoch: 19/300 batch  59/188  Train Loss: 0.178, Acc: 0.945\n",
      "epoch: 19/300 batch  60/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 19/300 batch  61/188  Train Loss: 0.058, Acc: 0.980\n",
      "epoch: 19/300 batch  62/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 19/300 batch  63/188  Train Loss: 0.084, Acc: 0.977\n",
      "epoch: 19/300 batch  64/188  Train Loss: 0.106, Acc: 0.980\n",
      "epoch: 19/300 batch  65/188  Train Loss: 0.060, Acc: 0.984\n",
      "epoch: 19/300 batch  66/188  Train Loss: 0.064, Acc: 0.992\n",
      "epoch: 19/300 batch  67/188  Train Loss: 0.074, Acc: 0.961\n",
      "epoch: 19/300 batch  68/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 19/300 batch  69/188  Train Loss: 0.062, Acc: 0.977\n",
      "epoch: 19/300 batch  70/188  Train Loss: 0.074, Acc: 0.977\n",
      "epoch: 19/300 batch  71/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 19/300 batch  72/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 19/300 batch  73/188  Train Loss: 0.094, Acc: 0.977\n",
      "epoch: 19/300 batch  74/188  Train Loss: 0.049, Acc: 0.980\n",
      "epoch: 19/300 batch  75/188  Train Loss: 0.083, Acc: 0.969\n",
      "epoch: 19/300 batch  76/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 19/300 batch  77/188  Train Loss: 0.101, Acc: 0.969\n",
      "epoch: 19/300 batch  78/188  Train Loss: 0.069, Acc: 0.980\n",
      "epoch: 19/300 batch  79/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 19/300 batch  80/188  Train Loss: 0.067, Acc: 0.977\n",
      "epoch: 19/300 batch  81/188  Train Loss: 0.123, Acc: 0.965\n",
      "epoch: 19/300 batch  82/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 19/300 batch  83/188  Train Loss: 0.094, Acc: 0.965\n",
      "epoch: 19/300 batch  84/188  Train Loss: 0.121, Acc: 0.977\n",
      "epoch: 19/300 batch  85/188  Train Loss: 0.057, Acc: 0.980\n",
      "epoch: 19/300 batch  86/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 19/300 batch  87/188  Train Loss: 0.067, Acc: 0.977\n",
      "epoch: 19/300 batch  88/188  Train Loss: 0.115, Acc: 0.969\n",
      "epoch: 19/300 batch  89/188  Train Loss: 0.079, Acc: 0.973\n",
      "epoch: 19/300 batch  90/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 19/300 batch  91/188  Train Loss: 0.052, Acc: 0.980\n",
      "epoch: 19/300 batch  92/188  Train Loss: 0.097, Acc: 0.969\n",
      "epoch: 19/300 batch  93/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 19/300 batch  94/188  Train Loss: 0.080, Acc: 0.973\n",
      "epoch: 19/300 batch  95/188  Train Loss: 0.065, Acc: 0.984\n",
      "epoch: 19/300 batch  96/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 19/300 batch  97/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 19/300 batch  98/188  Train Loss: 0.095, Acc: 0.973\n",
      "epoch: 19/300 batch  99/188  Train Loss: 0.110, Acc: 0.969\n",
      "epoch: 19/300 batch 100/188  Train Loss: 0.070, Acc: 0.969\n",
      "epoch: 19/300 batch 101/188  Train Loss: 0.080, Acc: 0.973\n",
      "epoch: 19/300 batch 102/188  Train Loss: 0.080, Acc: 0.969\n",
      "epoch: 19/300 batch 103/188  Train Loss: 0.063, Acc: 0.980\n",
      "epoch: 19/300 batch 104/188  Train Loss: 0.095, Acc: 0.957\n",
      "epoch: 19/300 batch 105/188  Train Loss: 0.074, Acc: 0.977\n",
      "epoch: 19/300 batch 106/188  Train Loss: 0.060, Acc: 0.980\n",
      "epoch: 19/300 batch 107/188  Train Loss: 0.066, Acc: 0.980\n",
      "epoch: 19/300 batch 108/188  Train Loss: 0.111, Acc: 0.973\n",
      "epoch: 19/300 batch 109/188  Train Loss: 0.073, Acc: 0.980\n",
      "epoch: 19/300 batch 110/188  Train Loss: 0.089, Acc: 0.965\n",
      "epoch: 19/300 batch 111/188  Train Loss: 0.074, Acc: 0.977\n",
      "epoch: 19/300 batch 112/188  Train Loss: 0.069, Acc: 0.980\n",
      "epoch: 19/300 batch 113/188  Train Loss: 0.099, Acc: 0.969\n",
      "epoch: 19/300 batch 114/188  Train Loss: 0.075, Acc: 0.969\n",
      "epoch: 19/300 batch 115/188  Train Loss: 0.134, Acc: 0.961\n",
      "epoch: 19/300 batch 116/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 19/300 batch 117/188  Train Loss: 0.067, Acc: 0.984\n",
      "epoch: 19/300 batch 118/188  Train Loss: 0.101, Acc: 0.965\n",
      "epoch: 19/300 batch 119/188  Train Loss: 0.077, Acc: 0.988\n",
      "epoch: 19/300 batch 120/188  Train Loss: 0.080, Acc: 0.980\n",
      "epoch: 19/300 batch 121/188  Train Loss: 0.136, Acc: 0.953\n",
      "epoch: 19/300 batch 122/188  Train Loss: 0.104, Acc: 0.973\n",
      "epoch: 19/300 batch 123/188  Train Loss: 0.067, Acc: 0.973\n",
      "epoch: 19/300 batch 124/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 19/300 batch 125/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 19/300 batch 126/188  Train Loss: 0.082, Acc: 0.984\n",
      "epoch: 19/300 batch 127/188  Train Loss: 0.054, Acc: 0.980\n",
      "epoch: 19/300 batch 128/188  Train Loss: 0.081, Acc: 0.973\n",
      "epoch: 19/300 batch 129/188  Train Loss: 0.109, Acc: 0.969\n",
      "epoch: 19/300 batch 130/188  Train Loss: 0.167, Acc: 0.949\n",
      "epoch: 19/300 batch 131/188  Train Loss: 0.142, Acc: 0.969\n",
      "epoch: 19/300 batch 132/188  Train Loss: 0.071, Acc: 0.980\n",
      "epoch: 19/300 batch 133/188  Train Loss: 0.085, Acc: 0.973\n",
      "epoch: 19/300 batch 134/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 19/300 batch 135/188  Train Loss: 0.120, Acc: 0.953\n",
      "epoch: 19/300 batch 136/188  Train Loss: 0.079, Acc: 0.973\n",
      "epoch: 19/300 batch 137/188  Train Loss: 0.078, Acc: 0.977\n",
      "epoch: 19/300 batch 138/188  Train Loss: 0.084, Acc: 0.969\n",
      "epoch: 19/300 batch 139/188  Train Loss: 0.091, Acc: 0.973\n",
      "epoch: 19/300 batch 140/188  Train Loss: 0.060, Acc: 0.980\n",
      "epoch: 19/300 batch 141/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 19/300 batch 142/188  Train Loss: 0.109, Acc: 0.977\n",
      "epoch: 19/300 batch 143/188  Train Loss: 0.069, Acc: 0.977\n",
      "epoch: 19/300 batch 144/188  Train Loss: 0.095, Acc: 0.969\n",
      "epoch: 19/300 batch 145/188  Train Loss: 0.092, Acc: 0.973\n",
      "epoch: 19/300 batch 146/188  Train Loss: 0.080, Acc: 0.980\n",
      "epoch: 19/300 batch 147/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 19/300 batch 148/188  Train Loss: 0.108, Acc: 0.965\n",
      "epoch: 19/300 batch 149/188  Train Loss: 0.153, Acc: 0.945\n",
      "epoch: 19/300 batch 150/188  Train Loss: 0.076, Acc: 0.973\n",
      "epoch: 19/300 batch 151/188  Train Loss: 0.115, Acc: 0.980\n",
      "epoch: 19/300 batch 152/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 19/300 batch 153/188  Train Loss: 0.074, Acc: 0.973\n",
      "epoch: 19/300 batch 154/188  Train Loss: 0.119, Acc: 0.961\n",
      "epoch: 19/300 batch 155/188  Train Loss: 0.169, Acc: 0.949\n",
      "epoch: 19/300 batch 156/188  Train Loss: 0.163, Acc: 0.953\n",
      "epoch: 19/300 batch 157/188  Train Loss: 0.076, Acc: 0.961\n",
      "epoch: 19/300 batch 158/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 19/300 batch 159/188  Train Loss: 0.091, Acc: 0.969\n",
      "epoch: 19/300 batch 160/188  Train Loss: 0.072, Acc: 0.980\n",
      "epoch: 19/300 batch 161/188  Train Loss: 0.103, Acc: 0.961\n",
      "epoch: 19/300 batch 162/188  Train Loss: 0.058, Acc: 0.988\n",
      "epoch: 19/300 batch 163/188  Train Loss: 0.098, Acc: 0.973\n",
      "epoch: 19/300 batch 164/188  Train Loss: 0.090, Acc: 0.973\n",
      "epoch: 19/300 batch 165/188  Train Loss: 0.062, Acc: 0.977\n",
      "epoch: 19/300 batch 166/188  Train Loss: 0.081, Acc: 0.973\n",
      "epoch: 19/300 batch 167/188  Train Loss: 0.106, Acc: 0.969\n",
      "epoch: 19/300 batch 168/188  Train Loss: 0.115, Acc: 0.957\n",
      "epoch: 19/300 batch 169/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 19/300 batch 170/188  Train Loss: 0.082, Acc: 0.977\n",
      "epoch: 19/300 batch 171/188  Train Loss: 0.092, Acc: 0.973\n",
      "epoch: 19/300 batch 172/188  Train Loss: 0.071, Acc: 0.980\n",
      "epoch: 19/300 batch 173/188  Train Loss: 0.116, Acc: 0.969\n",
      "epoch: 19/300 batch 174/188  Train Loss: 0.109, Acc: 0.965\n",
      "epoch: 19/300 batch 175/188  Train Loss: 0.079, Acc: 0.973\n",
      "epoch: 19/300 batch 176/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 19/300 batch 177/188  Train Loss: 0.078, Acc: 0.977\n",
      "epoch: 19/300 batch 178/188  Train Loss: 0.055, Acc: 0.980\n",
      "epoch: 19/300 batch 179/188  Train Loss: 0.104, Acc: 0.977\n",
      "epoch: 19/300 batch 180/188  Train Loss: 0.106, Acc: 0.961\n",
      "epoch: 19/300 batch 181/188  Train Loss: 0.091, Acc: 0.977\n",
      "epoch: 19/300 batch 182/188  Train Loss: 0.056, Acc: 0.977\n",
      "epoch: 19/300 batch 183/188  Train Loss: 0.090, Acc: 0.984\n",
      "epoch: 19/300 batch 184/188  Train Loss: 0.083, Acc: 0.969\n",
      "epoch: 19/300 batch 185/188  Train Loss: 0.089, Acc: 0.973\n",
      "epoch: 19/300 batch 186/188  Train Loss: 0.102, Acc: 0.984\n",
      "epoch: 19/300 batch 187/188  Train Loss: 0.070, Acc: 0.984\n",
      "Train Loss: 0.077170, Acc: 0.977\n",
      "Val Loss: 0.085262, Acc: 0.975\n",
      "epoch: 20/300 batch   0/188  Train Loss: 0.070, Acc: 0.977\n",
      "epoch: 20/300 batch   1/188  Train Loss: 0.126, Acc: 0.969\n",
      "epoch: 20/300 batch   2/188  Train Loss: 0.150, Acc: 0.957\n",
      "epoch: 20/300 batch   3/188  Train Loss: 0.061, Acc: 0.980\n",
      "epoch: 20/300 batch   4/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 20/300 batch   5/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 20/300 batch   6/188  Train Loss: 0.074, Acc: 0.969\n",
      "epoch: 20/300 batch   7/188  Train Loss: 0.079, Acc: 0.973\n",
      "epoch: 20/300 batch   8/188  Train Loss: 0.079, Acc: 0.980\n",
      "epoch: 20/300 batch   9/188  Train Loss: 0.072, Acc: 0.980\n",
      "epoch: 20/300 batch  10/188  Train Loss: 0.069, Acc: 0.977\n",
      "epoch: 20/300 batch  11/188  Train Loss: 0.071, Acc: 0.977\n",
      "epoch: 20/300 batch  12/188  Train Loss: 0.088, Acc: 0.969\n",
      "epoch: 20/300 batch  13/188  Train Loss: 0.084, Acc: 0.977\n",
      "epoch: 20/300 batch  14/188  Train Loss: 0.077, Acc: 0.973\n",
      "epoch: 20/300 batch  15/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 20/300 batch  16/188  Train Loss: 0.093, Acc: 0.973\n",
      "epoch: 20/300 batch  17/188  Train Loss: 0.096, Acc: 0.965\n",
      "epoch: 20/300 batch  18/188  Train Loss: 0.079, Acc: 0.984\n",
      "epoch: 20/300 batch  19/188  Train Loss: 0.079, Acc: 0.969\n",
      "epoch: 20/300 batch  20/188  Train Loss: 0.068, Acc: 0.973\n",
      "epoch: 20/300 batch  21/188  Train Loss: 0.103, Acc: 0.969\n",
      "epoch: 20/300 batch  22/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 20/300 batch  23/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 20/300 batch  24/188  Train Loss: 0.110, Acc: 0.973\n",
      "epoch: 20/300 batch  25/188  Train Loss: 0.070, Acc: 0.977\n",
      "epoch: 20/300 batch  26/188  Train Loss: 0.085, Acc: 0.977\n",
      "epoch: 20/300 batch  27/188  Train Loss: 0.065, Acc: 0.980\n",
      "epoch: 20/300 batch  28/188  Train Loss: 0.052, Acc: 0.977\n",
      "epoch: 20/300 batch  29/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 20/300 batch  30/188  Train Loss: 0.075, Acc: 0.969\n",
      "epoch: 20/300 batch  31/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 20/300 batch  32/188  Train Loss: 0.124, Acc: 0.965\n",
      "epoch: 20/300 batch  33/188  Train Loss: 0.075, Acc: 0.977\n",
      "epoch: 20/300 batch  34/188  Train Loss: 0.046, Acc: 0.980\n",
      "epoch: 20/300 batch  35/188  Train Loss: 0.073, Acc: 0.984\n",
      "epoch: 20/300 batch  36/188  Train Loss: 0.089, Acc: 0.969\n",
      "epoch: 20/300 batch  37/188  Train Loss: 0.060, Acc: 0.984\n",
      "epoch: 20/300 batch  38/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 20/300 batch  39/188  Train Loss: 0.047, Acc: 0.980\n",
      "epoch: 20/300 batch  40/188  Train Loss: 0.093, Acc: 0.965\n",
      "epoch: 20/300 batch  41/188  Train Loss: 0.119, Acc: 0.953\n",
      "epoch: 20/300 batch  42/188  Train Loss: 0.084, Acc: 0.969\n",
      "epoch: 20/300 batch  43/188  Train Loss: 0.097, Acc: 0.977\n",
      "epoch: 20/300 batch  44/188  Train Loss: 0.091, Acc: 0.961\n",
      "epoch: 20/300 batch  45/188  Train Loss: 0.073, Acc: 0.980\n",
      "epoch: 20/300 batch  46/188  Train Loss: 0.082, Acc: 0.965\n",
      "epoch: 20/300 batch  47/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 20/300 batch  48/188  Train Loss: 0.091, Acc: 0.961\n",
      "epoch: 20/300 batch  49/188  Train Loss: 0.141, Acc: 0.969\n",
      "epoch: 20/300 batch  50/188  Train Loss: 0.065, Acc: 0.992\n",
      "epoch: 20/300 batch  51/188  Train Loss: 0.088, Acc: 0.980\n",
      "epoch: 20/300 batch  52/188  Train Loss: 0.061, Acc: 0.984\n",
      "epoch: 20/300 batch  53/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 20/300 batch  54/188  Train Loss: 0.086, Acc: 0.980\n",
      "epoch: 20/300 batch  55/188  Train Loss: 0.098, Acc: 0.973\n",
      "epoch: 20/300 batch  56/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 20/300 batch  57/188  Train Loss: 0.075, Acc: 0.980\n",
      "epoch: 20/300 batch  58/188  Train Loss: 0.095, Acc: 0.957\n",
      "epoch: 20/300 batch  59/188  Train Loss: 0.059, Acc: 0.988\n",
      "epoch: 20/300 batch  60/188  Train Loss: 0.124, Acc: 0.953\n",
      "epoch: 20/300 batch  61/188  Train Loss: 0.074, Acc: 0.984\n",
      "epoch: 20/300 batch  62/188  Train Loss: 0.077, Acc: 0.977\n",
      "epoch: 20/300 batch  63/188  Train Loss: 0.083, Acc: 0.973\n",
      "epoch: 20/300 batch  64/188  Train Loss: 0.082, Acc: 0.969\n",
      "epoch: 20/300 batch  65/188  Train Loss: 0.083, Acc: 0.980\n",
      "epoch: 20/300 batch  66/188  Train Loss: 0.089, Acc: 0.969\n",
      "epoch: 20/300 batch  67/188  Train Loss: 0.092, Acc: 0.965\n",
      "epoch: 20/300 batch  68/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 20/300 batch  69/188  Train Loss: 0.057, Acc: 0.980\n",
      "epoch: 20/300 batch  70/188  Train Loss: 0.079, Acc: 0.977\n",
      "epoch: 20/300 batch  71/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 20/300 batch  72/188  Train Loss: 0.062, Acc: 0.980\n",
      "epoch: 20/300 batch  73/188  Train Loss: 0.078, Acc: 0.973\n",
      "epoch: 20/300 batch  74/188  Train Loss: 0.092, Acc: 0.973\n",
      "epoch: 20/300 batch  75/188  Train Loss: 0.059, Acc: 0.980\n",
      "epoch: 20/300 batch  76/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 20/300 batch  77/188  Train Loss: 0.101, Acc: 0.961\n",
      "epoch: 20/300 batch  78/188  Train Loss: 0.056, Acc: 0.980\n",
      "epoch: 20/300 batch  79/188  Train Loss: 0.074, Acc: 0.977\n",
      "epoch: 20/300 batch  80/188  Train Loss: 0.137, Acc: 0.965\n",
      "epoch: 20/300 batch  81/188  Train Loss: 0.128, Acc: 0.973\n",
      "epoch: 20/300 batch  82/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 20/300 batch  83/188  Train Loss: 0.077, Acc: 0.977\n",
      "epoch: 20/300 batch  84/188  Train Loss: 0.056, Acc: 0.980\n",
      "epoch: 20/300 batch  85/188  Train Loss: 0.093, Acc: 0.969\n",
      "epoch: 20/300 batch  86/188  Train Loss: 0.070, Acc: 0.977\n",
      "epoch: 20/300 batch  87/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 20/300 batch  88/188  Train Loss: 0.095, Acc: 0.957\n",
      "epoch: 20/300 batch  89/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 20/300 batch  90/188  Train Loss: 0.063, Acc: 0.984\n",
      "epoch: 20/300 batch  91/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 20/300 batch  92/188  Train Loss: 0.114, Acc: 0.965\n",
      "epoch: 20/300 batch  93/188  Train Loss: 0.101, Acc: 0.965\n",
      "epoch: 20/300 batch  94/188  Train Loss: 0.117, Acc: 0.969\n",
      "epoch: 20/300 batch  95/188  Train Loss: 0.082, Acc: 0.980\n",
      "epoch: 20/300 batch  96/188  Train Loss: 0.066, Acc: 0.980\n",
      "epoch: 20/300 batch  97/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 20/300 batch  98/188  Train Loss: 0.076, Acc: 0.977\n",
      "epoch: 20/300 batch  99/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 20/300 batch 100/188  Train Loss: 0.046, Acc: 0.996\n",
      "epoch: 20/300 batch 101/188  Train Loss: 0.085, Acc: 0.973\n",
      "epoch: 20/300 batch 102/188  Train Loss: 0.048, Acc: 0.996\n",
      "epoch: 20/300 batch 103/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 20/300 batch 104/188  Train Loss: 0.076, Acc: 0.969\n",
      "epoch: 20/300 batch 105/188  Train Loss: 0.079, Acc: 0.969\n",
      "epoch: 20/300 batch 106/188  Train Loss: 0.059, Acc: 0.984\n",
      "epoch: 20/300 batch 107/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 20/300 batch 108/188  Train Loss: 0.070, Acc: 0.984\n",
      "epoch: 20/300 batch 109/188  Train Loss: 0.100, Acc: 0.973\n",
      "epoch: 20/300 batch 110/188  Train Loss: 0.069, Acc: 0.980\n",
      "epoch: 20/300 batch 111/188  Train Loss: 0.066, Acc: 0.980\n",
      "epoch: 20/300 batch 112/188  Train Loss: 0.120, Acc: 0.973\n",
      "epoch: 20/300 batch 113/188  Train Loss: 0.085, Acc: 0.984\n",
      "epoch: 20/300 batch 114/188  Train Loss: 0.065, Acc: 0.984\n",
      "epoch: 20/300 batch 115/188  Train Loss: 0.083, Acc: 0.977\n",
      "epoch: 20/300 batch 116/188  Train Loss: 0.101, Acc: 0.977\n",
      "epoch: 20/300 batch 117/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 20/300 batch 118/188  Train Loss: 0.063, Acc: 0.984\n",
      "epoch: 20/300 batch 119/188  Train Loss: 0.075, Acc: 0.980\n",
      "epoch: 20/300 batch 120/188  Train Loss: 0.060, Acc: 0.984\n",
      "epoch: 20/300 batch 121/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 20/300 batch 122/188  Train Loss: 0.079, Acc: 0.980\n",
      "epoch: 20/300 batch 123/188  Train Loss: 0.091, Acc: 0.969\n",
      "epoch: 20/300 batch 124/188  Train Loss: 0.092, Acc: 0.965\n",
      "epoch: 20/300 batch 125/188  Train Loss: 0.095, Acc: 0.969\n",
      "epoch: 20/300 batch 126/188  Train Loss: 0.061, Acc: 0.988\n",
      "epoch: 20/300 batch 127/188  Train Loss: 0.135, Acc: 0.980\n",
      "epoch: 20/300 batch 128/188  Train Loss: 0.128, Acc: 0.965\n",
      "epoch: 20/300 batch 129/188  Train Loss: 0.070, Acc: 0.980\n",
      "epoch: 20/300 batch 130/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 20/300 batch 131/188  Train Loss: 0.109, Acc: 0.969\n",
      "epoch: 20/300 batch 132/188  Train Loss: 0.085, Acc: 0.969\n",
      "epoch: 20/300 batch 133/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 20/300 batch 134/188  Train Loss: 0.117, Acc: 0.961\n",
      "epoch: 20/300 batch 135/188  Train Loss: 0.063, Acc: 0.980\n",
      "epoch: 20/300 batch 136/188  Train Loss: 0.067, Acc: 0.980\n",
      "epoch: 20/300 batch 137/188  Train Loss: 0.076, Acc: 0.973\n",
      "epoch: 20/300 batch 138/188  Train Loss: 0.069, Acc: 0.977\n",
      "epoch: 20/300 batch 139/188  Train Loss: 0.076, Acc: 0.977\n",
      "epoch: 20/300 batch 140/188  Train Loss: 0.083, Acc: 0.980\n",
      "epoch: 20/300 batch 141/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 20/300 batch 142/188  Train Loss: 0.078, Acc: 0.973\n",
      "epoch: 20/300 batch 143/188  Train Loss: 0.134, Acc: 0.977\n",
      "epoch: 20/300 batch 144/188  Train Loss: 0.129, Acc: 0.969\n",
      "epoch: 20/300 batch 145/188  Train Loss: 0.063, Acc: 0.977\n",
      "epoch: 20/300 batch 146/188  Train Loss: 0.088, Acc: 0.969\n",
      "epoch: 20/300 batch 147/188  Train Loss: 0.103, Acc: 0.977\n",
      "epoch: 20/300 batch 148/188  Train Loss: 0.084, Acc: 0.977\n",
      "epoch: 20/300 batch 149/188  Train Loss: 0.090, Acc: 0.977\n",
      "epoch: 20/300 batch 150/188  Train Loss: 0.106, Acc: 0.949\n",
      "epoch: 20/300 batch 151/188  Train Loss: 0.080, Acc: 0.977\n",
      "epoch: 20/300 batch 152/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 20/300 batch 153/188  Train Loss: 0.067, Acc: 0.984\n",
      "epoch: 20/300 batch 154/188  Train Loss: 0.101, Acc: 0.973\n",
      "epoch: 20/300 batch 155/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 20/300 batch 156/188  Train Loss: 0.084, Acc: 0.973\n",
      "epoch: 20/300 batch 157/188  Train Loss: 0.070, Acc: 0.980\n",
      "epoch: 20/300 batch 158/188  Train Loss: 0.107, Acc: 0.969\n",
      "epoch: 20/300 batch 159/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 20/300 batch 160/188  Train Loss: 0.084, Acc: 0.973\n",
      "epoch: 20/300 batch 161/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 20/300 batch 162/188  Train Loss: 0.046, Acc: 0.980\n",
      "epoch: 20/300 batch 163/188  Train Loss: 0.062, Acc: 0.988\n",
      "epoch: 20/300 batch 164/188  Train Loss: 0.141, Acc: 0.953\n",
      "epoch: 20/300 batch 165/188  Train Loss: 0.138, Acc: 0.965\n",
      "epoch: 20/300 batch 166/188  Train Loss: 0.090, Acc: 0.969\n",
      "epoch: 20/300 batch 167/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 20/300 batch 168/188  Train Loss: 0.074, Acc: 0.984\n",
      "epoch: 20/300 batch 169/188  Train Loss: 0.047, Acc: 0.977\n",
      "epoch: 20/300 batch 170/188  Train Loss: 0.094, Acc: 0.973\n",
      "epoch: 20/300 batch 171/188  Train Loss: 0.080, Acc: 0.969\n",
      "epoch: 20/300 batch 172/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 20/300 batch 173/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 20/300 batch 174/188  Train Loss: 0.086, Acc: 0.973\n",
      "epoch: 20/300 batch 175/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 20/300 batch 176/188  Train Loss: 0.075, Acc: 0.984\n",
      "epoch: 20/300 batch 177/188  Train Loss: 0.103, Acc: 0.965\n",
      "epoch: 20/300 batch 178/188  Train Loss: 0.073, Acc: 0.973\n",
      "epoch: 20/300 batch 179/188  Train Loss: 0.082, Acc: 0.969\n",
      "epoch: 20/300 batch 180/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 20/300 batch 181/188  Train Loss: 0.096, Acc: 0.984\n",
      "epoch: 20/300 batch 182/188  Train Loss: 0.066, Acc: 0.984\n",
      "epoch: 20/300 batch 183/188  Train Loss: 0.063, Acc: 0.980\n",
      "epoch: 20/300 batch 184/188  Train Loss: 0.112, Acc: 0.957\n",
      "epoch: 20/300 batch 185/188  Train Loss: 0.088, Acc: 0.980\n",
      "epoch: 20/300 batch 186/188  Train Loss: 0.073, Acc: 0.977\n",
      "epoch: 20/300 batch 187/188  Train Loss: 0.077, Acc: 0.984\n",
      "Train Loss: 0.076774, Acc: 0.977\n",
      "Val Loss: 0.083173, Acc: 0.975\n",
      "epoch: 21/300 batch   0/188  Train Loss: 0.062, Acc: 0.980\n",
      "epoch: 21/300 batch   1/188  Train Loss: 0.056, Acc: 0.980\n",
      "epoch: 21/300 batch   2/188  Train Loss: 0.084, Acc: 0.980\n",
      "epoch: 21/300 batch   3/188  Train Loss: 0.060, Acc: 0.980\n",
      "epoch: 21/300 batch   4/188  Train Loss: 0.061, Acc: 0.984\n",
      "epoch: 21/300 batch   5/188  Train Loss: 0.085, Acc: 0.973\n",
      "epoch: 21/300 batch   6/188  Train Loss: 0.072, Acc: 0.980\n",
      "epoch: 21/300 batch   7/188  Train Loss: 0.073, Acc: 0.977\n",
      "epoch: 21/300 batch   8/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 21/300 batch   9/188  Train Loss: 0.074, Acc: 0.988\n",
      "epoch: 21/300 batch  10/188  Train Loss: 0.063, Acc: 0.973\n",
      "epoch: 21/300 batch  11/188  Train Loss: 0.061, Acc: 0.977\n",
      "epoch: 21/300 batch  12/188  Train Loss: 0.124, Acc: 0.969\n",
      "epoch: 21/300 batch  13/188  Train Loss: 0.077, Acc: 0.980\n",
      "epoch: 21/300 batch  14/188  Train Loss: 0.072, Acc: 0.969\n",
      "epoch: 21/300 batch  15/188  Train Loss: 0.048, Acc: 0.980\n",
      "epoch: 21/300 batch  16/188  Train Loss: 0.055, Acc: 0.980\n",
      "epoch: 21/300 batch  17/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 21/300 batch  18/188  Train Loss: 0.060, Acc: 0.980\n",
      "epoch: 21/300 batch  19/188  Train Loss: 0.082, Acc: 0.977\n",
      "epoch: 21/300 batch  20/188  Train Loss: 0.089, Acc: 0.980\n",
      "epoch: 21/300 batch  21/188  Train Loss: 0.047, Acc: 0.980\n",
      "epoch: 21/300 batch  22/188  Train Loss: 0.090, Acc: 0.965\n",
      "epoch: 21/300 batch  23/188  Train Loss: 0.052, Acc: 0.977\n",
      "epoch: 21/300 batch  24/188  Train Loss: 0.088, Acc: 0.980\n",
      "epoch: 21/300 batch  25/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 21/300 batch  26/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 21/300 batch  27/188  Train Loss: 0.058, Acc: 0.977\n",
      "epoch: 21/300 batch  28/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 21/300 batch  29/188  Train Loss: 0.042, Acc: 0.996\n",
      "epoch: 21/300 batch  30/188  Train Loss: 0.110, Acc: 0.969\n",
      "epoch: 21/300 batch  31/188  Train Loss: 0.083, Acc: 0.969\n",
      "epoch: 21/300 batch  32/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 21/300 batch  33/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 21/300 batch  34/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 21/300 batch  35/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 21/300 batch  36/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 21/300 batch  37/188  Train Loss: 0.086, Acc: 0.969\n",
      "epoch: 21/300 batch  38/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 21/300 batch  39/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 21/300 batch  40/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 21/300 batch  41/188  Train Loss: 0.050, Acc: 0.980\n",
      "epoch: 21/300 batch  42/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 21/300 batch  43/188  Train Loss: 0.041, Acc: 0.980\n",
      "epoch: 21/300 batch  44/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 21/300 batch  45/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 21/300 batch  46/188  Train Loss: 0.069, Acc: 0.980\n",
      "epoch: 21/300 batch  47/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 21/300 batch  48/188  Train Loss: 0.077, Acc: 0.980\n",
      "epoch: 21/300 batch  49/188  Train Loss: 0.084, Acc: 0.980\n",
      "epoch: 21/300 batch  50/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 21/300 batch  51/188  Train Loss: 0.070, Acc: 0.980\n",
      "epoch: 21/300 batch  52/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 21/300 batch  53/188  Train Loss: 0.072, Acc: 0.980\n",
      "epoch: 21/300 batch  54/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 21/300 batch  55/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 21/300 batch  56/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 21/300 batch  57/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 21/300 batch  58/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 21/300 batch  59/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 21/300 batch  60/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 21/300 batch  61/188  Train Loss: 0.044, Acc: 0.980\n",
      "epoch: 21/300 batch  62/188  Train Loss: 0.058, Acc: 0.980\n",
      "epoch: 21/300 batch  63/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 21/300 batch  64/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 21/300 batch  65/188  Train Loss: 0.054, Acc: 0.980\n",
      "epoch: 21/300 batch  66/188  Train Loss: 0.048, Acc: 0.980\n",
      "epoch: 21/300 batch  67/188  Train Loss: 0.059, Acc: 0.977\n",
      "epoch: 21/300 batch  68/188  Train Loss: 0.060, Acc: 0.992\n",
      "epoch: 21/300 batch  69/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 21/300 batch  70/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 21/300 batch  71/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 21/300 batch  72/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 21/300 batch  73/188  Train Loss: 0.056, Acc: 0.973\n",
      "epoch: 21/300 batch  74/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 21/300 batch  75/188  Train Loss: 0.069, Acc: 0.980\n",
      "epoch: 21/300 batch  76/188  Train Loss: 0.115, Acc: 0.977\n",
      "epoch: 21/300 batch  77/188  Train Loss: 0.072, Acc: 0.980\n",
      "epoch: 21/300 batch  78/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 21/300 batch  79/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 21/300 batch  80/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 21/300 batch  81/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 21/300 batch  82/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 21/300 batch  83/188  Train Loss: 0.040, Acc: 0.980\n",
      "epoch: 21/300 batch  84/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 21/300 batch  85/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 21/300 batch  86/188  Train Loss: 0.096, Acc: 0.969\n",
      "epoch: 21/300 batch  87/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 21/300 batch  88/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 21/300 batch  89/188  Train Loss: 0.033, Acc: 0.984\n",
      "epoch: 21/300 batch  90/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 21/300 batch  91/188  Train Loss: 0.066, Acc: 0.980\n",
      "epoch: 21/300 batch  92/188  Train Loss: 0.057, Acc: 0.977\n",
      "epoch: 21/300 batch  93/188  Train Loss: 0.076, Acc: 0.973\n",
      "epoch: 21/300 batch  94/188  Train Loss: 0.068, Acc: 0.980\n",
      "epoch: 21/300 batch  95/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 21/300 batch  96/188  Train Loss: 0.076, Acc: 0.973\n",
      "epoch: 21/300 batch  97/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 21/300 batch  98/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 21/300 batch  99/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 21/300 batch 100/188  Train Loss: 0.055, Acc: 0.992\n",
      "epoch: 21/300 batch 101/188  Train Loss: 0.061, Acc: 0.988\n",
      "epoch: 21/300 batch 102/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 21/300 batch 103/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 21/300 batch 104/188  Train Loss: 0.057, Acc: 0.980\n",
      "epoch: 21/300 batch 105/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 21/300 batch 106/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 21/300 batch 107/188  Train Loss: 0.072, Acc: 0.980\n",
      "epoch: 21/300 batch 108/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 21/300 batch 109/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 21/300 batch 110/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 21/300 batch 111/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 21/300 batch 112/188  Train Loss: 0.079, Acc: 0.984\n",
      "epoch: 21/300 batch 113/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 21/300 batch 114/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 21/300 batch 115/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 21/300 batch 116/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 21/300 batch 117/188  Train Loss: 0.064, Acc: 0.988\n",
      "epoch: 21/300 batch 118/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 21/300 batch 119/188  Train Loss: 0.063, Acc: 0.977\n",
      "epoch: 21/300 batch 120/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 21/300 batch 121/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 21/300 batch 122/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 21/300 batch 123/188  Train Loss: 0.042, Acc: 0.980\n",
      "epoch: 21/300 batch 124/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 21/300 batch 125/188  Train Loss: 0.067, Acc: 0.980\n",
      "epoch: 21/300 batch 126/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 21/300 batch 127/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 21/300 batch 128/188  Train Loss: 0.052, Acc: 0.977\n",
      "epoch: 21/300 batch 129/188  Train Loss: 0.060, Acc: 0.992\n",
      "epoch: 21/300 batch 130/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 21/300 batch 131/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 21/300 batch 132/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 21/300 batch 133/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 21/300 batch 134/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 21/300 batch 135/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 21/300 batch 136/188  Train Loss: 0.041, Acc: 0.977\n",
      "epoch: 21/300 batch 137/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 21/300 batch 138/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 21/300 batch 139/188  Train Loss: 0.116, Acc: 0.980\n",
      "epoch: 21/300 batch 140/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 21/300 batch 141/188  Train Loss: 0.068, Acc: 0.980\n",
      "epoch: 21/300 batch 142/188  Train Loss: 0.066, Acc: 0.973\n",
      "epoch: 21/300 batch 143/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 21/300 batch 144/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 21/300 batch 145/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 21/300 batch 146/188  Train Loss: 0.050, Acc: 0.980\n",
      "epoch: 21/300 batch 147/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 21/300 batch 148/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 21/300 batch 149/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 21/300 batch 150/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 21/300 batch 151/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 21/300 batch 152/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 21/300 batch 153/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 21/300 batch 154/188  Train Loss: 0.049, Acc: 0.980\n",
      "epoch: 21/300 batch 155/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 21/300 batch 156/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 21/300 batch 157/188  Train Loss: 0.072, Acc: 0.980\n",
      "epoch: 21/300 batch 158/188  Train Loss: 0.063, Acc: 0.973\n",
      "epoch: 21/300 batch 159/188  Train Loss: 0.060, Acc: 0.992\n",
      "epoch: 21/300 batch 160/188  Train Loss: 0.059, Acc: 0.988\n",
      "epoch: 21/300 batch 161/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 21/300 batch 162/188  Train Loss: 0.063, Acc: 0.977\n",
      "epoch: 21/300 batch 163/188  Train Loss: 0.059, Acc: 0.980\n",
      "epoch: 21/300 batch 164/188  Train Loss: 0.069, Acc: 0.980\n",
      "epoch: 21/300 batch 165/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 21/300 batch 166/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 21/300 batch 167/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 21/300 batch 168/188  Train Loss: 0.077, Acc: 0.977\n",
      "epoch: 21/300 batch 169/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 21/300 batch 170/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 21/300 batch 171/188  Train Loss: 0.033, Acc: 0.984\n",
      "epoch: 21/300 batch 172/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 21/300 batch 173/188  Train Loss: 0.043, Acc: 0.980\n",
      "epoch: 21/300 batch 174/188  Train Loss: 0.075, Acc: 0.977\n",
      "epoch: 21/300 batch 175/188  Train Loss: 0.057, Acc: 0.988\n",
      "epoch: 21/300 batch 176/188  Train Loss: 0.057, Acc: 0.988\n",
      "epoch: 21/300 batch 177/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 21/300 batch 178/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 21/300 batch 179/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 21/300 batch 180/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 21/300 batch 181/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 21/300 batch 182/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 21/300 batch 183/188  Train Loss: 0.056, Acc: 0.977\n",
      "epoch: 21/300 batch 184/188  Train Loss: 0.063, Acc: 0.977\n",
      "epoch: 21/300 batch 185/188  Train Loss: 0.085, Acc: 0.980\n",
      "epoch: 21/300 batch 186/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 21/300 batch 187/188  Train Loss: 0.019, Acc: 1.000\n",
      "Train Loss: 0.051707, Acc: 0.985\n",
      "Val Loss: 0.059309, Acc: 0.983\n",
      "epoch: 22/300 batch   0/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 22/300 batch   1/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 22/300 batch   2/188  Train Loss: 0.072, Acc: 0.977\n",
      "epoch: 22/300 batch   3/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 22/300 batch   4/188  Train Loss: 0.081, Acc: 0.980\n",
      "epoch: 22/300 batch   5/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 22/300 batch   6/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 22/300 batch   7/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 22/300 batch   8/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 22/300 batch   9/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 22/300 batch  10/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 22/300 batch  11/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 22/300 batch  12/188  Train Loss: 0.051, Acc: 0.980\n",
      "epoch: 22/300 batch  13/188  Train Loss: 0.047, Acc: 0.980\n",
      "epoch: 22/300 batch  14/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 22/300 batch  15/188  Train Loss: 0.060, Acc: 0.977\n",
      "epoch: 22/300 batch  16/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 22/300 batch  17/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 22/300 batch  18/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 22/300 batch  19/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 22/300 batch  20/188  Train Loss: 0.060, Acc: 0.980\n",
      "epoch: 22/300 batch  21/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 22/300 batch  22/188  Train Loss: 0.047, Acc: 0.996\n",
      "epoch: 22/300 batch  23/188  Train Loss: 0.060, Acc: 0.988\n",
      "epoch: 22/300 batch  24/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 22/300 batch  25/188  Train Loss: 0.064, Acc: 0.977\n",
      "epoch: 22/300 batch  26/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 22/300 batch  27/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 22/300 batch  28/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 22/300 batch  29/188  Train Loss: 0.085, Acc: 0.977\n",
      "epoch: 22/300 batch  30/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 22/300 batch  31/188  Train Loss: 0.105, Acc: 0.973\n",
      "epoch: 22/300 batch  32/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 22/300 batch  33/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 22/300 batch  34/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 22/300 batch  35/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 22/300 batch  36/188  Train Loss: 0.047, Acc: 0.980\n",
      "epoch: 22/300 batch  37/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 22/300 batch  38/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 22/300 batch  39/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 22/300 batch  40/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 22/300 batch  41/188  Train Loss: 0.066, Acc: 0.984\n",
      "epoch: 22/300 batch  42/188  Train Loss: 0.068, Acc: 0.977\n",
      "epoch: 22/300 batch  43/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 22/300 batch  44/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 22/300 batch  45/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 22/300 batch  46/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 22/300 batch  47/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 22/300 batch  48/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 22/300 batch  49/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 22/300 batch  50/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 22/300 batch  51/188  Train Loss: 0.057, Acc: 0.980\n",
      "epoch: 22/300 batch  52/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 22/300 batch  53/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 22/300 batch  54/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 22/300 batch  55/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 22/300 batch  56/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 22/300 batch  57/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 22/300 batch  58/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 22/300 batch  59/188  Train Loss: 0.064, Acc: 0.980\n",
      "epoch: 22/300 batch  60/188  Train Loss: 0.059, Acc: 0.992\n",
      "epoch: 22/300 batch  61/188  Train Loss: 0.061, Acc: 0.992\n",
      "epoch: 22/300 batch  62/188  Train Loss: 0.061, Acc: 0.973\n",
      "epoch: 22/300 batch  63/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 22/300 batch  64/188  Train Loss: 0.058, Acc: 0.977\n",
      "epoch: 22/300 batch  65/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 22/300 batch  66/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 22/300 batch  67/188  Train Loss: 0.060, Acc: 0.988\n",
      "epoch: 22/300 batch  68/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 22/300 batch  69/188  Train Loss: 0.084, Acc: 0.980\n",
      "epoch: 22/300 batch  70/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 22/300 batch  71/188  Train Loss: 0.055, Acc: 0.977\n",
      "epoch: 22/300 batch  72/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 22/300 batch  73/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 22/300 batch  74/188  Train Loss: 0.046, Acc: 0.980\n",
      "epoch: 22/300 batch  75/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 22/300 batch  76/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 22/300 batch  77/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 22/300 batch  78/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 22/300 batch  79/188  Train Loss: 0.056, Acc: 0.988\n",
      "epoch: 22/300 batch  80/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 22/300 batch  81/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 22/300 batch  82/188  Train Loss: 0.043, Acc: 0.980\n",
      "epoch: 22/300 batch  83/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 22/300 batch  84/188  Train Loss: 0.062, Acc: 0.984\n",
      "epoch: 22/300 batch  85/188  Train Loss: 0.076, Acc: 0.984\n",
      "epoch: 22/300 batch  86/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 22/300 batch  87/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 22/300 batch  88/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 22/300 batch  89/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 22/300 batch  90/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 22/300 batch  91/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 22/300 batch  92/188  Train Loss: 0.088, Acc: 0.977\n",
      "epoch: 22/300 batch  93/188  Train Loss: 0.048, Acc: 0.980\n",
      "epoch: 22/300 batch  94/188  Train Loss: 0.080, Acc: 0.980\n",
      "epoch: 22/300 batch  95/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 22/300 batch  96/188  Train Loss: 0.079, Acc: 0.977\n",
      "epoch: 22/300 batch  97/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 22/300 batch  98/188  Train Loss: 0.060, Acc: 0.984\n",
      "epoch: 22/300 batch  99/188  Train Loss: 0.066, Acc: 0.984\n",
      "epoch: 22/300 batch 100/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 22/300 batch 101/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 22/300 batch 102/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 22/300 batch 103/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 22/300 batch 104/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 22/300 batch 105/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 22/300 batch 106/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 22/300 batch 107/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 22/300 batch 108/188  Train Loss: 0.058, Acc: 0.980\n",
      "epoch: 22/300 batch 109/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 22/300 batch 110/188  Train Loss: 0.049, Acc: 0.980\n",
      "epoch: 22/300 batch 111/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 22/300 batch 112/188  Train Loss: 0.086, Acc: 0.973\n",
      "epoch: 22/300 batch 113/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 22/300 batch 114/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 22/300 batch 115/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 22/300 batch 116/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 22/300 batch 117/188  Train Loss: 0.072, Acc: 0.980\n",
      "epoch: 22/300 batch 118/188  Train Loss: 0.056, Acc: 0.980\n",
      "epoch: 22/300 batch 119/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 22/300 batch 120/188  Train Loss: 0.045, Acc: 0.980\n",
      "epoch: 22/300 batch 121/188  Train Loss: 0.069, Acc: 0.980\n",
      "epoch: 22/300 batch 122/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 22/300 batch 123/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 22/300 batch 124/188  Train Loss: 0.049, Acc: 0.980\n",
      "epoch: 22/300 batch 125/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 22/300 batch 126/188  Train Loss: 0.068, Acc: 0.977\n",
      "epoch: 22/300 batch 127/188  Train Loss: 0.053, Acc: 0.980\n",
      "epoch: 22/300 batch 128/188  Train Loss: 0.071, Acc: 0.988\n",
      "epoch: 22/300 batch 129/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 22/300 batch 130/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 22/300 batch 131/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 22/300 batch 132/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 22/300 batch 133/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 22/300 batch 134/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 22/300 batch 135/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 22/300 batch 136/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 22/300 batch 137/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 22/300 batch 138/188  Train Loss: 0.054, Acc: 0.980\n",
      "epoch: 22/300 batch 139/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 22/300 batch 140/188  Train Loss: 0.060, Acc: 0.984\n",
      "epoch: 22/300 batch 141/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 22/300 batch 142/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 22/300 batch 143/188  Train Loss: 0.065, Acc: 0.980\n",
      "epoch: 22/300 batch 144/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 22/300 batch 145/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 22/300 batch 146/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 22/300 batch 147/188  Train Loss: 0.066, Acc: 0.977\n",
      "epoch: 22/300 batch 148/188  Train Loss: 0.079, Acc: 0.980\n",
      "epoch: 22/300 batch 149/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 22/300 batch 150/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 22/300 batch 151/188  Train Loss: 0.085, Acc: 0.977\n",
      "epoch: 22/300 batch 152/188  Train Loss: 0.064, Acc: 0.977\n",
      "epoch: 22/300 batch 153/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 22/300 batch 154/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 22/300 batch 155/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 22/300 batch 156/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 22/300 batch 157/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 22/300 batch 158/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 22/300 batch 159/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 22/300 batch 160/188  Train Loss: 0.063, Acc: 0.984\n",
      "epoch: 22/300 batch 161/188  Train Loss: 0.089, Acc: 0.980\n",
      "epoch: 22/300 batch 162/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 22/300 batch 163/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 22/300 batch 164/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 22/300 batch 165/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 22/300 batch 166/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 22/300 batch 167/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 22/300 batch 168/188  Train Loss: 0.070, Acc: 0.988\n",
      "epoch: 22/300 batch 169/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 22/300 batch 170/188  Train Loss: 0.060, Acc: 0.984\n",
      "epoch: 22/300 batch 171/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 22/300 batch 172/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 22/300 batch 173/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 22/300 batch 174/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 22/300 batch 175/188  Train Loss: 0.071, Acc: 0.980\n",
      "epoch: 22/300 batch 176/188  Train Loss: 0.065, Acc: 0.980\n",
      "epoch: 22/300 batch 177/188  Train Loss: 0.045, Acc: 0.996\n",
      "epoch: 22/300 batch 178/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 22/300 batch 179/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 22/300 batch 180/188  Train Loss: 0.062, Acc: 0.988\n",
      "epoch: 22/300 batch 181/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 22/300 batch 182/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 22/300 batch 183/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 22/300 batch 184/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 22/300 batch 185/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 22/300 batch 186/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 22/300 batch 187/188  Train Loss: 0.027, Acc: 0.992\n",
      "Train Loss: 0.045676, Acc: 0.988\n",
      "Val Loss: 0.059210, Acc: 0.982\n",
      "epoch: 23/300 batch   0/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 23/300 batch   1/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 23/300 batch   2/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 23/300 batch   3/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 23/300 batch   4/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 23/300 batch   5/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 23/300 batch   6/188  Train Loss: 0.081, Acc: 0.980\n",
      "epoch: 23/300 batch   7/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 23/300 batch   8/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 23/300 batch   9/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 23/300 batch  10/188  Train Loss: 0.064, Acc: 0.977\n",
      "epoch: 23/300 batch  11/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 23/300 batch  12/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 23/300 batch  13/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 23/300 batch  14/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 23/300 batch  15/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 23/300 batch  16/188  Train Loss: 0.049, Acc: 0.977\n",
      "epoch: 23/300 batch  17/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 23/300 batch  18/188  Train Loss: 0.072, Acc: 0.984\n",
      "epoch: 23/300 batch  19/188  Train Loss: 0.058, Acc: 0.977\n",
      "epoch: 23/300 batch  20/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 23/300 batch  21/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 23/300 batch  22/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 23/300 batch  23/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 23/300 batch  24/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 23/300 batch  25/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 23/300 batch  26/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 23/300 batch  27/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 23/300 batch  28/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 23/300 batch  29/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 23/300 batch  30/188  Train Loss: 0.086, Acc: 0.988\n",
      "epoch: 23/300 batch  31/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 23/300 batch  32/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 23/300 batch  33/188  Train Loss: 0.059, Acc: 0.992\n",
      "epoch: 23/300 batch  34/188  Train Loss: 0.023, Acc: 0.988\n",
      "epoch: 23/300 batch  35/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 23/300 batch  36/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 23/300 batch  37/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 23/300 batch  38/188  Train Loss: 0.068, Acc: 0.980\n",
      "epoch: 23/300 batch  39/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 23/300 batch  40/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 23/300 batch  41/188  Train Loss: 0.065, Acc: 0.980\n",
      "epoch: 23/300 batch  42/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 23/300 batch  43/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 23/300 batch  44/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 23/300 batch  45/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 23/300 batch  46/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 23/300 batch  47/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 23/300 batch  48/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 23/300 batch  49/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 23/300 batch  50/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 23/300 batch  51/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 23/300 batch  52/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 23/300 batch  53/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 23/300 batch  54/188  Train Loss: 0.056, Acc: 0.988\n",
      "epoch: 23/300 batch  55/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 23/300 batch  56/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 23/300 batch  57/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 23/300 batch  58/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 23/300 batch  59/188  Train Loss: 0.050, Acc: 0.980\n",
      "epoch: 23/300 batch  60/188  Train Loss: 0.069, Acc: 0.977\n",
      "epoch: 23/300 batch  61/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 23/300 batch  62/188  Train Loss: 0.054, Acc: 0.992\n",
      "epoch: 23/300 batch  63/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 23/300 batch  64/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 23/300 batch  65/188  Train Loss: 0.043, Acc: 0.996\n",
      "epoch: 23/300 batch  66/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 23/300 batch  67/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 23/300 batch  68/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 23/300 batch  69/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 23/300 batch  70/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 23/300 batch  71/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 23/300 batch  72/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 23/300 batch  73/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 23/300 batch  74/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 23/300 batch  75/188  Train Loss: 0.067, Acc: 0.980\n",
      "epoch: 23/300 batch  76/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 23/300 batch  77/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 23/300 batch  78/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 23/300 batch  79/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 23/300 batch  80/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 23/300 batch  81/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 23/300 batch  82/188  Train Loss: 0.081, Acc: 0.980\n",
      "epoch: 23/300 batch  83/188  Train Loss: 0.059, Acc: 0.988\n",
      "epoch: 23/300 batch  84/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 23/300 batch  85/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 23/300 batch  86/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 23/300 batch  87/188  Train Loss: 0.046, Acc: 0.996\n",
      "epoch: 23/300 batch  88/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 23/300 batch  89/188  Train Loss: 0.065, Acc: 0.984\n",
      "epoch: 23/300 batch  90/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 23/300 batch  91/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 23/300 batch  92/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 23/300 batch  93/188  Train Loss: 0.052, Acc: 0.977\n",
      "epoch: 23/300 batch  94/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 23/300 batch  95/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 23/300 batch  96/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 23/300 batch  97/188  Train Loss: 0.088, Acc: 0.988\n",
      "epoch: 23/300 batch  98/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 23/300 batch  99/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 23/300 batch 100/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 23/300 batch 101/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 23/300 batch 102/188  Train Loss: 0.102, Acc: 0.961\n",
      "epoch: 23/300 batch 103/188  Train Loss: 0.047, Acc: 0.996\n",
      "epoch: 23/300 batch 104/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 23/300 batch 105/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 23/300 batch 106/188  Train Loss: 0.045, Acc: 0.996\n",
      "epoch: 23/300 batch 107/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 23/300 batch 108/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 23/300 batch 109/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 23/300 batch 110/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 23/300 batch 111/188  Train Loss: 0.080, Acc: 0.980\n",
      "epoch: 23/300 batch 112/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 23/300 batch 113/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 23/300 batch 114/188  Train Loss: 0.063, Acc: 0.988\n",
      "epoch: 23/300 batch 115/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 23/300 batch 116/188  Train Loss: 0.063, Acc: 0.980\n",
      "epoch: 23/300 batch 117/188  Train Loss: 0.096, Acc: 0.969\n",
      "epoch: 23/300 batch 118/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 23/300 batch 119/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 23/300 batch 120/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 23/300 batch 121/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 23/300 batch 122/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 23/300 batch 123/188  Train Loss: 0.057, Acc: 0.980\n",
      "epoch: 23/300 batch 124/188  Train Loss: 0.061, Acc: 0.980\n",
      "epoch: 23/300 batch 125/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 23/300 batch 126/188  Train Loss: 0.049, Acc: 0.977\n",
      "epoch: 23/300 batch 127/188  Train Loss: 0.060, Acc: 0.977\n",
      "epoch: 23/300 batch 128/188  Train Loss: 0.077, Acc: 0.977\n",
      "epoch: 23/300 batch 129/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 23/300 batch 130/188  Train Loss: 0.057, Acc: 0.980\n",
      "epoch: 23/300 batch 131/188  Train Loss: 0.069, Acc: 0.984\n",
      "epoch: 23/300 batch 132/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 23/300 batch 133/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 23/300 batch 134/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 23/300 batch 135/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 23/300 batch 136/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 23/300 batch 137/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 23/300 batch 138/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 23/300 batch 139/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 23/300 batch 140/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 23/300 batch 141/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 23/300 batch 142/188  Train Loss: 0.064, Acc: 0.984\n",
      "epoch: 23/300 batch 143/188  Train Loss: 0.050, Acc: 0.980\n",
      "epoch: 23/300 batch 144/188  Train Loss: 0.065, Acc: 0.984\n",
      "epoch: 23/300 batch 145/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 23/300 batch 146/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 23/300 batch 147/188  Train Loss: 0.069, Acc: 0.973\n",
      "epoch: 23/300 batch 148/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 23/300 batch 149/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 23/300 batch 150/188  Train Loss: 0.062, Acc: 0.977\n",
      "epoch: 23/300 batch 151/188  Train Loss: 0.068, Acc: 0.980\n",
      "epoch: 23/300 batch 152/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 23/300 batch 153/188  Train Loss: 0.093, Acc: 0.980\n",
      "epoch: 23/300 batch 154/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 23/300 batch 155/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 23/300 batch 156/188  Train Loss: 0.048, Acc: 0.980\n",
      "epoch: 23/300 batch 157/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 23/300 batch 158/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 23/300 batch 159/188  Train Loss: 0.089, Acc: 0.961\n",
      "epoch: 23/300 batch 160/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 23/300 batch 161/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 23/300 batch 162/188  Train Loss: 0.098, Acc: 0.973\n",
      "epoch: 23/300 batch 163/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 23/300 batch 164/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 23/300 batch 165/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 23/300 batch 166/188  Train Loss: 0.053, Acc: 0.992\n",
      "epoch: 23/300 batch 167/188  Train Loss: 0.072, Acc: 0.980\n",
      "epoch: 23/300 batch 168/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 23/300 batch 169/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 23/300 batch 170/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 23/300 batch 171/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 23/300 batch 172/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 23/300 batch 173/188  Train Loss: 0.080, Acc: 0.984\n",
      "epoch: 23/300 batch 174/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 23/300 batch 175/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 23/300 batch 176/188  Train Loss: 0.058, Acc: 0.980\n",
      "epoch: 23/300 batch 177/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 23/300 batch 178/188  Train Loss: 0.051, Acc: 0.992\n",
      "epoch: 23/300 batch 179/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 23/300 batch 180/188  Train Loss: 0.066, Acc: 0.980\n",
      "epoch: 23/300 batch 181/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 23/300 batch 182/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 23/300 batch 183/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 23/300 batch 184/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 23/300 batch 185/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 23/300 batch 186/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 23/300 batch 187/188  Train Loss: 0.030, Acc: 0.992\n",
      "Train Loss: 0.044793, Acc: 0.988\n",
      "Val Loss: 0.060220, Acc: 0.982\n",
      "epoch: 24/300 batch   0/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 24/300 batch   1/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 24/300 batch   2/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 24/300 batch   3/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 24/300 batch   4/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 24/300 batch   5/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 24/300 batch   6/188  Train Loss: 0.064, Acc: 0.977\n",
      "epoch: 24/300 batch   7/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 24/300 batch   8/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 24/300 batch   9/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 24/300 batch  10/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 24/300 batch  11/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 24/300 batch  12/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 24/300 batch  13/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 24/300 batch  14/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 24/300 batch  15/188  Train Loss: 0.052, Acc: 0.992\n",
      "epoch: 24/300 batch  16/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 24/300 batch  17/188  Train Loss: 0.067, Acc: 0.980\n",
      "epoch: 24/300 batch  18/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 24/300 batch  19/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 24/300 batch  20/188  Train Loss: 0.036, Acc: 0.980\n",
      "epoch: 24/300 batch  21/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 24/300 batch  22/188  Train Loss: 0.065, Acc: 0.984\n",
      "epoch: 24/300 batch  23/188  Train Loss: 0.079, Acc: 0.984\n",
      "epoch: 24/300 batch  24/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 24/300 batch  25/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 24/300 batch  26/188  Train Loss: 0.068, Acc: 0.988\n",
      "epoch: 24/300 batch  27/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 24/300 batch  28/188  Train Loss: 0.052, Acc: 0.980\n",
      "epoch: 24/300 batch  29/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 24/300 batch  30/188  Train Loss: 0.054, Acc: 0.980\n",
      "epoch: 24/300 batch  31/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 24/300 batch  32/188  Train Loss: 0.041, Acc: 0.977\n",
      "epoch: 24/300 batch  33/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 24/300 batch  34/188  Train Loss: 0.069, Acc: 0.992\n",
      "epoch: 24/300 batch  35/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 24/300 batch  36/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 24/300 batch  37/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 24/300 batch  38/188  Train Loss: 0.055, Acc: 0.977\n",
      "epoch: 24/300 batch  39/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 24/300 batch  40/188  Train Loss: 0.063, Acc: 0.977\n",
      "epoch: 24/300 batch  41/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 24/300 batch  42/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 24/300 batch  43/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 24/300 batch  44/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 24/300 batch  45/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 24/300 batch  46/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 24/300 batch  47/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 24/300 batch  48/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 24/300 batch  49/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 24/300 batch  50/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 24/300 batch  51/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 24/300 batch  52/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 24/300 batch  53/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 24/300 batch  54/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 24/300 batch  55/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 24/300 batch  56/188  Train Loss: 0.084, Acc: 0.980\n",
      "epoch: 24/300 batch  57/188  Train Loss: 0.059, Acc: 0.980\n",
      "epoch: 24/300 batch  58/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 24/300 batch  59/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 24/300 batch  60/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 24/300 batch  61/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 24/300 batch  62/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 24/300 batch  63/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 24/300 batch  64/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 24/300 batch  65/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 24/300 batch  66/188  Train Loss: 0.054, Acc: 0.977\n",
      "epoch: 24/300 batch  67/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 24/300 batch  68/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 24/300 batch  69/188  Train Loss: 0.064, Acc: 0.984\n",
      "epoch: 24/300 batch  70/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 24/300 batch  71/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 24/300 batch  72/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 24/300 batch  73/188  Train Loss: 0.069, Acc: 0.977\n",
      "epoch: 24/300 batch  74/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 24/300 batch  75/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 24/300 batch  76/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 24/300 batch  77/188  Train Loss: 0.083, Acc: 0.980\n",
      "epoch: 24/300 batch  78/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 24/300 batch  79/188  Train Loss: 0.060, Acc: 0.984\n",
      "epoch: 24/300 batch  80/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 24/300 batch  81/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 24/300 batch  82/188  Train Loss: 0.067, Acc: 0.980\n",
      "epoch: 24/300 batch  83/188  Train Loss: 0.068, Acc: 0.980\n",
      "epoch: 24/300 batch  84/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 24/300 batch  85/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 24/300 batch  86/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 24/300 batch  87/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 24/300 batch  88/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 24/300 batch  89/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 24/300 batch  90/188  Train Loss: 0.057, Acc: 0.988\n",
      "epoch: 24/300 batch  91/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 24/300 batch  92/188  Train Loss: 0.056, Acc: 0.980\n",
      "epoch: 24/300 batch  93/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 24/300 batch  94/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 24/300 batch  95/188  Train Loss: 0.057, Acc: 0.980\n",
      "epoch: 24/300 batch  96/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 24/300 batch  97/188  Train Loss: 0.060, Acc: 0.977\n",
      "epoch: 24/300 batch  98/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 24/300 batch  99/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 24/300 batch 100/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 24/300 batch 101/188  Train Loss: 0.075, Acc: 0.977\n",
      "epoch: 24/300 batch 102/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 24/300 batch 103/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 24/300 batch 104/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 24/300 batch 105/188  Train Loss: 0.056, Acc: 0.988\n",
      "epoch: 24/300 batch 106/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 24/300 batch 107/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 24/300 batch 108/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 24/300 batch 109/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 24/300 batch 110/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 24/300 batch 111/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 24/300 batch 112/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 24/300 batch 113/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 24/300 batch 114/188  Train Loss: 0.056, Acc: 0.973\n",
      "epoch: 24/300 batch 115/188  Train Loss: 0.063, Acc: 0.992\n",
      "epoch: 24/300 batch 116/188  Train Loss: 0.070, Acc: 0.984\n",
      "epoch: 24/300 batch 117/188  Train Loss: 0.055, Acc: 0.980\n",
      "epoch: 24/300 batch 118/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 24/300 batch 119/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 24/300 batch 120/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 24/300 batch 121/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 24/300 batch 122/188  Train Loss: 0.054, Acc: 0.992\n",
      "epoch: 24/300 batch 123/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 24/300 batch 124/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 24/300 batch 125/188  Train Loss: 0.056, Acc: 0.980\n",
      "epoch: 24/300 batch 126/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 24/300 batch 127/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 24/300 batch 128/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 24/300 batch 129/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 24/300 batch 130/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 24/300 batch 131/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 24/300 batch 132/188  Train Loss: 0.056, Acc: 0.980\n",
      "epoch: 24/300 batch 133/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 24/300 batch 134/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 24/300 batch 135/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 24/300 batch 136/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 24/300 batch 137/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 24/300 batch 138/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 24/300 batch 139/188  Train Loss: 0.070, Acc: 0.977\n",
      "epoch: 24/300 batch 140/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 24/300 batch 141/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 24/300 batch 142/188  Train Loss: 0.054, Acc: 0.980\n",
      "epoch: 24/300 batch 143/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 24/300 batch 144/188  Train Loss: 0.049, Acc: 0.980\n",
      "epoch: 24/300 batch 145/188  Train Loss: 0.064, Acc: 0.984\n",
      "epoch: 24/300 batch 146/188  Train Loss: 0.058, Acc: 0.988\n",
      "epoch: 24/300 batch 147/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 24/300 batch 148/188  Train Loss: 0.055, Acc: 0.992\n",
      "epoch: 24/300 batch 149/188  Train Loss: 0.073, Acc: 0.977\n",
      "epoch: 24/300 batch 150/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 24/300 batch 151/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 24/300 batch 152/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 24/300 batch 153/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 24/300 batch 154/188  Train Loss: 0.062, Acc: 0.980\n",
      "epoch: 24/300 batch 155/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 24/300 batch 156/188  Train Loss: 0.098, Acc: 0.973\n",
      "epoch: 24/300 batch 157/188  Train Loss: 0.039, Acc: 0.980\n",
      "epoch: 24/300 batch 158/188  Train Loss: 0.056, Acc: 0.988\n",
      "epoch: 24/300 batch 159/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 24/300 batch 160/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 24/300 batch 161/188  Train Loss: 0.076, Acc: 0.973\n",
      "epoch: 24/300 batch 162/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 24/300 batch 163/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 24/300 batch 164/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 24/300 batch 165/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 24/300 batch 166/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 24/300 batch 167/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 24/300 batch 168/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 24/300 batch 169/188  Train Loss: 0.061, Acc: 0.977\n",
      "epoch: 24/300 batch 170/188  Train Loss: 0.046, Acc: 0.980\n",
      "epoch: 24/300 batch 171/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 24/300 batch 172/188  Train Loss: 0.060, Acc: 0.988\n",
      "epoch: 24/300 batch 173/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 24/300 batch 174/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 24/300 batch 175/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 24/300 batch 176/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 24/300 batch 177/188  Train Loss: 0.070, Acc: 0.977\n",
      "epoch: 24/300 batch 178/188  Train Loss: 0.125, Acc: 0.965\n",
      "epoch: 24/300 batch 179/188  Train Loss: 0.072, Acc: 0.988\n",
      "epoch: 24/300 batch 180/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 24/300 batch 181/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 24/300 batch 182/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 24/300 batch 183/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 24/300 batch 184/188  Train Loss: 0.066, Acc: 0.988\n",
      "epoch: 24/300 batch 185/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 24/300 batch 186/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 24/300 batch 187/188  Train Loss: 0.052, Acc: 0.977\n",
      "Train Loss: 0.044863, Acc: 0.989\n",
      "Val Loss: 0.059965, Acc: 0.983\n",
      "epoch: 25/300 batch   0/188  Train Loss: 0.056, Acc: 0.992\n",
      "epoch: 25/300 batch   1/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 25/300 batch   2/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 25/300 batch   3/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 25/300 batch   4/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 25/300 batch   5/188  Train Loss: 0.062, Acc: 0.977\n",
      "epoch: 25/300 batch   6/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 25/300 batch   7/188  Train Loss: 0.032, Acc: 0.980\n",
      "epoch: 25/300 batch   8/188  Train Loss: 0.056, Acc: 0.980\n",
      "epoch: 25/300 batch   9/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 25/300 batch  10/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 25/300 batch  11/188  Train Loss: 0.062, Acc: 0.984\n",
      "epoch: 25/300 batch  12/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 25/300 batch  13/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 25/300 batch  14/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 25/300 batch  15/188  Train Loss: 0.042, Acc: 0.996\n",
      "epoch: 25/300 batch  16/188  Train Loss: 0.063, Acc: 0.977\n",
      "epoch: 25/300 batch  17/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 25/300 batch  18/188  Train Loss: 0.058, Acc: 0.980\n",
      "epoch: 25/300 batch  19/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 25/300 batch  20/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 25/300 batch  21/188  Train Loss: 0.057, Acc: 0.988\n",
      "epoch: 25/300 batch  22/188  Train Loss: 0.076, Acc: 0.977\n",
      "epoch: 25/300 batch  23/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 25/300 batch  24/188  Train Loss: 0.047, Acc: 0.980\n",
      "epoch: 25/300 batch  25/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 25/300 batch  26/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 25/300 batch  27/188  Train Loss: 0.062, Acc: 0.977\n",
      "epoch: 25/300 batch  28/188  Train Loss: 0.055, Acc: 0.980\n",
      "epoch: 25/300 batch  29/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 25/300 batch  30/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 25/300 batch  31/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 25/300 batch  32/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 25/300 batch  33/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 25/300 batch  34/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 25/300 batch  35/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 25/300 batch  36/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 25/300 batch  37/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 25/300 batch  38/188  Train Loss: 0.053, Acc: 0.980\n",
      "epoch: 25/300 batch  39/188  Train Loss: 0.063, Acc: 0.988\n",
      "epoch: 25/300 batch  40/188  Train Loss: 0.051, Acc: 0.980\n",
      "epoch: 25/300 batch  41/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 25/300 batch  42/188  Train Loss: 0.051, Acc: 0.980\n",
      "epoch: 25/300 batch  43/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 25/300 batch  44/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 25/300 batch  45/188  Train Loss: 0.025, Acc: 0.988\n",
      "epoch: 25/300 batch  46/188  Train Loss: 0.067, Acc: 0.984\n",
      "epoch: 25/300 batch  47/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 25/300 batch  48/188  Train Loss: 0.023, Acc: 0.988\n",
      "epoch: 25/300 batch  49/188  Train Loss: 0.066, Acc: 0.984\n",
      "epoch: 25/300 batch  50/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 25/300 batch  51/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 25/300 batch  52/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 25/300 batch  53/188  Train Loss: 0.062, Acc: 0.980\n",
      "epoch: 25/300 batch  54/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 25/300 batch  55/188  Train Loss: 0.059, Acc: 0.973\n",
      "epoch: 25/300 batch  56/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 25/300 batch  57/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 25/300 batch  58/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 25/300 batch  59/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 25/300 batch  60/188  Train Loss: 0.059, Acc: 0.984\n",
      "epoch: 25/300 batch  61/188  Train Loss: 0.058, Acc: 0.988\n",
      "epoch: 25/300 batch  62/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 25/300 batch  63/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 25/300 batch  64/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 25/300 batch  65/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 25/300 batch  66/188  Train Loss: 0.039, Acc: 0.980\n",
      "epoch: 25/300 batch  67/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 25/300 batch  68/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 25/300 batch  69/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 25/300 batch  70/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 25/300 batch  71/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 25/300 batch  72/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 25/300 batch  73/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 25/300 batch  74/188  Train Loss: 0.060, Acc: 0.980\n",
      "epoch: 25/300 batch  75/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 25/300 batch  76/188  Train Loss: 0.063, Acc: 0.980\n",
      "epoch: 25/300 batch  77/188  Train Loss: 0.040, Acc: 1.000\n",
      "epoch: 25/300 batch  78/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 25/300 batch  79/188  Train Loss: 0.064, Acc: 0.969\n",
      "epoch: 25/300 batch  80/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 25/300 batch  81/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 25/300 batch  82/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 25/300 batch  83/188  Train Loss: 0.058, Acc: 0.980\n",
      "epoch: 25/300 batch  84/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 25/300 batch  85/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 25/300 batch  86/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 25/300 batch  87/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 25/300 batch  88/188  Train Loss: 0.063, Acc: 0.988\n",
      "epoch: 25/300 batch  89/188  Train Loss: 0.068, Acc: 0.984\n",
      "epoch: 25/300 batch  90/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 25/300 batch  91/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 25/300 batch  92/188  Train Loss: 0.085, Acc: 0.980\n",
      "epoch: 25/300 batch  93/188  Train Loss: 0.044, Acc: 0.980\n",
      "epoch: 25/300 batch  94/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 25/300 batch  95/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 25/300 batch  96/188  Train Loss: 0.067, Acc: 0.980\n",
      "epoch: 25/300 batch  97/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 25/300 batch  98/188  Train Loss: 0.059, Acc: 0.977\n",
      "epoch: 25/300 batch  99/188  Train Loss: 0.057, Acc: 0.977\n",
      "epoch: 25/300 batch 100/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 25/300 batch 101/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 25/300 batch 102/188  Train Loss: 0.050, Acc: 0.980\n",
      "epoch: 25/300 batch 103/188  Train Loss: 0.050, Acc: 0.977\n",
      "epoch: 25/300 batch 104/188  Train Loss: 0.054, Acc: 0.980\n",
      "epoch: 25/300 batch 105/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 25/300 batch 106/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 25/300 batch 107/188  Train Loss: 0.082, Acc: 0.973\n",
      "epoch: 25/300 batch 108/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 25/300 batch 109/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 25/300 batch 110/188  Train Loss: 0.058, Acc: 0.996\n",
      "epoch: 25/300 batch 111/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 25/300 batch 112/188  Train Loss: 0.074, Acc: 0.973\n",
      "epoch: 25/300 batch 113/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 25/300 batch 114/188  Train Loss: 0.052, Acc: 0.992\n",
      "epoch: 25/300 batch 115/188  Train Loss: 0.033, Acc: 0.984\n",
      "epoch: 25/300 batch 116/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 25/300 batch 117/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 25/300 batch 118/188  Train Loss: 0.033, Acc: 1.000\n",
      "epoch: 25/300 batch 119/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 25/300 batch 120/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 25/300 batch 121/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 25/300 batch 122/188  Train Loss: 0.067, Acc: 0.980\n",
      "epoch: 25/300 batch 123/188  Train Loss: 0.043, Acc: 0.996\n",
      "epoch: 25/300 batch 124/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 25/300 batch 125/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 25/300 batch 126/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 25/300 batch 127/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 25/300 batch 128/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 25/300 batch 129/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 25/300 batch 130/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 25/300 batch 131/188  Train Loss: 0.062, Acc: 0.980\n",
      "epoch: 25/300 batch 132/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 25/300 batch 133/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 25/300 batch 134/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 25/300 batch 135/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 25/300 batch 136/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 25/300 batch 137/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 25/300 batch 138/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 25/300 batch 139/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 25/300 batch 140/188  Train Loss: 0.062, Acc: 0.980\n",
      "epoch: 25/300 batch 141/188  Train Loss: 0.070, Acc: 0.980\n",
      "epoch: 25/300 batch 142/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 25/300 batch 143/188  Train Loss: 0.108, Acc: 0.980\n",
      "epoch: 25/300 batch 144/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 25/300 batch 145/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 25/300 batch 146/188  Train Loss: 0.070, Acc: 0.980\n",
      "epoch: 25/300 batch 147/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 25/300 batch 148/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 25/300 batch 149/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 25/300 batch 150/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 25/300 batch 151/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 25/300 batch 152/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 25/300 batch 153/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 25/300 batch 154/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 25/300 batch 155/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 25/300 batch 156/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 25/300 batch 157/188  Train Loss: 0.051, Acc: 0.980\n",
      "epoch: 25/300 batch 158/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 25/300 batch 159/188  Train Loss: 0.080, Acc: 0.984\n",
      "epoch: 25/300 batch 160/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 25/300 batch 161/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 25/300 batch 162/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 25/300 batch 163/188  Train Loss: 0.062, Acc: 0.977\n",
      "epoch: 25/300 batch 164/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 25/300 batch 165/188  Train Loss: 0.055, Acc: 0.980\n",
      "epoch: 25/300 batch 166/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 25/300 batch 167/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 25/300 batch 168/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 25/300 batch 169/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 25/300 batch 170/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 25/300 batch 171/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 25/300 batch 172/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 25/300 batch 173/188  Train Loss: 0.064, Acc: 0.984\n",
      "epoch: 25/300 batch 174/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 25/300 batch 175/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 25/300 batch 176/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 25/300 batch 177/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 25/300 batch 178/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 25/300 batch 179/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 25/300 batch 180/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 25/300 batch 181/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 25/300 batch 182/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 25/300 batch 183/188  Train Loss: 0.100, Acc: 0.977\n",
      "epoch: 25/300 batch 184/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 25/300 batch 185/188  Train Loss: 0.059, Acc: 0.977\n",
      "epoch: 25/300 batch 186/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 25/300 batch 187/188  Train Loss: 0.039, Acc: 1.000\n",
      "Train Loss: 0.044366, Acc: 0.988\n",
      "Val Loss: 0.058224, Acc: 0.982\n",
      "epoch: 26/300 batch   0/188  Train Loss: 0.050, Acc: 0.980\n",
      "epoch: 26/300 batch   1/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 26/300 batch   2/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 26/300 batch   3/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 26/300 batch   4/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 26/300 batch   5/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 26/300 batch   6/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 26/300 batch   7/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 26/300 batch   8/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 26/300 batch   9/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 26/300 batch  10/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 26/300 batch  11/188  Train Loss: 0.048, Acc: 0.980\n",
      "epoch: 26/300 batch  12/188  Train Loss: 0.024, Acc: 0.988\n",
      "epoch: 26/300 batch  13/188  Train Loss: 0.064, Acc: 0.984\n",
      "epoch: 26/300 batch  14/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 26/300 batch  15/188  Train Loss: 0.031, Acc: 1.000\n",
      "epoch: 26/300 batch  16/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 26/300 batch  17/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 26/300 batch  18/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 26/300 batch  19/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 26/300 batch  20/188  Train Loss: 0.056, Acc: 0.988\n",
      "epoch: 26/300 batch  21/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 26/300 batch  22/188  Train Loss: 0.057, Acc: 0.988\n",
      "epoch: 26/300 batch  23/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 26/300 batch  24/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 26/300 batch  25/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 26/300 batch  26/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 26/300 batch  27/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 26/300 batch  28/188  Train Loss: 0.047, Acc: 0.996\n",
      "epoch: 26/300 batch  29/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 26/300 batch  30/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 26/300 batch  31/188  Train Loss: 0.047, Acc: 0.996\n",
      "epoch: 26/300 batch  32/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 26/300 batch  33/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 26/300 batch  34/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 26/300 batch  35/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 26/300 batch  36/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 26/300 batch  37/188  Train Loss: 0.060, Acc: 0.980\n",
      "epoch: 26/300 batch  38/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 26/300 batch  39/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 26/300 batch  40/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 26/300 batch  41/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 26/300 batch  42/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 26/300 batch  43/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 26/300 batch  44/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 26/300 batch  45/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 26/300 batch  46/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 26/300 batch  47/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 26/300 batch  48/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 26/300 batch  49/188  Train Loss: 0.059, Acc: 0.988\n",
      "epoch: 26/300 batch  50/188  Train Loss: 0.067, Acc: 0.984\n",
      "epoch: 26/300 batch  51/188  Train Loss: 0.072, Acc: 0.977\n",
      "epoch: 26/300 batch  52/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 26/300 batch  53/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 26/300 batch  54/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 26/300 batch  55/188  Train Loss: 0.048, Acc: 0.980\n",
      "epoch: 26/300 batch  56/188  Train Loss: 0.058, Acc: 0.988\n",
      "epoch: 26/300 batch  57/188  Train Loss: 0.049, Acc: 0.996\n",
      "epoch: 26/300 batch  58/188  Train Loss: 0.046, Acc: 0.980\n",
      "epoch: 26/300 batch  59/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 26/300 batch  60/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 26/300 batch  61/188  Train Loss: 0.074, Acc: 0.973\n",
      "epoch: 26/300 batch  62/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 26/300 batch  63/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 26/300 batch  64/188  Train Loss: 0.054, Acc: 0.977\n",
      "epoch: 26/300 batch  65/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 26/300 batch  66/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 26/300 batch  67/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 26/300 batch  68/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 26/300 batch  69/188  Train Loss: 0.050, Acc: 0.980\n",
      "epoch: 26/300 batch  70/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 26/300 batch  71/188  Train Loss: 0.074, Acc: 0.969\n",
      "epoch: 26/300 batch  72/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 26/300 batch  73/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 26/300 batch  74/188  Train Loss: 0.078, Acc: 0.980\n",
      "epoch: 26/300 batch  75/188  Train Loss: 0.090, Acc: 0.965\n",
      "epoch: 26/300 batch  76/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 26/300 batch  77/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 26/300 batch  78/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 26/300 batch  79/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 26/300 batch  80/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 26/300 batch  81/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 26/300 batch  82/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 26/300 batch  83/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 26/300 batch  84/188  Train Loss: 0.071, Acc: 0.977\n",
      "epoch: 26/300 batch  85/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 26/300 batch  86/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 26/300 batch  87/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 26/300 batch  88/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 26/300 batch  89/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 26/300 batch  90/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 26/300 batch  91/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 26/300 batch  92/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 26/300 batch  93/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 26/300 batch  94/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 26/300 batch  95/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 26/300 batch  96/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 26/300 batch  97/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 26/300 batch  98/188  Train Loss: 0.053, Acc: 0.973\n",
      "epoch: 26/300 batch  99/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 26/300 batch 100/188  Train Loss: 0.057, Acc: 0.977\n",
      "epoch: 26/300 batch 101/188  Train Loss: 0.068, Acc: 0.988\n",
      "epoch: 26/300 batch 102/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 26/300 batch 103/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 26/300 batch 104/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 26/300 batch 105/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 26/300 batch 106/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 26/300 batch 107/188  Train Loss: 0.045, Acc: 0.980\n",
      "epoch: 26/300 batch 108/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 26/300 batch 109/188  Train Loss: 0.068, Acc: 0.977\n",
      "epoch: 26/300 batch 110/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 26/300 batch 111/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 26/300 batch 112/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 26/300 batch 113/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 26/300 batch 114/188  Train Loss: 0.062, Acc: 0.988\n",
      "epoch: 26/300 batch 115/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 26/300 batch 116/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 26/300 batch 117/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 26/300 batch 118/188  Train Loss: 0.054, Acc: 0.996\n",
      "epoch: 26/300 batch 119/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 26/300 batch 120/188  Train Loss: 0.046, Acc: 0.980\n",
      "epoch: 26/300 batch 121/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 26/300 batch 122/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 26/300 batch 123/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 26/300 batch 124/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 26/300 batch 125/188  Train Loss: 0.068, Acc: 0.984\n",
      "epoch: 26/300 batch 126/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 26/300 batch 127/188  Train Loss: 0.061, Acc: 0.984\n",
      "epoch: 26/300 batch 128/188  Train Loss: 0.061, Acc: 0.984\n",
      "epoch: 26/300 batch 129/188  Train Loss: 0.082, Acc: 0.988\n",
      "epoch: 26/300 batch 130/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 26/300 batch 131/188  Train Loss: 0.046, Acc: 0.980\n",
      "epoch: 26/300 batch 132/188  Train Loss: 0.065, Acc: 0.977\n",
      "epoch: 26/300 batch 133/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 26/300 batch 134/188  Train Loss: 0.066, Acc: 0.984\n",
      "epoch: 26/300 batch 135/188  Train Loss: 0.069, Acc: 0.988\n",
      "epoch: 26/300 batch 136/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 26/300 batch 137/188  Train Loss: 0.038, Acc: 0.980\n",
      "epoch: 26/300 batch 138/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 26/300 batch 139/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 26/300 batch 140/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 26/300 batch 141/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 26/300 batch 142/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 26/300 batch 143/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 26/300 batch 144/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 26/300 batch 145/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 26/300 batch 146/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 26/300 batch 147/188  Train Loss: 0.062, Acc: 0.984\n",
      "epoch: 26/300 batch 148/188  Train Loss: 0.078, Acc: 0.977\n",
      "epoch: 26/300 batch 149/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 26/300 batch 150/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 26/300 batch 151/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 26/300 batch 152/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 26/300 batch 153/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 26/300 batch 154/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 26/300 batch 155/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 26/300 batch 156/188  Train Loss: 0.061, Acc: 0.984\n",
      "epoch: 26/300 batch 157/188  Train Loss: 0.061, Acc: 0.973\n",
      "epoch: 26/300 batch 158/188  Train Loss: 0.052, Acc: 0.980\n",
      "epoch: 26/300 batch 159/188  Train Loss: 0.042, Acc: 0.996\n",
      "epoch: 26/300 batch 160/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 26/300 batch 161/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 26/300 batch 162/188  Train Loss: 0.054, Acc: 0.977\n",
      "epoch: 26/300 batch 163/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 26/300 batch 164/188  Train Loss: 0.063, Acc: 0.980\n",
      "epoch: 26/300 batch 165/188  Train Loss: 0.053, Acc: 0.977\n",
      "epoch: 26/300 batch 166/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 26/300 batch 167/188  Train Loss: 0.078, Acc: 0.973\n",
      "epoch: 26/300 batch 168/188  Train Loss: 0.056, Acc: 0.980\n",
      "epoch: 26/300 batch 169/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 26/300 batch 170/188  Train Loss: 0.057, Acc: 0.973\n",
      "epoch: 26/300 batch 171/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 26/300 batch 172/188  Train Loss: 0.077, Acc: 0.969\n",
      "epoch: 26/300 batch 173/188  Train Loss: 0.051, Acc: 0.992\n",
      "epoch: 26/300 batch 174/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 26/300 batch 175/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 26/300 batch 176/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 26/300 batch 177/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 26/300 batch 178/188  Train Loss: 0.051, Acc: 0.992\n",
      "epoch: 26/300 batch 179/188  Train Loss: 0.046, Acc: 0.980\n",
      "epoch: 26/300 batch 180/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 26/300 batch 181/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 26/300 batch 182/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 26/300 batch 183/188  Train Loss: 0.052, Acc: 0.980\n",
      "epoch: 26/300 batch 184/188  Train Loss: 0.051, Acc: 0.992\n",
      "epoch: 26/300 batch 185/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 26/300 batch 186/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 26/300 batch 187/188  Train Loss: 0.032, Acc: 0.992\n",
      "Train Loss: 0.044271, Acc: 0.988\n",
      "Val Loss: 0.059919, Acc: 0.982\n",
      "epoch: 27/300 batch   0/188  Train Loss: 0.078, Acc: 0.977\n",
      "epoch: 27/300 batch   1/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 27/300 batch   2/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 27/300 batch   3/188  Train Loss: 0.051, Acc: 0.980\n",
      "epoch: 27/300 batch   4/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 27/300 batch   5/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 27/300 batch   6/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 27/300 batch   7/188  Train Loss: 0.085, Acc: 0.977\n",
      "epoch: 27/300 batch   8/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 27/300 batch   9/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 27/300 batch  10/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 27/300 batch  11/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 27/300 batch  12/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 27/300 batch  13/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 27/300 batch  14/188  Train Loss: 0.036, Acc: 0.980\n",
      "epoch: 27/300 batch  15/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 27/300 batch  16/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 27/300 batch  17/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 27/300 batch  18/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 27/300 batch  19/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 27/300 batch  20/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 27/300 batch  21/188  Train Loss: 0.056, Acc: 0.988\n",
      "epoch: 27/300 batch  22/188  Train Loss: 0.061, Acc: 0.984\n",
      "epoch: 27/300 batch  23/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 27/300 batch  24/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 27/300 batch  25/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 27/300 batch  26/188  Train Loss: 0.062, Acc: 0.984\n",
      "epoch: 27/300 batch  27/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 27/300 batch  28/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 27/300 batch  29/188  Train Loss: 0.057, Acc: 0.988\n",
      "epoch: 27/300 batch  30/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 27/300 batch  31/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 27/300 batch  32/188  Train Loss: 0.063, Acc: 0.984\n",
      "epoch: 27/300 batch  33/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 27/300 batch  34/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 27/300 batch  35/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 27/300 batch  36/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 27/300 batch  37/188  Train Loss: 0.051, Acc: 0.980\n",
      "epoch: 27/300 batch  38/188  Train Loss: 0.057, Acc: 0.988\n",
      "epoch: 27/300 batch  39/188  Train Loss: 0.055, Acc: 0.977\n",
      "epoch: 27/300 batch  40/188  Train Loss: 0.057, Acc: 0.988\n",
      "epoch: 27/300 batch  41/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 27/300 batch  42/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 27/300 batch  43/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 27/300 batch  44/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 27/300 batch  45/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 27/300 batch  46/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 27/300 batch  47/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 27/300 batch  48/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 27/300 batch  49/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 27/300 batch  50/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 27/300 batch  51/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 27/300 batch  52/188  Train Loss: 0.062, Acc: 0.980\n",
      "epoch: 27/300 batch  53/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 27/300 batch  54/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 27/300 batch  55/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 27/300 batch  56/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 27/300 batch  57/188  Train Loss: 0.067, Acc: 0.973\n",
      "epoch: 27/300 batch  58/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 27/300 batch  59/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 27/300 batch  60/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 27/300 batch  61/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 27/300 batch  62/188  Train Loss: 0.080, Acc: 0.980\n",
      "epoch: 27/300 batch  63/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 27/300 batch  64/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 27/300 batch  65/188  Train Loss: 0.048, Acc: 0.996\n",
      "epoch: 27/300 batch  66/188  Train Loss: 0.073, Acc: 0.984\n",
      "epoch: 27/300 batch  67/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 27/300 batch  68/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 27/300 batch  69/188  Train Loss: 0.063, Acc: 0.980\n",
      "epoch: 27/300 batch  70/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 27/300 batch  71/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 27/300 batch  72/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 27/300 batch  73/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 27/300 batch  74/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 27/300 batch  75/188  Train Loss: 0.059, Acc: 0.988\n",
      "epoch: 27/300 batch  76/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 27/300 batch  77/188  Train Loss: 0.053, Acc: 0.980\n",
      "epoch: 27/300 batch  78/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 27/300 batch  79/188  Train Loss: 0.060, Acc: 0.977\n",
      "epoch: 27/300 batch  80/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 27/300 batch  81/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 27/300 batch  82/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 27/300 batch  83/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 27/300 batch  84/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 27/300 batch  85/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 27/300 batch  86/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 27/300 batch  87/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 27/300 batch  88/188  Train Loss: 0.066, Acc: 0.980\n",
      "epoch: 27/300 batch  89/188  Train Loss: 0.092, Acc: 0.977\n",
      "epoch: 27/300 batch  90/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 27/300 batch  91/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 27/300 batch  92/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 27/300 batch  93/188  Train Loss: 0.068, Acc: 0.984\n",
      "epoch: 27/300 batch  94/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 27/300 batch  95/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 27/300 batch  96/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 27/300 batch  97/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 27/300 batch  98/188  Train Loss: 0.061, Acc: 0.988\n",
      "epoch: 27/300 batch  99/188  Train Loss: 0.054, Acc: 0.977\n",
      "epoch: 27/300 batch 100/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 27/300 batch 101/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 27/300 batch 102/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 27/300 batch 103/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 27/300 batch 104/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 27/300 batch 105/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 27/300 batch 106/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 27/300 batch 107/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 27/300 batch 108/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 27/300 batch 109/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 27/300 batch 110/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 27/300 batch 111/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 27/300 batch 112/188  Train Loss: 0.048, Acc: 0.980\n",
      "epoch: 27/300 batch 113/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 27/300 batch 114/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 27/300 batch 115/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 27/300 batch 116/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 27/300 batch 117/188  Train Loss: 0.070, Acc: 0.984\n",
      "epoch: 27/300 batch 118/188  Train Loss: 0.060, Acc: 0.984\n",
      "epoch: 27/300 batch 119/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 27/300 batch 120/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 27/300 batch 121/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 27/300 batch 122/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 27/300 batch 123/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 27/300 batch 124/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 27/300 batch 125/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 27/300 batch 126/188  Train Loss: 0.052, Acc: 0.996\n",
      "epoch: 27/300 batch 127/188  Train Loss: 0.048, Acc: 0.977\n",
      "epoch: 27/300 batch 128/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 27/300 batch 129/188  Train Loss: 0.051, Acc: 0.980\n",
      "epoch: 27/300 batch 130/188  Train Loss: 0.090, Acc: 0.977\n",
      "epoch: 27/300 batch 131/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 27/300 batch 132/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 27/300 batch 133/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 27/300 batch 134/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 27/300 batch 135/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 27/300 batch 136/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 27/300 batch 137/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 27/300 batch 138/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 27/300 batch 139/188  Train Loss: 0.041, Acc: 0.980\n",
      "epoch: 27/300 batch 140/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 27/300 batch 141/188  Train Loss: 0.069, Acc: 0.980\n",
      "epoch: 27/300 batch 142/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 27/300 batch 143/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 27/300 batch 144/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 27/300 batch 145/188  Train Loss: 0.084, Acc: 0.977\n",
      "epoch: 27/300 batch 146/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 27/300 batch 147/188  Train Loss: 0.061, Acc: 0.984\n",
      "epoch: 27/300 batch 148/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 27/300 batch 149/188  Train Loss: 0.074, Acc: 0.977\n",
      "epoch: 27/300 batch 150/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 27/300 batch 151/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 27/300 batch 152/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 27/300 batch 153/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 27/300 batch 154/188  Train Loss: 0.042, Acc: 0.996\n",
      "epoch: 27/300 batch 155/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 27/300 batch 156/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 27/300 batch 157/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 27/300 batch 158/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 27/300 batch 159/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 27/300 batch 160/188  Train Loss: 0.061, Acc: 0.977\n",
      "epoch: 27/300 batch 161/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 27/300 batch 162/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 27/300 batch 163/188  Train Loss: 0.078, Acc: 0.977\n",
      "epoch: 27/300 batch 164/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 27/300 batch 165/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 27/300 batch 166/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 27/300 batch 167/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 27/300 batch 168/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 27/300 batch 169/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 27/300 batch 170/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 27/300 batch 171/188  Train Loss: 0.070, Acc: 0.992\n",
      "epoch: 27/300 batch 172/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 27/300 batch 173/188  Train Loss: 0.068, Acc: 0.980\n",
      "epoch: 27/300 batch 174/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 27/300 batch 175/188  Train Loss: 0.060, Acc: 0.980\n",
      "epoch: 27/300 batch 176/188  Train Loss: 0.062, Acc: 0.980\n",
      "epoch: 27/300 batch 177/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 27/300 batch 178/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 27/300 batch 179/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 27/300 batch 180/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 27/300 batch 181/188  Train Loss: 0.071, Acc: 0.973\n",
      "epoch: 27/300 batch 182/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 27/300 batch 183/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 27/300 batch 184/188  Train Loss: 0.060, Acc: 0.984\n",
      "epoch: 27/300 batch 185/188  Train Loss: 0.060, Acc: 0.984\n",
      "epoch: 27/300 batch 186/188  Train Loss: 0.077, Acc: 0.973\n",
      "epoch: 27/300 batch 187/188  Train Loss: 0.026, Acc: 1.000\n",
      "Train Loss: 0.043859, Acc: 0.989\n",
      "Val Loss: 0.060260, Acc: 0.982\n",
      "epoch: 28/300 batch   0/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 28/300 batch   1/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 28/300 batch   2/188  Train Loss: 0.031, Acc: 1.000\n",
      "epoch: 28/300 batch   3/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 28/300 batch   4/188  Train Loss: 0.069, Acc: 0.984\n",
      "epoch: 28/300 batch   5/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 28/300 batch   6/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 28/300 batch   7/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 28/300 batch   8/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 28/300 batch   9/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 28/300 batch  10/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 28/300 batch  11/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 28/300 batch  12/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 28/300 batch  13/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 28/300 batch  14/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 28/300 batch  15/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 28/300 batch  16/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 28/300 batch  17/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 28/300 batch  18/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 28/300 batch  19/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 28/300 batch  20/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 28/300 batch  21/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 28/300 batch  22/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 28/300 batch  23/188  Train Loss: 0.051, Acc: 0.980\n",
      "epoch: 28/300 batch  24/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 28/300 batch  25/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 28/300 batch  26/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 28/300 batch  27/188  Train Loss: 0.062, Acc: 0.988\n",
      "epoch: 28/300 batch  28/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 28/300 batch  29/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 28/300 batch  30/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 28/300 batch  31/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 28/300 batch  32/188  Train Loss: 0.057, Acc: 0.973\n",
      "epoch: 28/300 batch  33/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 28/300 batch  34/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 28/300 batch  35/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 28/300 batch  36/188  Train Loss: 0.060, Acc: 0.980\n",
      "epoch: 28/300 batch  37/188  Train Loss: 0.062, Acc: 0.984\n",
      "epoch: 28/300 batch  38/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 28/300 batch  39/188  Train Loss: 0.060, Acc: 0.984\n",
      "epoch: 28/300 batch  40/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 28/300 batch  41/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 28/300 batch  42/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 28/300 batch  43/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 28/300 batch  44/188  Train Loss: 0.032, Acc: 1.000\n",
      "epoch: 28/300 batch  45/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 28/300 batch  46/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 28/300 batch  47/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 28/300 batch  48/188  Train Loss: 0.058, Acc: 0.980\n",
      "epoch: 28/300 batch  49/188  Train Loss: 0.084, Acc: 0.988\n",
      "epoch: 28/300 batch  50/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 28/300 batch  51/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 28/300 batch  52/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 28/300 batch  53/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 28/300 batch  54/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 28/300 batch  55/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 28/300 batch  56/188  Train Loss: 0.055, Acc: 0.980\n",
      "epoch: 28/300 batch  57/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 28/300 batch  58/188  Train Loss: 0.057, Acc: 0.980\n",
      "epoch: 28/300 batch  59/188  Train Loss: 0.063, Acc: 0.973\n",
      "epoch: 28/300 batch  60/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 28/300 batch  61/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 28/300 batch  62/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 28/300 batch  63/188  Train Loss: 0.047, Acc: 0.980\n",
      "epoch: 28/300 batch  64/188  Train Loss: 0.060, Acc: 0.977\n",
      "epoch: 28/300 batch  65/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 28/300 batch  66/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 28/300 batch  67/188  Train Loss: 0.063, Acc: 0.977\n",
      "epoch: 28/300 batch  68/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 28/300 batch  69/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 28/300 batch  70/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 28/300 batch  71/188  Train Loss: 0.060, Acc: 0.984\n",
      "epoch: 28/300 batch  72/188  Train Loss: 0.056, Acc: 0.980\n",
      "epoch: 28/300 batch  73/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 28/300 batch  74/188  Train Loss: 0.048, Acc: 0.980\n",
      "epoch: 28/300 batch  75/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 28/300 batch  76/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 28/300 batch  77/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 28/300 batch  78/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 28/300 batch  79/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 28/300 batch  80/188  Train Loss: 0.087, Acc: 0.980\n",
      "epoch: 28/300 batch  81/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 28/300 batch  82/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 28/300 batch  83/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 28/300 batch  84/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 28/300 batch  85/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 28/300 batch  86/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 28/300 batch  87/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 28/300 batch  88/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 28/300 batch  89/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 28/300 batch  90/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 28/300 batch  91/188  Train Loss: 0.056, Acc: 0.977\n",
      "epoch: 28/300 batch  92/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 28/300 batch  93/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 28/300 batch  94/188  Train Loss: 0.067, Acc: 0.980\n",
      "epoch: 28/300 batch  95/188  Train Loss: 0.072, Acc: 0.980\n",
      "epoch: 28/300 batch  96/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 28/300 batch  97/188  Train Loss: 0.118, Acc: 0.961\n",
      "epoch: 28/300 batch  98/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 28/300 batch  99/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 28/300 batch 100/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 28/300 batch 101/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 28/300 batch 102/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 28/300 batch 103/188  Train Loss: 0.065, Acc: 0.980\n",
      "epoch: 28/300 batch 104/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 28/300 batch 105/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 28/300 batch 106/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 28/300 batch 107/188  Train Loss: 0.070, Acc: 0.988\n",
      "epoch: 28/300 batch 108/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 28/300 batch 109/188  Train Loss: 0.058, Acc: 0.988\n",
      "epoch: 28/300 batch 110/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 28/300 batch 111/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 28/300 batch 112/188  Train Loss: 0.056, Acc: 0.992\n",
      "epoch: 28/300 batch 113/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 28/300 batch 114/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 28/300 batch 115/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 28/300 batch 116/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 28/300 batch 117/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 28/300 batch 118/188  Train Loss: 0.060, Acc: 0.980\n",
      "epoch: 28/300 batch 119/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 28/300 batch 120/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 28/300 batch 121/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 28/300 batch 122/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 28/300 batch 123/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 28/300 batch 124/188  Train Loss: 0.054, Acc: 0.980\n",
      "epoch: 28/300 batch 125/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 28/300 batch 126/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 28/300 batch 127/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 28/300 batch 128/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 28/300 batch 129/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 28/300 batch 130/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 28/300 batch 131/188  Train Loss: 0.095, Acc: 0.973\n",
      "epoch: 28/300 batch 132/188  Train Loss: 0.062, Acc: 0.988\n",
      "epoch: 28/300 batch 133/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 28/300 batch 134/188  Train Loss: 0.071, Acc: 0.984\n",
      "epoch: 28/300 batch 135/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 28/300 batch 136/188  Train Loss: 0.090, Acc: 0.969\n",
      "epoch: 28/300 batch 137/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 28/300 batch 138/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 28/300 batch 139/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 28/300 batch 140/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 28/300 batch 141/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 28/300 batch 142/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 28/300 batch 143/188  Train Loss: 0.032, Acc: 1.000\n",
      "epoch: 28/300 batch 144/188  Train Loss: 0.045, Acc: 0.977\n",
      "epoch: 28/300 batch 145/188  Train Loss: 0.065, Acc: 0.980\n",
      "epoch: 28/300 batch 146/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 28/300 batch 147/188  Train Loss: 0.049, Acc: 0.977\n",
      "epoch: 28/300 batch 148/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 28/300 batch 149/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 28/300 batch 150/188  Train Loss: 0.095, Acc: 0.980\n",
      "epoch: 28/300 batch 151/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 28/300 batch 152/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 28/300 batch 153/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 28/300 batch 154/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 28/300 batch 155/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 28/300 batch 156/188  Train Loss: 0.058, Acc: 0.977\n",
      "epoch: 28/300 batch 157/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 28/300 batch 158/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 28/300 batch 159/188  Train Loss: 0.058, Acc: 0.988\n",
      "epoch: 28/300 batch 160/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 28/300 batch 161/188  Train Loss: 0.058, Acc: 0.992\n",
      "epoch: 28/300 batch 162/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 28/300 batch 163/188  Train Loss: 0.059, Acc: 0.980\n",
      "epoch: 28/300 batch 164/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 28/300 batch 165/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 28/300 batch 166/188  Train Loss: 0.053, Acc: 0.992\n",
      "epoch: 28/300 batch 167/188  Train Loss: 0.048, Acc: 0.980\n",
      "epoch: 28/300 batch 168/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 28/300 batch 169/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 28/300 batch 170/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 28/300 batch 171/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 28/300 batch 172/188  Train Loss: 0.057, Acc: 0.980\n",
      "epoch: 28/300 batch 173/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 28/300 batch 174/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 28/300 batch 175/188  Train Loss: 0.041, Acc: 0.977\n",
      "epoch: 28/300 batch 176/188  Train Loss: 0.076, Acc: 0.969\n",
      "epoch: 28/300 batch 177/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 28/300 batch 178/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 28/300 batch 179/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 28/300 batch 180/188  Train Loss: 0.060, Acc: 0.984\n",
      "epoch: 28/300 batch 181/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 28/300 batch 182/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 28/300 batch 183/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 28/300 batch 184/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 28/300 batch 185/188  Train Loss: 0.075, Acc: 0.984\n",
      "epoch: 28/300 batch 186/188  Train Loss: 0.051, Acc: 0.980\n",
      "epoch: 28/300 batch 187/188  Train Loss: 0.052, Acc: 0.992\n",
      "Train Loss: 0.043998, Acc: 0.989\n",
      "Val Loss: 0.059879, Acc: 0.983\n",
      "epoch: 29/300 batch   0/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 29/300 batch   1/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 29/300 batch   2/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 29/300 batch   3/188  Train Loss: 0.060, Acc: 0.988\n",
      "epoch: 29/300 batch   4/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 29/300 batch   5/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 29/300 batch   6/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 29/300 batch   7/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 29/300 batch   8/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 29/300 batch   9/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 29/300 batch  10/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 29/300 batch  11/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 29/300 batch  12/188  Train Loss: 0.068, Acc: 0.984\n",
      "epoch: 29/300 batch  13/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 29/300 batch  14/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 29/300 batch  15/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 29/300 batch  16/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 29/300 batch  17/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 29/300 batch  18/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 29/300 batch  19/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 29/300 batch  20/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 29/300 batch  21/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 29/300 batch  22/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 29/300 batch  23/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 29/300 batch  24/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 29/300 batch  25/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 29/300 batch  26/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 29/300 batch  27/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 29/300 batch  28/188  Train Loss: 0.049, Acc: 0.980\n",
      "epoch: 29/300 batch  29/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 29/300 batch  30/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 29/300 batch  31/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 29/300 batch  32/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 29/300 batch  33/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 29/300 batch  34/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 29/300 batch  35/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 29/300 batch  36/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 29/300 batch  37/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 29/300 batch  38/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 29/300 batch  39/188  Train Loss: 0.081, Acc: 0.980\n",
      "epoch: 29/300 batch  40/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 29/300 batch  41/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 29/300 batch  42/188  Train Loss: 0.081, Acc: 0.973\n",
      "epoch: 29/300 batch  43/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 29/300 batch  44/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 29/300 batch  45/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 29/300 batch  46/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 29/300 batch  47/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 29/300 batch  48/188  Train Loss: 0.048, Acc: 0.977\n",
      "epoch: 29/300 batch  49/188  Train Loss: 0.066, Acc: 0.984\n",
      "epoch: 29/300 batch  50/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 29/300 batch  51/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 29/300 batch  52/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 29/300 batch  53/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 29/300 batch  54/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 29/300 batch  55/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 29/300 batch  56/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 29/300 batch  57/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 29/300 batch  58/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 29/300 batch  59/188  Train Loss: 0.078, Acc: 0.973\n",
      "epoch: 29/300 batch  60/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 29/300 batch  61/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 29/300 batch  62/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 29/300 batch  63/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 29/300 batch  64/188  Train Loss: 0.069, Acc: 0.984\n",
      "epoch: 29/300 batch  65/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 29/300 batch  66/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 29/300 batch  67/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 29/300 batch  68/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 29/300 batch  69/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 29/300 batch  70/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 29/300 batch  71/188  Train Loss: 0.056, Acc: 0.988\n",
      "epoch: 29/300 batch  72/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 29/300 batch  73/188  Train Loss: 0.069, Acc: 0.980\n",
      "epoch: 29/300 batch  74/188  Train Loss: 0.090, Acc: 0.977\n",
      "epoch: 29/300 batch  75/188  Train Loss: 0.057, Acc: 0.988\n",
      "epoch: 29/300 batch  76/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 29/300 batch  77/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 29/300 batch  78/188  Train Loss: 0.052, Acc: 0.980\n",
      "epoch: 29/300 batch  79/188  Train Loss: 0.062, Acc: 0.980\n",
      "epoch: 29/300 batch  80/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 29/300 batch  81/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 29/300 batch  82/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 29/300 batch  83/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 29/300 batch  84/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 29/300 batch  85/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 29/300 batch  86/188  Train Loss: 0.062, Acc: 0.984\n",
      "epoch: 29/300 batch  87/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 29/300 batch  88/188  Train Loss: 0.066, Acc: 0.984\n",
      "epoch: 29/300 batch  89/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 29/300 batch  90/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 29/300 batch  91/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 29/300 batch  92/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 29/300 batch  93/188  Train Loss: 0.052, Acc: 0.992\n",
      "epoch: 29/300 batch  94/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 29/300 batch  95/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 29/300 batch  96/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 29/300 batch  97/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 29/300 batch  98/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 29/300 batch  99/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 29/300 batch 100/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 29/300 batch 101/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 29/300 batch 102/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 29/300 batch 103/188  Train Loss: 0.068, Acc: 0.977\n",
      "epoch: 29/300 batch 104/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 29/300 batch 105/188  Train Loss: 0.051, Acc: 0.992\n",
      "epoch: 29/300 batch 106/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 29/300 batch 107/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 29/300 batch 108/188  Train Loss: 0.064, Acc: 0.984\n",
      "epoch: 29/300 batch 109/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 29/300 batch 110/188  Train Loss: 0.049, Acc: 0.980\n",
      "epoch: 29/300 batch 111/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 29/300 batch 112/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 29/300 batch 113/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 29/300 batch 114/188  Train Loss: 0.068, Acc: 0.977\n",
      "epoch: 29/300 batch 115/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 29/300 batch 116/188  Train Loss: 0.049, Acc: 0.980\n",
      "epoch: 29/300 batch 117/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 29/300 batch 118/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 29/300 batch 119/188  Train Loss: 0.055, Acc: 0.992\n",
      "epoch: 29/300 batch 120/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 29/300 batch 121/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 29/300 batch 122/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 29/300 batch 123/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 29/300 batch 124/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 29/300 batch 125/188  Train Loss: 0.063, Acc: 0.984\n",
      "epoch: 29/300 batch 126/188  Train Loss: 0.079, Acc: 0.984\n",
      "epoch: 29/300 batch 127/188  Train Loss: 0.062, Acc: 0.996\n",
      "epoch: 29/300 batch 128/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 29/300 batch 129/188  Train Loss: 0.058, Acc: 0.980\n",
      "epoch: 29/300 batch 130/188  Train Loss: 0.053, Acc: 0.992\n",
      "epoch: 29/300 batch 131/188  Train Loss: 0.064, Acc: 0.984\n",
      "epoch: 29/300 batch 132/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 29/300 batch 133/188  Train Loss: 0.072, Acc: 0.984\n",
      "epoch: 29/300 batch 134/188  Train Loss: 0.063, Acc: 0.984\n",
      "epoch: 29/300 batch 135/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 29/300 batch 136/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 29/300 batch 137/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 29/300 batch 138/188  Train Loss: 0.063, Acc: 0.977\n",
      "epoch: 29/300 batch 139/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 29/300 batch 140/188  Train Loss: 0.068, Acc: 0.977\n",
      "epoch: 29/300 batch 141/188  Train Loss: 0.070, Acc: 0.977\n",
      "epoch: 29/300 batch 142/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 29/300 batch 143/188  Train Loss: 0.062, Acc: 0.980\n",
      "epoch: 29/300 batch 144/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 29/300 batch 145/188  Train Loss: 0.059, Acc: 0.984\n",
      "epoch: 29/300 batch 146/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 29/300 batch 147/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 29/300 batch 148/188  Train Loss: 0.064, Acc: 0.984\n",
      "epoch: 29/300 batch 149/188  Train Loss: 0.062, Acc: 0.984\n",
      "epoch: 29/300 batch 150/188  Train Loss: 0.062, Acc: 0.984\n",
      "epoch: 29/300 batch 151/188  Train Loss: 0.074, Acc: 0.977\n",
      "epoch: 29/300 batch 152/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 29/300 batch 153/188  Train Loss: 0.054, Acc: 0.980\n",
      "epoch: 29/300 batch 154/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 29/300 batch 155/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 29/300 batch 156/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 29/300 batch 157/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 29/300 batch 158/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 29/300 batch 159/188  Train Loss: 0.034, Acc: 0.984\n",
      "epoch: 29/300 batch 160/188  Train Loss: 0.067, Acc: 0.984\n",
      "epoch: 29/300 batch 161/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 29/300 batch 162/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 29/300 batch 163/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 29/300 batch 164/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 29/300 batch 165/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 29/300 batch 166/188  Train Loss: 0.063, Acc: 0.980\n",
      "epoch: 29/300 batch 167/188  Train Loss: 0.061, Acc: 0.980\n",
      "epoch: 29/300 batch 168/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 29/300 batch 169/188  Train Loss: 0.067, Acc: 0.980\n",
      "epoch: 29/300 batch 170/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 29/300 batch 171/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 29/300 batch 172/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 29/300 batch 173/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 29/300 batch 174/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 29/300 batch 175/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 29/300 batch 176/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 29/300 batch 177/188  Train Loss: 0.045, Acc: 0.977\n",
      "epoch: 29/300 batch 178/188  Train Loss: 0.064, Acc: 0.984\n",
      "epoch: 29/300 batch 179/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 29/300 batch 180/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 29/300 batch 181/188  Train Loss: 0.059, Acc: 0.992\n",
      "epoch: 29/300 batch 182/188  Train Loss: 0.059, Acc: 0.988\n",
      "epoch: 29/300 batch 183/188  Train Loss: 0.059, Acc: 0.984\n",
      "epoch: 29/300 batch 184/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 29/300 batch 185/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 29/300 batch 186/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 29/300 batch 187/188  Train Loss: 0.032, Acc: 0.992\n",
      "Train Loss: 0.043451, Acc: 0.989\n",
      "Val Loss: 0.061864, Acc: 0.981\n",
      "epoch: 30/300 batch   0/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 30/300 batch   1/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 30/300 batch   2/188  Train Loss: 0.070, Acc: 0.973\n",
      "epoch: 30/300 batch   3/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 30/300 batch   4/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 30/300 batch   5/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 30/300 batch   6/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 30/300 batch   7/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 30/300 batch   8/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 30/300 batch   9/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 30/300 batch  10/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 30/300 batch  11/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 30/300 batch  12/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 30/300 batch  13/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 30/300 batch  14/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 30/300 batch  15/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 30/300 batch  16/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 30/300 batch  17/188  Train Loss: 0.025, Acc: 0.988\n",
      "epoch: 30/300 batch  18/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 30/300 batch  19/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 30/300 batch  20/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 30/300 batch  21/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 30/300 batch  22/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 30/300 batch  23/188  Train Loss: 0.035, Acc: 1.000\n",
      "epoch: 30/300 batch  24/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 30/300 batch  25/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 30/300 batch  26/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 30/300 batch  27/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 30/300 batch  28/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 30/300 batch  29/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 30/300 batch  30/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 30/300 batch  31/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 30/300 batch  32/188  Train Loss: 0.061, Acc: 0.988\n",
      "epoch: 30/300 batch  33/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 30/300 batch  34/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 30/300 batch  35/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 30/300 batch  36/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 30/300 batch  37/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 30/300 batch  38/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 30/300 batch  39/188  Train Loss: 0.053, Acc: 0.980\n",
      "epoch: 30/300 batch  40/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 30/300 batch  41/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 30/300 batch  42/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 30/300 batch  43/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 30/300 batch  44/188  Train Loss: 0.034, Acc: 0.984\n",
      "epoch: 30/300 batch  45/188  Train Loss: 0.046, Acc: 0.980\n",
      "epoch: 30/300 batch  46/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 30/300 batch  47/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 30/300 batch  48/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 30/300 batch  49/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 30/300 batch  50/188  Train Loss: 0.061, Acc: 0.984\n",
      "epoch: 30/300 batch  51/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 30/300 batch  52/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 30/300 batch  53/188  Train Loss: 0.057, Acc: 0.980\n",
      "epoch: 30/300 batch  54/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 30/300 batch  55/188  Train Loss: 0.064, Acc: 0.980\n",
      "epoch: 30/300 batch  56/188  Train Loss: 0.033, Acc: 1.000\n",
      "epoch: 30/300 batch  57/188  Train Loss: 0.065, Acc: 0.977\n",
      "epoch: 30/300 batch  58/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 30/300 batch  59/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 30/300 batch  60/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 30/300 batch  61/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 30/300 batch  62/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 30/300 batch  63/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 30/300 batch  64/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 30/300 batch  65/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 30/300 batch  66/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 30/300 batch  67/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 30/300 batch  68/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 30/300 batch  69/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 30/300 batch  70/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 30/300 batch  71/188  Train Loss: 0.057, Acc: 0.977\n",
      "epoch: 30/300 batch  72/188  Train Loss: 0.045, Acc: 0.980\n",
      "epoch: 30/300 batch  73/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 30/300 batch  74/188  Train Loss: 0.060, Acc: 0.988\n",
      "epoch: 30/300 batch  75/188  Train Loss: 0.060, Acc: 0.980\n",
      "epoch: 30/300 batch  76/188  Train Loss: 0.098, Acc: 0.973\n",
      "epoch: 30/300 batch  77/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 30/300 batch  78/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 30/300 batch  79/188  Train Loss: 0.082, Acc: 0.980\n",
      "epoch: 30/300 batch  80/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 30/300 batch  81/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 30/300 batch  82/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 30/300 batch  83/188  Train Loss: 0.069, Acc: 0.977\n",
      "epoch: 30/300 batch  84/188  Train Loss: 0.076, Acc: 0.988\n",
      "epoch: 30/300 batch  85/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 30/300 batch  86/188  Train Loss: 0.053, Acc: 0.996\n",
      "epoch: 30/300 batch  87/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 30/300 batch  88/188  Train Loss: 0.034, Acc: 0.984\n",
      "epoch: 30/300 batch  89/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 30/300 batch  90/188  Train Loss: 0.101, Acc: 0.973\n",
      "epoch: 30/300 batch  91/188  Train Loss: 0.078, Acc: 0.969\n",
      "epoch: 30/300 batch  92/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 30/300 batch  93/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 30/300 batch  94/188  Train Loss: 0.054, Acc: 0.980\n",
      "epoch: 30/300 batch  95/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 30/300 batch  96/188  Train Loss: 0.072, Acc: 0.980\n",
      "epoch: 30/300 batch  97/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 30/300 batch  98/188  Train Loss: 0.065, Acc: 0.984\n",
      "epoch: 30/300 batch  99/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 30/300 batch 100/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 30/300 batch 101/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 30/300 batch 102/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 30/300 batch 103/188  Train Loss: 0.060, Acc: 0.984\n",
      "epoch: 30/300 batch 104/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 30/300 batch 105/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 30/300 batch 106/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 30/300 batch 107/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 30/300 batch 108/188  Train Loss: 0.071, Acc: 0.973\n",
      "epoch: 30/300 batch 109/188  Train Loss: 0.047, Acc: 0.980\n",
      "epoch: 30/300 batch 110/188  Train Loss: 0.073, Acc: 0.980\n",
      "epoch: 30/300 batch 111/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 30/300 batch 112/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 30/300 batch 113/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 30/300 batch 114/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 30/300 batch 115/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 30/300 batch 116/188  Train Loss: 0.060, Acc: 0.977\n",
      "epoch: 30/300 batch 117/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 30/300 batch 118/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 30/300 batch 119/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 30/300 batch 120/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 30/300 batch 121/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 30/300 batch 122/188  Train Loss: 0.052, Acc: 0.980\n",
      "epoch: 30/300 batch 123/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 30/300 batch 124/188  Train Loss: 0.042, Acc: 0.996\n",
      "epoch: 30/300 batch 125/188  Train Loss: 0.080, Acc: 0.984\n",
      "epoch: 30/300 batch 126/188  Train Loss: 0.068, Acc: 0.977\n",
      "epoch: 30/300 batch 127/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 30/300 batch 128/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 30/300 batch 129/188  Train Loss: 0.062, Acc: 0.980\n",
      "epoch: 30/300 batch 130/188  Train Loss: 0.062, Acc: 0.973\n",
      "epoch: 30/300 batch 131/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 30/300 batch 132/188  Train Loss: 0.065, Acc: 0.973\n",
      "epoch: 30/300 batch 133/188  Train Loss: 0.034, Acc: 0.984\n",
      "epoch: 30/300 batch 134/188  Train Loss: 0.072, Acc: 0.980\n",
      "epoch: 30/300 batch 135/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 30/300 batch 136/188  Train Loss: 0.058, Acc: 0.988\n",
      "epoch: 30/300 batch 137/188  Train Loss: 0.060, Acc: 0.984\n",
      "epoch: 30/300 batch 138/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 30/300 batch 139/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 30/300 batch 140/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 30/300 batch 141/188  Train Loss: 0.071, Acc: 0.980\n",
      "epoch: 30/300 batch 142/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 30/300 batch 143/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 30/300 batch 144/188  Train Loss: 0.061, Acc: 0.984\n",
      "epoch: 30/300 batch 145/188  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 30/300 batch 146/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 30/300 batch 147/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 30/300 batch 148/188  Train Loss: 0.068, Acc: 0.984\n",
      "epoch: 30/300 batch 149/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 30/300 batch 150/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 30/300 batch 151/188  Train Loss: 0.060, Acc: 0.980\n",
      "epoch: 30/300 batch 152/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 30/300 batch 153/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 30/300 batch 154/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 30/300 batch 155/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 30/300 batch 156/188  Train Loss: 0.070, Acc: 0.980\n",
      "epoch: 30/300 batch 157/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 30/300 batch 158/188  Train Loss: 0.086, Acc: 0.965\n",
      "epoch: 30/300 batch 159/188  Train Loss: 0.050, Acc: 0.980\n",
      "epoch: 30/300 batch 160/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 30/300 batch 161/188  Train Loss: 0.044, Acc: 0.980\n",
      "epoch: 30/300 batch 162/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 30/300 batch 163/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 30/300 batch 164/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 30/300 batch 165/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 30/300 batch 166/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 30/300 batch 167/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 30/300 batch 168/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 30/300 batch 169/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 30/300 batch 170/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 30/300 batch 171/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 30/300 batch 172/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 30/300 batch 173/188  Train Loss: 0.056, Acc: 0.980\n",
      "epoch: 30/300 batch 174/188  Train Loss: 0.054, Acc: 0.980\n",
      "epoch: 30/300 batch 175/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 30/300 batch 176/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 30/300 batch 177/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 30/300 batch 178/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 30/300 batch 179/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 30/300 batch 180/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 30/300 batch 181/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 30/300 batch 182/188  Train Loss: 0.054, Acc: 0.992\n",
      "epoch: 30/300 batch 183/188  Train Loss: 0.061, Acc: 0.988\n",
      "epoch: 30/300 batch 184/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 30/300 batch 185/188  Train Loss: 0.066, Acc: 0.973\n",
      "epoch: 30/300 batch 186/188  Train Loss: 0.057, Acc: 0.988\n",
      "epoch: 30/300 batch 187/188  Train Loss: 0.053, Acc: 0.984\n",
      "Train Loss: 0.043942, Acc: 0.988\n",
      "Val Loss: 0.059986, Acc: 0.983\n",
      "epoch: 31/300 batch   0/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 31/300 batch   1/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 31/300 batch   2/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 31/300 batch   3/188  Train Loss: 0.065, Acc: 0.988\n",
      "epoch: 31/300 batch   4/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 31/300 batch   5/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 31/300 batch   6/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 31/300 batch   7/188  Train Loss: 0.054, Acc: 0.992\n",
      "epoch: 31/300 batch   8/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 31/300 batch   9/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 31/300 batch  10/188  Train Loss: 0.051, Acc: 0.980\n",
      "epoch: 31/300 batch  11/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 31/300 batch  12/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 31/300 batch  13/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 31/300 batch  14/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 31/300 batch  15/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 31/300 batch  16/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 31/300 batch  17/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 31/300 batch  18/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 31/300 batch  19/188  Train Loss: 0.068, Acc: 0.988\n",
      "epoch: 31/300 batch  20/188  Train Loss: 0.103, Acc: 0.988\n",
      "epoch: 31/300 batch  21/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 31/300 batch  22/188  Train Loss: 0.040, Acc: 0.980\n",
      "epoch: 31/300 batch  23/188  Train Loss: 0.056, Acc: 0.988\n",
      "epoch: 31/300 batch  24/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 31/300 batch  25/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 31/300 batch  26/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 31/300 batch  27/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 31/300 batch  28/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 31/300 batch  29/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 31/300 batch  30/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 31/300 batch  31/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 31/300 batch  32/188  Train Loss: 0.067, Acc: 0.988\n",
      "epoch: 31/300 batch  33/188  Train Loss: 0.052, Acc: 0.992\n",
      "epoch: 31/300 batch  34/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 31/300 batch  35/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 31/300 batch  36/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 31/300 batch  37/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 31/300 batch  38/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 31/300 batch  39/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 31/300 batch  40/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 31/300 batch  41/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 31/300 batch  42/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 31/300 batch  43/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 31/300 batch  44/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 31/300 batch  45/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 31/300 batch  46/188  Train Loss: 0.076, Acc: 0.977\n",
      "epoch: 31/300 batch  47/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 31/300 batch  48/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 31/300 batch  49/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 31/300 batch  50/188  Train Loss: 0.052, Acc: 0.980\n",
      "epoch: 31/300 batch  51/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 31/300 batch  52/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 31/300 batch  53/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 31/300 batch  54/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 31/300 batch  55/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 31/300 batch  56/188  Train Loss: 0.055, Acc: 0.977\n",
      "epoch: 31/300 batch  57/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 31/300 batch  58/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 31/300 batch  59/188  Train Loss: 0.073, Acc: 0.988\n",
      "epoch: 31/300 batch  60/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 31/300 batch  61/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 31/300 batch  62/188  Train Loss: 0.076, Acc: 0.973\n",
      "epoch: 31/300 batch  63/188  Train Loss: 0.079, Acc: 0.977\n",
      "epoch: 31/300 batch  64/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 31/300 batch  65/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 31/300 batch  66/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 31/300 batch  67/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 31/300 batch  68/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 31/300 batch  69/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 31/300 batch  70/188  Train Loss: 0.028, Acc: 0.984\n",
      "epoch: 31/300 batch  71/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 31/300 batch  72/188  Train Loss: 0.057, Acc: 0.980\n",
      "epoch: 31/300 batch  73/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 31/300 batch  74/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 31/300 batch  75/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 31/300 batch  76/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 31/300 batch  77/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 31/300 batch  78/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 31/300 batch  79/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 31/300 batch  80/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 31/300 batch  81/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 31/300 batch  82/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 31/300 batch  83/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 31/300 batch  84/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 31/300 batch  85/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 31/300 batch  86/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 31/300 batch  87/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 31/300 batch  88/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 31/300 batch  89/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 31/300 batch  90/188  Train Loss: 0.032, Acc: 0.984\n",
      "epoch: 31/300 batch  91/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 31/300 batch  92/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 31/300 batch  93/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 31/300 batch  94/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 31/300 batch  95/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 31/300 batch  96/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 31/300 batch  97/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 31/300 batch  98/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 31/300 batch  99/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 31/300 batch 100/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 31/300 batch 101/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 31/300 batch 102/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 31/300 batch 103/188  Train Loss: 0.031, Acc: 1.000\n",
      "epoch: 31/300 batch 104/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 31/300 batch 105/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 31/300 batch 106/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 31/300 batch 107/188  Train Loss: 0.054, Acc: 0.980\n",
      "epoch: 31/300 batch 108/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 31/300 batch 109/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 31/300 batch 110/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 31/300 batch 111/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 31/300 batch 112/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 31/300 batch 113/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 31/300 batch 114/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 31/300 batch 115/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 31/300 batch 116/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 31/300 batch 117/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 31/300 batch 118/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 31/300 batch 119/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 31/300 batch 120/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 31/300 batch 121/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 31/300 batch 122/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 31/300 batch 123/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 31/300 batch 124/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 31/300 batch 125/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 31/300 batch 126/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 31/300 batch 127/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 31/300 batch 128/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 31/300 batch 129/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 31/300 batch 130/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 31/300 batch 131/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 31/300 batch 132/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 31/300 batch 133/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 31/300 batch 134/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 31/300 batch 135/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 31/300 batch 136/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 31/300 batch 137/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 31/300 batch 138/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 31/300 batch 139/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 31/300 batch 140/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 31/300 batch 141/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 31/300 batch 142/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 31/300 batch 143/188  Train Loss: 0.071, Acc: 0.980\n",
      "epoch: 31/300 batch 144/188  Train Loss: 0.061, Acc: 0.977\n",
      "epoch: 31/300 batch 145/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 31/300 batch 146/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 31/300 batch 147/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 31/300 batch 148/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 31/300 batch 149/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 31/300 batch 150/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 31/300 batch 151/188  Train Loss: 0.047, Acc: 0.996\n",
      "epoch: 31/300 batch 152/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 31/300 batch 153/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 31/300 batch 154/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 31/300 batch 155/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 31/300 batch 156/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 31/300 batch 157/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 31/300 batch 158/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 31/300 batch 159/188  Train Loss: 0.092, Acc: 0.973\n",
      "epoch: 31/300 batch 160/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 31/300 batch 161/188  Train Loss: 0.059, Acc: 0.980\n",
      "epoch: 31/300 batch 162/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 31/300 batch 163/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 31/300 batch 164/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 31/300 batch 165/188  Train Loss: 0.046, Acc: 0.980\n",
      "epoch: 31/300 batch 166/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 31/300 batch 167/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 31/300 batch 168/188  Train Loss: 0.050, Acc: 0.996\n",
      "epoch: 31/300 batch 169/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 31/300 batch 170/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 31/300 batch 171/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 31/300 batch 172/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 31/300 batch 173/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 31/300 batch 174/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 31/300 batch 175/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 31/300 batch 176/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 31/300 batch 177/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 31/300 batch 178/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 31/300 batch 179/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 31/300 batch 180/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 31/300 batch 181/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 31/300 batch 182/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 31/300 batch 183/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 31/300 batch 184/188  Train Loss: 0.049, Acc: 0.980\n",
      "epoch: 31/300 batch 185/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 31/300 batch 186/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 31/300 batch 187/188  Train Loss: 0.039, Acc: 0.984\n",
      "Train Loss: 0.038468, Acc: 0.991\n",
      "Val Loss: 0.057781, Acc: 0.983\n",
      "epoch: 32/300 batch   0/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 32/300 batch   1/188  Train Loss: 0.052, Acc: 0.992\n",
      "epoch: 32/300 batch   2/188  Train Loss: 0.079, Acc: 0.973\n",
      "epoch: 32/300 batch   3/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 32/300 batch   4/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 32/300 batch   5/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 32/300 batch   6/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 32/300 batch   7/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 32/300 batch   8/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 32/300 batch   9/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 32/300 batch  10/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 32/300 batch  11/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 32/300 batch  12/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 32/300 batch  13/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 32/300 batch  14/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 32/300 batch  15/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 32/300 batch  16/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 32/300 batch  17/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 32/300 batch  18/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 32/300 batch  19/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 32/300 batch  20/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 32/300 batch  21/188  Train Loss: 0.069, Acc: 0.977\n",
      "epoch: 32/300 batch  22/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 32/300 batch  23/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 32/300 batch  24/188  Train Loss: 0.060, Acc: 0.984\n",
      "epoch: 32/300 batch  25/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 32/300 batch  26/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 32/300 batch  27/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 32/300 batch  28/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 32/300 batch  29/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 32/300 batch  30/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 32/300 batch  31/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 32/300 batch  32/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 32/300 batch  33/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 32/300 batch  34/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 32/300 batch  35/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 32/300 batch  36/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 32/300 batch  37/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 32/300 batch  38/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 32/300 batch  39/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 32/300 batch  40/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 32/300 batch  41/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 32/300 batch  42/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 32/300 batch  43/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 32/300 batch  44/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 32/300 batch  45/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 32/300 batch  46/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 32/300 batch  47/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 32/300 batch  48/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 32/300 batch  49/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 32/300 batch  50/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 32/300 batch  51/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 32/300 batch  52/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 32/300 batch  53/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 32/300 batch  54/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 32/300 batch  55/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 32/300 batch  56/188  Train Loss: 0.035, Acc: 1.000\n",
      "epoch: 32/300 batch  57/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 32/300 batch  58/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 32/300 batch  59/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 32/300 batch  60/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 32/300 batch  61/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 32/300 batch  62/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 32/300 batch  63/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 32/300 batch  64/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 32/300 batch  65/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 32/300 batch  66/188  Train Loss: 0.068, Acc: 0.977\n",
      "epoch: 32/300 batch  67/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 32/300 batch  68/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 32/300 batch  69/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 32/300 batch  70/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 32/300 batch  71/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 32/300 batch  72/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 32/300 batch  73/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 32/300 batch  74/188  Train Loss: 0.062, Acc: 0.984\n",
      "epoch: 32/300 batch  75/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 32/300 batch  76/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 32/300 batch  77/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 32/300 batch  78/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 32/300 batch  79/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 32/300 batch  80/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 32/300 batch  81/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 32/300 batch  82/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 32/300 batch  83/188  Train Loss: 0.071, Acc: 0.977\n",
      "epoch: 32/300 batch  84/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 32/300 batch  85/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 32/300 batch  86/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 32/300 batch  87/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 32/300 batch  88/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 32/300 batch  89/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 32/300 batch  90/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 32/300 batch  91/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 32/300 batch  92/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 32/300 batch  93/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 32/300 batch  94/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 32/300 batch  95/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 32/300 batch  96/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 32/300 batch  97/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 32/300 batch  98/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 32/300 batch  99/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 32/300 batch 100/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 32/300 batch 101/188  Train Loss: 0.060, Acc: 0.984\n",
      "epoch: 32/300 batch 102/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 32/300 batch 103/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 32/300 batch 104/188  Train Loss: 0.057, Acc: 0.980\n",
      "epoch: 32/300 batch 105/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 32/300 batch 106/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 32/300 batch 107/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 32/300 batch 108/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 32/300 batch 109/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 32/300 batch 110/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 32/300 batch 111/188  Train Loss: 0.059, Acc: 0.988\n",
      "epoch: 32/300 batch 112/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 32/300 batch 113/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 32/300 batch 114/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 32/300 batch 115/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 32/300 batch 116/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 32/300 batch 117/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 32/300 batch 118/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 32/300 batch 119/188  Train Loss: 0.054, Acc: 0.977\n",
      "epoch: 32/300 batch 120/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 32/300 batch 121/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 32/300 batch 122/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 32/300 batch 123/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 32/300 batch 124/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 32/300 batch 125/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 32/300 batch 126/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 32/300 batch 127/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 32/300 batch 128/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 32/300 batch 129/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 32/300 batch 130/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 32/300 batch 131/188  Train Loss: 0.067, Acc: 0.984\n",
      "epoch: 32/300 batch 132/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 32/300 batch 133/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 32/300 batch 134/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 32/300 batch 135/188  Train Loss: 0.071, Acc: 0.984\n",
      "epoch: 32/300 batch 136/188  Train Loss: 0.078, Acc: 0.980\n",
      "epoch: 32/300 batch 137/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 32/300 batch 138/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 32/300 batch 139/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 32/300 batch 140/188  Train Loss: 0.071, Acc: 0.988\n",
      "epoch: 32/300 batch 141/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 32/300 batch 142/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 32/300 batch 143/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 32/300 batch 144/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 32/300 batch 145/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 32/300 batch 146/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 32/300 batch 147/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 32/300 batch 148/188  Train Loss: 0.059, Acc: 0.980\n",
      "epoch: 32/300 batch 149/188  Train Loss: 0.056, Acc: 0.988\n",
      "epoch: 32/300 batch 150/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 32/300 batch 151/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 32/300 batch 152/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 32/300 batch 153/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 32/300 batch 154/188  Train Loss: 0.074, Acc: 0.984\n",
      "epoch: 32/300 batch 155/188  Train Loss: 0.043, Acc: 0.980\n",
      "epoch: 32/300 batch 156/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 32/300 batch 157/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 32/300 batch 158/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 32/300 batch 159/188  Train Loss: 0.072, Acc: 0.988\n",
      "epoch: 32/300 batch 160/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 32/300 batch 161/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 32/300 batch 162/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 32/300 batch 163/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 32/300 batch 164/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 32/300 batch 165/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 32/300 batch 166/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 32/300 batch 167/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 32/300 batch 168/188  Train Loss: 0.064, Acc: 0.984\n",
      "epoch: 32/300 batch 169/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 32/300 batch 170/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 32/300 batch 171/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 32/300 batch 172/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 32/300 batch 173/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 32/300 batch 174/188  Train Loss: 0.053, Acc: 0.992\n",
      "epoch: 32/300 batch 175/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 32/300 batch 176/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 32/300 batch 177/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 32/300 batch 178/188  Train Loss: 0.047, Acc: 0.980\n",
      "epoch: 32/300 batch 179/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 32/300 batch 180/188  Train Loss: 0.056, Acc: 0.992\n",
      "epoch: 32/300 batch 181/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 32/300 batch 182/188  Train Loss: 0.047, Acc: 0.980\n",
      "epoch: 32/300 batch 183/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 32/300 batch 184/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 32/300 batch 185/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 32/300 batch 186/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 32/300 batch 187/188  Train Loss: 0.025, Acc: 1.000\n",
      "Train Loss: 0.037703, Acc: 0.992\n",
      "Val Loss: 0.057644, Acc: 0.983\n",
      "epoch: 33/300 batch   0/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 33/300 batch   1/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 33/300 batch   2/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 33/300 batch   3/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 33/300 batch   4/188  Train Loss: 0.054, Acc: 0.980\n",
      "epoch: 33/300 batch   5/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 33/300 batch   6/188  Train Loss: 0.045, Acc: 0.996\n",
      "epoch: 33/300 batch   7/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 33/300 batch   8/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 33/300 batch   9/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 33/300 batch  10/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 33/300 batch  11/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 33/300 batch  12/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 33/300 batch  13/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 33/300 batch  14/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 33/300 batch  15/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 33/300 batch  16/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 33/300 batch  17/188  Train Loss: 0.047, Acc: 0.980\n",
      "epoch: 33/300 batch  18/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 33/300 batch  19/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 33/300 batch  20/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 33/300 batch  21/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 33/300 batch  22/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 33/300 batch  23/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 33/300 batch  24/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 33/300 batch  25/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 33/300 batch  26/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 33/300 batch  27/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 33/300 batch  28/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 33/300 batch  29/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 33/300 batch  30/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 33/300 batch  31/188  Train Loss: 0.069, Acc: 0.988\n",
      "epoch: 33/300 batch  32/188  Train Loss: 0.068, Acc: 0.996\n",
      "epoch: 33/300 batch  33/188  Train Loss: 0.064, Acc: 0.988\n",
      "epoch: 33/300 batch  34/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 33/300 batch  35/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 33/300 batch  36/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 33/300 batch  37/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 33/300 batch  38/188  Train Loss: 0.036, Acc: 1.000\n",
      "epoch: 33/300 batch  39/188  Train Loss: 0.060, Acc: 0.980\n",
      "epoch: 33/300 batch  40/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 33/300 batch  41/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 33/300 batch  42/188  Train Loss: 0.049, Acc: 0.980\n",
      "epoch: 33/300 batch  43/188  Train Loss: 0.057, Acc: 0.980\n",
      "epoch: 33/300 batch  44/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 33/300 batch  45/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 33/300 batch  46/188  Train Loss: 0.059, Acc: 0.973\n",
      "epoch: 33/300 batch  47/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 33/300 batch  48/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 33/300 batch  49/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 33/300 batch  50/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 33/300 batch  51/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 33/300 batch  52/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 33/300 batch  53/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 33/300 batch  54/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 33/300 batch  55/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 33/300 batch  56/188  Train Loss: 0.052, Acc: 0.977\n",
      "epoch: 33/300 batch  57/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 33/300 batch  58/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 33/300 batch  59/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 33/300 batch  60/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 33/300 batch  61/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 33/300 batch  62/188  Train Loss: 0.059, Acc: 0.980\n",
      "epoch: 33/300 batch  63/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 33/300 batch  64/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 33/300 batch  65/188  Train Loss: 0.056, Acc: 0.988\n",
      "epoch: 33/300 batch  66/188  Train Loss: 0.050, Acc: 0.980\n",
      "epoch: 33/300 batch  67/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 33/300 batch  68/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 33/300 batch  69/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 33/300 batch  70/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 33/300 batch  71/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 33/300 batch  72/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 33/300 batch  73/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 33/300 batch  74/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 33/300 batch  75/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 33/300 batch  76/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 33/300 batch  77/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 33/300 batch  78/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 33/300 batch  79/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 33/300 batch  80/188  Train Loss: 0.051, Acc: 0.980\n",
      "epoch: 33/300 batch  81/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 33/300 batch  82/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 33/300 batch  83/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 33/300 batch  84/188  Train Loss: 0.076, Acc: 0.980\n",
      "epoch: 33/300 batch  85/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 33/300 batch  86/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 33/300 batch  87/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 33/300 batch  88/188  Train Loss: 0.060, Acc: 0.980\n",
      "epoch: 33/300 batch  89/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 33/300 batch  90/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 33/300 batch  91/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 33/300 batch  92/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 33/300 batch  93/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 33/300 batch  94/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 33/300 batch  95/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 33/300 batch  96/188  Train Loss: 0.056, Acc: 0.980\n",
      "epoch: 33/300 batch  97/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 33/300 batch  98/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 33/300 batch  99/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 33/300 batch 100/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 33/300 batch 101/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 33/300 batch 102/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 33/300 batch 103/188  Train Loss: 0.047, Acc: 0.996\n",
      "epoch: 33/300 batch 104/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 33/300 batch 105/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 33/300 batch 106/188  Train Loss: 0.089, Acc: 0.980\n",
      "epoch: 33/300 batch 107/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 33/300 batch 108/188  Train Loss: 0.063, Acc: 0.980\n",
      "epoch: 33/300 batch 109/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 33/300 batch 110/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 33/300 batch 111/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 33/300 batch 112/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 33/300 batch 113/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 33/300 batch 114/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 33/300 batch 115/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 33/300 batch 116/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 33/300 batch 117/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 33/300 batch 118/188  Train Loss: 0.045, Acc: 0.980\n",
      "epoch: 33/300 batch 119/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 33/300 batch 120/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 33/300 batch 121/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 33/300 batch 122/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 33/300 batch 123/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 33/300 batch 124/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 33/300 batch 125/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 33/300 batch 126/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 33/300 batch 127/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 33/300 batch 128/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 33/300 batch 129/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 33/300 batch 130/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 33/300 batch 131/188  Train Loss: 0.045, Acc: 0.996\n",
      "epoch: 33/300 batch 132/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 33/300 batch 133/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 33/300 batch 134/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 33/300 batch 135/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 33/300 batch 136/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 33/300 batch 137/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 33/300 batch 138/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 33/300 batch 139/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 33/300 batch 140/188  Train Loss: 0.052, Acc: 0.996\n",
      "epoch: 33/300 batch 141/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 33/300 batch 142/188  Train Loss: 0.050, Acc: 0.977\n",
      "epoch: 33/300 batch 143/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 33/300 batch 144/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 33/300 batch 145/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 33/300 batch 146/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 33/300 batch 147/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 33/300 batch 148/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 33/300 batch 149/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 33/300 batch 150/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 33/300 batch 151/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 33/300 batch 152/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 33/300 batch 153/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 33/300 batch 154/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 33/300 batch 155/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 33/300 batch 156/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 33/300 batch 157/188  Train Loss: 0.066, Acc: 0.984\n",
      "epoch: 33/300 batch 158/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 33/300 batch 159/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 33/300 batch 160/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 33/300 batch 161/188  Train Loss: 0.080, Acc: 0.977\n",
      "epoch: 33/300 batch 162/188  Train Loss: 0.059, Acc: 0.988\n",
      "epoch: 33/300 batch 163/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 33/300 batch 164/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 33/300 batch 165/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 33/300 batch 166/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 33/300 batch 167/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 33/300 batch 168/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 33/300 batch 169/188  Train Loss: 0.074, Acc: 0.969\n",
      "epoch: 33/300 batch 170/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 33/300 batch 171/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 33/300 batch 172/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 33/300 batch 173/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 33/300 batch 174/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 33/300 batch 175/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 33/300 batch 176/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 33/300 batch 177/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 33/300 batch 178/188  Train Loss: 0.042, Acc: 0.980\n",
      "epoch: 33/300 batch 179/188  Train Loss: 0.068, Acc: 0.980\n",
      "epoch: 33/300 batch 180/188  Train Loss: 0.033, Acc: 1.000\n",
      "epoch: 33/300 batch 181/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 33/300 batch 182/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 33/300 batch 183/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 33/300 batch 184/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 33/300 batch 185/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 33/300 batch 186/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 33/300 batch 187/188  Train Loss: 0.067, Acc: 0.984\n",
      "Train Loss: 0.037672, Acc: 0.991\n",
      "Val Loss: 0.057804, Acc: 0.983\n",
      "epoch: 34/300 batch   0/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 34/300 batch   1/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 34/300 batch   2/188  Train Loss: 0.063, Acc: 0.988\n",
      "epoch: 34/300 batch   3/188  Train Loss: 0.059, Acc: 0.992\n",
      "epoch: 34/300 batch   4/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 34/300 batch   5/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 34/300 batch   6/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 34/300 batch   7/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 34/300 batch   8/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 34/300 batch   9/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 34/300 batch  10/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 34/300 batch  11/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 34/300 batch  12/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 34/300 batch  13/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 34/300 batch  14/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 34/300 batch  15/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 34/300 batch  16/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 34/300 batch  17/188  Train Loss: 0.035, Acc: 1.000\n",
      "epoch: 34/300 batch  18/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 34/300 batch  19/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 34/300 batch  20/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 34/300 batch  21/188  Train Loss: 0.064, Acc: 0.992\n",
      "epoch: 34/300 batch  22/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 34/300 batch  23/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 34/300 batch  24/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 34/300 batch  25/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 34/300 batch  26/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 34/300 batch  27/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 34/300 batch  28/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 34/300 batch  29/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 34/300 batch  30/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 34/300 batch  31/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 34/300 batch  32/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 34/300 batch  33/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 34/300 batch  34/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 34/300 batch  35/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 34/300 batch  36/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 34/300 batch  37/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 34/300 batch  38/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 34/300 batch  39/188  Train Loss: 0.080, Acc: 0.980\n",
      "epoch: 34/300 batch  40/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 34/300 batch  41/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 34/300 batch  42/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 34/300 batch  43/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 34/300 batch  44/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 34/300 batch  45/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 34/300 batch  46/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 34/300 batch  47/188  Train Loss: 0.060, Acc: 0.977\n",
      "epoch: 34/300 batch  48/188  Train Loss: 0.042, Acc: 0.980\n",
      "epoch: 34/300 batch  49/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 34/300 batch  50/188  Train Loss: 0.065, Acc: 0.980\n",
      "epoch: 34/300 batch  51/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 34/300 batch  52/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 34/300 batch  53/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 34/300 batch  54/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 34/300 batch  55/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 34/300 batch  56/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 34/300 batch  57/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 34/300 batch  58/188  Train Loss: 0.013, Acc: 0.996\n",
      "epoch: 34/300 batch  59/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 34/300 batch  60/188  Train Loss: 0.099, Acc: 0.973\n",
      "epoch: 34/300 batch  61/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 34/300 batch  62/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 34/300 batch  63/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 34/300 batch  64/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 34/300 batch  65/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 34/300 batch  66/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 34/300 batch  67/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 34/300 batch  68/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 34/300 batch  69/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 34/300 batch  70/188  Train Loss: 0.057, Acc: 0.992\n",
      "epoch: 34/300 batch  71/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 34/300 batch  72/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 34/300 batch  73/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 34/300 batch  74/188  Train Loss: 0.069, Acc: 0.980\n",
      "epoch: 34/300 batch  75/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 34/300 batch  76/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 34/300 batch  77/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 34/300 batch  78/188  Train Loss: 0.060, Acc: 0.980\n",
      "epoch: 34/300 batch  79/188  Train Loss: 0.049, Acc: 0.980\n",
      "epoch: 34/300 batch  80/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 34/300 batch  81/188  Train Loss: 0.025, Acc: 0.988\n",
      "epoch: 34/300 batch  82/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 34/300 batch  83/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 34/300 batch  84/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 34/300 batch  85/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 34/300 batch  86/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 34/300 batch  87/188  Train Loss: 0.085, Acc: 0.977\n",
      "epoch: 34/300 batch  88/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 34/300 batch  89/188  Train Loss: 0.034, Acc: 0.984\n",
      "epoch: 34/300 batch  90/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 34/300 batch  91/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 34/300 batch  92/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 34/300 batch  93/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 34/300 batch  94/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 34/300 batch  95/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 34/300 batch  96/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 34/300 batch  97/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 34/300 batch  98/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 34/300 batch  99/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 34/300 batch 100/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 34/300 batch 101/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 34/300 batch 102/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 34/300 batch 103/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 34/300 batch 104/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 34/300 batch 105/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 34/300 batch 106/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 34/300 batch 107/188  Train Loss: 0.085, Acc: 0.984\n",
      "epoch: 34/300 batch 108/188  Train Loss: 0.051, Acc: 0.980\n",
      "epoch: 34/300 batch 109/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 34/300 batch 110/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 34/300 batch 111/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 34/300 batch 112/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 34/300 batch 113/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 34/300 batch 114/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 34/300 batch 115/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 34/300 batch 116/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 34/300 batch 117/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 34/300 batch 118/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 34/300 batch 119/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 34/300 batch 120/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 34/300 batch 121/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 34/300 batch 122/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 34/300 batch 123/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 34/300 batch 124/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 34/300 batch 125/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 34/300 batch 126/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 34/300 batch 127/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 34/300 batch 128/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 34/300 batch 129/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 34/300 batch 130/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 34/300 batch 131/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 34/300 batch 132/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 34/300 batch 133/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 34/300 batch 134/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 34/300 batch 135/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 34/300 batch 136/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 34/300 batch 137/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 34/300 batch 138/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 34/300 batch 139/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 34/300 batch 140/188  Train Loss: 0.073, Acc: 0.984\n",
      "epoch: 34/300 batch 141/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 34/300 batch 142/188  Train Loss: 0.061, Acc: 0.988\n",
      "epoch: 34/300 batch 143/188  Train Loss: 0.054, Acc: 0.980\n",
      "epoch: 34/300 batch 144/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 34/300 batch 145/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 34/300 batch 146/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 34/300 batch 147/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 34/300 batch 148/188  Train Loss: 0.059, Acc: 0.980\n",
      "epoch: 34/300 batch 149/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 34/300 batch 150/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 34/300 batch 151/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 34/300 batch 152/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 34/300 batch 153/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 34/300 batch 154/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 34/300 batch 155/188  Train Loss: 0.051, Acc: 0.980\n",
      "epoch: 34/300 batch 156/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 34/300 batch 157/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 34/300 batch 158/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 34/300 batch 159/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 34/300 batch 160/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 34/300 batch 161/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 34/300 batch 162/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 34/300 batch 163/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 34/300 batch 164/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 34/300 batch 165/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 34/300 batch 166/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 34/300 batch 167/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 34/300 batch 168/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 34/300 batch 169/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 34/300 batch 170/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 34/300 batch 171/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 34/300 batch 172/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 34/300 batch 173/188  Train Loss: 0.047, Acc: 0.980\n",
      "epoch: 34/300 batch 174/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 34/300 batch 175/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 34/300 batch 176/188  Train Loss: 0.042, Acc: 0.996\n",
      "epoch: 34/300 batch 177/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 34/300 batch 178/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 34/300 batch 179/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 34/300 batch 180/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 34/300 batch 181/188  Train Loss: 0.042, Acc: 0.980\n",
      "epoch: 34/300 batch 182/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 34/300 batch 183/188  Train Loss: 0.064, Acc: 0.984\n",
      "epoch: 34/300 batch 184/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 34/300 batch 185/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 34/300 batch 186/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 34/300 batch 187/188  Train Loss: 0.038, Acc: 0.992\n",
      "Train Loss: 0.037550, Acc: 0.991\n",
      "Val Loss: 0.057678, Acc: 0.983\n",
      "epoch: 35/300 batch   0/188  Train Loss: 0.058, Acc: 0.980\n",
      "epoch: 35/300 batch   1/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 35/300 batch   2/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 35/300 batch   3/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 35/300 batch   4/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 35/300 batch   5/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 35/300 batch   6/188  Train Loss: 0.058, Acc: 0.973\n",
      "epoch: 35/300 batch   7/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 35/300 batch   8/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 35/300 batch   9/188  Train Loss: 0.065, Acc: 0.980\n",
      "epoch: 35/300 batch  10/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 35/300 batch  11/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 35/300 batch  12/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 35/300 batch  13/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 35/300 batch  14/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 35/300 batch  15/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 35/300 batch  16/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 35/300 batch  17/188  Train Loss: 0.042, Acc: 0.996\n",
      "epoch: 35/300 batch  18/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 35/300 batch  19/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 35/300 batch  20/188  Train Loss: 0.082, Acc: 0.973\n",
      "epoch: 35/300 batch  21/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 35/300 batch  22/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 35/300 batch  23/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 35/300 batch  24/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 35/300 batch  25/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 35/300 batch  26/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 35/300 batch  27/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 35/300 batch  28/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 35/300 batch  29/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 35/300 batch  30/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 35/300 batch  31/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 35/300 batch  32/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 35/300 batch  33/188  Train Loss: 0.068, Acc: 0.980\n",
      "epoch: 35/300 batch  34/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 35/300 batch  35/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 35/300 batch  36/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 35/300 batch  37/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 35/300 batch  38/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 35/300 batch  39/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 35/300 batch  40/188  Train Loss: 0.054, Acc: 0.992\n",
      "epoch: 35/300 batch  41/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 35/300 batch  42/188  Train Loss: 0.046, Acc: 0.996\n",
      "epoch: 35/300 batch  43/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 35/300 batch  44/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 35/300 batch  45/188  Train Loss: 0.052, Acc: 0.992\n",
      "epoch: 35/300 batch  46/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 35/300 batch  47/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 35/300 batch  48/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 35/300 batch  49/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 35/300 batch  50/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 35/300 batch  51/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 35/300 batch  52/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 35/300 batch  53/188  Train Loss: 0.054, Acc: 0.992\n",
      "epoch: 35/300 batch  54/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 35/300 batch  55/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 35/300 batch  56/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 35/300 batch  57/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 35/300 batch  58/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 35/300 batch  59/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 35/300 batch  60/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 35/300 batch  61/188  Train Loss: 0.068, Acc: 0.984\n",
      "epoch: 35/300 batch  62/188  Train Loss: 0.033, Acc: 1.000\n",
      "epoch: 35/300 batch  63/188  Train Loss: 0.041, Acc: 0.980\n",
      "epoch: 35/300 batch  64/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 35/300 batch  65/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 35/300 batch  66/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 35/300 batch  67/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 35/300 batch  68/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 35/300 batch  69/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 35/300 batch  70/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 35/300 batch  71/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 35/300 batch  72/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 35/300 batch  73/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 35/300 batch  74/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 35/300 batch  75/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 35/300 batch  76/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 35/300 batch  77/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 35/300 batch  78/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 35/300 batch  79/188  Train Loss: 0.062, Acc: 0.980\n",
      "epoch: 35/300 batch  80/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 35/300 batch  81/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 35/300 batch  82/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 35/300 batch  83/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 35/300 batch  84/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 35/300 batch  85/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 35/300 batch  86/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 35/300 batch  87/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 35/300 batch  88/188  Train Loss: 0.061, Acc: 0.980\n",
      "epoch: 35/300 batch  89/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 35/300 batch  90/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 35/300 batch  91/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 35/300 batch  92/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 35/300 batch  93/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 35/300 batch  94/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 35/300 batch  95/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 35/300 batch  96/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 35/300 batch  97/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 35/300 batch  98/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 35/300 batch  99/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 35/300 batch 100/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 35/300 batch 101/188  Train Loss: 0.074, Acc: 0.973\n",
      "epoch: 35/300 batch 102/188  Train Loss: 0.049, Acc: 0.980\n",
      "epoch: 35/300 batch 103/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 35/300 batch 104/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 35/300 batch 105/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 35/300 batch 106/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 35/300 batch 107/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 35/300 batch 108/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 35/300 batch 109/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 35/300 batch 110/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 35/300 batch 111/188  Train Loss: 0.059, Acc: 0.992\n",
      "epoch: 35/300 batch 112/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 35/300 batch 113/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 35/300 batch 114/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 35/300 batch 115/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 35/300 batch 116/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 35/300 batch 117/188  Train Loss: 0.063, Acc: 0.984\n",
      "epoch: 35/300 batch 118/188  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 35/300 batch 119/188  Train Loss: 0.053, Acc: 0.977\n",
      "epoch: 35/300 batch 120/188  Train Loss: 0.063, Acc: 0.988\n",
      "epoch: 35/300 batch 121/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 35/300 batch 122/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 35/300 batch 123/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 35/300 batch 124/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 35/300 batch 125/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 35/300 batch 126/188  Train Loss: 0.044, Acc: 0.980\n",
      "epoch: 35/300 batch 127/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 35/300 batch 128/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 35/300 batch 129/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 35/300 batch 130/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 35/300 batch 131/188  Train Loss: 0.031, Acc: 1.000\n",
      "epoch: 35/300 batch 132/188  Train Loss: 0.067, Acc: 0.984\n",
      "epoch: 35/300 batch 133/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 35/300 batch 134/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 35/300 batch 135/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 35/300 batch 136/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 35/300 batch 137/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 35/300 batch 138/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 35/300 batch 139/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 35/300 batch 140/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 35/300 batch 141/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 35/300 batch 142/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 35/300 batch 143/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 35/300 batch 144/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 35/300 batch 145/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 35/300 batch 146/188  Train Loss: 0.047, Acc: 0.980\n",
      "epoch: 35/300 batch 147/188  Train Loss: 0.056, Acc: 0.988\n",
      "epoch: 35/300 batch 148/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 35/300 batch 149/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 35/300 batch 150/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 35/300 batch 151/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 35/300 batch 152/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 35/300 batch 153/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 35/300 batch 154/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 35/300 batch 155/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 35/300 batch 156/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 35/300 batch 157/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 35/300 batch 158/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 35/300 batch 159/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 35/300 batch 160/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 35/300 batch 161/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 35/300 batch 162/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 35/300 batch 163/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 35/300 batch 164/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 35/300 batch 165/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 35/300 batch 166/188  Train Loss: 0.063, Acc: 0.992\n",
      "epoch: 35/300 batch 167/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 35/300 batch 168/188  Train Loss: 0.062, Acc: 0.980\n",
      "epoch: 35/300 batch 169/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 35/300 batch 170/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 35/300 batch 171/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 35/300 batch 172/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 35/300 batch 173/188  Train Loss: 0.077, Acc: 0.977\n",
      "epoch: 35/300 batch 174/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 35/300 batch 175/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 35/300 batch 176/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 35/300 batch 177/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 35/300 batch 178/188  Train Loss: 0.060, Acc: 0.984\n",
      "epoch: 35/300 batch 179/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 35/300 batch 180/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 35/300 batch 181/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 35/300 batch 182/188  Train Loss: 0.069, Acc: 0.992\n",
      "epoch: 35/300 batch 183/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 35/300 batch 184/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 35/300 batch 185/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 35/300 batch 186/188  Train Loss: 0.068, Acc: 0.984\n",
      "epoch: 35/300 batch 187/188  Train Loss: 0.024, Acc: 1.000\n",
      "Train Loss: 0.037502, Acc: 0.992\n",
      "Val Loss: 0.057973, Acc: 0.982\n",
      "epoch: 36/300 batch   0/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 36/300 batch   1/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 36/300 batch   2/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 36/300 batch   3/188  Train Loss: 0.059, Acc: 0.984\n",
      "epoch: 36/300 batch   4/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 36/300 batch   5/188  Train Loss: 0.052, Acc: 0.977\n",
      "epoch: 36/300 batch   6/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 36/300 batch   7/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 36/300 batch   8/188  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 36/300 batch   9/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 36/300 batch  10/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 36/300 batch  11/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 36/300 batch  12/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 36/300 batch  13/188  Train Loss: 0.033, Acc: 1.000\n",
      "epoch: 36/300 batch  14/188  Train Loss: 0.057, Acc: 0.992\n",
      "epoch: 36/300 batch  15/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 36/300 batch  16/188  Train Loss: 0.042, Acc: 0.996\n",
      "epoch: 36/300 batch  17/188  Train Loss: 0.035, Acc: 1.000\n",
      "epoch: 36/300 batch  18/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 36/300 batch  19/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 36/300 batch  20/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 36/300 batch  21/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 36/300 batch  22/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 36/300 batch  23/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 36/300 batch  24/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 36/300 batch  25/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 36/300 batch  26/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 36/300 batch  27/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 36/300 batch  28/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 36/300 batch  29/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 36/300 batch  30/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 36/300 batch  31/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 36/300 batch  32/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 36/300 batch  33/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 36/300 batch  34/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 36/300 batch  35/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 36/300 batch  36/188  Train Loss: 0.031, Acc: 1.000\n",
      "epoch: 36/300 batch  37/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 36/300 batch  38/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 36/300 batch  39/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 36/300 batch  40/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 36/300 batch  41/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 36/300 batch  42/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 36/300 batch  43/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 36/300 batch  44/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 36/300 batch  45/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 36/300 batch  46/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 36/300 batch  47/188  Train Loss: 0.032, Acc: 1.000\n",
      "epoch: 36/300 batch  48/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 36/300 batch  49/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 36/300 batch  50/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 36/300 batch  51/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 36/300 batch  52/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 36/300 batch  53/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 36/300 batch  54/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 36/300 batch  55/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 36/300 batch  56/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 36/300 batch  57/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 36/300 batch  58/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 36/300 batch  59/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 36/300 batch  60/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 36/300 batch  61/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 36/300 batch  62/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 36/300 batch  63/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 36/300 batch  64/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 36/300 batch  65/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 36/300 batch  66/188  Train Loss: 0.047, Acc: 0.996\n",
      "epoch: 36/300 batch  67/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 36/300 batch  68/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 36/300 batch  69/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 36/300 batch  70/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 36/300 batch  71/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 36/300 batch  72/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 36/300 batch  73/188  Train Loss: 0.064, Acc: 0.977\n",
      "epoch: 36/300 batch  74/188  Train Loss: 0.071, Acc: 0.992\n",
      "epoch: 36/300 batch  75/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 36/300 batch  76/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 36/300 batch  77/188  Train Loss: 0.063, Acc: 0.992\n",
      "epoch: 36/300 batch  78/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 36/300 batch  79/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 36/300 batch  80/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 36/300 batch  81/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 36/300 batch  82/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 36/300 batch  83/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 36/300 batch  84/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 36/300 batch  85/188  Train Loss: 0.070, Acc: 0.973\n",
      "epoch: 36/300 batch  86/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 36/300 batch  87/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 36/300 batch  88/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 36/300 batch  89/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 36/300 batch  90/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 36/300 batch  91/188  Train Loss: 0.061, Acc: 0.988\n",
      "epoch: 36/300 batch  92/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 36/300 batch  93/188  Train Loss: 0.049, Acc: 0.996\n",
      "epoch: 36/300 batch  94/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 36/300 batch  95/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 36/300 batch  96/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 36/300 batch  97/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 36/300 batch  98/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 36/300 batch  99/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 36/300 batch 100/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 36/300 batch 101/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 36/300 batch 102/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 36/300 batch 103/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 36/300 batch 104/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 36/300 batch 105/188  Train Loss: 0.043, Acc: 0.980\n",
      "epoch: 36/300 batch 106/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 36/300 batch 107/188  Train Loss: 0.092, Acc: 0.977\n",
      "epoch: 36/300 batch 108/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 36/300 batch 109/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 36/300 batch 110/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 36/300 batch 111/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 36/300 batch 112/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 36/300 batch 113/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 36/300 batch 114/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 36/300 batch 115/188  Train Loss: 0.068, Acc: 0.980\n",
      "epoch: 36/300 batch 116/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 36/300 batch 117/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 36/300 batch 118/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 36/300 batch 119/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 36/300 batch 120/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 36/300 batch 121/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 36/300 batch 122/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 36/300 batch 123/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 36/300 batch 124/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 36/300 batch 125/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 36/300 batch 126/188  Train Loss: 0.051, Acc: 0.980\n",
      "epoch: 36/300 batch 127/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 36/300 batch 128/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 36/300 batch 129/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 36/300 batch 130/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 36/300 batch 131/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 36/300 batch 132/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 36/300 batch 133/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 36/300 batch 134/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 36/300 batch 135/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 36/300 batch 136/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 36/300 batch 137/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 36/300 batch 138/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 36/300 batch 139/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 36/300 batch 140/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 36/300 batch 141/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 36/300 batch 142/188  Train Loss: 0.050, Acc: 0.980\n",
      "epoch: 36/300 batch 143/188  Train Loss: 0.027, Acc: 0.988\n",
      "epoch: 36/300 batch 144/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 36/300 batch 145/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 36/300 batch 146/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 36/300 batch 147/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 36/300 batch 148/188  Train Loss: 0.060, Acc: 0.988\n",
      "epoch: 36/300 batch 149/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 36/300 batch 150/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 36/300 batch 151/188  Train Loss: 0.059, Acc: 0.984\n",
      "epoch: 36/300 batch 152/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 36/300 batch 153/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 36/300 batch 154/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 36/300 batch 155/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 36/300 batch 156/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 36/300 batch 157/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 36/300 batch 158/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 36/300 batch 159/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 36/300 batch 160/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 36/300 batch 161/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 36/300 batch 162/188  Train Loss: 0.065, Acc: 0.980\n",
      "epoch: 36/300 batch 163/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 36/300 batch 164/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 36/300 batch 165/188  Train Loss: 0.055, Acc: 0.992\n",
      "epoch: 36/300 batch 166/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 36/300 batch 167/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 36/300 batch 168/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 36/300 batch 169/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 36/300 batch 170/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 36/300 batch 171/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 36/300 batch 172/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 36/300 batch 173/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 36/300 batch 174/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 36/300 batch 175/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 36/300 batch 176/188  Train Loss: 0.052, Acc: 0.992\n",
      "epoch: 36/300 batch 177/188  Train Loss: 0.046, Acc: 0.980\n",
      "epoch: 36/300 batch 178/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 36/300 batch 179/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 36/300 batch 180/188  Train Loss: 0.059, Acc: 0.988\n",
      "epoch: 36/300 batch 181/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 36/300 batch 182/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 36/300 batch 183/188  Train Loss: 0.056, Acc: 0.977\n",
      "epoch: 36/300 batch 184/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 36/300 batch 185/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 36/300 batch 186/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 36/300 batch 187/188  Train Loss: 0.073, Acc: 0.984\n",
      "Train Loss: 0.037615, Acc: 0.992\n",
      "Val Loss: 0.057842, Acc: 0.983\n",
      "epoch: 37/300 batch   0/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 37/300 batch   1/188  Train Loss: 0.033, Acc: 0.984\n",
      "epoch: 37/300 batch   2/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 37/300 batch   3/188  Train Loss: 0.063, Acc: 0.984\n",
      "epoch: 37/300 batch   4/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 37/300 batch   5/188  Train Loss: 0.059, Acc: 0.988\n",
      "epoch: 37/300 batch   6/188  Train Loss: 0.056, Acc: 0.980\n",
      "epoch: 37/300 batch   7/188  Train Loss: 0.068, Acc: 0.980\n",
      "epoch: 37/300 batch   8/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 37/300 batch   9/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 37/300 batch  10/188  Train Loss: 0.050, Acc: 0.980\n",
      "epoch: 37/300 batch  11/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 37/300 batch  12/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 37/300 batch  13/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 37/300 batch  14/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 37/300 batch  15/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 37/300 batch  16/188  Train Loss: 0.058, Acc: 0.980\n",
      "epoch: 37/300 batch  17/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 37/300 batch  18/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 37/300 batch  19/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 37/300 batch  20/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 37/300 batch  21/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 37/300 batch  22/188  Train Loss: 0.064, Acc: 0.977\n",
      "epoch: 37/300 batch  23/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 37/300 batch  24/188  Train Loss: 0.032, Acc: 1.000\n",
      "epoch: 37/300 batch  25/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 37/300 batch  26/188  Train Loss: 0.051, Acc: 0.996\n",
      "epoch: 37/300 batch  27/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 37/300 batch  28/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 37/300 batch  29/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 37/300 batch  30/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 37/300 batch  31/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 37/300 batch  32/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 37/300 batch  33/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 37/300 batch  34/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 37/300 batch  35/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 37/300 batch  36/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 37/300 batch  37/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 37/300 batch  38/188  Train Loss: 0.063, Acc: 0.980\n",
      "epoch: 37/300 batch  39/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 37/300 batch  40/188  Train Loss: 0.066, Acc: 0.980\n",
      "epoch: 37/300 batch  41/188  Train Loss: 0.052, Acc: 0.973\n",
      "epoch: 37/300 batch  42/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 37/300 batch  43/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 37/300 batch  44/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 37/300 batch  45/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 37/300 batch  46/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 37/300 batch  47/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 37/300 batch  48/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 37/300 batch  49/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 37/300 batch  50/188  Train Loss: 0.049, Acc: 0.980\n",
      "epoch: 37/300 batch  51/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 37/300 batch  52/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 37/300 batch  53/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 37/300 batch  54/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 37/300 batch  55/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 37/300 batch  56/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 37/300 batch  57/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 37/300 batch  58/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 37/300 batch  59/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 37/300 batch  60/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 37/300 batch  61/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 37/300 batch  62/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 37/300 batch  63/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 37/300 batch  64/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 37/300 batch  65/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 37/300 batch  66/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 37/300 batch  67/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 37/300 batch  68/188  Train Loss: 0.058, Acc: 0.992\n",
      "epoch: 37/300 batch  69/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 37/300 batch  70/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 37/300 batch  71/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 37/300 batch  72/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 37/300 batch  73/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 37/300 batch  74/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 37/300 batch  75/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 37/300 batch  76/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 37/300 batch  77/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 37/300 batch  78/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 37/300 batch  79/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 37/300 batch  80/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 37/300 batch  81/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 37/300 batch  82/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 37/300 batch  83/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 37/300 batch  84/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 37/300 batch  85/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 37/300 batch  86/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 37/300 batch  87/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 37/300 batch  88/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 37/300 batch  89/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 37/300 batch  90/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 37/300 batch  91/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 37/300 batch  92/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 37/300 batch  93/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 37/300 batch  94/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 37/300 batch  95/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 37/300 batch  96/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 37/300 batch  97/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 37/300 batch  98/188  Train Loss: 0.057, Acc: 0.977\n",
      "epoch: 37/300 batch  99/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 37/300 batch 100/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 37/300 batch 101/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 37/300 batch 102/188  Train Loss: 0.031, Acc: 1.000\n",
      "epoch: 37/300 batch 103/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 37/300 batch 104/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 37/300 batch 105/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 37/300 batch 106/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 37/300 batch 107/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 37/300 batch 108/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 37/300 batch 109/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 37/300 batch 110/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 37/300 batch 111/188  Train Loss: 0.040, Acc: 0.980\n",
      "epoch: 37/300 batch 112/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 37/300 batch 113/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 37/300 batch 114/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 37/300 batch 115/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 37/300 batch 116/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 37/300 batch 117/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 37/300 batch 118/188  Train Loss: 0.015, Acc: 0.996\n",
      "epoch: 37/300 batch 119/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 37/300 batch 120/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 37/300 batch 121/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 37/300 batch 122/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 37/300 batch 123/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 37/300 batch 124/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 37/300 batch 125/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 37/300 batch 126/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 37/300 batch 127/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 37/300 batch 128/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 37/300 batch 129/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 37/300 batch 130/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 37/300 batch 131/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 37/300 batch 132/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 37/300 batch 133/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 37/300 batch 134/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 37/300 batch 135/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 37/300 batch 136/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 37/300 batch 137/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 37/300 batch 138/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 37/300 batch 139/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 37/300 batch 140/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 37/300 batch 141/188  Train Loss: 0.054, Acc: 0.992\n",
      "epoch: 37/300 batch 142/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 37/300 batch 143/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 37/300 batch 144/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 37/300 batch 145/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 37/300 batch 146/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 37/300 batch 147/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 37/300 batch 148/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 37/300 batch 149/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 37/300 batch 150/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 37/300 batch 151/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 37/300 batch 152/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 37/300 batch 153/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 37/300 batch 154/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 37/300 batch 155/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 37/300 batch 156/188  Train Loss: 0.031, Acc: 0.984\n",
      "epoch: 37/300 batch 157/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 37/300 batch 158/188  Train Loss: 0.065, Acc: 0.988\n",
      "epoch: 37/300 batch 159/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 37/300 batch 160/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 37/300 batch 161/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 37/300 batch 162/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 37/300 batch 163/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 37/300 batch 164/188  Train Loss: 0.075, Acc: 0.980\n",
      "epoch: 37/300 batch 165/188  Train Loss: 0.103, Acc: 0.973\n",
      "epoch: 37/300 batch 166/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 37/300 batch 167/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 37/300 batch 168/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 37/300 batch 169/188  Train Loss: 0.080, Acc: 0.980\n",
      "epoch: 37/300 batch 170/188  Train Loss: 0.027, Acc: 0.988\n",
      "epoch: 37/300 batch 171/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 37/300 batch 172/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 37/300 batch 173/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 37/300 batch 174/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 37/300 batch 175/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 37/300 batch 176/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 37/300 batch 177/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 37/300 batch 178/188  Train Loss: 0.070, Acc: 0.984\n",
      "epoch: 37/300 batch 179/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 37/300 batch 180/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 37/300 batch 181/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 37/300 batch 182/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 37/300 batch 183/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 37/300 batch 184/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 37/300 batch 185/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 37/300 batch 186/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 37/300 batch 187/188  Train Loss: 0.017, Acc: 1.000\n",
      "Train Loss: 0.037360, Acc: 0.991\n",
      "Val Loss: 0.057960, Acc: 0.982\n",
      "epoch: 38/300 batch   0/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 38/300 batch   1/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 38/300 batch   2/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 38/300 batch   3/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 38/300 batch   4/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 38/300 batch   5/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 38/300 batch   6/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 38/300 batch   7/188  Train Loss: 0.051, Acc: 0.992\n",
      "epoch: 38/300 batch   8/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 38/300 batch   9/188  Train Loss: 0.069, Acc: 0.977\n",
      "epoch: 38/300 batch  10/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 38/300 batch  11/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 38/300 batch  12/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 38/300 batch  13/188  Train Loss: 0.073, Acc: 0.984\n",
      "epoch: 38/300 batch  14/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 38/300 batch  15/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 38/300 batch  16/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 38/300 batch  17/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 38/300 batch  18/188  Train Loss: 0.071, Acc: 0.980\n",
      "epoch: 38/300 batch  19/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 38/300 batch  20/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 38/300 batch  21/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 38/300 batch  22/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 38/300 batch  23/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 38/300 batch  24/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 38/300 batch  25/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 38/300 batch  26/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 38/300 batch  27/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 38/300 batch  28/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 38/300 batch  29/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 38/300 batch  30/188  Train Loss: 0.058, Acc: 0.980\n",
      "epoch: 38/300 batch  31/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 38/300 batch  32/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 38/300 batch  33/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 38/300 batch  34/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 38/300 batch  35/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 38/300 batch  36/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 38/300 batch  37/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 38/300 batch  38/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 38/300 batch  39/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 38/300 batch  40/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 38/300 batch  41/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 38/300 batch  42/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 38/300 batch  43/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 38/300 batch  44/188  Train Loss: 0.069, Acc: 0.977\n",
      "epoch: 38/300 batch  45/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 38/300 batch  46/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 38/300 batch  47/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 38/300 batch  48/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 38/300 batch  49/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 38/300 batch  50/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 38/300 batch  51/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 38/300 batch  52/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 38/300 batch  53/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 38/300 batch  54/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 38/300 batch  55/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 38/300 batch  56/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 38/300 batch  57/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 38/300 batch  58/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 38/300 batch  59/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 38/300 batch  60/188  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 38/300 batch  61/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 38/300 batch  62/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 38/300 batch  63/188  Train Loss: 0.048, Acc: 0.996\n",
      "epoch: 38/300 batch  64/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 38/300 batch  65/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 38/300 batch  66/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 38/300 batch  67/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 38/300 batch  68/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 38/300 batch  69/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 38/300 batch  70/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 38/300 batch  71/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 38/300 batch  72/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 38/300 batch  73/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 38/300 batch  74/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 38/300 batch  75/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 38/300 batch  76/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 38/300 batch  77/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 38/300 batch  78/188  Train Loss: 0.053, Acc: 0.980\n",
      "epoch: 38/300 batch  79/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 38/300 batch  80/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 38/300 batch  81/188  Train Loss: 0.061, Acc: 0.973\n",
      "epoch: 38/300 batch  82/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 38/300 batch  83/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 38/300 batch  84/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 38/300 batch  85/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 38/300 batch  86/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 38/300 batch  87/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 38/300 batch  88/188  Train Loss: 0.072, Acc: 0.988\n",
      "epoch: 38/300 batch  89/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 38/300 batch  90/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 38/300 batch  91/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 38/300 batch  92/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 38/300 batch  93/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 38/300 batch  94/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 38/300 batch  95/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 38/300 batch  96/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 38/300 batch  97/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 38/300 batch  98/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 38/300 batch  99/188  Train Loss: 0.062, Acc: 0.988\n",
      "epoch: 38/300 batch 100/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 38/300 batch 101/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 38/300 batch 102/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 38/300 batch 103/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 38/300 batch 104/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 38/300 batch 105/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 38/300 batch 106/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 38/300 batch 107/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 38/300 batch 108/188  Train Loss: 0.064, Acc: 0.980\n",
      "epoch: 38/300 batch 109/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 38/300 batch 110/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 38/300 batch 111/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 38/300 batch 112/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 38/300 batch 113/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 38/300 batch 114/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 38/300 batch 115/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 38/300 batch 116/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 38/300 batch 117/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 38/300 batch 118/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 38/300 batch 119/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 38/300 batch 120/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 38/300 batch 121/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 38/300 batch 122/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 38/300 batch 123/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 38/300 batch 124/188  Train Loss: 0.064, Acc: 0.984\n",
      "epoch: 38/300 batch 125/188  Train Loss: 0.027, Acc: 0.988\n",
      "epoch: 38/300 batch 126/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 38/300 batch 127/188  Train Loss: 0.082, Acc: 0.984\n",
      "epoch: 38/300 batch 128/188  Train Loss: 0.052, Acc: 0.992\n",
      "epoch: 38/300 batch 129/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 38/300 batch 130/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 38/300 batch 131/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 38/300 batch 132/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 38/300 batch 133/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 38/300 batch 134/188  Train Loss: 0.042, Acc: 0.980\n",
      "epoch: 38/300 batch 135/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 38/300 batch 136/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 38/300 batch 137/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 38/300 batch 138/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 38/300 batch 139/188  Train Loss: 0.060, Acc: 0.984\n",
      "epoch: 38/300 batch 140/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 38/300 batch 141/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 38/300 batch 142/188  Train Loss: 0.055, Acc: 0.992\n",
      "epoch: 38/300 batch 143/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 38/300 batch 144/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 38/300 batch 145/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 38/300 batch 146/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 38/300 batch 147/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 38/300 batch 148/188  Train Loss: 0.066, Acc: 0.984\n",
      "epoch: 38/300 batch 149/188  Train Loss: 0.044, Acc: 0.996\n",
      "epoch: 38/300 batch 150/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 38/300 batch 151/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 38/300 batch 152/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 38/300 batch 153/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 38/300 batch 154/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 38/300 batch 155/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 38/300 batch 156/188  Train Loss: 0.062, Acc: 0.980\n",
      "epoch: 38/300 batch 157/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 38/300 batch 158/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 38/300 batch 159/188  Train Loss: 0.037, Acc: 0.980\n",
      "epoch: 38/300 batch 160/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 38/300 batch 161/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 38/300 batch 162/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 38/300 batch 163/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 38/300 batch 164/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 38/300 batch 165/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 38/300 batch 166/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 38/300 batch 167/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 38/300 batch 168/188  Train Loss: 0.061, Acc: 0.984\n",
      "epoch: 38/300 batch 169/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 38/300 batch 170/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 38/300 batch 171/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 38/300 batch 172/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 38/300 batch 173/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 38/300 batch 174/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 38/300 batch 175/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 38/300 batch 176/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 38/300 batch 177/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 38/300 batch 178/188  Train Loss: 0.054, Acc: 0.980\n",
      "epoch: 38/300 batch 179/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 38/300 batch 180/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 38/300 batch 181/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 38/300 batch 182/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 38/300 batch 183/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 38/300 batch 184/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 38/300 batch 185/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 38/300 batch 186/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 38/300 batch 187/188  Train Loss: 0.026, Acc: 0.992\n",
      "Train Loss: 0.037343, Acc: 0.992\n",
      "Val Loss: 0.057771, Acc: 0.983\n",
      "epoch: 39/300 batch   0/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 39/300 batch   1/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 39/300 batch   2/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 39/300 batch   3/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 39/300 batch   4/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 39/300 batch   5/188  Train Loss: 0.059, Acc: 0.988\n",
      "epoch: 39/300 batch   6/188  Train Loss: 0.045, Acc: 0.996\n",
      "epoch: 39/300 batch   7/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 39/300 batch   8/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 39/300 batch   9/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 39/300 batch  10/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 39/300 batch  11/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 39/300 batch  12/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 39/300 batch  13/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 39/300 batch  14/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 39/300 batch  15/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 39/300 batch  16/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 39/300 batch  17/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 39/300 batch  18/188  Train Loss: 0.060, Acc: 0.977\n",
      "epoch: 39/300 batch  19/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 39/300 batch  20/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 39/300 batch  21/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 39/300 batch  22/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 39/300 batch  23/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 39/300 batch  24/188  Train Loss: 0.052, Acc: 0.980\n",
      "epoch: 39/300 batch  25/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 39/300 batch  26/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 39/300 batch  27/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 39/300 batch  28/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 39/300 batch  29/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 39/300 batch  30/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 39/300 batch  31/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 39/300 batch  32/188  Train Loss: 0.043, Acc: 0.996\n",
      "epoch: 39/300 batch  33/188  Train Loss: 0.055, Acc: 0.980\n",
      "epoch: 39/300 batch  34/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 39/300 batch  35/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 39/300 batch  36/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 39/300 batch  37/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 39/300 batch  38/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 39/300 batch  39/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 39/300 batch  40/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 39/300 batch  41/188  Train Loss: 0.048, Acc: 0.996\n",
      "epoch: 39/300 batch  42/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 39/300 batch  43/188  Train Loss: 0.059, Acc: 0.984\n",
      "epoch: 39/300 batch  44/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 39/300 batch  45/188  Train Loss: 0.069, Acc: 0.977\n",
      "epoch: 39/300 batch  46/188  Train Loss: 0.062, Acc: 0.996\n",
      "epoch: 39/300 batch  47/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 39/300 batch  48/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 39/300 batch  49/188  Train Loss: 0.043, Acc: 0.996\n",
      "epoch: 39/300 batch  50/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 39/300 batch  51/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 39/300 batch  52/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 39/300 batch  53/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 39/300 batch  54/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 39/300 batch  55/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 39/300 batch  56/188  Train Loss: 0.044, Acc: 0.996\n",
      "epoch: 39/300 batch  57/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 39/300 batch  58/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 39/300 batch  59/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 39/300 batch  60/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 39/300 batch  61/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 39/300 batch  62/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 39/300 batch  63/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 39/300 batch  64/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 39/300 batch  65/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 39/300 batch  66/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 39/300 batch  67/188  Train Loss: 0.070, Acc: 0.980\n",
      "epoch: 39/300 batch  68/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 39/300 batch  69/188  Train Loss: 0.051, Acc: 0.980\n",
      "epoch: 39/300 batch  70/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 39/300 batch  71/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 39/300 batch  72/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 39/300 batch  73/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 39/300 batch  74/188  Train Loss: 0.060, Acc: 0.984\n",
      "epoch: 39/300 batch  75/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 39/300 batch  76/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 39/300 batch  77/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 39/300 batch  78/188  Train Loss: 0.048, Acc: 0.980\n",
      "epoch: 39/300 batch  79/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 39/300 batch  80/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 39/300 batch  81/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 39/300 batch  82/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 39/300 batch  83/188  Train Loss: 0.066, Acc: 0.973\n",
      "epoch: 39/300 batch  84/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 39/300 batch  85/188  Train Loss: 0.063, Acc: 0.988\n",
      "epoch: 39/300 batch  86/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 39/300 batch  87/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 39/300 batch  88/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 39/300 batch  89/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 39/300 batch  90/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 39/300 batch  91/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 39/300 batch  92/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 39/300 batch  93/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 39/300 batch  94/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 39/300 batch  95/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 39/300 batch  96/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 39/300 batch  97/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 39/300 batch  98/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 39/300 batch  99/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 39/300 batch 100/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 39/300 batch 101/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 39/300 batch 102/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 39/300 batch 103/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 39/300 batch 104/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 39/300 batch 105/188  Train Loss: 0.087, Acc: 0.980\n",
      "epoch: 39/300 batch 106/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 39/300 batch 107/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 39/300 batch 108/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 39/300 batch 109/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 39/300 batch 110/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 39/300 batch 111/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 39/300 batch 112/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 39/300 batch 113/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 39/300 batch 114/188  Train Loss: 0.056, Acc: 0.977\n",
      "epoch: 39/300 batch 115/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 39/300 batch 116/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 39/300 batch 117/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 39/300 batch 118/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 39/300 batch 119/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 39/300 batch 120/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 39/300 batch 121/188  Train Loss: 0.055, Acc: 0.980\n",
      "epoch: 39/300 batch 122/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 39/300 batch 123/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 39/300 batch 124/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 39/300 batch 125/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 39/300 batch 126/188  Train Loss: 0.062, Acc: 0.973\n",
      "epoch: 39/300 batch 127/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 39/300 batch 128/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 39/300 batch 129/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 39/300 batch 130/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 39/300 batch 131/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 39/300 batch 132/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 39/300 batch 133/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 39/300 batch 134/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 39/300 batch 135/188  Train Loss: 0.061, Acc: 0.988\n",
      "epoch: 39/300 batch 136/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 39/300 batch 137/188  Train Loss: 0.057, Acc: 0.992\n",
      "epoch: 39/300 batch 138/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 39/300 batch 139/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 39/300 batch 140/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 39/300 batch 141/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 39/300 batch 142/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 39/300 batch 143/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 39/300 batch 144/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 39/300 batch 145/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 39/300 batch 146/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 39/300 batch 147/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 39/300 batch 148/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 39/300 batch 149/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 39/300 batch 150/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 39/300 batch 151/188  Train Loss: 0.043, Acc: 0.996\n",
      "epoch: 39/300 batch 152/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 39/300 batch 153/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 39/300 batch 154/188  Train Loss: 0.065, Acc: 0.973\n",
      "epoch: 39/300 batch 155/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 39/300 batch 156/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 39/300 batch 157/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 39/300 batch 158/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 39/300 batch 159/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 39/300 batch 160/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 39/300 batch 161/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 39/300 batch 162/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 39/300 batch 163/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 39/300 batch 164/188  Train Loss: 0.058, Acc: 0.988\n",
      "epoch: 39/300 batch 165/188  Train Loss: 0.049, Acc: 0.996\n",
      "epoch: 39/300 batch 166/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 39/300 batch 167/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 39/300 batch 168/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 39/300 batch 169/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 39/300 batch 170/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 39/300 batch 171/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 39/300 batch 172/188  Train Loss: 0.047, Acc: 0.980\n",
      "epoch: 39/300 batch 173/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 39/300 batch 174/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 39/300 batch 175/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 39/300 batch 176/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 39/300 batch 177/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 39/300 batch 178/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 39/300 batch 179/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 39/300 batch 180/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 39/300 batch 181/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 39/300 batch 182/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 39/300 batch 183/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 39/300 batch 184/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 39/300 batch 185/188  Train Loss: 0.065, Acc: 0.980\n",
      "epoch: 39/300 batch 186/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 39/300 batch 187/188  Train Loss: 0.036, Acc: 0.992\n",
      "Train Loss: 0.037373, Acc: 0.992\n",
      "Val Loss: 0.058039, Acc: 0.983\n",
      "epoch: 40/300 batch   0/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 40/300 batch   1/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 40/300 batch   2/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 40/300 batch   3/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 40/300 batch   4/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 40/300 batch   5/188  Train Loss: 0.032, Acc: 1.000\n",
      "epoch: 40/300 batch   6/188  Train Loss: 0.055, Acc: 0.980\n",
      "epoch: 40/300 batch   7/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 40/300 batch   8/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 40/300 batch   9/188  Train Loss: 0.032, Acc: 0.984\n",
      "epoch: 40/300 batch  10/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 40/300 batch  11/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 40/300 batch  12/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 40/300 batch  13/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 40/300 batch  14/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 40/300 batch  15/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 40/300 batch  16/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 40/300 batch  17/188  Train Loss: 0.055, Acc: 0.992\n",
      "epoch: 40/300 batch  18/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 40/300 batch  19/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 40/300 batch  20/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 40/300 batch  21/188  Train Loss: 0.071, Acc: 0.992\n",
      "epoch: 40/300 batch  22/188  Train Loss: 0.059, Acc: 0.988\n",
      "epoch: 40/300 batch  23/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 40/300 batch  24/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 40/300 batch  25/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 40/300 batch  26/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 40/300 batch  27/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 40/300 batch  28/188  Train Loss: 0.061, Acc: 0.984\n",
      "epoch: 40/300 batch  29/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 40/300 batch  30/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 40/300 batch  31/188  Train Loss: 0.060, Acc: 0.977\n",
      "epoch: 40/300 batch  32/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 40/300 batch  33/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 40/300 batch  34/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 40/300 batch  35/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 40/300 batch  36/188  Train Loss: 0.056, Acc: 0.988\n",
      "epoch: 40/300 batch  37/188  Train Loss: 0.041, Acc: 0.980\n",
      "epoch: 40/300 batch  38/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 40/300 batch  39/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 40/300 batch  40/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 40/300 batch  41/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 40/300 batch  42/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 40/300 batch  43/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 40/300 batch  44/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 40/300 batch  45/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 40/300 batch  46/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 40/300 batch  47/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 40/300 batch  48/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 40/300 batch  49/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 40/300 batch  50/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 40/300 batch  51/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 40/300 batch  52/188  Train Loss: 0.059, Acc: 0.984\n",
      "epoch: 40/300 batch  53/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 40/300 batch  54/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 40/300 batch  55/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 40/300 batch  56/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 40/300 batch  57/188  Train Loss: 0.071, Acc: 0.980\n",
      "epoch: 40/300 batch  58/188  Train Loss: 0.053, Acc: 0.977\n",
      "epoch: 40/300 batch  59/188  Train Loss: 0.051, Acc: 0.992\n",
      "epoch: 40/300 batch  60/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 40/300 batch  61/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 40/300 batch  62/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 40/300 batch  63/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 40/300 batch  64/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 40/300 batch  65/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 40/300 batch  66/188  Train Loss: 0.041, Acc: 0.980\n",
      "epoch: 40/300 batch  67/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 40/300 batch  68/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 40/300 batch  69/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 40/300 batch  70/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 40/300 batch  71/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 40/300 batch  72/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 40/300 batch  73/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 40/300 batch  74/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 40/300 batch  75/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 40/300 batch  76/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 40/300 batch  77/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 40/300 batch  78/188  Train Loss: 0.066, Acc: 0.984\n",
      "epoch: 40/300 batch  79/188  Train Loss: 0.034, Acc: 1.000\n",
      "epoch: 40/300 batch  80/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 40/300 batch  81/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 40/300 batch  82/188  Train Loss: 0.063, Acc: 0.973\n",
      "epoch: 40/300 batch  83/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 40/300 batch  84/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 40/300 batch  85/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 40/300 batch  86/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 40/300 batch  87/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 40/300 batch  88/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 40/300 batch  89/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 40/300 batch  90/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 40/300 batch  91/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 40/300 batch  92/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 40/300 batch  93/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 40/300 batch  94/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 40/300 batch  95/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 40/300 batch  96/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 40/300 batch  97/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 40/300 batch  98/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 40/300 batch  99/188  Train Loss: 0.056, Acc: 0.973\n",
      "epoch: 40/300 batch 100/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 40/300 batch 101/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 40/300 batch 102/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 40/300 batch 103/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 40/300 batch 104/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 40/300 batch 105/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 40/300 batch 106/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 40/300 batch 107/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 40/300 batch 108/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 40/300 batch 109/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 40/300 batch 110/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 40/300 batch 111/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 40/300 batch 112/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 40/300 batch 113/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 40/300 batch 114/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 40/300 batch 115/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 40/300 batch 116/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 40/300 batch 117/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 40/300 batch 118/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 40/300 batch 119/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 40/300 batch 120/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 40/300 batch 121/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 40/300 batch 122/188  Train Loss: 0.052, Acc: 0.980\n",
      "epoch: 40/300 batch 123/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 40/300 batch 124/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 40/300 batch 125/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 40/300 batch 126/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 40/300 batch 127/188  Train Loss: 0.065, Acc: 0.988\n",
      "epoch: 40/300 batch 128/188  Train Loss: 0.059, Acc: 0.984\n",
      "epoch: 40/300 batch 129/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 40/300 batch 130/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 40/300 batch 131/188  Train Loss: 0.052, Acc: 0.996\n",
      "epoch: 40/300 batch 132/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 40/300 batch 133/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 40/300 batch 134/188  Train Loss: 0.052, Acc: 0.992\n",
      "epoch: 40/300 batch 135/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 40/300 batch 136/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 40/300 batch 137/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 40/300 batch 138/188  Train Loss: 0.034, Acc: 0.984\n",
      "epoch: 40/300 batch 139/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 40/300 batch 140/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 40/300 batch 141/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 40/300 batch 142/188  Train Loss: 0.026, Acc: 0.988\n",
      "epoch: 40/300 batch 143/188  Train Loss: 0.060, Acc: 0.984\n",
      "epoch: 40/300 batch 144/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 40/300 batch 145/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 40/300 batch 146/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 40/300 batch 147/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 40/300 batch 148/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 40/300 batch 149/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 40/300 batch 150/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 40/300 batch 151/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 40/300 batch 152/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 40/300 batch 153/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 40/300 batch 154/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 40/300 batch 155/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 40/300 batch 156/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 40/300 batch 157/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 40/300 batch 158/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 40/300 batch 159/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 40/300 batch 160/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 40/300 batch 161/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 40/300 batch 162/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 40/300 batch 163/188  Train Loss: 0.067, Acc: 0.984\n",
      "epoch: 40/300 batch 164/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 40/300 batch 165/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 40/300 batch 166/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 40/300 batch 167/188  Train Loss: 0.054, Acc: 0.977\n",
      "epoch: 40/300 batch 168/188  Train Loss: 0.058, Acc: 0.992\n",
      "epoch: 40/300 batch 169/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 40/300 batch 170/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 40/300 batch 171/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 40/300 batch 172/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 40/300 batch 173/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 40/300 batch 174/188  Train Loss: 0.044, Acc: 0.996\n",
      "epoch: 40/300 batch 175/188  Train Loss: 0.032, Acc: 0.984\n",
      "epoch: 40/300 batch 176/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 40/300 batch 177/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 40/300 batch 178/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 40/300 batch 179/188  Train Loss: 0.059, Acc: 0.988\n",
      "epoch: 40/300 batch 180/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 40/300 batch 181/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 40/300 batch 182/188  Train Loss: 0.042, Acc: 0.996\n",
      "epoch: 40/300 batch 183/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 40/300 batch 184/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 40/300 batch 185/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 40/300 batch 186/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 40/300 batch 187/188  Train Loss: 0.031, Acc: 1.000\n",
      "Train Loss: 0.037355, Acc: 0.992\n",
      "Val Loss: 0.057769, Acc: 0.982\n",
      "epoch: 41/300 batch   0/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 41/300 batch   1/188  Train Loss: 0.037, Acc: 0.980\n",
      "epoch: 41/300 batch   2/188  Train Loss: 0.059, Acc: 0.980\n",
      "epoch: 41/300 batch   3/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 41/300 batch   4/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 41/300 batch   5/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 41/300 batch   6/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 41/300 batch   7/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 41/300 batch   8/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 41/300 batch   9/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 41/300 batch  10/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 41/300 batch  11/188  Train Loss: 0.033, Acc: 1.000\n",
      "epoch: 41/300 batch  12/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 41/300 batch  13/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 41/300 batch  14/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 41/300 batch  15/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 41/300 batch  16/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 41/300 batch  17/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 41/300 batch  18/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 41/300 batch  19/188  Train Loss: 0.048, Acc: 0.980\n",
      "epoch: 41/300 batch  20/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 41/300 batch  21/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 41/300 batch  22/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 41/300 batch  23/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 41/300 batch  24/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 41/300 batch  25/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 41/300 batch  26/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 41/300 batch  27/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 41/300 batch  28/188  Train Loss: 0.086, Acc: 0.977\n",
      "epoch: 41/300 batch  29/188  Train Loss: 0.064, Acc: 0.980\n",
      "epoch: 41/300 batch  30/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 41/300 batch  31/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 41/300 batch  32/188  Train Loss: 0.049, Acc: 0.980\n",
      "epoch: 41/300 batch  33/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 41/300 batch  34/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 41/300 batch  35/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 41/300 batch  36/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 41/300 batch  37/188  Train Loss: 0.060, Acc: 0.984\n",
      "epoch: 41/300 batch  38/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 41/300 batch  39/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 41/300 batch  40/188  Train Loss: 0.051, Acc: 0.980\n",
      "epoch: 41/300 batch  41/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 41/300 batch  42/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 41/300 batch  43/188  Train Loss: 0.061, Acc: 0.980\n",
      "epoch: 41/300 batch  44/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 41/300 batch  45/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 41/300 batch  46/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 41/300 batch  47/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 41/300 batch  48/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 41/300 batch  49/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 41/300 batch  50/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 41/300 batch  51/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 41/300 batch  52/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 41/300 batch  53/188  Train Loss: 0.032, Acc: 1.000\n",
      "epoch: 41/300 batch  54/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 41/300 batch  55/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 41/300 batch  56/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 41/300 batch  57/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 41/300 batch  58/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 41/300 batch  59/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 41/300 batch  60/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 41/300 batch  61/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 41/300 batch  62/188  Train Loss: 0.073, Acc: 0.984\n",
      "epoch: 41/300 batch  63/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 41/300 batch  64/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 41/300 batch  65/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 41/300 batch  66/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 41/300 batch  67/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 41/300 batch  68/188  Train Loss: 0.057, Acc: 0.980\n",
      "epoch: 41/300 batch  69/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 41/300 batch  70/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 41/300 batch  71/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 41/300 batch  72/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 41/300 batch  73/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 41/300 batch  74/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 41/300 batch  75/188  Train Loss: 0.054, Acc: 0.977\n",
      "epoch: 41/300 batch  76/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 41/300 batch  77/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 41/300 batch  78/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 41/300 batch  79/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 41/300 batch  80/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 41/300 batch  81/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 41/300 batch  82/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 41/300 batch  83/188  Train Loss: 0.089, Acc: 0.992\n",
      "epoch: 41/300 batch  84/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 41/300 batch  85/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 41/300 batch  86/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 41/300 batch  87/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 41/300 batch  88/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 41/300 batch  89/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 41/300 batch  90/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 41/300 batch  91/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 41/300 batch  92/188  Train Loss: 0.065, Acc: 0.984\n",
      "epoch: 41/300 batch  93/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 41/300 batch  94/188  Train Loss: 0.067, Acc: 0.984\n",
      "epoch: 41/300 batch  95/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 41/300 batch  96/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 41/300 batch  97/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 41/300 batch  98/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 41/300 batch  99/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 41/300 batch 100/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 41/300 batch 101/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 41/300 batch 102/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 41/300 batch 103/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 41/300 batch 104/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 41/300 batch 105/188  Train Loss: 0.061, Acc: 0.977\n",
      "epoch: 41/300 batch 106/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 41/300 batch 107/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 41/300 batch 108/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 41/300 batch 109/188  Train Loss: 0.079, Acc: 0.988\n",
      "epoch: 41/300 batch 110/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 41/300 batch 111/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 41/300 batch 112/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 41/300 batch 113/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 41/300 batch 114/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 41/300 batch 115/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 41/300 batch 116/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 41/300 batch 117/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 41/300 batch 118/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 41/300 batch 119/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 41/300 batch 120/188  Train Loss: 0.052, Acc: 0.992\n",
      "epoch: 41/300 batch 121/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 41/300 batch 122/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 41/300 batch 123/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 41/300 batch 124/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 41/300 batch 125/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 41/300 batch 126/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 41/300 batch 127/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 41/300 batch 128/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 41/300 batch 129/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 41/300 batch 130/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 41/300 batch 131/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 41/300 batch 132/188  Train Loss: 0.056, Acc: 0.992\n",
      "epoch: 41/300 batch 133/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 41/300 batch 134/188  Train Loss: 0.061, Acc: 0.988\n",
      "epoch: 41/300 batch 135/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 41/300 batch 136/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 41/300 batch 137/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 41/300 batch 138/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 41/300 batch 139/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 41/300 batch 140/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 41/300 batch 141/188  Train Loss: 0.067, Acc: 0.973\n",
      "epoch: 41/300 batch 142/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 41/300 batch 143/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 41/300 batch 144/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 41/300 batch 145/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 41/300 batch 146/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 41/300 batch 147/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 41/300 batch 148/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 41/300 batch 149/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 41/300 batch 150/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 41/300 batch 151/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 41/300 batch 152/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 41/300 batch 153/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 41/300 batch 154/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 41/300 batch 155/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 41/300 batch 156/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 41/300 batch 157/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 41/300 batch 158/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 41/300 batch 159/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 41/300 batch 160/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 41/300 batch 161/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 41/300 batch 162/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 41/300 batch 163/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 41/300 batch 164/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 41/300 batch 165/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 41/300 batch 166/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 41/300 batch 167/188  Train Loss: 0.075, Acc: 0.980\n",
      "epoch: 41/300 batch 168/188  Train Loss: 0.089, Acc: 0.977\n",
      "epoch: 41/300 batch 169/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 41/300 batch 170/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 41/300 batch 171/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 41/300 batch 172/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 41/300 batch 173/188  Train Loss: 0.057, Acc: 0.988\n",
      "epoch: 41/300 batch 174/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 41/300 batch 175/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 41/300 batch 176/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 41/300 batch 177/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 41/300 batch 178/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 41/300 batch 179/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 41/300 batch 180/188  Train Loss: 0.047, Acc: 0.980\n",
      "epoch: 41/300 batch 181/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 41/300 batch 182/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 41/300 batch 183/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 41/300 batch 184/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 41/300 batch 185/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 41/300 batch 186/188  Train Loss: 0.060, Acc: 0.969\n",
      "epoch: 41/300 batch 187/188  Train Loss: 0.011, Acc: 1.000\n",
      "Train Loss: 0.037227, Acc: 0.992\n",
      "Val Loss: 0.057965, Acc: 0.982\n",
      "epoch: 42/300 batch   0/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 42/300 batch   1/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 42/300 batch   2/188  Train Loss: 0.059, Acc: 0.980\n",
      "epoch: 42/300 batch   3/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 42/300 batch   4/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 42/300 batch   5/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 42/300 batch   6/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 42/300 batch   7/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 42/300 batch   8/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 42/300 batch   9/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 42/300 batch  10/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 42/300 batch  11/188  Train Loss: 0.057, Acc: 0.992\n",
      "epoch: 42/300 batch  12/188  Train Loss: 0.060, Acc: 0.988\n",
      "epoch: 42/300 batch  13/188  Train Loss: 0.076, Acc: 0.977\n",
      "epoch: 42/300 batch  14/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 42/300 batch  15/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 42/300 batch  16/188  Train Loss: 0.047, Acc: 0.973\n",
      "epoch: 42/300 batch  17/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 42/300 batch  18/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 42/300 batch  19/188  Train Loss: 0.027, Acc: 0.988\n",
      "epoch: 42/300 batch  20/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 42/300 batch  21/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 42/300 batch  22/188  Train Loss: 0.056, Acc: 0.988\n",
      "epoch: 42/300 batch  23/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 42/300 batch  24/188  Train Loss: 0.031, Acc: 1.000\n",
      "epoch: 42/300 batch  25/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 42/300 batch  26/188  Train Loss: 0.043, Acc: 0.980\n",
      "epoch: 42/300 batch  27/188  Train Loss: 0.057, Acc: 0.988\n",
      "epoch: 42/300 batch  28/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 42/300 batch  29/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 42/300 batch  30/188  Train Loss: 0.056, Acc: 0.988\n",
      "epoch: 42/300 batch  31/188  Train Loss: 0.046, Acc: 0.980\n",
      "epoch: 42/300 batch  32/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 42/300 batch  33/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 42/300 batch  34/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 42/300 batch  35/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 42/300 batch  36/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 42/300 batch  37/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 42/300 batch  38/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 42/300 batch  39/188  Train Loss: 0.047, Acc: 0.996\n",
      "epoch: 42/300 batch  40/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 42/300 batch  41/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 42/300 batch  42/188  Train Loss: 0.047, Acc: 0.980\n",
      "epoch: 42/300 batch  43/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 42/300 batch  44/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 42/300 batch  45/188  Train Loss: 0.066, Acc: 0.980\n",
      "epoch: 42/300 batch  46/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 42/300 batch  47/188  Train Loss: 0.044, Acc: 0.980\n",
      "epoch: 42/300 batch  48/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 42/300 batch  49/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 42/300 batch  50/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 42/300 batch  51/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 42/300 batch  52/188  Train Loss: 0.058, Acc: 0.980\n",
      "epoch: 42/300 batch  53/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 42/300 batch  54/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 42/300 batch  55/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 42/300 batch  56/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 42/300 batch  57/188  Train Loss: 0.040, Acc: 0.980\n",
      "epoch: 42/300 batch  58/188  Train Loss: 0.033, Acc: 0.984\n",
      "epoch: 42/300 batch  59/188  Train Loss: 0.026, Acc: 0.988\n",
      "epoch: 42/300 batch  60/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 42/300 batch  61/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 42/300 batch  62/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 42/300 batch  63/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 42/300 batch  64/188  Train Loss: 0.073, Acc: 0.980\n",
      "epoch: 42/300 batch  65/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 42/300 batch  66/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 42/300 batch  67/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 42/300 batch  68/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 42/300 batch  69/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 42/300 batch  70/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 42/300 batch  71/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 42/300 batch  72/188  Train Loss: 0.048, Acc: 0.980\n",
      "epoch: 42/300 batch  73/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 42/300 batch  74/188  Train Loss: 0.061, Acc: 0.988\n",
      "epoch: 42/300 batch  75/188  Train Loss: 0.044, Acc: 0.996\n",
      "epoch: 42/300 batch  76/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 42/300 batch  77/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 42/300 batch  78/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 42/300 batch  79/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 42/300 batch  80/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 42/300 batch  81/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 42/300 batch  82/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 42/300 batch  83/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 42/300 batch  84/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 42/300 batch  85/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 42/300 batch  86/188  Train Loss: 0.065, Acc: 0.984\n",
      "epoch: 42/300 batch  87/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 42/300 batch  88/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 42/300 batch  89/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 42/300 batch  90/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 42/300 batch  91/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 42/300 batch  92/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 42/300 batch  93/188  Train Loss: 0.116, Acc: 0.977\n",
      "epoch: 42/300 batch  94/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 42/300 batch  95/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 42/300 batch  96/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 42/300 batch  97/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 42/300 batch  98/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 42/300 batch  99/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 42/300 batch 100/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 42/300 batch 101/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 42/300 batch 102/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 42/300 batch 103/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 42/300 batch 104/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 42/300 batch 105/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 42/300 batch 106/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 42/300 batch 107/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 42/300 batch 108/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 42/300 batch 109/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 42/300 batch 110/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 42/300 batch 111/188  Train Loss: 0.065, Acc: 0.984\n",
      "epoch: 42/300 batch 112/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 42/300 batch 113/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 42/300 batch 114/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 42/300 batch 115/188  Train Loss: 0.044, Acc: 0.996\n",
      "epoch: 42/300 batch 116/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 42/300 batch 117/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 42/300 batch 118/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 42/300 batch 119/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 42/300 batch 120/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 42/300 batch 121/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 42/300 batch 122/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 42/300 batch 123/188  Train Loss: 0.051, Acc: 0.980\n",
      "epoch: 42/300 batch 124/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 42/300 batch 125/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 42/300 batch 126/188  Train Loss: 0.051, Acc: 0.992\n",
      "epoch: 42/300 batch 127/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 42/300 batch 128/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 42/300 batch 129/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 42/300 batch 130/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 42/300 batch 131/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 42/300 batch 132/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 42/300 batch 133/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 42/300 batch 134/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 42/300 batch 135/188  Train Loss: 0.073, Acc: 0.980\n",
      "epoch: 42/300 batch 136/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 42/300 batch 137/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 42/300 batch 138/188  Train Loss: 0.034, Acc: 0.984\n",
      "epoch: 42/300 batch 139/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 42/300 batch 140/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 42/300 batch 141/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 42/300 batch 142/188  Train Loss: 0.046, Acc: 0.996\n",
      "epoch: 42/300 batch 143/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 42/300 batch 144/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 42/300 batch 145/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 42/300 batch 146/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 42/300 batch 147/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 42/300 batch 148/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 42/300 batch 149/188  Train Loss: 0.046, Acc: 0.980\n",
      "epoch: 42/300 batch 150/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 42/300 batch 151/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 42/300 batch 152/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 42/300 batch 153/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 42/300 batch 154/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 42/300 batch 155/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 42/300 batch 156/188  Train Loss: 0.035, Acc: 1.000\n",
      "epoch: 42/300 batch 157/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 42/300 batch 158/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 42/300 batch 159/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 42/300 batch 160/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 42/300 batch 161/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 42/300 batch 162/188  Train Loss: 0.075, Acc: 0.984\n",
      "epoch: 42/300 batch 163/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 42/300 batch 164/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 42/300 batch 165/188  Train Loss: 0.070, Acc: 0.977\n",
      "epoch: 42/300 batch 166/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 42/300 batch 167/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 42/300 batch 168/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 42/300 batch 169/188  Train Loss: 0.060, Acc: 0.980\n",
      "epoch: 42/300 batch 170/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 42/300 batch 171/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 42/300 batch 172/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 42/300 batch 173/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 42/300 batch 174/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 42/300 batch 175/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 42/300 batch 176/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 42/300 batch 177/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 42/300 batch 178/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 42/300 batch 179/188  Train Loss: 0.050, Acc: 0.980\n",
      "epoch: 42/300 batch 180/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 42/300 batch 181/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 42/300 batch 182/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 42/300 batch 183/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 42/300 batch 184/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 42/300 batch 185/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 42/300 batch 186/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 42/300 batch 187/188  Train Loss: 0.041, Acc: 0.984\n",
      "Train Loss: 0.037305, Acc: 0.992\n",
      "Val Loss: 0.058087, Acc: 0.983\n",
      "epoch: 43/300 batch   0/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 43/300 batch   1/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 43/300 batch   2/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 43/300 batch   3/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 43/300 batch   4/188  Train Loss: 0.053, Acc: 0.980\n",
      "epoch: 43/300 batch   5/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 43/300 batch   6/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 43/300 batch   7/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 43/300 batch   8/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 43/300 batch   9/188  Train Loss: 0.058, Acc: 0.988\n",
      "epoch: 43/300 batch  10/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 43/300 batch  11/188  Train Loss: 0.061, Acc: 0.984\n",
      "epoch: 43/300 batch  12/188  Train Loss: 0.053, Acc: 0.980\n",
      "epoch: 43/300 batch  13/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 43/300 batch  14/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 43/300 batch  15/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 43/300 batch  16/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 43/300 batch  17/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 43/300 batch  18/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 43/300 batch  19/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 43/300 batch  20/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 43/300 batch  21/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 43/300 batch  22/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 43/300 batch  23/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 43/300 batch  24/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 43/300 batch  25/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 43/300 batch  26/188  Train Loss: 0.050, Acc: 0.980\n",
      "epoch: 43/300 batch  27/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 43/300 batch  28/188  Train Loss: 0.063, Acc: 0.984\n",
      "epoch: 43/300 batch  29/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 43/300 batch  30/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 43/300 batch  31/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 43/300 batch  32/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 43/300 batch  33/188  Train Loss: 0.059, Acc: 0.988\n",
      "epoch: 43/300 batch  34/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 43/300 batch  35/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 43/300 batch  36/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 43/300 batch  37/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 43/300 batch  38/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 43/300 batch  39/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 43/300 batch  40/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 43/300 batch  41/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 43/300 batch  42/188  Train Loss: 0.044, Acc: 0.980\n",
      "epoch: 43/300 batch  43/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 43/300 batch  44/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 43/300 batch  45/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 43/300 batch  46/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 43/300 batch  47/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 43/300 batch  48/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 43/300 batch  49/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 43/300 batch  50/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 43/300 batch  51/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 43/300 batch  52/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 43/300 batch  53/188  Train Loss: 0.062, Acc: 0.992\n",
      "epoch: 43/300 batch  54/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 43/300 batch  55/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 43/300 batch  56/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 43/300 batch  57/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 43/300 batch  58/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 43/300 batch  59/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 43/300 batch  60/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 43/300 batch  61/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 43/300 batch  62/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 43/300 batch  63/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 43/300 batch  64/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 43/300 batch  65/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 43/300 batch  66/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 43/300 batch  67/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 43/300 batch  68/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 43/300 batch  69/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 43/300 batch  70/188  Train Loss: 0.054, Acc: 0.980\n",
      "epoch: 43/300 batch  71/188  Train Loss: 0.070, Acc: 0.969\n",
      "epoch: 43/300 batch  72/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 43/300 batch  73/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 43/300 batch  74/188  Train Loss: 0.058, Acc: 0.977\n",
      "epoch: 43/300 batch  75/188  Train Loss: 0.069, Acc: 0.984\n",
      "epoch: 43/300 batch  76/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 43/300 batch  77/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 43/300 batch  78/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 43/300 batch  79/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 43/300 batch  80/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 43/300 batch  81/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 43/300 batch  82/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 43/300 batch  83/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 43/300 batch  84/188  Train Loss: 0.061, Acc: 0.984\n",
      "epoch: 43/300 batch  85/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 43/300 batch  86/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 43/300 batch  87/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 43/300 batch  88/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 43/300 batch  89/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 43/300 batch  90/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 43/300 batch  91/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 43/300 batch  92/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 43/300 batch  93/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 43/300 batch  94/188  Train Loss: 0.060, Acc: 0.980\n",
      "epoch: 43/300 batch  95/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 43/300 batch  96/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 43/300 batch  97/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 43/300 batch  98/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 43/300 batch  99/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 43/300 batch 100/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 43/300 batch 101/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 43/300 batch 102/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 43/300 batch 103/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 43/300 batch 104/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 43/300 batch 105/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 43/300 batch 106/188  Train Loss: 0.078, Acc: 0.988\n",
      "epoch: 43/300 batch 107/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 43/300 batch 108/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 43/300 batch 109/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 43/300 batch 110/188  Train Loss: 0.060, Acc: 0.977\n",
      "epoch: 43/300 batch 111/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 43/300 batch 112/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 43/300 batch 113/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 43/300 batch 114/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 43/300 batch 115/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 43/300 batch 116/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 43/300 batch 117/188  Train Loss: 0.044, Acc: 0.996\n",
      "epoch: 43/300 batch 118/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 43/300 batch 119/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 43/300 batch 120/188  Train Loss: 0.055, Acc: 0.980\n",
      "epoch: 43/300 batch 121/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 43/300 batch 122/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 43/300 batch 123/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 43/300 batch 124/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 43/300 batch 125/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 43/300 batch 126/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 43/300 batch 127/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 43/300 batch 128/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 43/300 batch 129/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 43/300 batch 130/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 43/300 batch 131/188  Train Loss: 0.069, Acc: 0.984\n",
      "epoch: 43/300 batch 132/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 43/300 batch 133/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 43/300 batch 134/188  Train Loss: 0.047, Acc: 0.980\n",
      "epoch: 43/300 batch 135/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 43/300 batch 136/188  Train Loss: 0.036, Acc: 1.000\n",
      "epoch: 43/300 batch 137/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 43/300 batch 138/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 43/300 batch 139/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 43/300 batch 140/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 43/300 batch 141/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 43/300 batch 142/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 43/300 batch 143/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 43/300 batch 144/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 43/300 batch 145/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 43/300 batch 146/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 43/300 batch 147/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 43/300 batch 148/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 43/300 batch 149/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 43/300 batch 150/188  Train Loss: 0.027, Acc: 0.988\n",
      "epoch: 43/300 batch 151/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 43/300 batch 152/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 43/300 batch 153/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 43/300 batch 154/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 43/300 batch 155/188  Train Loss: 0.056, Acc: 0.988\n",
      "epoch: 43/300 batch 156/188  Train Loss: 0.057, Acc: 0.980\n",
      "epoch: 43/300 batch 157/188  Train Loss: 0.061, Acc: 0.980\n",
      "epoch: 43/300 batch 158/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 43/300 batch 159/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 43/300 batch 160/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 43/300 batch 161/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 43/300 batch 162/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 43/300 batch 163/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 43/300 batch 164/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 43/300 batch 165/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 43/300 batch 166/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 43/300 batch 167/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 43/300 batch 168/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 43/300 batch 169/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 43/300 batch 170/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 43/300 batch 171/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 43/300 batch 172/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 43/300 batch 173/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 43/300 batch 174/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 43/300 batch 175/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 43/300 batch 176/188  Train Loss: 0.026, Acc: 0.988\n",
      "epoch: 43/300 batch 177/188  Train Loss: 0.071, Acc: 0.984\n",
      "epoch: 43/300 batch 178/188  Train Loss: 0.027, Acc: 0.988\n",
      "epoch: 43/300 batch 179/188  Train Loss: 0.050, Acc: 0.980\n",
      "epoch: 43/300 batch 180/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 43/300 batch 181/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 43/300 batch 182/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 43/300 batch 183/188  Train Loss: 0.062, Acc: 0.980\n",
      "epoch: 43/300 batch 184/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 43/300 batch 185/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 43/300 batch 186/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 43/300 batch 187/188  Train Loss: 0.050, Acc: 0.992\n",
      "Train Loss: 0.037248, Acc: 0.991\n",
      "Val Loss: 0.058025, Acc: 0.983\n",
      "epoch: 44/300 batch   0/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 44/300 batch   1/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 44/300 batch   2/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 44/300 batch   3/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 44/300 batch   4/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 44/300 batch   5/188  Train Loss: 0.064, Acc: 0.980\n",
      "epoch: 44/300 batch   6/188  Train Loss: 0.033, Acc: 0.980\n",
      "epoch: 44/300 batch   7/188  Train Loss: 0.059, Acc: 0.984\n",
      "epoch: 44/300 batch   8/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 44/300 batch   9/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 44/300 batch  10/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 44/300 batch  11/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 44/300 batch  12/188  Train Loss: 0.035, Acc: 1.000\n",
      "epoch: 44/300 batch  13/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 44/300 batch  14/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 44/300 batch  15/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 44/300 batch  16/188  Train Loss: 0.065, Acc: 0.980\n",
      "epoch: 44/300 batch  17/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 44/300 batch  18/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 44/300 batch  19/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 44/300 batch  20/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 44/300 batch  21/188  Train Loss: 0.037, Acc: 0.980\n",
      "epoch: 44/300 batch  22/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 44/300 batch  23/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 44/300 batch  24/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 44/300 batch  25/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 44/300 batch  26/188  Train Loss: 0.060, Acc: 0.988\n",
      "epoch: 44/300 batch  27/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 44/300 batch  28/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 44/300 batch  29/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 44/300 batch  30/188  Train Loss: 0.048, Acc: 0.977\n",
      "epoch: 44/300 batch  31/188  Train Loss: 0.067, Acc: 0.977\n",
      "epoch: 44/300 batch  32/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 44/300 batch  33/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 44/300 batch  34/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 44/300 batch  35/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 44/300 batch  36/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 44/300 batch  37/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 44/300 batch  38/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 44/300 batch  39/188  Train Loss: 0.062, Acc: 0.988\n",
      "epoch: 44/300 batch  40/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 44/300 batch  41/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 44/300 batch  42/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 44/300 batch  43/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 44/300 batch  44/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 44/300 batch  45/188  Train Loss: 0.072, Acc: 0.977\n",
      "epoch: 44/300 batch  46/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 44/300 batch  47/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 44/300 batch  48/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 44/300 batch  49/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 44/300 batch  50/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 44/300 batch  51/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 44/300 batch  52/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 44/300 batch  53/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 44/300 batch  54/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 44/300 batch  55/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 44/300 batch  56/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 44/300 batch  57/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 44/300 batch  58/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 44/300 batch  59/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 44/300 batch  60/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 44/300 batch  61/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 44/300 batch  62/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 44/300 batch  63/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 44/300 batch  64/188  Train Loss: 0.052, Acc: 0.980\n",
      "epoch: 44/300 batch  65/188  Train Loss: 0.060, Acc: 0.988\n",
      "epoch: 44/300 batch  66/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 44/300 batch  67/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 44/300 batch  68/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 44/300 batch  69/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 44/300 batch  70/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 44/300 batch  71/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 44/300 batch  72/188  Train Loss: 0.054, Acc: 0.980\n",
      "epoch: 44/300 batch  73/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 44/300 batch  74/188  Train Loss: 0.061, Acc: 0.977\n",
      "epoch: 44/300 batch  75/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 44/300 batch  76/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 44/300 batch  77/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 44/300 batch  78/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 44/300 batch  79/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 44/300 batch  80/188  Train Loss: 0.026, Acc: 0.988\n",
      "epoch: 44/300 batch  81/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 44/300 batch  82/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 44/300 batch  83/188  Train Loss: 0.088, Acc: 0.969\n",
      "epoch: 44/300 batch  84/188  Train Loss: 0.051, Acc: 0.980\n",
      "epoch: 44/300 batch  85/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 44/300 batch  86/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 44/300 batch  87/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 44/300 batch  88/188  Train Loss: 0.044, Acc: 0.996\n",
      "epoch: 44/300 batch  89/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 44/300 batch  90/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 44/300 batch  91/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 44/300 batch  92/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 44/300 batch  93/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 44/300 batch  94/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 44/300 batch  95/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 44/300 batch  96/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 44/300 batch  97/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 44/300 batch  98/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 44/300 batch  99/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 44/300 batch 100/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 44/300 batch 101/188  Train Loss: 0.063, Acc: 0.988\n",
      "epoch: 44/300 batch 102/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 44/300 batch 103/188  Train Loss: 0.060, Acc: 0.977\n",
      "epoch: 44/300 batch 104/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 44/300 batch 105/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 44/300 batch 106/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 44/300 batch 107/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 44/300 batch 108/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 44/300 batch 109/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 44/300 batch 110/188  Train Loss: 0.062, Acc: 0.980\n",
      "epoch: 44/300 batch 111/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 44/300 batch 112/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 44/300 batch 113/188  Train Loss: 0.057, Acc: 0.977\n",
      "epoch: 44/300 batch 114/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 44/300 batch 115/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 44/300 batch 116/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 44/300 batch 117/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 44/300 batch 118/188  Train Loss: 0.055, Acc: 0.992\n",
      "epoch: 44/300 batch 119/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 44/300 batch 120/188  Train Loss: 0.056, Acc: 0.988\n",
      "epoch: 44/300 batch 121/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 44/300 batch 122/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 44/300 batch 123/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 44/300 batch 124/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 44/300 batch 125/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 44/300 batch 126/188  Train Loss: 0.072, Acc: 0.988\n",
      "epoch: 44/300 batch 127/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 44/300 batch 128/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 44/300 batch 129/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 44/300 batch 130/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 44/300 batch 131/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 44/300 batch 132/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 44/300 batch 133/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 44/300 batch 134/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 44/300 batch 135/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 44/300 batch 136/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 44/300 batch 137/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 44/300 batch 138/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 44/300 batch 139/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 44/300 batch 140/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 44/300 batch 141/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 44/300 batch 142/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 44/300 batch 143/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 44/300 batch 144/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 44/300 batch 145/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 44/300 batch 146/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 44/300 batch 147/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 44/300 batch 148/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 44/300 batch 149/188  Train Loss: 0.047, Acc: 0.980\n",
      "epoch: 44/300 batch 150/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 44/300 batch 151/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 44/300 batch 152/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 44/300 batch 153/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 44/300 batch 154/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 44/300 batch 155/188  Train Loss: 0.015, Acc: 0.996\n",
      "epoch: 44/300 batch 156/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 44/300 batch 157/188  Train Loss: 0.059, Acc: 0.992\n",
      "epoch: 44/300 batch 158/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 44/300 batch 159/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 44/300 batch 160/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 44/300 batch 161/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 44/300 batch 162/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 44/300 batch 163/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 44/300 batch 164/188  Train Loss: 0.046, Acc: 0.980\n",
      "epoch: 44/300 batch 165/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 44/300 batch 166/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 44/300 batch 167/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 44/300 batch 168/188  Train Loss: 0.052, Acc: 0.992\n",
      "epoch: 44/300 batch 169/188  Train Loss: 0.069, Acc: 0.980\n",
      "epoch: 44/300 batch 170/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 44/300 batch 171/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 44/300 batch 172/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 44/300 batch 173/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 44/300 batch 174/188  Train Loss: 0.057, Acc: 0.992\n",
      "epoch: 44/300 batch 175/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 44/300 batch 176/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 44/300 batch 177/188  Train Loss: 0.089, Acc: 0.977\n",
      "epoch: 44/300 batch 178/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 44/300 batch 179/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 44/300 batch 180/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 44/300 batch 181/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 44/300 batch 182/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 44/300 batch 183/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 44/300 batch 184/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 44/300 batch 185/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 44/300 batch 186/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 44/300 batch 187/188  Train Loss: 0.045, Acc: 0.992\n",
      "Train Loss: 0.037197, Acc: 0.991\n",
      "Val Loss: 0.057947, Acc: 0.982\n",
      "epoch: 45/300 batch   0/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 45/300 batch   1/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 45/300 batch   2/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 45/300 batch   3/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 45/300 batch   4/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 45/300 batch   5/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 45/300 batch   6/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 45/300 batch   7/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 45/300 batch   8/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 45/300 batch   9/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 45/300 batch  10/188  Train Loss: 0.060, Acc: 0.980\n",
      "epoch: 45/300 batch  11/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 45/300 batch  12/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 45/300 batch  13/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 45/300 batch  14/188  Train Loss: 0.063, Acc: 0.984\n",
      "epoch: 45/300 batch  15/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 45/300 batch  16/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 45/300 batch  17/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 45/300 batch  18/188  Train Loss: 0.064, Acc: 0.988\n",
      "epoch: 45/300 batch  19/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 45/300 batch  20/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 45/300 batch  21/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 45/300 batch  22/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 45/300 batch  23/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 45/300 batch  24/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 45/300 batch  25/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 45/300 batch  26/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 45/300 batch  27/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 45/300 batch  28/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 45/300 batch  29/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 45/300 batch  30/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 45/300 batch  31/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 45/300 batch  32/188  Train Loss: 0.063, Acc: 0.988\n",
      "epoch: 45/300 batch  33/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 45/300 batch  34/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 45/300 batch  35/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 45/300 batch  36/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 45/300 batch  37/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 45/300 batch  38/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 45/300 batch  39/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 45/300 batch  40/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 45/300 batch  41/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 45/300 batch  42/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 45/300 batch  43/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 45/300 batch  44/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 45/300 batch  45/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 45/300 batch  46/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 45/300 batch  47/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 45/300 batch  48/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 45/300 batch  49/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 45/300 batch  50/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 45/300 batch  51/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 45/300 batch  52/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 45/300 batch  53/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 45/300 batch  54/188  Train Loss: 0.062, Acc: 0.977\n",
      "epoch: 45/300 batch  55/188  Train Loss: 0.056, Acc: 0.992\n",
      "epoch: 45/300 batch  56/188  Train Loss: 0.062, Acc: 0.992\n",
      "epoch: 45/300 batch  57/188  Train Loss: 0.025, Acc: 0.988\n",
      "epoch: 45/300 batch  58/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 45/300 batch  59/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 45/300 batch  60/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 45/300 batch  61/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 45/300 batch  62/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 45/300 batch  63/188  Train Loss: 0.078, Acc: 0.984\n",
      "epoch: 45/300 batch  64/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 45/300 batch  65/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 45/300 batch  66/188  Train Loss: 0.053, Acc: 0.980\n",
      "epoch: 45/300 batch  67/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 45/300 batch  68/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 45/300 batch  69/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 45/300 batch  70/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 45/300 batch  71/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 45/300 batch  72/188  Train Loss: 0.045, Acc: 0.996\n",
      "epoch: 45/300 batch  73/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 45/300 batch  74/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 45/300 batch  75/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 45/300 batch  76/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 45/300 batch  77/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 45/300 batch  78/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 45/300 batch  79/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 45/300 batch  80/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 45/300 batch  81/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 45/300 batch  82/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 45/300 batch  83/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 45/300 batch  84/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 45/300 batch  85/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 45/300 batch  86/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 45/300 batch  87/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 45/300 batch  88/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 45/300 batch  89/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 45/300 batch  90/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 45/300 batch  91/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 45/300 batch  92/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 45/300 batch  93/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 45/300 batch  94/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 45/300 batch  95/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 45/300 batch  96/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 45/300 batch  97/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 45/300 batch  98/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 45/300 batch  99/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 45/300 batch 100/188  Train Loss: 0.088, Acc: 0.969\n",
      "epoch: 45/300 batch 101/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 45/300 batch 102/188  Train Loss: 0.042, Acc: 0.996\n",
      "epoch: 45/300 batch 103/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 45/300 batch 104/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 45/300 batch 105/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 45/300 batch 106/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 45/300 batch 107/188  Train Loss: 0.065, Acc: 0.980\n",
      "epoch: 45/300 batch 108/188  Train Loss: 0.051, Acc: 0.973\n",
      "epoch: 45/300 batch 109/188  Train Loss: 0.041, Acc: 0.977\n",
      "epoch: 45/300 batch 110/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 45/300 batch 111/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 45/300 batch 112/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 45/300 batch 113/188  Train Loss: 0.056, Acc: 0.996\n",
      "epoch: 45/300 batch 114/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 45/300 batch 115/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 45/300 batch 116/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 45/300 batch 117/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 45/300 batch 118/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 45/300 batch 119/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 45/300 batch 120/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 45/300 batch 121/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 45/300 batch 122/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 45/300 batch 123/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 45/300 batch 124/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 45/300 batch 125/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 45/300 batch 126/188  Train Loss: 0.047, Acc: 0.980\n",
      "epoch: 45/300 batch 127/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 45/300 batch 128/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 45/300 batch 129/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 45/300 batch 130/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 45/300 batch 131/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 45/300 batch 132/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 45/300 batch 133/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 45/300 batch 134/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 45/300 batch 135/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 45/300 batch 136/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 45/300 batch 137/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 45/300 batch 138/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 45/300 batch 139/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 45/300 batch 140/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 45/300 batch 141/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 45/300 batch 142/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 45/300 batch 143/188  Train Loss: 0.060, Acc: 0.988\n",
      "epoch: 45/300 batch 144/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 45/300 batch 145/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 45/300 batch 146/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 45/300 batch 147/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 45/300 batch 148/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 45/300 batch 149/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 45/300 batch 150/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 45/300 batch 151/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 45/300 batch 152/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 45/300 batch 153/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 45/300 batch 154/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 45/300 batch 155/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 45/300 batch 156/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 45/300 batch 157/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 45/300 batch 158/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 45/300 batch 159/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 45/300 batch 160/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 45/300 batch 161/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 45/300 batch 162/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 45/300 batch 163/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 45/300 batch 164/188  Train Loss: 0.083, Acc: 0.977\n",
      "epoch: 45/300 batch 165/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 45/300 batch 166/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 45/300 batch 167/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 45/300 batch 168/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 45/300 batch 169/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 45/300 batch 170/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 45/300 batch 171/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 45/300 batch 172/188  Train Loss: 0.061, Acc: 0.977\n",
      "epoch: 45/300 batch 173/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 45/300 batch 174/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 45/300 batch 175/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 45/300 batch 176/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 45/300 batch 177/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 45/300 batch 178/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 45/300 batch 179/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 45/300 batch 180/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 45/300 batch 181/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 45/300 batch 182/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 45/300 batch 183/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 45/300 batch 184/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 45/300 batch 185/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 45/300 batch 186/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 45/300 batch 187/188  Train Loss: 0.042, Acc: 0.992\n",
      "Train Loss: 0.037167, Acc: 0.991\n",
      "Val Loss: 0.057893, Acc: 0.982\n",
      "epoch: 46/300 batch   0/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 46/300 batch   1/188  Train Loss: 0.015, Acc: 0.996\n",
      "epoch: 46/300 batch   2/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 46/300 batch   3/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 46/300 batch   4/188  Train Loss: 0.060, Acc: 0.992\n",
      "epoch: 46/300 batch   5/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 46/300 batch   6/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 46/300 batch   7/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 46/300 batch   8/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 46/300 batch   9/188  Train Loss: 0.057, Acc: 0.980\n",
      "epoch: 46/300 batch  10/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 46/300 batch  11/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 46/300 batch  12/188  Train Loss: 0.066, Acc: 0.980\n",
      "epoch: 46/300 batch  13/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 46/300 batch  14/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 46/300 batch  15/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 46/300 batch  16/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 46/300 batch  17/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 46/300 batch  18/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 46/300 batch  19/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 46/300 batch  20/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 46/300 batch  21/188  Train Loss: 0.040, Acc: 0.980\n",
      "epoch: 46/300 batch  22/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 46/300 batch  23/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 46/300 batch  24/188  Train Loss: 0.044, Acc: 0.996\n",
      "epoch: 46/300 batch  25/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 46/300 batch  26/188  Train Loss: 0.061, Acc: 0.988\n",
      "epoch: 46/300 batch  27/188  Train Loss: 0.072, Acc: 0.980\n",
      "epoch: 46/300 batch  28/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 46/300 batch  29/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 46/300 batch  30/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 46/300 batch  31/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 46/300 batch  32/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 46/300 batch  33/188  Train Loss: 0.061, Acc: 0.988\n",
      "epoch: 46/300 batch  34/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 46/300 batch  35/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 46/300 batch  36/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 46/300 batch  37/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 46/300 batch  38/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 46/300 batch  39/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 46/300 batch  40/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 46/300 batch  41/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 46/300 batch  42/188  Train Loss: 0.049, Acc: 0.980\n",
      "epoch: 46/300 batch  43/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 46/300 batch  44/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 46/300 batch  45/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 46/300 batch  46/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 46/300 batch  47/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 46/300 batch  48/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 46/300 batch  49/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 46/300 batch  50/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 46/300 batch  51/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 46/300 batch  52/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 46/300 batch  53/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 46/300 batch  54/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 46/300 batch  55/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 46/300 batch  56/188  Train Loss: 0.070, Acc: 0.980\n",
      "epoch: 46/300 batch  57/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 46/300 batch  58/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 46/300 batch  59/188  Train Loss: 0.052, Acc: 0.980\n",
      "epoch: 46/300 batch  60/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 46/300 batch  61/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 46/300 batch  62/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 46/300 batch  63/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 46/300 batch  64/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 46/300 batch  65/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 46/300 batch  66/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 46/300 batch  67/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 46/300 batch  68/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 46/300 batch  69/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 46/300 batch  70/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 46/300 batch  71/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 46/300 batch  72/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 46/300 batch  73/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 46/300 batch  74/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 46/300 batch  75/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 46/300 batch  76/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 46/300 batch  77/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 46/300 batch  78/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 46/300 batch  79/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 46/300 batch  80/188  Train Loss: 0.062, Acc: 0.984\n",
      "epoch: 46/300 batch  81/188  Train Loss: 0.061, Acc: 0.984\n",
      "epoch: 46/300 batch  82/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 46/300 batch  83/188  Train Loss: 0.053, Acc: 0.992\n",
      "epoch: 46/300 batch  84/188  Train Loss: 0.063, Acc: 0.992\n",
      "epoch: 46/300 batch  85/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 46/300 batch  86/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 46/300 batch  87/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 46/300 batch  88/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 46/300 batch  89/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 46/300 batch  90/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 46/300 batch  91/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 46/300 batch  92/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 46/300 batch  93/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 46/300 batch  94/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 46/300 batch  95/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 46/300 batch  96/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 46/300 batch  97/188  Train Loss: 0.075, Acc: 0.984\n",
      "epoch: 46/300 batch  98/188  Train Loss: 0.061, Acc: 0.984\n",
      "epoch: 46/300 batch  99/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 46/300 batch 100/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 46/300 batch 101/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 46/300 batch 102/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 46/300 batch 103/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 46/300 batch 104/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 46/300 batch 105/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 46/300 batch 106/188  Train Loss: 0.062, Acc: 0.988\n",
      "epoch: 46/300 batch 107/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 46/300 batch 108/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 46/300 batch 109/188  Train Loss: 0.060, Acc: 0.980\n",
      "epoch: 46/300 batch 110/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 46/300 batch 111/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 46/300 batch 112/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 46/300 batch 113/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 46/300 batch 114/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 46/300 batch 115/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 46/300 batch 116/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 46/300 batch 117/188  Train Loss: 0.050, Acc: 0.980\n",
      "epoch: 46/300 batch 118/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 46/300 batch 119/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 46/300 batch 120/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 46/300 batch 121/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 46/300 batch 122/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 46/300 batch 123/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 46/300 batch 124/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 46/300 batch 125/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 46/300 batch 126/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 46/300 batch 127/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 46/300 batch 128/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 46/300 batch 129/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 46/300 batch 130/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 46/300 batch 131/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 46/300 batch 132/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 46/300 batch 133/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 46/300 batch 134/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 46/300 batch 135/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 46/300 batch 136/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 46/300 batch 137/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 46/300 batch 138/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 46/300 batch 139/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 46/300 batch 140/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 46/300 batch 141/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 46/300 batch 142/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 46/300 batch 143/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 46/300 batch 144/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 46/300 batch 145/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 46/300 batch 146/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 46/300 batch 147/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 46/300 batch 148/188  Train Loss: 0.058, Acc: 0.977\n",
      "epoch: 46/300 batch 149/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 46/300 batch 150/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 46/300 batch 151/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 46/300 batch 152/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 46/300 batch 153/188  Train Loss: 0.074, Acc: 0.988\n",
      "epoch: 46/300 batch 154/188  Train Loss: 0.045, Acc: 0.996\n",
      "epoch: 46/300 batch 155/188  Train Loss: 0.065, Acc: 0.977\n",
      "epoch: 46/300 batch 156/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 46/300 batch 157/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 46/300 batch 158/188  Train Loss: 0.068, Acc: 0.980\n",
      "epoch: 46/300 batch 159/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 46/300 batch 160/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 46/300 batch 161/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 46/300 batch 162/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 46/300 batch 163/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 46/300 batch 164/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 46/300 batch 165/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 46/300 batch 166/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 46/300 batch 167/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 46/300 batch 168/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 46/300 batch 169/188  Train Loss: 0.066, Acc: 0.988\n",
      "epoch: 46/300 batch 170/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 46/300 batch 171/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 46/300 batch 172/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 46/300 batch 173/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 46/300 batch 174/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 46/300 batch 175/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 46/300 batch 176/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 46/300 batch 177/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 46/300 batch 178/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 46/300 batch 179/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 46/300 batch 180/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 46/300 batch 181/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 46/300 batch 182/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 46/300 batch 183/188  Train Loss: 0.055, Acc: 0.980\n",
      "epoch: 46/300 batch 184/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 46/300 batch 185/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 46/300 batch 186/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 46/300 batch 187/188  Train Loss: 0.025, Acc: 0.992\n",
      "Train Loss: 0.037104, Acc: 0.991\n",
      "Val Loss: 0.057877, Acc: 0.982\n",
      "epoch: 47/300 batch   0/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 47/300 batch   1/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 47/300 batch   2/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 47/300 batch   3/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 47/300 batch   4/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 47/300 batch   5/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 47/300 batch   6/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 47/300 batch   7/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 47/300 batch   8/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 47/300 batch   9/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 47/300 batch  10/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 47/300 batch  11/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 47/300 batch  12/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 47/300 batch  13/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 47/300 batch  14/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 47/300 batch  15/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 47/300 batch  16/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 47/300 batch  17/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 47/300 batch  18/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 47/300 batch  19/188  Train Loss: 0.039, Acc: 0.977\n",
      "epoch: 47/300 batch  20/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 47/300 batch  21/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 47/300 batch  22/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 47/300 batch  23/188  Train Loss: 0.059, Acc: 0.980\n",
      "epoch: 47/300 batch  24/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 47/300 batch  25/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 47/300 batch  26/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 47/300 batch  27/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 47/300 batch  28/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 47/300 batch  29/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 47/300 batch  30/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 47/300 batch  31/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 47/300 batch  32/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 47/300 batch  33/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 47/300 batch  34/188  Train Loss: 0.072, Acc: 0.984\n",
      "epoch: 47/300 batch  35/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 47/300 batch  36/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 47/300 batch  37/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 47/300 batch  38/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 47/300 batch  39/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 47/300 batch  40/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 47/300 batch  41/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 47/300 batch  42/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 47/300 batch  43/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 47/300 batch  44/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 47/300 batch  45/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 47/300 batch  46/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 47/300 batch  47/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 47/300 batch  48/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 47/300 batch  49/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 47/300 batch  50/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 47/300 batch  51/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 47/300 batch  52/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 47/300 batch  53/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 47/300 batch  54/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 47/300 batch  55/188  Train Loss: 0.061, Acc: 0.988\n",
      "epoch: 47/300 batch  56/188  Train Loss: 0.015, Acc: 0.996\n",
      "epoch: 47/300 batch  57/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 47/300 batch  58/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 47/300 batch  59/188  Train Loss: 0.065, Acc: 0.980\n",
      "epoch: 47/300 batch  60/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 47/300 batch  61/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 47/300 batch  62/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 47/300 batch  63/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 47/300 batch  64/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 47/300 batch  65/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 47/300 batch  66/188  Train Loss: 0.015, Acc: 0.996\n",
      "epoch: 47/300 batch  67/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 47/300 batch  68/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 47/300 batch  69/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 47/300 batch  70/188  Train Loss: 0.056, Acc: 0.980\n",
      "epoch: 47/300 batch  71/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 47/300 batch  72/188  Train Loss: 0.057, Acc: 0.996\n",
      "epoch: 47/300 batch  73/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 47/300 batch  74/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 47/300 batch  75/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 47/300 batch  76/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 47/300 batch  77/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 47/300 batch  78/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 47/300 batch  79/188  Train Loss: 0.043, Acc: 0.980\n",
      "epoch: 47/300 batch  80/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 47/300 batch  81/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 47/300 batch  82/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 47/300 batch  83/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 47/300 batch  84/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 47/300 batch  85/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 47/300 batch  86/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 47/300 batch  87/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 47/300 batch  88/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 47/300 batch  89/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 47/300 batch  90/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 47/300 batch  91/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 47/300 batch  92/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 47/300 batch  93/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 47/300 batch  94/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 47/300 batch  95/188  Train Loss: 0.061, Acc: 0.977\n",
      "epoch: 47/300 batch  96/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 47/300 batch  97/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 47/300 batch  98/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 47/300 batch  99/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 47/300 batch 100/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 47/300 batch 101/188  Train Loss: 0.054, Acc: 0.996\n",
      "epoch: 47/300 batch 102/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 47/300 batch 103/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 47/300 batch 104/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 47/300 batch 105/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 47/300 batch 106/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 47/300 batch 107/188  Train Loss: 0.071, Acc: 0.984\n",
      "epoch: 47/300 batch 108/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 47/300 batch 109/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 47/300 batch 110/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 47/300 batch 111/188  Train Loss: 0.049, Acc: 0.980\n",
      "epoch: 47/300 batch 112/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 47/300 batch 113/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 47/300 batch 114/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 47/300 batch 115/188  Train Loss: 0.067, Acc: 0.980\n",
      "epoch: 47/300 batch 116/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 47/300 batch 117/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 47/300 batch 118/188  Train Loss: 0.049, Acc: 0.996\n",
      "epoch: 47/300 batch 119/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 47/300 batch 120/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 47/300 batch 121/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 47/300 batch 122/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 47/300 batch 123/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 47/300 batch 124/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 47/300 batch 125/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 47/300 batch 126/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 47/300 batch 127/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 47/300 batch 128/188  Train Loss: 0.058, Acc: 0.988\n",
      "epoch: 47/300 batch 129/188  Train Loss: 0.041, Acc: 0.980\n",
      "epoch: 47/300 batch 130/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 47/300 batch 131/188  Train Loss: 0.069, Acc: 0.984\n",
      "epoch: 47/300 batch 132/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 47/300 batch 133/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 47/300 batch 134/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 47/300 batch 135/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 47/300 batch 136/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 47/300 batch 137/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 47/300 batch 138/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 47/300 batch 139/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 47/300 batch 140/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 47/300 batch 141/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 47/300 batch 142/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 47/300 batch 143/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 47/300 batch 144/188  Train Loss: 0.060, Acc: 0.988\n",
      "epoch: 47/300 batch 145/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 47/300 batch 146/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 47/300 batch 147/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 47/300 batch 148/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 47/300 batch 149/188  Train Loss: 0.062, Acc: 0.992\n",
      "epoch: 47/300 batch 150/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 47/300 batch 151/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 47/300 batch 152/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 47/300 batch 153/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 47/300 batch 154/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 47/300 batch 155/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 47/300 batch 156/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 47/300 batch 157/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 47/300 batch 158/188  Train Loss: 0.051, Acc: 0.992\n",
      "epoch: 47/300 batch 159/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 47/300 batch 160/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 47/300 batch 161/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 47/300 batch 162/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 47/300 batch 163/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 47/300 batch 164/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 47/300 batch 165/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 47/300 batch 166/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 47/300 batch 167/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 47/300 batch 168/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 47/300 batch 169/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 47/300 batch 170/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 47/300 batch 171/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 47/300 batch 172/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 47/300 batch 173/188  Train Loss: 0.056, Acc: 0.988\n",
      "epoch: 47/300 batch 174/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 47/300 batch 175/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 47/300 batch 176/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 47/300 batch 177/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 47/300 batch 178/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 47/300 batch 179/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 47/300 batch 180/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 47/300 batch 181/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 47/300 batch 182/188  Train Loss: 0.057, Acc: 0.980\n",
      "epoch: 47/300 batch 183/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 47/300 batch 184/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 47/300 batch 185/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 47/300 batch 186/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 47/300 batch 187/188  Train Loss: 0.038, Acc: 0.992\n",
      "Train Loss: 0.037099, Acc: 0.992\n",
      "Val Loss: 0.058048, Acc: 0.982\n",
      "epoch: 48/300 batch   0/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 48/300 batch   1/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 48/300 batch   2/188  Train Loss: 0.055, Acc: 0.980\n",
      "epoch: 48/300 batch   3/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 48/300 batch   4/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 48/300 batch   5/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 48/300 batch   6/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 48/300 batch   7/188  Train Loss: 0.061, Acc: 0.988\n",
      "epoch: 48/300 batch   8/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 48/300 batch   9/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 48/300 batch  10/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 48/300 batch  11/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 48/300 batch  12/188  Train Loss: 0.058, Acc: 0.980\n",
      "epoch: 48/300 batch  13/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 48/300 batch  14/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 48/300 batch  15/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 48/300 batch  16/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 48/300 batch  17/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 48/300 batch  18/188  Train Loss: 0.081, Acc: 0.984\n",
      "epoch: 48/300 batch  19/188  Train Loss: 0.060, Acc: 0.992\n",
      "epoch: 48/300 batch  20/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 48/300 batch  21/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 48/300 batch  22/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 48/300 batch  23/188  Train Loss: 0.056, Acc: 0.992\n",
      "epoch: 48/300 batch  24/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 48/300 batch  25/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 48/300 batch  26/188  Train Loss: 0.053, Acc: 0.980\n",
      "epoch: 48/300 batch  27/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 48/300 batch  28/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 48/300 batch  29/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 48/300 batch  30/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 48/300 batch  31/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 48/300 batch  32/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 48/300 batch  33/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 48/300 batch  34/188  Train Loss: 0.061, Acc: 0.984\n",
      "epoch: 48/300 batch  35/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 48/300 batch  36/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 48/300 batch  37/188  Train Loss: 0.039, Acc: 0.980\n",
      "epoch: 48/300 batch  38/188  Train Loss: 0.047, Acc: 0.996\n",
      "epoch: 48/300 batch  39/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 48/300 batch  40/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 48/300 batch  41/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 48/300 batch  42/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 48/300 batch  43/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 48/300 batch  44/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 48/300 batch  45/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 48/300 batch  46/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 48/300 batch  47/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 48/300 batch  48/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 48/300 batch  49/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 48/300 batch  50/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 48/300 batch  51/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 48/300 batch  52/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 48/300 batch  53/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 48/300 batch  54/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 48/300 batch  55/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 48/300 batch  56/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 48/300 batch  57/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 48/300 batch  58/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 48/300 batch  59/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 48/300 batch  60/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 48/300 batch  61/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 48/300 batch  62/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 48/300 batch  63/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 48/300 batch  64/188  Train Loss: 0.057, Acc: 0.980\n",
      "epoch: 48/300 batch  65/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 48/300 batch  66/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 48/300 batch  67/188  Train Loss: 0.066, Acc: 0.977\n",
      "epoch: 48/300 batch  68/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 48/300 batch  69/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 48/300 batch  70/188  Train Loss: 0.053, Acc: 0.980\n",
      "epoch: 48/300 batch  71/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 48/300 batch  72/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 48/300 batch  73/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 48/300 batch  74/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 48/300 batch  75/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 48/300 batch  76/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 48/300 batch  77/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 48/300 batch  78/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 48/300 batch  79/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 48/300 batch  80/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 48/300 batch  81/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 48/300 batch  82/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 48/300 batch  83/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 48/300 batch  84/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 48/300 batch  85/188  Train Loss: 0.044, Acc: 0.996\n",
      "epoch: 48/300 batch  86/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 48/300 batch  87/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 48/300 batch  88/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 48/300 batch  89/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 48/300 batch  90/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 48/300 batch  91/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 48/300 batch  92/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 48/300 batch  93/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 48/300 batch  94/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 48/300 batch  95/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 48/300 batch  96/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 48/300 batch  97/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 48/300 batch  98/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 48/300 batch  99/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 48/300 batch 100/188  Train Loss: 0.055, Acc: 0.973\n",
      "epoch: 48/300 batch 101/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 48/300 batch 102/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 48/300 batch 103/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 48/300 batch 104/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 48/300 batch 105/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 48/300 batch 106/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 48/300 batch 107/188  Train Loss: 0.044, Acc: 0.996\n",
      "epoch: 48/300 batch 108/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 48/300 batch 109/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 48/300 batch 110/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 48/300 batch 111/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 48/300 batch 112/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 48/300 batch 113/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 48/300 batch 114/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 48/300 batch 115/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 48/300 batch 116/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 48/300 batch 117/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 48/300 batch 118/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 48/300 batch 119/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 48/300 batch 120/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 48/300 batch 121/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 48/300 batch 122/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 48/300 batch 123/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 48/300 batch 124/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 48/300 batch 125/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 48/300 batch 126/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 48/300 batch 127/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 48/300 batch 128/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 48/300 batch 129/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 48/300 batch 130/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 48/300 batch 131/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 48/300 batch 132/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 48/300 batch 133/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 48/300 batch 134/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 48/300 batch 135/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 48/300 batch 136/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 48/300 batch 137/188  Train Loss: 0.071, Acc: 0.980\n",
      "epoch: 48/300 batch 138/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 48/300 batch 139/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 48/300 batch 140/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 48/300 batch 141/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 48/300 batch 142/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 48/300 batch 143/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 48/300 batch 144/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 48/300 batch 145/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 48/300 batch 146/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 48/300 batch 147/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 48/300 batch 148/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 48/300 batch 149/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 48/300 batch 150/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 48/300 batch 151/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 48/300 batch 152/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 48/300 batch 153/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 48/300 batch 154/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 48/300 batch 155/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 48/300 batch 156/188  Train Loss: 0.054, Acc: 0.996\n",
      "epoch: 48/300 batch 157/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 48/300 batch 158/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 48/300 batch 159/188  Train Loss: 0.059, Acc: 0.984\n",
      "epoch: 48/300 batch 160/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 48/300 batch 161/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 48/300 batch 162/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 48/300 batch 163/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 48/300 batch 164/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 48/300 batch 165/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 48/300 batch 166/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 48/300 batch 167/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 48/300 batch 168/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 48/300 batch 169/188  Train Loss: 0.080, Acc: 0.988\n",
      "epoch: 48/300 batch 170/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 48/300 batch 171/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 48/300 batch 172/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 48/300 batch 173/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 48/300 batch 174/188  Train Loss: 0.064, Acc: 0.984\n",
      "epoch: 48/300 batch 175/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 48/300 batch 176/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 48/300 batch 177/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 48/300 batch 178/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 48/300 batch 179/188  Train Loss: 0.062, Acc: 0.984\n",
      "epoch: 48/300 batch 180/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 48/300 batch 181/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 48/300 batch 182/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 48/300 batch 183/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 48/300 batch 184/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 48/300 batch 185/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 48/300 batch 186/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 48/300 batch 187/188  Train Loss: 0.096, Acc: 0.969\n",
      "Train Loss: 0.037194, Acc: 0.992\n",
      "Val Loss: 0.057858, Acc: 0.982\n",
      "epoch: 49/300 batch   0/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 49/300 batch   1/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 49/300 batch   2/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 49/300 batch   3/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 49/300 batch   4/188  Train Loss: 0.052, Acc: 0.992\n",
      "epoch: 49/300 batch   5/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 49/300 batch   6/188  Train Loss: 0.054, Acc: 0.980\n",
      "epoch: 49/300 batch   7/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 49/300 batch   8/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 49/300 batch   9/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 49/300 batch  10/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 49/300 batch  11/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 49/300 batch  12/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 49/300 batch  13/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 49/300 batch  14/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 49/300 batch  15/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 49/300 batch  16/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 49/300 batch  17/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 49/300 batch  18/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 49/300 batch  19/188  Train Loss: 0.050, Acc: 0.980\n",
      "epoch: 49/300 batch  20/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 49/300 batch  21/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 49/300 batch  22/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 49/300 batch  23/188  Train Loss: 0.076, Acc: 0.973\n",
      "epoch: 49/300 batch  24/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 49/300 batch  25/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 49/300 batch  26/188  Train Loss: 0.044, Acc: 0.996\n",
      "epoch: 49/300 batch  27/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 49/300 batch  28/188  Train Loss: 0.069, Acc: 0.980\n",
      "epoch: 49/300 batch  29/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 49/300 batch  30/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 49/300 batch  31/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 49/300 batch  32/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 49/300 batch  33/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 49/300 batch  34/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 49/300 batch  35/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 49/300 batch  36/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 49/300 batch  37/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 49/300 batch  38/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 49/300 batch  39/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 49/300 batch  40/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 49/300 batch  41/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 49/300 batch  42/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 49/300 batch  43/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 49/300 batch  44/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 49/300 batch  45/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 49/300 batch  46/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 49/300 batch  47/188  Train Loss: 0.054, Acc: 0.992\n",
      "epoch: 49/300 batch  48/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 49/300 batch  49/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 49/300 batch  50/188  Train Loss: 0.046, Acc: 0.996\n",
      "epoch: 49/300 batch  51/188  Train Loss: 0.059, Acc: 0.980\n",
      "epoch: 49/300 batch  52/188  Train Loss: 0.051, Acc: 0.992\n",
      "epoch: 49/300 batch  53/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 49/300 batch  54/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 49/300 batch  55/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 49/300 batch  56/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 49/300 batch  57/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 49/300 batch  58/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 49/300 batch  59/188  Train Loss: 0.048, Acc: 0.977\n",
      "epoch: 49/300 batch  60/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 49/300 batch  61/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 49/300 batch  62/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 49/300 batch  63/188  Train Loss: 0.053, Acc: 0.980\n",
      "epoch: 49/300 batch  64/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 49/300 batch  65/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 49/300 batch  66/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 49/300 batch  67/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 49/300 batch  68/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 49/300 batch  69/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 49/300 batch  70/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 49/300 batch  71/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 49/300 batch  72/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 49/300 batch  73/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 49/300 batch  74/188  Train Loss: 0.052, Acc: 0.992\n",
      "epoch: 49/300 batch  75/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 49/300 batch  76/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 49/300 batch  77/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 49/300 batch  78/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 49/300 batch  79/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 49/300 batch  80/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 49/300 batch  81/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 49/300 batch  82/188  Train Loss: 0.050, Acc: 0.980\n",
      "epoch: 49/300 batch  83/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 49/300 batch  84/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 49/300 batch  85/188  Train Loss: 0.057, Acc: 0.988\n",
      "epoch: 49/300 batch  86/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 49/300 batch  87/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 49/300 batch  88/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 49/300 batch  89/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 49/300 batch  90/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 49/300 batch  91/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 49/300 batch  92/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 49/300 batch  93/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 49/300 batch  94/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 49/300 batch  95/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 49/300 batch  96/188  Train Loss: 0.053, Acc: 0.980\n",
      "epoch: 49/300 batch  97/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 49/300 batch  98/188  Train Loss: 0.026, Acc: 0.988\n",
      "epoch: 49/300 batch  99/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 49/300 batch 100/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 49/300 batch 101/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 49/300 batch 102/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 49/300 batch 103/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 49/300 batch 104/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 49/300 batch 105/188  Train Loss: 0.060, Acc: 0.988\n",
      "epoch: 49/300 batch 106/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 49/300 batch 107/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 49/300 batch 108/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 49/300 batch 109/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 49/300 batch 110/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 49/300 batch 111/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 49/300 batch 112/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 49/300 batch 113/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 49/300 batch 114/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 49/300 batch 115/188  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 49/300 batch 116/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 49/300 batch 117/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 49/300 batch 118/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 49/300 batch 119/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 49/300 batch 120/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 49/300 batch 121/188  Train Loss: 0.048, Acc: 0.980\n",
      "epoch: 49/300 batch 122/188  Train Loss: 0.062, Acc: 0.984\n",
      "epoch: 49/300 batch 123/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 49/300 batch 124/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 49/300 batch 125/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 49/300 batch 126/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 49/300 batch 127/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 49/300 batch 128/188  Train Loss: 0.044, Acc: 0.996\n",
      "epoch: 49/300 batch 129/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 49/300 batch 130/188  Train Loss: 0.066, Acc: 0.984\n",
      "epoch: 49/300 batch 131/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 49/300 batch 132/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 49/300 batch 133/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 49/300 batch 134/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 49/300 batch 135/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 49/300 batch 136/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 49/300 batch 137/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 49/300 batch 138/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 49/300 batch 139/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 49/300 batch 140/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 49/300 batch 141/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 49/300 batch 142/188  Train Loss: 0.061, Acc: 0.980\n",
      "epoch: 49/300 batch 143/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 49/300 batch 144/188  Train Loss: 0.039, Acc: 0.977\n",
      "epoch: 49/300 batch 145/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 49/300 batch 146/188  Train Loss: 0.084, Acc: 0.980\n",
      "epoch: 49/300 batch 147/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 49/300 batch 148/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 49/300 batch 149/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 49/300 batch 150/188  Train Loss: 0.065, Acc: 0.988\n",
      "epoch: 49/300 batch 151/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 49/300 batch 152/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 49/300 batch 153/188  Train Loss: 0.063, Acc: 0.980\n",
      "epoch: 49/300 batch 154/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 49/300 batch 155/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 49/300 batch 156/188  Train Loss: 0.073, Acc: 0.984\n",
      "epoch: 49/300 batch 157/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 49/300 batch 158/188  Train Loss: 0.060, Acc: 0.988\n",
      "epoch: 49/300 batch 159/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 49/300 batch 160/188  Train Loss: 0.057, Acc: 0.980\n",
      "epoch: 49/300 batch 161/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 49/300 batch 162/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 49/300 batch 163/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 49/300 batch 164/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 49/300 batch 165/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 49/300 batch 166/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 49/300 batch 167/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 49/300 batch 168/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 49/300 batch 169/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 49/300 batch 170/188  Train Loss: 0.032, Acc: 1.000\n",
      "epoch: 49/300 batch 171/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 49/300 batch 172/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 49/300 batch 173/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 49/300 batch 174/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 49/300 batch 175/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 49/300 batch 176/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 49/300 batch 177/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 49/300 batch 178/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 49/300 batch 179/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 49/300 batch 180/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 49/300 batch 181/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 49/300 batch 182/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 49/300 batch 183/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 49/300 batch 184/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 49/300 batch 185/188  Train Loss: 0.016, Acc: 0.996\n",
      "epoch: 49/300 batch 186/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 49/300 batch 187/188  Train Loss: 0.032, Acc: 0.992\n",
      "Train Loss: 0.036932, Acc: 0.992\n",
      "Val Loss: 0.057974, Acc: 0.982\n",
      "epoch: 50/300 batch   0/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 50/300 batch   1/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 50/300 batch   2/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 50/300 batch   3/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 50/300 batch   4/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 50/300 batch   5/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 50/300 batch   6/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 50/300 batch   7/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 50/300 batch   8/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 50/300 batch   9/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 50/300 batch  10/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 50/300 batch  11/188  Train Loss: 0.061, Acc: 0.992\n",
      "epoch: 50/300 batch  12/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 50/300 batch  13/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 50/300 batch  14/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 50/300 batch  15/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 50/300 batch  16/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 50/300 batch  17/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 50/300 batch  18/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 50/300 batch  19/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 50/300 batch  20/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 50/300 batch  21/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 50/300 batch  22/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 50/300 batch  23/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 50/300 batch  24/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 50/300 batch  25/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 50/300 batch  26/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 50/300 batch  27/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 50/300 batch  28/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 50/300 batch  29/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 50/300 batch  30/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 50/300 batch  31/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 50/300 batch  32/188  Train Loss: 0.056, Acc: 0.980\n",
      "epoch: 50/300 batch  33/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 50/300 batch  34/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 50/300 batch  35/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 50/300 batch  36/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 50/300 batch  37/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 50/300 batch  38/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 50/300 batch  39/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 50/300 batch  40/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 50/300 batch  41/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 50/300 batch  42/188  Train Loss: 0.063, Acc: 0.977\n",
      "epoch: 50/300 batch  43/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 50/300 batch  44/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 50/300 batch  45/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 50/300 batch  46/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 50/300 batch  47/188  Train Loss: 0.088, Acc: 0.984\n",
      "epoch: 50/300 batch  48/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 50/300 batch  49/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 50/300 batch  50/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 50/300 batch  51/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 50/300 batch  52/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 50/300 batch  53/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 50/300 batch  54/188  Train Loss: 0.056, Acc: 0.977\n",
      "epoch: 50/300 batch  55/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 50/300 batch  56/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 50/300 batch  57/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 50/300 batch  58/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 50/300 batch  59/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 50/300 batch  60/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 50/300 batch  61/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 50/300 batch  62/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 50/300 batch  63/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 50/300 batch  64/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 50/300 batch  65/188  Train Loss: 0.075, Acc: 0.977\n",
      "epoch: 50/300 batch  66/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 50/300 batch  67/188  Train Loss: 0.061, Acc: 0.984\n",
      "epoch: 50/300 batch  68/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 50/300 batch  69/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 50/300 batch  70/188  Train Loss: 0.035, Acc: 1.000\n",
      "epoch: 50/300 batch  71/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 50/300 batch  72/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 50/300 batch  73/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 50/300 batch  74/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 50/300 batch  75/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 50/300 batch  76/188  Train Loss: 0.043, Acc: 0.996\n",
      "epoch: 50/300 batch  77/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 50/300 batch  78/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 50/300 batch  79/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 50/300 batch  80/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 50/300 batch  81/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 50/300 batch  82/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 50/300 batch  83/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 50/300 batch  84/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 50/300 batch  85/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 50/300 batch  86/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 50/300 batch  87/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 50/300 batch  88/188  Train Loss: 0.067, Acc: 0.992\n",
      "epoch: 50/300 batch  89/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 50/300 batch  90/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 50/300 batch  91/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 50/300 batch  92/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 50/300 batch  93/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 50/300 batch  94/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 50/300 batch  95/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 50/300 batch  96/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 50/300 batch  97/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 50/300 batch  98/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 50/300 batch  99/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 50/300 batch 100/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 50/300 batch 101/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 50/300 batch 102/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 50/300 batch 103/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 50/300 batch 104/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 50/300 batch 105/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 50/300 batch 106/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 50/300 batch 107/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 50/300 batch 108/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 50/300 batch 109/188  Train Loss: 0.061, Acc: 0.977\n",
      "epoch: 50/300 batch 110/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 50/300 batch 111/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 50/300 batch 112/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 50/300 batch 113/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 50/300 batch 114/188  Train Loss: 0.039, Acc: 1.000\n",
      "epoch: 50/300 batch 115/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 50/300 batch 116/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 50/300 batch 117/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 50/300 batch 118/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 50/300 batch 119/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 50/300 batch 120/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 50/300 batch 121/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 50/300 batch 122/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 50/300 batch 123/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 50/300 batch 124/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 50/300 batch 125/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 50/300 batch 126/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 50/300 batch 127/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 50/300 batch 128/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 50/300 batch 129/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 50/300 batch 130/188  Train Loss: 0.060, Acc: 0.988\n",
      "epoch: 50/300 batch 131/188  Train Loss: 0.051, Acc: 0.977\n",
      "epoch: 50/300 batch 132/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 50/300 batch 133/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 50/300 batch 134/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 50/300 batch 135/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 50/300 batch 136/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 50/300 batch 137/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 50/300 batch 138/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 50/300 batch 139/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 50/300 batch 140/188  Train Loss: 0.068, Acc: 0.977\n",
      "epoch: 50/300 batch 141/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 50/300 batch 142/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 50/300 batch 143/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 50/300 batch 144/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 50/300 batch 145/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 50/300 batch 146/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 50/300 batch 147/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 50/300 batch 148/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 50/300 batch 149/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 50/300 batch 150/188  Train Loss: 0.040, Acc: 0.980\n",
      "epoch: 50/300 batch 151/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 50/300 batch 152/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 50/300 batch 153/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 50/300 batch 154/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 50/300 batch 155/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 50/300 batch 156/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 50/300 batch 157/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 50/300 batch 158/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 50/300 batch 159/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 50/300 batch 160/188  Train Loss: 0.056, Acc: 0.992\n",
      "epoch: 50/300 batch 161/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 50/300 batch 162/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 50/300 batch 163/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 50/300 batch 164/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 50/300 batch 165/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 50/300 batch 166/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 50/300 batch 167/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 50/300 batch 168/188  Train Loss: 0.014, Acc: 0.996\n",
      "epoch: 50/300 batch 169/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 50/300 batch 170/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 50/300 batch 171/188  Train Loss: 0.045, Acc: 0.980\n",
      "epoch: 50/300 batch 172/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 50/300 batch 173/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 50/300 batch 174/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 50/300 batch 175/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 50/300 batch 176/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 50/300 batch 177/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 50/300 batch 178/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 50/300 batch 179/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 50/300 batch 180/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 50/300 batch 181/188  Train Loss: 0.052, Acc: 0.980\n",
      "epoch: 50/300 batch 182/188  Train Loss: 0.058, Acc: 0.977\n",
      "epoch: 50/300 batch 183/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 50/300 batch 184/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 50/300 batch 185/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 50/300 batch 186/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 50/300 batch 187/188  Train Loss: 0.024, Acc: 0.992\n",
      "Train Loss: 0.036954, Acc: 0.992\n",
      "Val Loss: 0.058161, Acc: 0.982\n",
      "epoch: 51/300 batch   0/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 51/300 batch   1/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 51/300 batch   2/188  Train Loss: 0.045, Acc: 0.977\n",
      "epoch: 51/300 batch   3/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 51/300 batch   4/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 51/300 batch   5/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 51/300 batch   6/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 51/300 batch   7/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 51/300 batch   8/188  Train Loss: 0.057, Acc: 0.988\n",
      "epoch: 51/300 batch   9/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 51/300 batch  10/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 51/300 batch  11/188  Train Loss: 0.026, Acc: 0.988\n",
      "epoch: 51/300 batch  12/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 51/300 batch  13/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 51/300 batch  14/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 51/300 batch  15/188  Train Loss: 0.065, Acc: 0.988\n",
      "epoch: 51/300 batch  16/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 51/300 batch  17/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 51/300 batch  18/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 51/300 batch  19/188  Train Loss: 0.046, Acc: 0.996\n",
      "epoch: 51/300 batch  20/188  Train Loss: 0.056, Acc: 0.988\n",
      "epoch: 51/300 batch  21/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 51/300 batch  22/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 51/300 batch  23/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 51/300 batch  24/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 51/300 batch  25/188  Train Loss: 0.082, Acc: 0.973\n",
      "epoch: 51/300 batch  26/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 51/300 batch  27/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 51/300 batch  28/188  Train Loss: 0.042, Acc: 0.980\n",
      "epoch: 51/300 batch  29/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 51/300 batch  30/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 51/300 batch  31/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 51/300 batch  32/188  Train Loss: 0.061, Acc: 0.992\n",
      "epoch: 51/300 batch  33/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 51/300 batch  34/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 51/300 batch  35/188  Train Loss: 0.069, Acc: 0.984\n",
      "epoch: 51/300 batch  36/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 51/300 batch  37/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 51/300 batch  38/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 51/300 batch  39/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 51/300 batch  40/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 51/300 batch  41/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 51/300 batch  42/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 51/300 batch  43/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 51/300 batch  44/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 51/300 batch  45/188  Train Loss: 0.025, Acc: 0.988\n",
      "epoch: 51/300 batch  46/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 51/300 batch  47/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 51/300 batch  48/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 51/300 batch  49/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 51/300 batch  50/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 51/300 batch  51/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 51/300 batch  52/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 51/300 batch  53/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 51/300 batch  54/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 51/300 batch  55/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 51/300 batch  56/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 51/300 batch  57/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 51/300 batch  58/188  Train Loss: 0.072, Acc: 0.977\n",
      "epoch: 51/300 batch  59/188  Train Loss: 0.045, Acc: 0.996\n",
      "epoch: 51/300 batch  60/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 51/300 batch  61/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 51/300 batch  62/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 51/300 batch  63/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 51/300 batch  64/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 51/300 batch  65/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 51/300 batch  66/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 51/300 batch  67/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 51/300 batch  68/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 51/300 batch  69/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 51/300 batch  70/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 51/300 batch  71/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 51/300 batch  72/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 51/300 batch  73/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 51/300 batch  74/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 51/300 batch  75/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 51/300 batch  76/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 51/300 batch  77/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 51/300 batch  78/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 51/300 batch  79/188  Train Loss: 0.053, Acc: 0.992\n",
      "epoch: 51/300 batch  80/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 51/300 batch  81/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 51/300 batch  82/188  Train Loss: 0.052, Acc: 0.992\n",
      "epoch: 51/300 batch  83/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 51/300 batch  84/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 51/300 batch  85/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 51/300 batch  86/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 51/300 batch  87/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 51/300 batch  88/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 51/300 batch  89/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 51/300 batch  90/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 51/300 batch  91/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 51/300 batch  92/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 51/300 batch  93/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 51/300 batch  94/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 51/300 batch  95/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 51/300 batch  96/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 51/300 batch  97/188  Train Loss: 0.061, Acc: 0.988\n",
      "epoch: 51/300 batch  98/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 51/300 batch  99/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 51/300 batch 100/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 51/300 batch 101/188  Train Loss: 0.056, Acc: 0.980\n",
      "epoch: 51/300 batch 102/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 51/300 batch 103/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 51/300 batch 104/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 51/300 batch 105/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 51/300 batch 106/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 51/300 batch 107/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 51/300 batch 108/188  Train Loss: 0.042, Acc: 0.980\n",
      "epoch: 51/300 batch 109/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 51/300 batch 110/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 51/300 batch 111/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 51/300 batch 112/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 51/300 batch 113/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 51/300 batch 114/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 51/300 batch 115/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 51/300 batch 116/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 51/300 batch 117/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 51/300 batch 118/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 51/300 batch 119/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 51/300 batch 120/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 51/300 batch 121/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 51/300 batch 122/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 51/300 batch 123/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 51/300 batch 124/188  Train Loss: 0.061, Acc: 0.984\n",
      "epoch: 51/300 batch 125/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 51/300 batch 126/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 51/300 batch 127/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 51/300 batch 128/188  Train Loss: 0.059, Acc: 0.984\n",
      "epoch: 51/300 batch 129/188  Train Loss: 0.058, Acc: 0.980\n",
      "epoch: 51/300 batch 130/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 51/300 batch 131/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 51/300 batch 132/188  Train Loss: 0.027, Acc: 0.988\n",
      "epoch: 51/300 batch 133/188  Train Loss: 0.057, Acc: 0.980\n",
      "epoch: 51/300 batch 134/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 51/300 batch 135/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 51/300 batch 136/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 51/300 batch 137/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 51/300 batch 138/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 51/300 batch 139/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 51/300 batch 140/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 51/300 batch 141/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 51/300 batch 142/188  Train Loss: 0.059, Acc: 0.984\n",
      "epoch: 51/300 batch 143/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 51/300 batch 144/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 51/300 batch 145/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 51/300 batch 146/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 51/300 batch 147/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 51/300 batch 148/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 51/300 batch 149/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 51/300 batch 150/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 51/300 batch 151/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 51/300 batch 152/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 51/300 batch 153/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 51/300 batch 154/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 51/300 batch 155/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 51/300 batch 156/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 51/300 batch 157/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 51/300 batch 158/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 51/300 batch 159/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 51/300 batch 160/188  Train Loss: 0.078, Acc: 0.992\n",
      "epoch: 51/300 batch 161/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 51/300 batch 162/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 51/300 batch 163/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 51/300 batch 164/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 51/300 batch 165/188  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 51/300 batch 166/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 51/300 batch 167/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 51/300 batch 168/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 51/300 batch 169/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 51/300 batch 170/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 51/300 batch 171/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 51/300 batch 172/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 51/300 batch 173/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 51/300 batch 174/188  Train Loss: 0.056, Acc: 0.988\n",
      "epoch: 51/300 batch 175/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 51/300 batch 176/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 51/300 batch 177/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 51/300 batch 178/188  Train Loss: 0.071, Acc: 0.980\n",
      "epoch: 51/300 batch 179/188  Train Loss: 0.043, Acc: 0.980\n",
      "epoch: 51/300 batch 180/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 51/300 batch 181/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 51/300 batch 182/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 51/300 batch 183/188  Train Loss: 0.023, Acc: 0.988\n",
      "epoch: 51/300 batch 184/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 51/300 batch 185/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 51/300 batch 186/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 51/300 batch 187/188  Train Loss: 0.065, Acc: 0.984\n",
      "Train Loss: 0.036987, Acc: 0.991\n",
      "Val Loss: 0.058045, Acc: 0.983\n",
      "epoch: 52/300 batch   0/188  Train Loss: 0.059, Acc: 0.977\n",
      "epoch: 52/300 batch   1/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 52/300 batch   2/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 52/300 batch   3/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 52/300 batch   4/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 52/300 batch   5/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 52/300 batch   6/188  Train Loss: 0.057, Acc: 0.980\n",
      "epoch: 52/300 batch   7/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 52/300 batch   8/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 52/300 batch   9/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 52/300 batch  10/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 52/300 batch  11/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 52/300 batch  12/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 52/300 batch  13/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 52/300 batch  14/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 52/300 batch  15/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 52/300 batch  16/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 52/300 batch  17/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 52/300 batch  18/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 52/300 batch  19/188  Train Loss: 0.066, Acc: 0.980\n",
      "epoch: 52/300 batch  20/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 52/300 batch  21/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 52/300 batch  22/188  Train Loss: 0.060, Acc: 0.977\n",
      "epoch: 52/300 batch  23/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 52/300 batch  24/188  Train Loss: 0.059, Acc: 0.988\n",
      "epoch: 52/300 batch  25/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 52/300 batch  26/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 52/300 batch  27/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 52/300 batch  28/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 52/300 batch  29/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 52/300 batch  30/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 52/300 batch  31/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 52/300 batch  32/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 52/300 batch  33/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 52/300 batch  34/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 52/300 batch  35/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 52/300 batch  36/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 52/300 batch  37/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 52/300 batch  38/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 52/300 batch  39/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 52/300 batch  40/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 52/300 batch  41/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 52/300 batch  42/188  Train Loss: 0.043, Acc: 0.996\n",
      "epoch: 52/300 batch  43/188  Train Loss: 0.031, Acc: 1.000\n",
      "epoch: 52/300 batch  44/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 52/300 batch  45/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 52/300 batch  46/188  Train Loss: 0.061, Acc: 0.984\n",
      "epoch: 52/300 batch  47/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 52/300 batch  48/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 52/300 batch  49/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 52/300 batch  50/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 52/300 batch  51/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 52/300 batch  52/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 52/300 batch  53/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 52/300 batch  54/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 52/300 batch  55/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 52/300 batch  56/188  Train Loss: 0.076, Acc: 0.973\n",
      "epoch: 52/300 batch  57/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 52/300 batch  58/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 52/300 batch  59/188  Train Loss: 0.070, Acc: 0.965\n",
      "epoch: 52/300 batch  60/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 52/300 batch  61/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 52/300 batch  62/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 52/300 batch  63/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 52/300 batch  64/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 52/300 batch  65/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 52/300 batch  66/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 52/300 batch  67/188  Train Loss: 0.064, Acc: 0.988\n",
      "epoch: 52/300 batch  68/188  Train Loss: 0.052, Acc: 0.992\n",
      "epoch: 52/300 batch  69/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 52/300 batch  70/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 52/300 batch  71/188  Train Loss: 0.072, Acc: 0.984\n",
      "epoch: 52/300 batch  72/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 52/300 batch  73/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 52/300 batch  74/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 52/300 batch  75/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 52/300 batch  76/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 52/300 batch  77/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 52/300 batch  78/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 52/300 batch  79/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 52/300 batch  80/188  Train Loss: 0.061, Acc: 0.988\n",
      "epoch: 52/300 batch  81/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 52/300 batch  82/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 52/300 batch  83/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 52/300 batch  84/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 52/300 batch  85/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 52/300 batch  86/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 52/300 batch  87/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 52/300 batch  88/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 52/300 batch  89/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 52/300 batch  90/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 52/300 batch  91/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 52/300 batch  92/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 52/300 batch  93/188  Train Loss: 0.058, Acc: 0.980\n",
      "epoch: 52/300 batch  94/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 52/300 batch  95/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 52/300 batch  96/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 52/300 batch  97/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 52/300 batch  98/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 52/300 batch  99/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 52/300 batch 100/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 52/300 batch 101/188  Train Loss: 0.064, Acc: 0.984\n",
      "epoch: 52/300 batch 102/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 52/300 batch 103/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 52/300 batch 104/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 52/300 batch 105/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 52/300 batch 106/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 52/300 batch 107/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 52/300 batch 108/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 52/300 batch 109/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 52/300 batch 110/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 52/300 batch 111/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 52/300 batch 112/188  Train Loss: 0.055, Acc: 0.992\n",
      "epoch: 52/300 batch 113/188  Train Loss: 0.058, Acc: 0.980\n",
      "epoch: 52/300 batch 114/188  Train Loss: 0.086, Acc: 0.977\n",
      "epoch: 52/300 batch 115/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 52/300 batch 116/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 52/300 batch 117/188  Train Loss: 0.059, Acc: 0.984\n",
      "epoch: 52/300 batch 118/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 52/300 batch 119/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 52/300 batch 120/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 52/300 batch 121/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 52/300 batch 122/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 52/300 batch 123/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 52/300 batch 124/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 52/300 batch 125/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 52/300 batch 126/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 52/300 batch 127/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 52/300 batch 128/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 52/300 batch 129/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 52/300 batch 130/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 52/300 batch 131/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 52/300 batch 132/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 52/300 batch 133/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 52/300 batch 134/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 52/300 batch 135/188  Train Loss: 0.060, Acc: 0.980\n",
      "epoch: 52/300 batch 136/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 52/300 batch 137/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 52/300 batch 138/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 52/300 batch 139/188  Train Loss: 0.059, Acc: 0.984\n",
      "epoch: 52/300 batch 140/188  Train Loss: 0.047, Acc: 0.980\n",
      "epoch: 52/300 batch 141/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 52/300 batch 142/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 52/300 batch 143/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 52/300 batch 144/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 52/300 batch 145/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 52/300 batch 146/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 52/300 batch 147/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 52/300 batch 148/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 52/300 batch 149/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 52/300 batch 150/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 52/300 batch 151/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 52/300 batch 152/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 52/300 batch 153/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 52/300 batch 154/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 52/300 batch 155/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 52/300 batch 156/188  Train Loss: 0.032, Acc: 0.984\n",
      "epoch: 52/300 batch 157/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 52/300 batch 158/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 52/300 batch 159/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 52/300 batch 160/188  Train Loss: 0.058, Acc: 0.980\n",
      "epoch: 52/300 batch 161/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 52/300 batch 162/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 52/300 batch 163/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 52/300 batch 164/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 52/300 batch 165/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 52/300 batch 166/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 52/300 batch 167/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 52/300 batch 168/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 52/300 batch 169/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 52/300 batch 170/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 52/300 batch 171/188  Train Loss: 0.024, Acc: 0.988\n",
      "epoch: 52/300 batch 172/188  Train Loss: 0.061, Acc: 0.977\n",
      "epoch: 52/300 batch 173/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 52/300 batch 174/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 52/300 batch 175/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 52/300 batch 176/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 52/300 batch 177/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 52/300 batch 178/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 52/300 batch 179/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 52/300 batch 180/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 52/300 batch 181/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 52/300 batch 182/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 52/300 batch 183/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 52/300 batch 184/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 52/300 batch 185/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 52/300 batch 186/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 52/300 batch 187/188  Train Loss: 0.054, Acc: 0.977\n",
      "Train Loss: 0.036934, Acc: 0.992\n",
      "Val Loss: 0.058065, Acc: 0.983\n",
      "epoch: 53/300 batch   0/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 53/300 batch   1/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 53/300 batch   2/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 53/300 batch   3/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 53/300 batch   4/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 53/300 batch   5/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 53/300 batch   6/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 53/300 batch   7/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 53/300 batch   8/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 53/300 batch   9/188  Train Loss: 0.071, Acc: 0.984\n",
      "epoch: 53/300 batch  10/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 53/300 batch  11/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 53/300 batch  12/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 53/300 batch  13/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 53/300 batch  14/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 53/300 batch  15/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 53/300 batch  16/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 53/300 batch  17/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 53/300 batch  18/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 53/300 batch  19/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 53/300 batch  20/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 53/300 batch  21/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 53/300 batch  22/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 53/300 batch  23/188  Train Loss: 0.085, Acc: 0.984\n",
      "epoch: 53/300 batch  24/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 53/300 batch  25/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 53/300 batch  26/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 53/300 batch  27/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 53/300 batch  28/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 53/300 batch  29/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 53/300 batch  30/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 53/300 batch  31/188  Train Loss: 0.037, Acc: 1.000\n",
      "epoch: 53/300 batch  32/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 53/300 batch  33/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 53/300 batch  34/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 53/300 batch  35/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 53/300 batch  36/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 53/300 batch  37/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 53/300 batch  38/188  Train Loss: 0.052, Acc: 0.992\n",
      "epoch: 53/300 batch  39/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 53/300 batch  40/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 53/300 batch  41/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 53/300 batch  42/188  Train Loss: 0.059, Acc: 0.988\n",
      "epoch: 53/300 batch  43/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 53/300 batch  44/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 53/300 batch  45/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 53/300 batch  46/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 53/300 batch  47/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 53/300 batch  48/188  Train Loss: 0.052, Acc: 0.980\n",
      "epoch: 53/300 batch  49/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 53/300 batch  50/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 53/300 batch  51/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 53/300 batch  52/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 53/300 batch  53/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 53/300 batch  54/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 53/300 batch  55/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 53/300 batch  56/188  Train Loss: 0.055, Acc: 0.992\n",
      "epoch: 53/300 batch  57/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 53/300 batch  58/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 53/300 batch  59/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 53/300 batch  60/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 53/300 batch  61/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 53/300 batch  62/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 53/300 batch  63/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 53/300 batch  64/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 53/300 batch  65/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 53/300 batch  66/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 53/300 batch  67/188  Train Loss: 0.060, Acc: 0.984\n",
      "epoch: 53/300 batch  68/188  Train Loss: 0.043, Acc: 0.980\n",
      "epoch: 53/300 batch  69/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 53/300 batch  70/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 53/300 batch  71/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 53/300 batch  72/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 53/300 batch  73/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 53/300 batch  74/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 53/300 batch  75/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 53/300 batch  76/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 53/300 batch  77/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 53/300 batch  78/188  Train Loss: 0.051, Acc: 0.980\n",
      "epoch: 53/300 batch  79/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 53/300 batch  80/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 53/300 batch  81/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 53/300 batch  82/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 53/300 batch  83/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 53/300 batch  84/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 53/300 batch  85/188  Train Loss: 0.026, Acc: 0.988\n",
      "epoch: 53/300 batch  86/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 53/300 batch  87/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 53/300 batch  88/188  Train Loss: 0.080, Acc: 0.977\n",
      "epoch: 53/300 batch  89/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 53/300 batch  90/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 53/300 batch  91/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 53/300 batch  92/188  Train Loss: 0.082, Acc: 0.984\n",
      "epoch: 53/300 batch  93/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 53/300 batch  94/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 53/300 batch  95/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 53/300 batch  96/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 53/300 batch  97/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 53/300 batch  98/188  Train Loss: 0.030, Acc: 0.984\n",
      "epoch: 53/300 batch  99/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 53/300 batch 100/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 53/300 batch 101/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 53/300 batch 102/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 53/300 batch 103/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 53/300 batch 104/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 53/300 batch 105/188  Train Loss: 0.042, Acc: 0.996\n",
      "epoch: 53/300 batch 106/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 53/300 batch 107/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 53/300 batch 108/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 53/300 batch 109/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 53/300 batch 110/188  Train Loss: 0.040, Acc: 0.977\n",
      "epoch: 53/300 batch 111/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 53/300 batch 112/188  Train Loss: 0.052, Acc: 0.992\n",
      "epoch: 53/300 batch 113/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 53/300 batch 114/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 53/300 batch 115/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 53/300 batch 116/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 53/300 batch 117/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 53/300 batch 118/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 53/300 batch 119/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 53/300 batch 120/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 53/300 batch 121/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 53/300 batch 122/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 53/300 batch 123/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 53/300 batch 124/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 53/300 batch 125/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 53/300 batch 126/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 53/300 batch 127/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 53/300 batch 128/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 53/300 batch 129/188  Train Loss: 0.071, Acc: 0.980\n",
      "epoch: 53/300 batch 130/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 53/300 batch 131/188  Train Loss: 0.052, Acc: 0.980\n",
      "epoch: 53/300 batch 132/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 53/300 batch 133/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 53/300 batch 134/188  Train Loss: 0.052, Acc: 0.977\n",
      "epoch: 53/300 batch 135/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 53/300 batch 136/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 53/300 batch 137/188  Train Loss: 0.055, Acc: 0.977\n",
      "epoch: 53/300 batch 138/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 53/300 batch 139/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 53/300 batch 140/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 53/300 batch 141/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 53/300 batch 142/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 53/300 batch 143/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 53/300 batch 144/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 53/300 batch 145/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 53/300 batch 146/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 53/300 batch 147/188  Train Loss: 0.076, Acc: 0.973\n",
      "epoch: 53/300 batch 148/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 53/300 batch 149/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 53/300 batch 150/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 53/300 batch 151/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 53/300 batch 152/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 53/300 batch 153/188  Train Loss: 0.060, Acc: 0.977\n",
      "epoch: 53/300 batch 154/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 53/300 batch 155/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 53/300 batch 156/188  Train Loss: 0.042, Acc: 0.996\n",
      "epoch: 53/300 batch 157/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 53/300 batch 158/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 53/300 batch 159/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 53/300 batch 160/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 53/300 batch 161/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 53/300 batch 162/188  Train Loss: 0.034, Acc: 0.984\n",
      "epoch: 53/300 batch 163/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 53/300 batch 164/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 53/300 batch 165/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 53/300 batch 166/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 53/300 batch 167/188  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 53/300 batch 168/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 53/300 batch 169/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 53/300 batch 170/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 53/300 batch 171/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 53/300 batch 172/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 53/300 batch 173/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 53/300 batch 174/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 53/300 batch 175/188  Train Loss: 0.057, Acc: 0.980\n",
      "epoch: 53/300 batch 176/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 53/300 batch 177/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 53/300 batch 178/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 53/300 batch 179/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 53/300 batch 180/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 53/300 batch 181/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 53/300 batch 182/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 53/300 batch 183/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 53/300 batch 184/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 53/300 batch 185/188  Train Loss: 0.072, Acc: 0.984\n",
      "epoch: 53/300 batch 186/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 53/300 batch 187/188  Train Loss: 0.035, Acc: 0.992\n",
      "Train Loss: 0.036871, Acc: 0.992\n",
      "Val Loss: 0.058097, Acc: 0.982\n",
      "epoch: 54/300 batch   0/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 54/300 batch   1/188  Train Loss: 0.056, Acc: 0.988\n",
      "epoch: 54/300 batch   2/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 54/300 batch   3/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 54/300 batch   4/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 54/300 batch   5/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 54/300 batch   6/188  Train Loss: 0.050, Acc: 0.980\n",
      "epoch: 54/300 batch   7/188  Train Loss: 0.078, Acc: 0.984\n",
      "epoch: 54/300 batch   8/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 54/300 batch   9/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 54/300 batch  10/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 54/300 batch  11/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 54/300 batch  12/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 54/300 batch  13/188  Train Loss: 0.056, Acc: 0.988\n",
      "epoch: 54/300 batch  14/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 54/300 batch  15/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 54/300 batch  16/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 54/300 batch  17/188  Train Loss: 0.062, Acc: 0.977\n",
      "epoch: 54/300 batch  18/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 54/300 batch  19/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 54/300 batch  20/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 54/300 batch  21/188  Train Loss: 0.075, Acc: 0.992\n",
      "epoch: 54/300 batch  22/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 54/300 batch  23/188  Train Loss: 0.050, Acc: 0.980\n",
      "epoch: 54/300 batch  24/188  Train Loss: 0.047, Acc: 0.977\n",
      "epoch: 54/300 batch  25/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 54/300 batch  26/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 54/300 batch  27/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 54/300 batch  28/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 54/300 batch  29/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 54/300 batch  30/188  Train Loss: 0.060, Acc: 0.988\n",
      "epoch: 54/300 batch  31/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 54/300 batch  32/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 54/300 batch  33/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 54/300 batch  34/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 54/300 batch  35/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 54/300 batch  36/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 54/300 batch  37/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 54/300 batch  38/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 54/300 batch  39/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 54/300 batch  40/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 54/300 batch  41/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 54/300 batch  42/188  Train Loss: 0.032, Acc: 1.000\n",
      "epoch: 54/300 batch  43/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 54/300 batch  44/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 54/300 batch  45/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 54/300 batch  46/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 54/300 batch  47/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 54/300 batch  48/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 54/300 batch  49/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 54/300 batch  50/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 54/300 batch  51/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 54/300 batch  52/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 54/300 batch  53/188  Train Loss: 0.054, Acc: 0.992\n",
      "epoch: 54/300 batch  54/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 54/300 batch  55/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 54/300 batch  56/188  Train Loss: 0.065, Acc: 0.980\n",
      "epoch: 54/300 batch  57/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 54/300 batch  58/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 54/300 batch  59/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 54/300 batch  60/188  Train Loss: 0.062, Acc: 0.988\n",
      "epoch: 54/300 batch  61/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 54/300 batch  62/188  Train Loss: 0.044, Acc: 0.996\n",
      "epoch: 54/300 batch  63/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 54/300 batch  64/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 54/300 batch  65/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 54/300 batch  66/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 54/300 batch  67/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 54/300 batch  68/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 54/300 batch  69/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 54/300 batch  70/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 54/300 batch  71/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 54/300 batch  72/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 54/300 batch  73/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 54/300 batch  74/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 54/300 batch  75/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 54/300 batch  76/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 54/300 batch  77/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 54/300 batch  78/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 54/300 batch  79/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 54/300 batch  80/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 54/300 batch  81/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 54/300 batch  82/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 54/300 batch  83/188  Train Loss: 0.054, Acc: 0.980\n",
      "epoch: 54/300 batch  84/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 54/300 batch  85/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 54/300 batch  86/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 54/300 batch  87/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 54/300 batch  88/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 54/300 batch  89/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 54/300 batch  90/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 54/300 batch  91/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 54/300 batch  92/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 54/300 batch  93/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 54/300 batch  94/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 54/300 batch  95/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 54/300 batch  96/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 54/300 batch  97/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 54/300 batch  98/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 54/300 batch  99/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 54/300 batch 100/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 54/300 batch 101/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 54/300 batch 102/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 54/300 batch 103/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 54/300 batch 104/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 54/300 batch 105/188  Train Loss: 0.053, Acc: 0.992\n",
      "epoch: 54/300 batch 106/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 54/300 batch 107/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 54/300 batch 108/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 54/300 batch 109/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 54/300 batch 110/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 54/300 batch 111/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 54/300 batch 112/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 54/300 batch 113/188  Train Loss: 0.059, Acc: 0.984\n",
      "epoch: 54/300 batch 114/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 54/300 batch 115/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 54/300 batch 116/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 54/300 batch 117/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 54/300 batch 118/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 54/300 batch 119/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 54/300 batch 120/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 54/300 batch 121/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 54/300 batch 122/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 54/300 batch 123/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 54/300 batch 124/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 54/300 batch 125/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 54/300 batch 126/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 54/300 batch 127/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 54/300 batch 128/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 54/300 batch 129/188  Train Loss: 0.057, Acc: 0.980\n",
      "epoch: 54/300 batch 130/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 54/300 batch 131/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 54/300 batch 132/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 54/300 batch 133/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 54/300 batch 134/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 54/300 batch 135/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 54/300 batch 136/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 54/300 batch 137/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 54/300 batch 138/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 54/300 batch 139/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 54/300 batch 140/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 54/300 batch 141/188  Train Loss: 0.066, Acc: 0.984\n",
      "epoch: 54/300 batch 142/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 54/300 batch 143/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 54/300 batch 144/188  Train Loss: 0.068, Acc: 0.977\n",
      "epoch: 54/300 batch 145/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 54/300 batch 146/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 54/300 batch 147/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 54/300 batch 148/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 54/300 batch 149/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 54/300 batch 150/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 54/300 batch 151/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 54/300 batch 152/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 54/300 batch 153/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 54/300 batch 154/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 54/300 batch 155/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 54/300 batch 156/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 54/300 batch 157/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 54/300 batch 158/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 54/300 batch 159/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 54/300 batch 160/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 54/300 batch 161/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 54/300 batch 162/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 54/300 batch 163/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 54/300 batch 164/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 54/300 batch 165/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 54/300 batch 166/188  Train Loss: 0.075, Acc: 0.977\n",
      "epoch: 54/300 batch 167/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 54/300 batch 168/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 54/300 batch 169/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 54/300 batch 170/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 54/300 batch 171/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 54/300 batch 172/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 54/300 batch 173/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 54/300 batch 174/188  Train Loss: 0.057, Acc: 0.988\n",
      "epoch: 54/300 batch 175/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 54/300 batch 176/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 54/300 batch 177/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 54/300 batch 178/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 54/300 batch 179/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 54/300 batch 180/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 54/300 batch 181/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 54/300 batch 182/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 54/300 batch 183/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 54/300 batch 184/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 54/300 batch 185/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 54/300 batch 186/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 54/300 batch 187/188  Train Loss: 0.023, Acc: 1.000\n",
      "Train Loss: 0.036772, Acc: 0.992\n",
      "Val Loss: 0.057878, Acc: 0.983\n",
      "epoch: 55/300 batch   0/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 55/300 batch   1/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 55/300 batch   2/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 55/300 batch   3/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 55/300 batch   4/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 55/300 batch   5/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 55/300 batch   6/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 55/300 batch   7/188  Train Loss: 0.032, Acc: 1.000\n",
      "epoch: 55/300 batch   8/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 55/300 batch   9/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 55/300 batch  10/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 55/300 batch  11/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 55/300 batch  12/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 55/300 batch  13/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 55/300 batch  14/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 55/300 batch  15/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 55/300 batch  16/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 55/300 batch  17/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 55/300 batch  18/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 55/300 batch  19/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 55/300 batch  20/188  Train Loss: 0.065, Acc: 0.984\n",
      "epoch: 55/300 batch  21/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 55/300 batch  22/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 55/300 batch  23/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 55/300 batch  24/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 55/300 batch  25/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 55/300 batch  26/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 55/300 batch  27/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 55/300 batch  28/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 55/300 batch  29/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 55/300 batch  30/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 55/300 batch  31/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 55/300 batch  32/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 55/300 batch  33/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 55/300 batch  34/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 55/300 batch  35/188  Train Loss: 0.072, Acc: 0.988\n",
      "epoch: 55/300 batch  36/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 55/300 batch  37/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 55/300 batch  38/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 55/300 batch  39/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 55/300 batch  40/188  Train Loss: 0.077, Acc: 0.977\n",
      "epoch: 55/300 batch  41/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 55/300 batch  42/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 55/300 batch  43/188  Train Loss: 0.016, Acc: 0.996\n",
      "epoch: 55/300 batch  44/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 55/300 batch  45/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 55/300 batch  46/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 55/300 batch  47/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 55/300 batch  48/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 55/300 batch  49/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 55/300 batch  50/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 55/300 batch  51/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 55/300 batch  52/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 55/300 batch  53/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 55/300 batch  54/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 55/300 batch  55/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 55/300 batch  56/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 55/300 batch  57/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 55/300 batch  58/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 55/300 batch  59/188  Train Loss: 0.045, Acc: 0.980\n",
      "epoch: 55/300 batch  60/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 55/300 batch  61/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 55/300 batch  62/188  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 55/300 batch  63/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 55/300 batch  64/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 55/300 batch  65/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 55/300 batch  66/188  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 55/300 batch  67/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 55/300 batch  68/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 55/300 batch  69/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 55/300 batch  70/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 55/300 batch  71/188  Train Loss: 0.058, Acc: 0.980\n",
      "epoch: 55/300 batch  72/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 55/300 batch  73/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 55/300 batch  74/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 55/300 batch  75/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 55/300 batch  76/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 55/300 batch  77/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 55/300 batch  78/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 55/300 batch  79/188  Train Loss: 0.068, Acc: 0.984\n",
      "epoch: 55/300 batch  80/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 55/300 batch  81/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 55/300 batch  82/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 55/300 batch  83/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 55/300 batch  84/188  Train Loss: 0.053, Acc: 0.980\n",
      "epoch: 55/300 batch  85/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 55/300 batch  86/188  Train Loss: 0.048, Acc: 0.977\n",
      "epoch: 55/300 batch  87/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 55/300 batch  88/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 55/300 batch  89/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 55/300 batch  90/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 55/300 batch  91/188  Train Loss: 0.053, Acc: 0.992\n",
      "epoch: 55/300 batch  92/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 55/300 batch  93/188  Train Loss: 0.065, Acc: 0.977\n",
      "epoch: 55/300 batch  94/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 55/300 batch  95/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 55/300 batch  96/188  Train Loss: 0.057, Acc: 0.980\n",
      "epoch: 55/300 batch  97/188  Train Loss: 0.043, Acc: 0.996\n",
      "epoch: 55/300 batch  98/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 55/300 batch  99/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 55/300 batch 100/188  Train Loss: 0.059, Acc: 0.992\n",
      "epoch: 55/300 batch 101/188  Train Loss: 0.053, Acc: 0.992\n",
      "epoch: 55/300 batch 102/188  Train Loss: 0.040, Acc: 1.000\n",
      "epoch: 55/300 batch 103/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 55/300 batch 104/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 55/300 batch 105/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 55/300 batch 106/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 55/300 batch 107/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 55/300 batch 108/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 55/300 batch 109/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 55/300 batch 110/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 55/300 batch 111/188  Train Loss: 0.077, Acc: 0.980\n",
      "epoch: 55/300 batch 112/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 55/300 batch 113/188  Train Loss: 0.066, Acc: 0.984\n",
      "epoch: 55/300 batch 114/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 55/300 batch 115/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 55/300 batch 116/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 55/300 batch 117/188  Train Loss: 0.071, Acc: 0.973\n",
      "epoch: 55/300 batch 118/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 55/300 batch 119/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 55/300 batch 120/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 55/300 batch 121/188  Train Loss: 0.046, Acc: 0.977\n",
      "epoch: 55/300 batch 122/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 55/300 batch 123/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 55/300 batch 124/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 55/300 batch 125/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 55/300 batch 126/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 55/300 batch 127/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 55/300 batch 128/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 55/300 batch 129/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 55/300 batch 130/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 55/300 batch 131/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 55/300 batch 132/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 55/300 batch 133/188  Train Loss: 0.047, Acc: 0.996\n",
      "epoch: 55/300 batch 134/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 55/300 batch 135/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 55/300 batch 136/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 55/300 batch 137/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 55/300 batch 138/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 55/300 batch 139/188  Train Loss: 0.059, Acc: 0.980\n",
      "epoch: 55/300 batch 140/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 55/300 batch 141/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 55/300 batch 142/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 55/300 batch 143/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 55/300 batch 144/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 55/300 batch 145/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 55/300 batch 146/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 55/300 batch 147/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 55/300 batch 148/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 55/300 batch 149/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 55/300 batch 150/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 55/300 batch 151/188  Train Loss: 0.057, Acc: 0.980\n",
      "epoch: 55/300 batch 152/188  Train Loss: 0.042, Acc: 0.980\n",
      "epoch: 55/300 batch 153/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 55/300 batch 154/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 55/300 batch 155/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 55/300 batch 156/188  Train Loss: 0.050, Acc: 0.980\n",
      "epoch: 55/300 batch 157/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 55/300 batch 158/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 55/300 batch 159/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 55/300 batch 160/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 55/300 batch 161/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 55/300 batch 162/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 55/300 batch 163/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 55/300 batch 164/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 55/300 batch 165/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 55/300 batch 166/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 55/300 batch 167/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 55/300 batch 168/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 55/300 batch 169/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 55/300 batch 170/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 55/300 batch 171/188  Train Loss: 0.042, Acc: 0.996\n",
      "epoch: 55/300 batch 172/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 55/300 batch 173/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 55/300 batch 174/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 55/300 batch 175/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 55/300 batch 176/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 55/300 batch 177/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 55/300 batch 178/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 55/300 batch 179/188  Train Loss: 0.065, Acc: 0.984\n",
      "epoch: 55/300 batch 180/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 55/300 batch 181/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 55/300 batch 182/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 55/300 batch 183/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 55/300 batch 184/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 55/300 batch 185/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 55/300 batch 186/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 55/300 batch 187/188  Train Loss: 0.017, Acc: 1.000\n",
      "Train Loss: 0.036727, Acc: 0.991\n",
      "Val Loss: 0.057958, Acc: 0.983\n",
      "epoch: 56/300 batch   0/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 56/300 batch   1/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 56/300 batch   2/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 56/300 batch   3/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 56/300 batch   4/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 56/300 batch   5/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 56/300 batch   6/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 56/300 batch   7/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 56/300 batch   8/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 56/300 batch   9/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 56/300 batch  10/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 56/300 batch  11/188  Train Loss: 0.060, Acc: 0.988\n",
      "epoch: 56/300 batch  12/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 56/300 batch  13/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 56/300 batch  14/188  Train Loss: 0.074, Acc: 0.973\n",
      "epoch: 56/300 batch  15/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 56/300 batch  16/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 56/300 batch  17/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 56/300 batch  18/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 56/300 batch  19/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 56/300 batch  20/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 56/300 batch  21/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 56/300 batch  22/188  Train Loss: 0.055, Acc: 0.980\n",
      "epoch: 56/300 batch  23/188  Train Loss: 0.051, Acc: 0.992\n",
      "epoch: 56/300 batch  24/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 56/300 batch  25/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 56/300 batch  26/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 56/300 batch  27/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 56/300 batch  28/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 56/300 batch  29/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 56/300 batch  30/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 56/300 batch  31/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 56/300 batch  32/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 56/300 batch  33/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 56/300 batch  34/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 56/300 batch  35/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 56/300 batch  36/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 56/300 batch  37/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 56/300 batch  38/188  Train Loss: 0.034, Acc: 0.984\n",
      "epoch: 56/300 batch  39/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 56/300 batch  40/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 56/300 batch  41/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 56/300 batch  42/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 56/300 batch  43/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 56/300 batch  44/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 56/300 batch  45/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 56/300 batch  46/188  Train Loss: 0.073, Acc: 0.980\n",
      "epoch: 56/300 batch  47/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 56/300 batch  48/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 56/300 batch  49/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 56/300 batch  50/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 56/300 batch  51/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 56/300 batch  52/188  Train Loss: 0.048, Acc: 0.973\n",
      "epoch: 56/300 batch  53/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 56/300 batch  54/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 56/300 batch  55/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 56/300 batch  56/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 56/300 batch  57/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 56/300 batch  58/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 56/300 batch  59/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 56/300 batch  60/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 56/300 batch  61/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 56/300 batch  62/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 56/300 batch  63/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 56/300 batch  64/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 56/300 batch  65/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 56/300 batch  66/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 56/300 batch  67/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 56/300 batch  68/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 56/300 batch  69/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 56/300 batch  70/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 56/300 batch  71/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 56/300 batch  72/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 56/300 batch  73/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 56/300 batch  74/188  Train Loss: 0.064, Acc: 0.988\n",
      "epoch: 56/300 batch  75/188  Train Loss: 0.053, Acc: 0.996\n",
      "epoch: 56/300 batch  76/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 56/300 batch  77/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 56/300 batch  78/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 56/300 batch  79/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 56/300 batch  80/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 56/300 batch  81/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 56/300 batch  82/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 56/300 batch  83/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 56/300 batch  84/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 56/300 batch  85/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 56/300 batch  86/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 56/300 batch  87/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 56/300 batch  88/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 56/300 batch  89/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 56/300 batch  90/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 56/300 batch  91/188  Train Loss: 0.063, Acc: 0.984\n",
      "epoch: 56/300 batch  92/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 56/300 batch  93/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 56/300 batch  94/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 56/300 batch  95/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 56/300 batch  96/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 56/300 batch  97/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 56/300 batch  98/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 56/300 batch  99/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 56/300 batch 100/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 56/300 batch 101/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 56/300 batch 102/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 56/300 batch 103/188  Train Loss: 0.056, Acc: 0.980\n",
      "epoch: 56/300 batch 104/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 56/300 batch 105/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 56/300 batch 106/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 56/300 batch 107/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 56/300 batch 108/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 56/300 batch 109/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 56/300 batch 110/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 56/300 batch 111/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 56/300 batch 112/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 56/300 batch 113/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 56/300 batch 114/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 56/300 batch 115/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 56/300 batch 116/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 56/300 batch 117/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 56/300 batch 118/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 56/300 batch 119/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 56/300 batch 120/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 56/300 batch 121/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 56/300 batch 122/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 56/300 batch 123/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 56/300 batch 124/188  Train Loss: 0.062, Acc: 0.988\n",
      "epoch: 56/300 batch 125/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 56/300 batch 126/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 56/300 batch 127/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 56/300 batch 128/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 56/300 batch 129/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 56/300 batch 130/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 56/300 batch 131/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 56/300 batch 132/188  Train Loss: 0.074, Acc: 0.973\n",
      "epoch: 56/300 batch 133/188  Train Loss: 0.062, Acc: 0.980\n",
      "epoch: 56/300 batch 134/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 56/300 batch 135/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 56/300 batch 136/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 56/300 batch 137/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 56/300 batch 138/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 56/300 batch 139/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 56/300 batch 140/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 56/300 batch 141/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 56/300 batch 142/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 56/300 batch 143/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 56/300 batch 144/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 56/300 batch 145/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 56/300 batch 146/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 56/300 batch 147/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 56/300 batch 148/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 56/300 batch 149/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 56/300 batch 150/188  Train Loss: 0.058, Acc: 0.988\n",
      "epoch: 56/300 batch 151/188  Train Loss: 0.044, Acc: 0.980\n",
      "epoch: 56/300 batch 152/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 56/300 batch 153/188  Train Loss: 0.046, Acc: 0.980\n",
      "epoch: 56/300 batch 154/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 56/300 batch 155/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 56/300 batch 156/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 56/300 batch 157/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 56/300 batch 158/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 56/300 batch 159/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 56/300 batch 160/188  Train Loss: 0.053, Acc: 0.980\n",
      "epoch: 56/300 batch 161/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 56/300 batch 162/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 56/300 batch 163/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 56/300 batch 164/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 56/300 batch 165/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 56/300 batch 166/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 56/300 batch 167/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 56/300 batch 168/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 56/300 batch 169/188  Train Loss: 0.070, Acc: 0.984\n",
      "epoch: 56/300 batch 170/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 56/300 batch 171/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 56/300 batch 172/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 56/300 batch 173/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 56/300 batch 174/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 56/300 batch 175/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 56/300 batch 176/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 56/300 batch 177/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 56/300 batch 178/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 56/300 batch 179/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 56/300 batch 180/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 56/300 batch 181/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 56/300 batch 182/188  Train Loss: 0.042, Acc: 0.996\n",
      "epoch: 56/300 batch 183/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 56/300 batch 184/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 56/300 batch 185/188  Train Loss: 0.079, Acc: 0.984\n",
      "epoch: 56/300 batch 186/188  Train Loss: 0.049, Acc: 0.980\n",
      "epoch: 56/300 batch 187/188  Train Loss: 0.032, Acc: 0.984\n",
      "Train Loss: 0.036698, Acc: 0.992\n",
      "Val Loss: 0.057957, Acc: 0.982\n",
      "epoch: 57/300 batch   0/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 57/300 batch   1/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 57/300 batch   2/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 57/300 batch   3/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 57/300 batch   4/188  Train Loss: 0.041, Acc: 0.980\n",
      "epoch: 57/300 batch   5/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 57/300 batch   6/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 57/300 batch   7/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 57/300 batch   8/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 57/300 batch   9/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 57/300 batch  10/188  Train Loss: 0.072, Acc: 0.984\n",
      "epoch: 57/300 batch  11/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 57/300 batch  12/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 57/300 batch  13/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 57/300 batch  14/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 57/300 batch  15/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 57/300 batch  16/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 57/300 batch  17/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 57/300 batch  18/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 57/300 batch  19/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 57/300 batch  20/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 57/300 batch  21/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 57/300 batch  22/188  Train Loss: 0.066, Acc: 0.992\n",
      "epoch: 57/300 batch  23/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 57/300 batch  24/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 57/300 batch  25/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 57/300 batch  26/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 57/300 batch  27/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 57/300 batch  28/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 57/300 batch  29/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 57/300 batch  30/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 57/300 batch  31/188  Train Loss: 0.048, Acc: 0.980\n",
      "epoch: 57/300 batch  32/188  Train Loss: 0.039, Acc: 0.980\n",
      "epoch: 57/300 batch  33/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 57/300 batch  34/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 57/300 batch  35/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 57/300 batch  36/188  Train Loss: 0.058, Acc: 0.977\n",
      "epoch: 57/300 batch  37/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 57/300 batch  38/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 57/300 batch  39/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 57/300 batch  40/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 57/300 batch  41/188  Train Loss: 0.088, Acc: 0.977\n",
      "epoch: 57/300 batch  42/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 57/300 batch  43/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 57/300 batch  44/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 57/300 batch  45/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 57/300 batch  46/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 57/300 batch  47/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 57/300 batch  48/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 57/300 batch  49/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 57/300 batch  50/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 57/300 batch  51/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 57/300 batch  52/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 57/300 batch  53/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 57/300 batch  54/188  Train Loss: 0.049, Acc: 0.980\n",
      "epoch: 57/300 batch  55/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 57/300 batch  56/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 57/300 batch  57/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 57/300 batch  58/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 57/300 batch  59/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 57/300 batch  60/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 57/300 batch  61/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 57/300 batch  62/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 57/300 batch  63/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 57/300 batch  64/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 57/300 batch  65/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 57/300 batch  66/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 57/300 batch  67/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 57/300 batch  68/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 57/300 batch  69/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 57/300 batch  70/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 57/300 batch  71/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 57/300 batch  72/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 57/300 batch  73/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 57/300 batch  74/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 57/300 batch  75/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 57/300 batch  76/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 57/300 batch  77/188  Train Loss: 0.042, Acc: 0.996\n",
      "epoch: 57/300 batch  78/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 57/300 batch  79/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 57/300 batch  80/188  Train Loss: 0.033, Acc: 1.000\n",
      "epoch: 57/300 batch  81/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 57/300 batch  82/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 57/300 batch  83/188  Train Loss: 0.053, Acc: 0.992\n",
      "epoch: 57/300 batch  84/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 57/300 batch  85/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 57/300 batch  86/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 57/300 batch  87/188  Train Loss: 0.065, Acc: 0.984\n",
      "epoch: 57/300 batch  88/188  Train Loss: 0.056, Acc: 0.977\n",
      "epoch: 57/300 batch  89/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 57/300 batch  90/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 57/300 batch  91/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 57/300 batch  92/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 57/300 batch  93/188  Train Loss: 0.058, Acc: 0.980\n",
      "epoch: 57/300 batch  94/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 57/300 batch  95/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 57/300 batch  96/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 57/300 batch  97/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 57/300 batch  98/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 57/300 batch  99/188  Train Loss: 0.061, Acc: 0.977\n",
      "epoch: 57/300 batch 100/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 57/300 batch 101/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 57/300 batch 102/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 57/300 batch 103/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 57/300 batch 104/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 57/300 batch 105/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 57/300 batch 106/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 57/300 batch 107/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 57/300 batch 108/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 57/300 batch 109/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 57/300 batch 110/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 57/300 batch 111/188  Train Loss: 0.056, Acc: 0.996\n",
      "epoch: 57/300 batch 112/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 57/300 batch 113/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 57/300 batch 114/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 57/300 batch 115/188  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 57/300 batch 116/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 57/300 batch 117/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 57/300 batch 118/188  Train Loss: 0.053, Acc: 0.980\n",
      "epoch: 57/300 batch 119/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 57/300 batch 120/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 57/300 batch 121/188  Train Loss: 0.015, Acc: 0.996\n",
      "epoch: 57/300 batch 122/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 57/300 batch 123/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 57/300 batch 124/188  Train Loss: 0.041, Acc: 0.977\n",
      "epoch: 57/300 batch 125/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 57/300 batch 126/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 57/300 batch 127/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 57/300 batch 128/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 57/300 batch 129/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 57/300 batch 130/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 57/300 batch 131/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 57/300 batch 132/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 57/300 batch 133/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 57/300 batch 134/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 57/300 batch 135/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 57/300 batch 136/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 57/300 batch 137/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 57/300 batch 138/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 57/300 batch 139/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 57/300 batch 140/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 57/300 batch 141/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 57/300 batch 142/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 57/300 batch 143/188  Train Loss: 0.059, Acc: 0.988\n",
      "epoch: 57/300 batch 144/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 57/300 batch 145/188  Train Loss: 0.056, Acc: 0.988\n",
      "epoch: 57/300 batch 146/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 57/300 batch 147/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 57/300 batch 148/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 57/300 batch 149/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 57/300 batch 150/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 57/300 batch 151/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 57/300 batch 152/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 57/300 batch 153/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 57/300 batch 154/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 57/300 batch 155/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 57/300 batch 156/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 57/300 batch 157/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 57/300 batch 158/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 57/300 batch 159/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 57/300 batch 160/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 57/300 batch 161/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 57/300 batch 162/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 57/300 batch 163/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 57/300 batch 164/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 57/300 batch 165/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 57/300 batch 166/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 57/300 batch 167/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 57/300 batch 168/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 57/300 batch 169/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 57/300 batch 170/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 57/300 batch 171/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 57/300 batch 172/188  Train Loss: 0.069, Acc: 0.977\n",
      "epoch: 57/300 batch 173/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 57/300 batch 174/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 57/300 batch 175/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 57/300 batch 176/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 57/300 batch 177/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 57/300 batch 178/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 57/300 batch 179/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 57/300 batch 180/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 57/300 batch 181/188  Train Loss: 0.063, Acc: 0.988\n",
      "epoch: 57/300 batch 182/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 57/300 batch 183/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 57/300 batch 184/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 57/300 batch 185/188  Train Loss: 0.053, Acc: 0.992\n",
      "epoch: 57/300 batch 186/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 57/300 batch 187/188  Train Loss: 0.015, Acc: 1.000\n",
      "Train Loss: 0.036626, Acc: 0.992\n",
      "Val Loss: 0.058019, Acc: 0.982\n",
      "epoch: 58/300 batch   0/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 58/300 batch   1/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 58/300 batch   2/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 58/300 batch   3/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 58/300 batch   4/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 58/300 batch   5/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 58/300 batch   6/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 58/300 batch   7/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 58/300 batch   8/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 58/300 batch   9/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 58/300 batch  10/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 58/300 batch  11/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 58/300 batch  12/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 58/300 batch  13/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 58/300 batch  14/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 58/300 batch  15/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 58/300 batch  16/188  Train Loss: 0.066, Acc: 0.977\n",
      "epoch: 58/300 batch  17/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 58/300 batch  18/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 58/300 batch  19/188  Train Loss: 0.055, Acc: 0.977\n",
      "epoch: 58/300 batch  20/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 58/300 batch  21/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 58/300 batch  22/188  Train Loss: 0.036, Acc: 0.980\n",
      "epoch: 58/300 batch  23/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 58/300 batch  24/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 58/300 batch  25/188  Train Loss: 0.041, Acc: 0.980\n",
      "epoch: 58/300 batch  26/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 58/300 batch  27/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 58/300 batch  28/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 58/300 batch  29/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 58/300 batch  30/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 58/300 batch  31/188  Train Loss: 0.078, Acc: 0.980\n",
      "epoch: 58/300 batch  32/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 58/300 batch  33/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 58/300 batch  34/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 58/300 batch  35/188  Train Loss: 0.026, Acc: 0.988\n",
      "epoch: 58/300 batch  36/188  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 58/300 batch  37/188  Train Loss: 0.073, Acc: 0.984\n",
      "epoch: 58/300 batch  38/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 58/300 batch  39/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 58/300 batch  40/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 58/300 batch  41/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 58/300 batch  42/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 58/300 batch  43/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 58/300 batch  44/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 58/300 batch  45/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 58/300 batch  46/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 58/300 batch  47/188  Train Loss: 0.055, Acc: 0.992\n",
      "epoch: 58/300 batch  48/188  Train Loss: 0.063, Acc: 0.977\n",
      "epoch: 58/300 batch  49/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 58/300 batch  50/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 58/300 batch  51/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 58/300 batch  52/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 58/300 batch  53/188  Train Loss: 0.063, Acc: 0.984\n",
      "epoch: 58/300 batch  54/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 58/300 batch  55/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 58/300 batch  56/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 58/300 batch  57/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 58/300 batch  58/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 58/300 batch  59/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 58/300 batch  60/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 58/300 batch  61/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 58/300 batch  62/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 58/300 batch  63/188  Train Loss: 0.054, Acc: 0.977\n",
      "epoch: 58/300 batch  64/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 58/300 batch  65/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 58/300 batch  66/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 58/300 batch  67/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 58/300 batch  68/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 58/300 batch  69/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 58/300 batch  70/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 58/300 batch  71/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 58/300 batch  72/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 58/300 batch  73/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 58/300 batch  74/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 58/300 batch  75/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 58/300 batch  76/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 58/300 batch  77/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 58/300 batch  78/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 58/300 batch  79/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 58/300 batch  80/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 58/300 batch  81/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 58/300 batch  82/188  Train Loss: 0.055, Acc: 0.980\n",
      "epoch: 58/300 batch  83/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 58/300 batch  84/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 58/300 batch  85/188  Train Loss: 0.063, Acc: 0.977\n",
      "epoch: 58/300 batch  86/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 58/300 batch  87/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 58/300 batch  88/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 58/300 batch  89/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 58/300 batch  90/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 58/300 batch  91/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 58/300 batch  92/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 58/300 batch  93/188  Train Loss: 0.044, Acc: 0.980\n",
      "epoch: 58/300 batch  94/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 58/300 batch  95/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 58/300 batch  96/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 58/300 batch  97/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 58/300 batch  98/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 58/300 batch  99/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 58/300 batch 100/188  Train Loss: 0.052, Acc: 0.992\n",
      "epoch: 58/300 batch 101/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 58/300 batch 102/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 58/300 batch 103/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 58/300 batch 104/188  Train Loss: 0.047, Acc: 0.977\n",
      "epoch: 58/300 batch 105/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 58/300 batch 106/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 58/300 batch 107/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 58/300 batch 108/188  Train Loss: 0.081, Acc: 0.988\n",
      "epoch: 58/300 batch 109/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 58/300 batch 110/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 58/300 batch 111/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 58/300 batch 112/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 58/300 batch 113/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 58/300 batch 114/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 58/300 batch 115/188  Train Loss: 0.033, Acc: 0.984\n",
      "epoch: 58/300 batch 116/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 58/300 batch 117/188  Train Loss: 0.056, Acc: 0.980\n",
      "epoch: 58/300 batch 118/188  Train Loss: 0.033, Acc: 1.000\n",
      "epoch: 58/300 batch 119/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 58/300 batch 120/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 58/300 batch 121/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 58/300 batch 122/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 58/300 batch 123/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 58/300 batch 124/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 58/300 batch 125/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 58/300 batch 126/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 58/300 batch 127/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 58/300 batch 128/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 58/300 batch 129/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 58/300 batch 130/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 58/300 batch 131/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 58/300 batch 132/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 58/300 batch 133/188  Train Loss: 0.057, Acc: 0.988\n",
      "epoch: 58/300 batch 134/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 58/300 batch 135/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 58/300 batch 136/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 58/300 batch 137/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 58/300 batch 138/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 58/300 batch 139/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 58/300 batch 140/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 58/300 batch 141/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 58/300 batch 142/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 58/300 batch 143/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 58/300 batch 144/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 58/300 batch 145/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 58/300 batch 146/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 58/300 batch 147/188  Train Loss: 0.057, Acc: 0.992\n",
      "epoch: 58/300 batch 148/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 58/300 batch 149/188  Train Loss: 0.051, Acc: 0.992\n",
      "epoch: 58/300 batch 150/188  Train Loss: 0.065, Acc: 0.980\n",
      "epoch: 58/300 batch 151/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 58/300 batch 152/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 58/300 batch 153/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 58/300 batch 154/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 58/300 batch 155/188  Train Loss: 0.051, Acc: 0.980\n",
      "epoch: 58/300 batch 156/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 58/300 batch 157/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 58/300 batch 158/188  Train Loss: 0.048, Acc: 0.980\n",
      "epoch: 58/300 batch 159/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 58/300 batch 160/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 58/300 batch 161/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 58/300 batch 162/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 58/300 batch 163/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 58/300 batch 164/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 58/300 batch 165/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 58/300 batch 166/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 58/300 batch 167/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 58/300 batch 168/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 58/300 batch 169/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 58/300 batch 170/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 58/300 batch 171/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 58/300 batch 172/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 58/300 batch 173/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 58/300 batch 174/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 58/300 batch 175/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 58/300 batch 176/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 58/300 batch 177/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 58/300 batch 178/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 58/300 batch 179/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 58/300 batch 180/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 58/300 batch 181/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 58/300 batch 182/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 58/300 batch 183/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 58/300 batch 184/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 58/300 batch 185/188  Train Loss: 0.054, Acc: 0.992\n",
      "epoch: 58/300 batch 186/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 58/300 batch 187/188  Train Loss: 0.041, Acc: 0.992\n",
      "Train Loss: 0.036638, Acc: 0.992\n",
      "Val Loss: 0.057817, Acc: 0.982\n",
      "epoch: 59/300 batch   0/188  Train Loss: 0.077, Acc: 0.980\n",
      "epoch: 59/300 batch   1/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 59/300 batch   2/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 59/300 batch   3/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 59/300 batch   4/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 59/300 batch   5/188  Train Loss: 0.052, Acc: 0.977\n",
      "epoch: 59/300 batch   6/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 59/300 batch   7/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 59/300 batch   8/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 59/300 batch   9/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 59/300 batch  10/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 59/300 batch  11/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 59/300 batch  12/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 59/300 batch  13/188  Train Loss: 0.060, Acc: 0.988\n",
      "epoch: 59/300 batch  14/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 59/300 batch  15/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 59/300 batch  16/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 59/300 batch  17/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 59/300 batch  18/188  Train Loss: 0.066, Acc: 0.980\n",
      "epoch: 59/300 batch  19/188  Train Loss: 0.056, Acc: 0.992\n",
      "epoch: 59/300 batch  20/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 59/300 batch  21/188  Train Loss: 0.065, Acc: 0.984\n",
      "epoch: 59/300 batch  22/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 59/300 batch  23/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 59/300 batch  24/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 59/300 batch  25/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 59/300 batch  26/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 59/300 batch  27/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 59/300 batch  28/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 59/300 batch  29/188  Train Loss: 0.031, Acc: 1.000\n",
      "epoch: 59/300 batch  30/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 59/300 batch  31/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 59/300 batch  32/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 59/300 batch  33/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 59/300 batch  34/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 59/300 batch  35/188  Train Loss: 0.071, Acc: 0.984\n",
      "epoch: 59/300 batch  36/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 59/300 batch  37/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 59/300 batch  38/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 59/300 batch  39/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 59/300 batch  40/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 59/300 batch  41/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 59/300 batch  42/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 59/300 batch  43/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 59/300 batch  44/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 59/300 batch  45/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 59/300 batch  46/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 59/300 batch  47/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 59/300 batch  48/188  Train Loss: 0.060, Acc: 0.984\n",
      "epoch: 59/300 batch  49/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 59/300 batch  50/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 59/300 batch  51/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 59/300 batch  52/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 59/300 batch  53/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 59/300 batch  54/188  Train Loss: 0.051, Acc: 0.992\n",
      "epoch: 59/300 batch  55/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 59/300 batch  56/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 59/300 batch  57/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 59/300 batch  58/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 59/300 batch  59/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 59/300 batch  60/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 59/300 batch  61/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 59/300 batch  62/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 59/300 batch  63/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 59/300 batch  64/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 59/300 batch  65/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 59/300 batch  66/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 59/300 batch  67/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 59/300 batch  68/188  Train Loss: 0.015, Acc: 0.996\n",
      "epoch: 59/300 batch  69/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 59/300 batch  70/188  Train Loss: 0.063, Acc: 0.980\n",
      "epoch: 59/300 batch  71/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 59/300 batch  72/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 59/300 batch  73/188  Train Loss: 0.048, Acc: 0.980\n",
      "epoch: 59/300 batch  74/188  Train Loss: 0.041, Acc: 0.980\n",
      "epoch: 59/300 batch  75/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 59/300 batch  76/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 59/300 batch  77/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 59/300 batch  78/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 59/300 batch  79/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 59/300 batch  80/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 59/300 batch  81/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 59/300 batch  82/188  Train Loss: 0.046, Acc: 0.996\n",
      "epoch: 59/300 batch  83/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 59/300 batch  84/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 59/300 batch  85/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 59/300 batch  86/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 59/300 batch  87/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 59/300 batch  88/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 59/300 batch  89/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 59/300 batch  90/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 59/300 batch  91/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 59/300 batch  92/188  Train Loss: 0.050, Acc: 0.977\n",
      "epoch: 59/300 batch  93/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 59/300 batch  94/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 59/300 batch  95/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 59/300 batch  96/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 59/300 batch  97/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 59/300 batch  98/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 59/300 batch  99/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 59/300 batch 100/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 59/300 batch 101/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 59/300 batch 102/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 59/300 batch 103/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 59/300 batch 104/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 59/300 batch 105/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 59/300 batch 106/188  Train Loss: 0.063, Acc: 0.988\n",
      "epoch: 59/300 batch 107/188  Train Loss: 0.059, Acc: 0.984\n",
      "epoch: 59/300 batch 108/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 59/300 batch 109/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 59/300 batch 110/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 59/300 batch 111/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 59/300 batch 112/188  Train Loss: 0.062, Acc: 0.988\n",
      "epoch: 59/300 batch 113/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 59/300 batch 114/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 59/300 batch 115/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 59/300 batch 116/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 59/300 batch 117/188  Train Loss: 0.057, Acc: 0.988\n",
      "epoch: 59/300 batch 118/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 59/300 batch 119/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 59/300 batch 120/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 59/300 batch 121/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 59/300 batch 122/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 59/300 batch 123/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 59/300 batch 124/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 59/300 batch 125/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 59/300 batch 126/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 59/300 batch 127/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 59/300 batch 128/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 59/300 batch 129/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 59/300 batch 130/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 59/300 batch 131/188  Train Loss: 0.057, Acc: 0.988\n",
      "epoch: 59/300 batch 132/188  Train Loss: 0.046, Acc: 0.980\n",
      "epoch: 59/300 batch 133/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 59/300 batch 134/188  Train Loss: 0.063, Acc: 0.977\n",
      "epoch: 59/300 batch 135/188  Train Loss: 0.057, Acc: 0.980\n",
      "epoch: 59/300 batch 136/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 59/300 batch 137/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 59/300 batch 138/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 59/300 batch 139/188  Train Loss: 0.053, Acc: 0.977\n",
      "epoch: 59/300 batch 140/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 59/300 batch 141/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 59/300 batch 142/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 59/300 batch 143/188  Train Loss: 0.065, Acc: 0.988\n",
      "epoch: 59/300 batch 144/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 59/300 batch 145/188  Train Loss: 0.058, Acc: 0.988\n",
      "epoch: 59/300 batch 146/188  Train Loss: 0.056, Acc: 0.988\n",
      "epoch: 59/300 batch 147/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 59/300 batch 148/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 59/300 batch 149/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 59/300 batch 150/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 59/300 batch 151/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 59/300 batch 152/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 59/300 batch 153/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 59/300 batch 154/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 59/300 batch 155/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 59/300 batch 156/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 59/300 batch 157/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 59/300 batch 158/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 59/300 batch 159/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 59/300 batch 160/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 59/300 batch 161/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 59/300 batch 162/188  Train Loss: 0.055, Acc: 0.980\n",
      "epoch: 59/300 batch 163/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 59/300 batch 164/188  Train Loss: 0.066, Acc: 0.984\n",
      "epoch: 59/300 batch 165/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 59/300 batch 166/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 59/300 batch 167/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 59/300 batch 168/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 59/300 batch 169/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 59/300 batch 170/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 59/300 batch 171/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 59/300 batch 172/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 59/300 batch 173/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 59/300 batch 174/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 59/300 batch 175/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 59/300 batch 176/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 59/300 batch 177/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 59/300 batch 178/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 59/300 batch 179/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 59/300 batch 180/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 59/300 batch 181/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 59/300 batch 182/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 59/300 batch 183/188  Train Loss: 0.051, Acc: 0.992\n",
      "epoch: 59/300 batch 184/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 59/300 batch 185/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 59/300 batch 186/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 59/300 batch 187/188  Train Loss: 0.014, Acc: 1.000\n",
      "Train Loss: 0.036587, Acc: 0.992\n",
      "Val Loss: 0.057912, Acc: 0.982\n",
      "epoch: 60/300 batch   0/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 60/300 batch   1/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 60/300 batch   2/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 60/300 batch   3/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 60/300 batch   4/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 60/300 batch   5/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 60/300 batch   6/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 60/300 batch   7/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 60/300 batch   8/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 60/300 batch   9/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 60/300 batch  10/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 60/300 batch  11/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 60/300 batch  12/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 60/300 batch  13/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 60/300 batch  14/188  Train Loss: 0.069, Acc: 0.977\n",
      "epoch: 60/300 batch  15/188  Train Loss: 0.071, Acc: 0.992\n",
      "epoch: 60/300 batch  16/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 60/300 batch  17/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 60/300 batch  18/188  Train Loss: 0.045, Acc: 0.980\n",
      "epoch: 60/300 batch  19/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 60/300 batch  20/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 60/300 batch  21/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 60/300 batch  22/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 60/300 batch  23/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 60/300 batch  24/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 60/300 batch  25/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 60/300 batch  26/188  Train Loss: 0.046, Acc: 0.980\n",
      "epoch: 60/300 batch  27/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 60/300 batch  28/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 60/300 batch  29/188  Train Loss: 0.052, Acc: 0.992\n",
      "epoch: 60/300 batch  30/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 60/300 batch  31/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 60/300 batch  32/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 60/300 batch  33/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 60/300 batch  34/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 60/300 batch  35/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 60/300 batch  36/188  Train Loss: 0.078, Acc: 0.973\n",
      "epoch: 60/300 batch  37/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 60/300 batch  38/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 60/300 batch  39/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 60/300 batch  40/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 60/300 batch  41/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 60/300 batch  42/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 60/300 batch  43/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 60/300 batch  44/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 60/300 batch  45/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 60/300 batch  46/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 60/300 batch  47/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 60/300 batch  48/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 60/300 batch  49/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 60/300 batch  50/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 60/300 batch  51/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 60/300 batch  52/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 60/300 batch  53/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 60/300 batch  54/188  Train Loss: 0.056, Acc: 0.980\n",
      "epoch: 60/300 batch  55/188  Train Loss: 0.042, Acc: 0.996\n",
      "epoch: 60/300 batch  56/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 60/300 batch  57/188  Train Loss: 0.057, Acc: 0.980\n",
      "epoch: 60/300 batch  58/188  Train Loss: 0.056, Acc: 0.992\n",
      "epoch: 60/300 batch  59/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 60/300 batch  60/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 60/300 batch  61/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 60/300 batch  62/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 60/300 batch  63/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 60/300 batch  64/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 60/300 batch  65/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 60/300 batch  66/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 60/300 batch  67/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 60/300 batch  68/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 60/300 batch  69/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 60/300 batch  70/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 60/300 batch  71/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 60/300 batch  72/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 60/300 batch  73/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 60/300 batch  74/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 60/300 batch  75/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 60/300 batch  76/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 60/300 batch  77/188  Train Loss: 0.061, Acc: 0.988\n",
      "epoch: 60/300 batch  78/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 60/300 batch  79/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 60/300 batch  80/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 60/300 batch  81/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 60/300 batch  82/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 60/300 batch  83/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 60/300 batch  84/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 60/300 batch  85/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 60/300 batch  86/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 60/300 batch  87/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 60/300 batch  88/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 60/300 batch  89/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 60/300 batch  90/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 60/300 batch  91/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 60/300 batch  92/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 60/300 batch  93/188  Train Loss: 0.056, Acc: 0.988\n",
      "epoch: 60/300 batch  94/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 60/300 batch  95/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 60/300 batch  96/188  Train Loss: 0.048, Acc: 0.980\n",
      "epoch: 60/300 batch  97/188  Train Loss: 0.021, Acc: 0.988\n",
      "epoch: 60/300 batch  98/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 60/300 batch  99/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 60/300 batch 100/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 60/300 batch 101/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 60/300 batch 102/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 60/300 batch 103/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 60/300 batch 104/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 60/300 batch 105/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 60/300 batch 106/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 60/300 batch 107/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 60/300 batch 108/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 60/300 batch 109/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 60/300 batch 110/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 60/300 batch 111/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 60/300 batch 112/188  Train Loss: 0.059, Acc: 0.980\n",
      "epoch: 60/300 batch 113/188  Train Loss: 0.064, Acc: 0.984\n",
      "epoch: 60/300 batch 114/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 60/300 batch 115/188  Train Loss: 0.074, Acc: 0.980\n",
      "epoch: 60/300 batch 116/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 60/300 batch 117/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 60/300 batch 118/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 60/300 batch 119/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 60/300 batch 120/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 60/300 batch 121/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 60/300 batch 122/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 60/300 batch 123/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 60/300 batch 124/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 60/300 batch 125/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 60/300 batch 126/188  Train Loss: 0.050, Acc: 0.980\n",
      "epoch: 60/300 batch 127/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 60/300 batch 128/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 60/300 batch 129/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 60/300 batch 130/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 60/300 batch 131/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 60/300 batch 132/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 60/300 batch 133/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 60/300 batch 134/188  Train Loss: 0.033, Acc: 0.984\n",
      "epoch: 60/300 batch 135/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 60/300 batch 136/188  Train Loss: 0.049, Acc: 0.980\n",
      "epoch: 60/300 batch 137/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 60/300 batch 138/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 60/300 batch 139/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 60/300 batch 140/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 60/300 batch 141/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 60/300 batch 142/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 60/300 batch 143/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 60/300 batch 144/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 60/300 batch 145/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 60/300 batch 146/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 60/300 batch 147/188  Train Loss: 0.044, Acc: 0.980\n",
      "epoch: 60/300 batch 148/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 60/300 batch 149/188  Train Loss: 0.052, Acc: 0.980\n",
      "epoch: 60/300 batch 150/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 60/300 batch 151/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 60/300 batch 152/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 60/300 batch 153/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 60/300 batch 154/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 60/300 batch 155/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 60/300 batch 156/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 60/300 batch 157/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 60/300 batch 158/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 60/300 batch 159/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 60/300 batch 160/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 60/300 batch 161/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 60/300 batch 162/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 60/300 batch 163/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 60/300 batch 164/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 60/300 batch 165/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 60/300 batch 166/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 60/300 batch 167/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 60/300 batch 168/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 60/300 batch 169/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 60/300 batch 170/188  Train Loss: 0.055, Acc: 0.992\n",
      "epoch: 60/300 batch 171/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 60/300 batch 172/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 60/300 batch 173/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 60/300 batch 174/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 60/300 batch 175/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 60/300 batch 176/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 60/300 batch 177/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 60/300 batch 178/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 60/300 batch 179/188  Train Loss: 0.057, Acc: 0.988\n",
      "epoch: 60/300 batch 180/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 60/300 batch 181/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 60/300 batch 182/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 60/300 batch 183/188  Train Loss: 0.053, Acc: 0.980\n",
      "epoch: 60/300 batch 184/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 60/300 batch 185/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 60/300 batch 186/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 60/300 batch 187/188  Train Loss: 0.029, Acc: 0.992\n",
      "Train Loss: 0.036583, Acc: 0.991\n",
      "Val Loss: 0.057724, Acc: 0.982\n",
      "epoch: 61/300 batch   0/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 61/300 batch   1/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 61/300 batch   2/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 61/300 batch   3/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 61/300 batch   4/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 61/300 batch   5/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 61/300 batch   6/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 61/300 batch   7/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 61/300 batch   8/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 61/300 batch   9/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 61/300 batch  10/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 61/300 batch  11/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 61/300 batch  12/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 61/300 batch  13/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 61/300 batch  14/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 61/300 batch  15/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 61/300 batch  16/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 61/300 batch  17/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 61/300 batch  18/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 61/300 batch  19/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 61/300 batch  20/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 61/300 batch  21/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 61/300 batch  22/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 61/300 batch  23/188  Train Loss: 0.033, Acc: 1.000\n",
      "epoch: 61/300 batch  24/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 61/300 batch  25/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 61/300 batch  26/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 61/300 batch  27/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 61/300 batch  28/188  Train Loss: 0.061, Acc: 0.988\n",
      "epoch: 61/300 batch  29/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 61/300 batch  30/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 61/300 batch  31/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 61/300 batch  32/188  Train Loss: 0.032, Acc: 0.984\n",
      "epoch: 61/300 batch  33/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 61/300 batch  34/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 61/300 batch  35/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 61/300 batch  36/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 61/300 batch  37/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 61/300 batch  38/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 61/300 batch  39/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 61/300 batch  40/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 61/300 batch  41/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 61/300 batch  42/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 61/300 batch  43/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 61/300 batch  44/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 61/300 batch  45/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 61/300 batch  46/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 61/300 batch  47/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 61/300 batch  48/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 61/300 batch  49/188  Train Loss: 0.060, Acc: 0.984\n",
      "epoch: 61/300 batch  50/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 61/300 batch  51/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 61/300 batch  52/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 61/300 batch  53/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 61/300 batch  54/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 61/300 batch  55/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 61/300 batch  56/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 61/300 batch  57/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 61/300 batch  58/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 61/300 batch  59/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 61/300 batch  60/188  Train Loss: 0.075, Acc: 0.980\n",
      "epoch: 61/300 batch  61/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 61/300 batch  62/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 61/300 batch  63/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 61/300 batch  64/188  Train Loss: 0.058, Acc: 0.980\n",
      "epoch: 61/300 batch  65/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 61/300 batch  66/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 61/300 batch  67/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 61/300 batch  68/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 61/300 batch  69/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 61/300 batch  70/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 61/300 batch  71/188  Train Loss: 0.031, Acc: 1.000\n",
      "epoch: 61/300 batch  72/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 61/300 batch  73/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 61/300 batch  74/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 61/300 batch  75/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 61/300 batch  76/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 61/300 batch  77/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 61/300 batch  78/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 61/300 batch  79/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 61/300 batch  80/188  Train Loss: 0.069, Acc: 0.984\n",
      "epoch: 61/300 batch  81/188  Train Loss: 0.056, Acc: 0.988\n",
      "epoch: 61/300 batch  82/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 61/300 batch  83/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 61/300 batch  84/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 61/300 batch  85/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 61/300 batch  86/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 61/300 batch  87/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 61/300 batch  88/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 61/300 batch  89/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 61/300 batch  90/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 61/300 batch  91/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 61/300 batch  92/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 61/300 batch  93/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 61/300 batch  94/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 61/300 batch  95/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 61/300 batch  96/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 61/300 batch  97/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 61/300 batch  98/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 61/300 batch  99/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 61/300 batch 100/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 61/300 batch 101/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 61/300 batch 102/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 61/300 batch 103/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 61/300 batch 104/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 61/300 batch 105/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 61/300 batch 106/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 61/300 batch 107/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 61/300 batch 108/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 61/300 batch 109/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 61/300 batch 110/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 61/300 batch 111/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 61/300 batch 112/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 61/300 batch 113/188  Train Loss: 0.046, Acc: 0.996\n",
      "epoch: 61/300 batch 114/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 61/300 batch 115/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 61/300 batch 116/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 61/300 batch 117/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 61/300 batch 118/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 61/300 batch 119/188  Train Loss: 0.052, Acc: 0.980\n",
      "epoch: 61/300 batch 120/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 61/300 batch 121/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 61/300 batch 122/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 61/300 batch 123/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 61/300 batch 124/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 61/300 batch 125/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 61/300 batch 126/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 61/300 batch 127/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 61/300 batch 128/188  Train Loss: 0.058, Acc: 0.980\n",
      "epoch: 61/300 batch 129/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 61/300 batch 130/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 61/300 batch 131/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 61/300 batch 132/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 61/300 batch 133/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 61/300 batch 134/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 61/300 batch 135/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 61/300 batch 136/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 61/300 batch 137/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 61/300 batch 138/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 61/300 batch 139/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 61/300 batch 140/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 61/300 batch 141/188  Train Loss: 0.028, Acc: 0.984\n",
      "epoch: 61/300 batch 142/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 61/300 batch 143/188  Train Loss: 0.066, Acc: 0.988\n",
      "epoch: 61/300 batch 144/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 61/300 batch 145/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 61/300 batch 146/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 61/300 batch 147/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 61/300 batch 148/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 61/300 batch 149/188  Train Loss: 0.054, Acc: 0.992\n",
      "epoch: 61/300 batch 150/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 61/300 batch 151/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 61/300 batch 152/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 61/300 batch 153/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 61/300 batch 154/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 61/300 batch 155/188  Train Loss: 0.089, Acc: 0.969\n",
      "epoch: 61/300 batch 156/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 61/300 batch 157/188  Train Loss: 0.064, Acc: 0.984\n",
      "epoch: 61/300 batch 158/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 61/300 batch 159/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 61/300 batch 160/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 61/300 batch 161/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 61/300 batch 162/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 61/300 batch 163/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 61/300 batch 164/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 61/300 batch 165/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 61/300 batch 166/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 61/300 batch 167/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 61/300 batch 168/188  Train Loss: 0.063, Acc: 0.980\n",
      "epoch: 61/300 batch 169/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 61/300 batch 170/188  Train Loss: 0.055, Acc: 0.980\n",
      "epoch: 61/300 batch 171/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 61/300 batch 172/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 61/300 batch 173/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 61/300 batch 174/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 61/300 batch 175/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 61/300 batch 176/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 61/300 batch 177/188  Train Loss: 0.032, Acc: 1.000\n",
      "epoch: 61/300 batch 178/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 61/300 batch 179/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 61/300 batch 180/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 61/300 batch 181/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 61/300 batch 182/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 61/300 batch 183/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 61/300 batch 184/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 61/300 batch 185/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 61/300 batch 186/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 61/300 batch 187/188  Train Loss: 0.015, Acc: 1.000\n",
      "Train Loss: 0.036516, Acc: 0.992\n",
      "Val Loss: 0.057767, Acc: 0.983\n",
      "epoch: 62/300 batch   0/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 62/300 batch   1/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 62/300 batch   2/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 62/300 batch   3/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 62/300 batch   4/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 62/300 batch   5/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 62/300 batch   6/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 62/300 batch   7/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 62/300 batch   8/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 62/300 batch   9/188  Train Loss: 0.061, Acc: 0.988\n",
      "epoch: 62/300 batch  10/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 62/300 batch  11/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 62/300 batch  12/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 62/300 batch  13/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 62/300 batch  14/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 62/300 batch  15/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 62/300 batch  16/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 62/300 batch  17/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 62/300 batch  18/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 62/300 batch  19/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 62/300 batch  20/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 62/300 batch  21/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 62/300 batch  22/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 62/300 batch  23/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 62/300 batch  24/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 62/300 batch  25/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 62/300 batch  26/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 62/300 batch  27/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 62/300 batch  28/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 62/300 batch  29/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 62/300 batch  30/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 62/300 batch  31/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 62/300 batch  32/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 62/300 batch  33/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 62/300 batch  34/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 62/300 batch  35/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 62/300 batch  36/188  Train Loss: 0.059, Acc: 0.980\n",
      "epoch: 62/300 batch  37/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 62/300 batch  38/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 62/300 batch  39/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 62/300 batch  40/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 62/300 batch  41/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 62/300 batch  42/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 62/300 batch  43/188  Train Loss: 0.046, Acc: 0.996\n",
      "epoch: 62/300 batch  44/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 62/300 batch  45/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 62/300 batch  46/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 62/300 batch  47/188  Train Loss: 0.049, Acc: 0.996\n",
      "epoch: 62/300 batch  48/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 62/300 batch  49/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 62/300 batch  50/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 62/300 batch  51/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 62/300 batch  52/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 62/300 batch  53/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 62/300 batch  54/188  Train Loss: 0.083, Acc: 0.977\n",
      "epoch: 62/300 batch  55/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 62/300 batch  56/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 62/300 batch  57/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 62/300 batch  58/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 62/300 batch  59/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 62/300 batch  60/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 62/300 batch  61/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 62/300 batch  62/188  Train Loss: 0.052, Acc: 0.992\n",
      "epoch: 62/300 batch  63/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 62/300 batch  64/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 62/300 batch  65/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 62/300 batch  66/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 62/300 batch  67/188  Train Loss: 0.060, Acc: 0.980\n",
      "epoch: 62/300 batch  68/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 62/300 batch  69/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 62/300 batch  70/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 62/300 batch  71/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 62/300 batch  72/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 62/300 batch  73/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 62/300 batch  74/188  Train Loss: 0.034, Acc: 1.000\n",
      "epoch: 62/300 batch  75/188  Train Loss: 0.058, Acc: 0.988\n",
      "epoch: 62/300 batch  76/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 62/300 batch  77/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 62/300 batch  78/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 62/300 batch  79/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 62/300 batch  80/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 62/300 batch  81/188  Train Loss: 0.080, Acc: 0.992\n",
      "epoch: 62/300 batch  82/188  Train Loss: 0.062, Acc: 0.984\n",
      "epoch: 62/300 batch  83/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 62/300 batch  84/188  Train Loss: 0.050, Acc: 0.980\n",
      "epoch: 62/300 batch  85/188  Train Loss: 0.077, Acc: 0.980\n",
      "epoch: 62/300 batch  86/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 62/300 batch  87/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 62/300 batch  88/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 62/300 batch  89/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 62/300 batch  90/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 62/300 batch  91/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 62/300 batch  92/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 62/300 batch  93/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 62/300 batch  94/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 62/300 batch  95/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 62/300 batch  96/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 62/300 batch  97/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 62/300 batch  98/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 62/300 batch  99/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 62/300 batch 100/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 62/300 batch 101/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 62/300 batch 102/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 62/300 batch 103/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 62/300 batch 104/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 62/300 batch 105/188  Train Loss: 0.048, Acc: 0.980\n",
      "epoch: 62/300 batch 106/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 62/300 batch 107/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 62/300 batch 108/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 62/300 batch 109/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 62/300 batch 110/188  Train Loss: 0.016, Acc: 0.996\n",
      "epoch: 62/300 batch 111/188  Train Loss: 0.059, Acc: 0.988\n",
      "epoch: 62/300 batch 112/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 62/300 batch 113/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 62/300 batch 114/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 62/300 batch 115/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 62/300 batch 116/188  Train Loss: 0.066, Acc: 0.980\n",
      "epoch: 62/300 batch 117/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 62/300 batch 118/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 62/300 batch 119/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 62/300 batch 120/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 62/300 batch 121/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 62/300 batch 122/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 62/300 batch 123/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 62/300 batch 124/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 62/300 batch 125/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 62/300 batch 126/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 62/300 batch 127/188  Train Loss: 0.061, Acc: 0.980\n",
      "epoch: 62/300 batch 128/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 62/300 batch 129/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 62/300 batch 130/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 62/300 batch 131/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 62/300 batch 132/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 62/300 batch 133/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 62/300 batch 134/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 62/300 batch 135/188  Train Loss: 0.059, Acc: 0.988\n",
      "epoch: 62/300 batch 136/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 62/300 batch 137/188  Train Loss: 0.074, Acc: 0.980\n",
      "epoch: 62/300 batch 138/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 62/300 batch 139/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 62/300 batch 140/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 62/300 batch 141/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 62/300 batch 142/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 62/300 batch 143/188  Train Loss: 0.032, Acc: 0.984\n",
      "epoch: 62/300 batch 144/188  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 62/300 batch 145/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 62/300 batch 146/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 62/300 batch 147/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 62/300 batch 148/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 62/300 batch 149/188  Train Loss: 0.056, Acc: 0.980\n",
      "epoch: 62/300 batch 150/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 62/300 batch 151/188  Train Loss: 0.060, Acc: 0.980\n",
      "epoch: 62/300 batch 152/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 62/300 batch 153/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 62/300 batch 154/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 62/300 batch 155/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 62/300 batch 156/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 62/300 batch 157/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 62/300 batch 158/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 62/300 batch 159/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 62/300 batch 160/188  Train Loss: 0.047, Acc: 0.980\n",
      "epoch: 62/300 batch 161/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 62/300 batch 162/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 62/300 batch 163/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 62/300 batch 164/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 62/300 batch 165/188  Train Loss: 0.066, Acc: 0.980\n",
      "epoch: 62/300 batch 166/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 62/300 batch 167/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 62/300 batch 168/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 62/300 batch 169/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 62/300 batch 170/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 62/300 batch 171/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 62/300 batch 172/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 62/300 batch 173/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 62/300 batch 174/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 62/300 batch 175/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 62/300 batch 176/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 62/300 batch 177/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 62/300 batch 178/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 62/300 batch 179/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 62/300 batch 180/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 62/300 batch 181/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 62/300 batch 182/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 62/300 batch 183/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 62/300 batch 184/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 62/300 batch 185/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 62/300 batch 186/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 62/300 batch 187/188  Train Loss: 0.012, Acc: 1.000\n",
      "Train Loss: 0.036471, Acc: 0.992\n",
      "Val Loss: 0.057746, Acc: 0.982\n",
      "epoch: 63/300 batch   0/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 63/300 batch   1/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 63/300 batch   2/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 63/300 batch   3/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 63/300 batch   4/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 63/300 batch   5/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 63/300 batch   6/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 63/300 batch   7/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 63/300 batch   8/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 63/300 batch   9/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 63/300 batch  10/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 63/300 batch  11/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 63/300 batch  12/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 63/300 batch  13/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 63/300 batch  14/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 63/300 batch  15/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 63/300 batch  16/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 63/300 batch  17/188  Train Loss: 0.044, Acc: 0.996\n",
      "epoch: 63/300 batch  18/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 63/300 batch  19/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 63/300 batch  20/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 63/300 batch  21/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 63/300 batch  22/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 63/300 batch  23/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 63/300 batch  24/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 63/300 batch  25/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 63/300 batch  26/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 63/300 batch  27/188  Train Loss: 0.032, Acc: 0.984\n",
      "epoch: 63/300 batch  28/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 63/300 batch  29/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 63/300 batch  30/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 63/300 batch  31/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 63/300 batch  32/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 63/300 batch  33/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 63/300 batch  34/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 63/300 batch  35/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 63/300 batch  36/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 63/300 batch  37/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 63/300 batch  38/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 63/300 batch  39/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 63/300 batch  40/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 63/300 batch  41/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 63/300 batch  42/188  Train Loss: 0.032, Acc: 1.000\n",
      "epoch: 63/300 batch  43/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 63/300 batch  44/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 63/300 batch  45/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 63/300 batch  46/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 63/300 batch  47/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 63/300 batch  48/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 63/300 batch  49/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 63/300 batch  50/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 63/300 batch  51/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 63/300 batch  52/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 63/300 batch  53/188  Train Loss: 0.044, Acc: 0.977\n",
      "epoch: 63/300 batch  54/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 63/300 batch  55/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 63/300 batch  56/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 63/300 batch  57/188  Train Loss: 0.050, Acc: 0.980\n",
      "epoch: 63/300 batch  58/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 63/300 batch  59/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 63/300 batch  60/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 63/300 batch  61/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 63/300 batch  62/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 63/300 batch  63/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 63/300 batch  64/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 63/300 batch  65/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 63/300 batch  66/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 63/300 batch  67/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 63/300 batch  68/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 63/300 batch  69/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 63/300 batch  70/188  Train Loss: 0.063, Acc: 0.992\n",
      "epoch: 63/300 batch  71/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 63/300 batch  72/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 63/300 batch  73/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 63/300 batch  74/188  Train Loss: 0.076, Acc: 0.980\n",
      "epoch: 63/300 batch  75/188  Train Loss: 0.044, Acc: 0.980\n",
      "epoch: 63/300 batch  76/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 63/300 batch  77/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 63/300 batch  78/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 63/300 batch  79/188  Train Loss: 0.059, Acc: 0.988\n",
      "epoch: 63/300 batch  80/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 63/300 batch  81/188  Train Loss: 0.054, Acc: 0.992\n",
      "epoch: 63/300 batch  82/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 63/300 batch  83/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 63/300 batch  84/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 63/300 batch  85/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 63/300 batch  86/188  Train Loss: 0.089, Acc: 0.988\n",
      "epoch: 63/300 batch  87/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 63/300 batch  88/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 63/300 batch  89/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 63/300 batch  90/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 63/300 batch  91/188  Train Loss: 0.056, Acc: 0.988\n",
      "epoch: 63/300 batch  92/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 63/300 batch  93/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 63/300 batch  94/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 63/300 batch  95/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 63/300 batch  96/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 63/300 batch  97/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 63/300 batch  98/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 63/300 batch  99/188  Train Loss: 0.075, Acc: 0.965\n",
      "epoch: 63/300 batch 100/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 63/300 batch 101/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 63/300 batch 102/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 63/300 batch 103/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 63/300 batch 104/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 63/300 batch 105/188  Train Loss: 0.050, Acc: 0.980\n",
      "epoch: 63/300 batch 106/188  Train Loss: 0.032, Acc: 0.980\n",
      "epoch: 63/300 batch 107/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 63/300 batch 108/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 63/300 batch 109/188  Train Loss: 0.045, Acc: 0.980\n",
      "epoch: 63/300 batch 110/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 63/300 batch 111/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 63/300 batch 112/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 63/300 batch 113/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 63/300 batch 114/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 63/300 batch 115/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 63/300 batch 116/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 63/300 batch 117/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 63/300 batch 118/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 63/300 batch 119/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 63/300 batch 120/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 63/300 batch 121/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 63/300 batch 122/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 63/300 batch 123/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 63/300 batch 124/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 63/300 batch 125/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 63/300 batch 126/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 63/300 batch 127/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 63/300 batch 128/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 63/300 batch 129/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 63/300 batch 130/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 63/300 batch 131/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 63/300 batch 132/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 63/300 batch 133/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 63/300 batch 134/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 63/300 batch 135/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 63/300 batch 136/188  Train Loss: 0.068, Acc: 0.969\n",
      "epoch: 63/300 batch 137/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 63/300 batch 138/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 63/300 batch 139/188  Train Loss: 0.057, Acc: 0.988\n",
      "epoch: 63/300 batch 140/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 63/300 batch 141/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 63/300 batch 142/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 63/300 batch 143/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 63/300 batch 144/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 63/300 batch 145/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 63/300 batch 146/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 63/300 batch 147/188  Train Loss: 0.047, Acc: 0.996\n",
      "epoch: 63/300 batch 148/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 63/300 batch 149/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 63/300 batch 150/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 63/300 batch 151/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 63/300 batch 152/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 63/300 batch 153/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 63/300 batch 154/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 63/300 batch 155/188  Train Loss: 0.051, Acc: 0.992\n",
      "epoch: 63/300 batch 156/188  Train Loss: 0.045, Acc: 0.980\n",
      "epoch: 63/300 batch 157/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 63/300 batch 158/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 63/300 batch 159/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 63/300 batch 160/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 63/300 batch 161/188  Train Loss: 0.057, Acc: 0.996\n",
      "epoch: 63/300 batch 162/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 63/300 batch 163/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 63/300 batch 164/188  Train Loss: 0.093, Acc: 0.969\n",
      "epoch: 63/300 batch 165/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 63/300 batch 166/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 63/300 batch 167/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 63/300 batch 168/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 63/300 batch 169/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 63/300 batch 170/188  Train Loss: 0.053, Acc: 0.980\n",
      "epoch: 63/300 batch 171/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 63/300 batch 172/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 63/300 batch 173/188  Train Loss: 0.050, Acc: 0.980\n",
      "epoch: 63/300 batch 174/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 63/300 batch 175/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 63/300 batch 176/188  Train Loss: 0.066, Acc: 0.980\n",
      "epoch: 63/300 batch 177/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 63/300 batch 178/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 63/300 batch 179/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 63/300 batch 180/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 63/300 batch 181/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 63/300 batch 182/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 63/300 batch 183/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 63/300 batch 184/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 63/300 batch 185/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 63/300 batch 186/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 63/300 batch 187/188  Train Loss: 0.037, Acc: 0.984\n",
      "Train Loss: 0.036434, Acc: 0.992\n",
      "Val Loss: 0.058346, Acc: 0.982\n",
      "epoch: 64/300 batch   0/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 64/300 batch   1/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 64/300 batch   2/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 64/300 batch   3/188  Train Loss: 0.048, Acc: 0.977\n",
      "epoch: 64/300 batch   4/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 64/300 batch   5/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 64/300 batch   6/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 64/300 batch   7/188  Train Loss: 0.090, Acc: 0.969\n",
      "epoch: 64/300 batch   8/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 64/300 batch   9/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 64/300 batch  10/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 64/300 batch  11/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 64/300 batch  12/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 64/300 batch  13/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 64/300 batch  14/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 64/300 batch  15/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 64/300 batch  16/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 64/300 batch  17/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 64/300 batch  18/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 64/300 batch  19/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 64/300 batch  20/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 64/300 batch  21/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 64/300 batch  22/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 64/300 batch  23/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 64/300 batch  24/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 64/300 batch  25/188  Train Loss: 0.034, Acc: 1.000\n",
      "epoch: 64/300 batch  26/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 64/300 batch  27/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 64/300 batch  28/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 64/300 batch  29/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 64/300 batch  30/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 64/300 batch  31/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 64/300 batch  32/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 64/300 batch  33/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 64/300 batch  34/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 64/300 batch  35/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 64/300 batch  36/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 64/300 batch  37/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 64/300 batch  38/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 64/300 batch  39/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 64/300 batch  40/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 64/300 batch  41/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 64/300 batch  42/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 64/300 batch  43/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 64/300 batch  44/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 64/300 batch  45/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 64/300 batch  46/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 64/300 batch  47/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 64/300 batch  48/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 64/300 batch  49/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 64/300 batch  50/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 64/300 batch  51/188  Train Loss: 0.056, Acc: 0.992\n",
      "epoch: 64/300 batch  52/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 64/300 batch  53/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 64/300 batch  54/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 64/300 batch  55/188  Train Loss: 0.064, Acc: 0.984\n",
      "epoch: 64/300 batch  56/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 64/300 batch  57/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 64/300 batch  58/188  Train Loss: 0.057, Acc: 0.980\n",
      "epoch: 64/300 batch  59/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 64/300 batch  60/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 64/300 batch  61/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 64/300 batch  62/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 64/300 batch  63/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 64/300 batch  64/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 64/300 batch  65/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 64/300 batch  66/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 64/300 batch  67/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 64/300 batch  68/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 64/300 batch  69/188  Train Loss: 0.061, Acc: 0.984\n",
      "epoch: 64/300 batch  70/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 64/300 batch  71/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 64/300 batch  72/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 64/300 batch  73/188  Train Loss: 0.074, Acc: 0.980\n",
      "epoch: 64/300 batch  74/188  Train Loss: 0.049, Acc: 0.980\n",
      "epoch: 64/300 batch  75/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 64/300 batch  76/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 64/300 batch  77/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 64/300 batch  78/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 64/300 batch  79/188  Train Loss: 0.046, Acc: 0.996\n",
      "epoch: 64/300 batch  80/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 64/300 batch  81/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 64/300 batch  82/188  Train Loss: 0.068, Acc: 0.980\n",
      "epoch: 64/300 batch  83/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 64/300 batch  84/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 64/300 batch  85/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 64/300 batch  86/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 64/300 batch  87/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 64/300 batch  88/188  Train Loss: 0.062, Acc: 0.984\n",
      "epoch: 64/300 batch  89/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 64/300 batch  90/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 64/300 batch  91/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 64/300 batch  92/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 64/300 batch  93/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 64/300 batch  94/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 64/300 batch  95/188  Train Loss: 0.024, Acc: 0.988\n",
      "epoch: 64/300 batch  96/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 64/300 batch  97/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 64/300 batch  98/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 64/300 batch  99/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 64/300 batch 100/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 64/300 batch 101/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 64/300 batch 102/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 64/300 batch 103/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 64/300 batch 104/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 64/300 batch 105/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 64/300 batch 106/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 64/300 batch 107/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 64/300 batch 108/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 64/300 batch 109/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 64/300 batch 110/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 64/300 batch 111/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 64/300 batch 112/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 64/300 batch 113/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 64/300 batch 114/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 64/300 batch 115/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 64/300 batch 116/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 64/300 batch 117/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 64/300 batch 118/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 64/300 batch 119/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 64/300 batch 120/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 64/300 batch 121/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 64/300 batch 122/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 64/300 batch 123/188  Train Loss: 0.068, Acc: 0.988\n",
      "epoch: 64/300 batch 124/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 64/300 batch 125/188  Train Loss: 0.047, Acc: 0.980\n",
      "epoch: 64/300 batch 126/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 64/300 batch 127/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 64/300 batch 128/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 64/300 batch 129/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 64/300 batch 130/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 64/300 batch 131/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 64/300 batch 132/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 64/300 batch 133/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 64/300 batch 134/188  Train Loss: 0.042, Acc: 0.980\n",
      "epoch: 64/300 batch 135/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 64/300 batch 136/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 64/300 batch 137/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 64/300 batch 138/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 64/300 batch 139/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 64/300 batch 140/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 64/300 batch 141/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 64/300 batch 142/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 64/300 batch 143/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 64/300 batch 144/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 64/300 batch 145/188  Train Loss: 0.057, Acc: 0.988\n",
      "epoch: 64/300 batch 146/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 64/300 batch 147/188  Train Loss: 0.058, Acc: 0.988\n",
      "epoch: 64/300 batch 148/188  Train Loss: 0.062, Acc: 0.977\n",
      "epoch: 64/300 batch 149/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 64/300 batch 150/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 64/300 batch 151/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 64/300 batch 152/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 64/300 batch 153/188  Train Loss: 0.062, Acc: 0.988\n",
      "epoch: 64/300 batch 154/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 64/300 batch 155/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 64/300 batch 156/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 64/300 batch 157/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 64/300 batch 158/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 64/300 batch 159/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 64/300 batch 160/188  Train Loss: 0.075, Acc: 0.980\n",
      "epoch: 64/300 batch 161/188  Train Loss: 0.049, Acc: 0.980\n",
      "epoch: 64/300 batch 162/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 64/300 batch 163/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 64/300 batch 164/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 64/300 batch 165/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 64/300 batch 166/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 64/300 batch 167/188  Train Loss: 0.063, Acc: 0.988\n",
      "epoch: 64/300 batch 168/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 64/300 batch 169/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 64/300 batch 170/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 64/300 batch 171/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 64/300 batch 172/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 64/300 batch 173/188  Train Loss: 0.053, Acc: 0.980\n",
      "epoch: 64/300 batch 174/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 64/300 batch 175/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 64/300 batch 176/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 64/300 batch 177/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 64/300 batch 178/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 64/300 batch 179/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 64/300 batch 180/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 64/300 batch 181/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 64/300 batch 182/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 64/300 batch 183/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 64/300 batch 184/188  Train Loss: 0.032, Acc: 1.000\n",
      "epoch: 64/300 batch 185/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 64/300 batch 186/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 64/300 batch 187/188  Train Loss: 0.020, Acc: 1.000\n",
      "Train Loss: 0.036389, Acc: 0.992\n",
      "Val Loss: 0.058039, Acc: 0.982\n",
      "epoch: 65/300 batch   0/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 65/300 batch   1/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 65/300 batch   2/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 65/300 batch   3/188  Train Loss: 0.062, Acc: 0.980\n",
      "epoch: 65/300 batch   4/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 65/300 batch   5/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 65/300 batch   6/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 65/300 batch   7/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 65/300 batch   8/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 65/300 batch   9/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 65/300 batch  10/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 65/300 batch  11/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 65/300 batch  12/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 65/300 batch  13/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 65/300 batch  14/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 65/300 batch  15/188  Train Loss: 0.063, Acc: 0.980\n",
      "epoch: 65/300 batch  16/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 65/300 batch  17/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 65/300 batch  18/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 65/300 batch  19/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 65/300 batch  20/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 65/300 batch  21/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 65/300 batch  22/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 65/300 batch  23/188  Train Loss: 0.033, Acc: 1.000\n",
      "epoch: 65/300 batch  24/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 65/300 batch  25/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 65/300 batch  26/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 65/300 batch  27/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 65/300 batch  28/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 65/300 batch  29/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 65/300 batch  30/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 65/300 batch  31/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 65/300 batch  32/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 65/300 batch  33/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 65/300 batch  34/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 65/300 batch  35/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 65/300 batch  36/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 65/300 batch  37/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 65/300 batch  38/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 65/300 batch  39/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 65/300 batch  40/188  Train Loss: 0.050, Acc: 0.980\n",
      "epoch: 65/300 batch  41/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 65/300 batch  42/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 65/300 batch  43/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 65/300 batch  44/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 65/300 batch  45/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 65/300 batch  46/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 65/300 batch  47/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 65/300 batch  48/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 65/300 batch  49/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 65/300 batch  50/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 65/300 batch  51/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 65/300 batch  52/188  Train Loss: 0.045, Acc: 0.980\n",
      "epoch: 65/300 batch  53/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 65/300 batch  54/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 65/300 batch  55/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 65/300 batch  56/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 65/300 batch  57/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 65/300 batch  58/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 65/300 batch  59/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 65/300 batch  60/188  Train Loss: 0.052, Acc: 0.980\n",
      "epoch: 65/300 batch  61/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 65/300 batch  62/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 65/300 batch  63/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 65/300 batch  64/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 65/300 batch  65/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 65/300 batch  66/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 65/300 batch  67/188  Train Loss: 0.046, Acc: 0.996\n",
      "epoch: 65/300 batch  68/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 65/300 batch  69/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 65/300 batch  70/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 65/300 batch  71/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 65/300 batch  72/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 65/300 batch  73/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 65/300 batch  74/188  Train Loss: 0.055, Acc: 0.977\n",
      "epoch: 65/300 batch  75/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 65/300 batch  76/188  Train Loss: 0.101, Acc: 0.984\n",
      "epoch: 65/300 batch  77/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 65/300 batch  78/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 65/300 batch  79/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 65/300 batch  80/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 65/300 batch  81/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 65/300 batch  82/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 65/300 batch  83/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 65/300 batch  84/188  Train Loss: 0.068, Acc: 0.980\n",
      "epoch: 65/300 batch  85/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 65/300 batch  86/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 65/300 batch  87/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 65/300 batch  88/188  Train Loss: 0.079, Acc: 0.977\n",
      "epoch: 65/300 batch  89/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 65/300 batch  90/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 65/300 batch  91/188  Train Loss: 0.043, Acc: 0.996\n",
      "epoch: 65/300 batch  92/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 65/300 batch  93/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 65/300 batch  94/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 65/300 batch  95/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 65/300 batch  96/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 65/300 batch  97/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 65/300 batch  98/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 65/300 batch  99/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 65/300 batch 100/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 65/300 batch 101/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 65/300 batch 102/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 65/300 batch 103/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 65/300 batch 104/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 65/300 batch 105/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 65/300 batch 106/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 65/300 batch 107/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 65/300 batch 108/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 65/300 batch 109/188  Train Loss: 0.039, Acc: 0.980\n",
      "epoch: 65/300 batch 110/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 65/300 batch 111/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 65/300 batch 112/188  Train Loss: 0.075, Acc: 0.973\n",
      "epoch: 65/300 batch 113/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 65/300 batch 114/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 65/300 batch 115/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 65/300 batch 116/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 65/300 batch 117/188  Train Loss: 0.026, Acc: 0.988\n",
      "epoch: 65/300 batch 118/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 65/300 batch 119/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 65/300 batch 120/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 65/300 batch 121/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 65/300 batch 122/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 65/300 batch 123/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 65/300 batch 124/188  Train Loss: 0.059, Acc: 0.969\n",
      "epoch: 65/300 batch 125/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 65/300 batch 126/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 65/300 batch 127/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 65/300 batch 128/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 65/300 batch 129/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 65/300 batch 130/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 65/300 batch 131/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 65/300 batch 132/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 65/300 batch 133/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 65/300 batch 134/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 65/300 batch 135/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 65/300 batch 136/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 65/300 batch 137/188  Train Loss: 0.065, Acc: 0.977\n",
      "epoch: 65/300 batch 138/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 65/300 batch 139/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 65/300 batch 140/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 65/300 batch 141/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 65/300 batch 142/188  Train Loss: 0.073, Acc: 0.984\n",
      "epoch: 65/300 batch 143/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 65/300 batch 144/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 65/300 batch 145/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 65/300 batch 146/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 65/300 batch 147/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 65/300 batch 148/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 65/300 batch 149/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 65/300 batch 150/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 65/300 batch 151/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 65/300 batch 152/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 65/300 batch 153/188  Train Loss: 0.058, Acc: 0.988\n",
      "epoch: 65/300 batch 154/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 65/300 batch 155/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 65/300 batch 156/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 65/300 batch 157/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 65/300 batch 158/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 65/300 batch 159/188  Train Loss: 0.047, Acc: 0.980\n",
      "epoch: 65/300 batch 160/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 65/300 batch 161/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 65/300 batch 162/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 65/300 batch 163/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 65/300 batch 164/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 65/300 batch 165/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 65/300 batch 166/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 65/300 batch 167/188  Train Loss: 0.032, Acc: 0.984\n",
      "epoch: 65/300 batch 168/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 65/300 batch 169/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 65/300 batch 170/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 65/300 batch 171/188  Train Loss: 0.057, Acc: 0.988\n",
      "epoch: 65/300 batch 172/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 65/300 batch 173/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 65/300 batch 174/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 65/300 batch 175/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 65/300 batch 176/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 65/300 batch 177/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 65/300 batch 178/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 65/300 batch 179/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 65/300 batch 180/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 65/300 batch 181/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 65/300 batch 182/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 65/300 batch 183/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 65/300 batch 184/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 65/300 batch 185/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 65/300 batch 186/188  Train Loss: 0.044, Acc: 0.996\n",
      "epoch: 65/300 batch 187/188  Train Loss: 0.013, Acc: 0.992\n",
      "Train Loss: 0.036331, Acc: 0.992\n",
      "Val Loss: 0.057832, Acc: 0.982\n",
      "epoch: 66/300 batch   0/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 66/300 batch   1/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 66/300 batch   2/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 66/300 batch   3/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 66/300 batch   4/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 66/300 batch   5/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 66/300 batch   6/188  Train Loss: 0.052, Acc: 0.980\n",
      "epoch: 66/300 batch   7/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 66/300 batch   8/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 66/300 batch   9/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 66/300 batch  10/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 66/300 batch  11/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 66/300 batch  12/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 66/300 batch  13/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 66/300 batch  14/188  Train Loss: 0.045, Acc: 0.996\n",
      "epoch: 66/300 batch  15/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 66/300 batch  16/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 66/300 batch  17/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 66/300 batch  18/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 66/300 batch  19/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 66/300 batch  20/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 66/300 batch  21/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 66/300 batch  22/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 66/300 batch  23/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 66/300 batch  24/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 66/300 batch  25/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 66/300 batch  26/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 66/300 batch  27/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 66/300 batch  28/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 66/300 batch  29/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 66/300 batch  30/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 66/300 batch  31/188  Train Loss: 0.037, Acc: 1.000\n",
      "epoch: 66/300 batch  32/188  Train Loss: 0.048, Acc: 0.980\n",
      "epoch: 66/300 batch  33/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 66/300 batch  34/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 66/300 batch  35/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 66/300 batch  36/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 66/300 batch  37/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 66/300 batch  38/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 66/300 batch  39/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 66/300 batch  40/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 66/300 batch  41/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 66/300 batch  42/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 66/300 batch  43/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 66/300 batch  44/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 66/300 batch  45/188  Train Loss: 0.076, Acc: 0.980\n",
      "epoch: 66/300 batch  46/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 66/300 batch  47/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 66/300 batch  48/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 66/300 batch  49/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 66/300 batch  50/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 66/300 batch  51/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 66/300 batch  52/188  Train Loss: 0.056, Acc: 0.988\n",
      "epoch: 66/300 batch  53/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 66/300 batch  54/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 66/300 batch  55/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 66/300 batch  56/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 66/300 batch  57/188  Train Loss: 0.052, Acc: 0.992\n",
      "epoch: 66/300 batch  58/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 66/300 batch  59/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 66/300 batch  60/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 66/300 batch  61/188  Train Loss: 0.042, Acc: 0.996\n",
      "epoch: 66/300 batch  62/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 66/300 batch  63/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 66/300 batch  64/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 66/300 batch  65/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 66/300 batch  66/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 66/300 batch  67/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 66/300 batch  68/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 66/300 batch  69/188  Train Loss: 0.073, Acc: 0.973\n",
      "epoch: 66/300 batch  70/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 66/300 batch  71/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 66/300 batch  72/188  Train Loss: 0.055, Acc: 0.992\n",
      "epoch: 66/300 batch  73/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 66/300 batch  74/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 66/300 batch  75/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 66/300 batch  76/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 66/300 batch  77/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 66/300 batch  78/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 66/300 batch  79/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 66/300 batch  80/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 66/300 batch  81/188  Train Loss: 0.075, Acc: 0.992\n",
      "epoch: 66/300 batch  82/188  Train Loss: 0.053, Acc: 0.980\n",
      "epoch: 66/300 batch  83/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 66/300 batch  84/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 66/300 batch  85/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 66/300 batch  86/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 66/300 batch  87/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 66/300 batch  88/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 66/300 batch  89/188  Train Loss: 0.061, Acc: 0.980\n",
      "epoch: 66/300 batch  90/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 66/300 batch  91/188  Train Loss: 0.054, Acc: 0.980\n",
      "epoch: 66/300 batch  92/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 66/300 batch  93/188  Train Loss: 0.068, Acc: 0.965\n",
      "epoch: 66/300 batch  94/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 66/300 batch  95/188  Train Loss: 0.044, Acc: 0.980\n",
      "epoch: 66/300 batch  96/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 66/300 batch  97/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 66/300 batch  98/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 66/300 batch  99/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 66/300 batch 100/188  Train Loss: 0.042, Acc: 0.996\n",
      "epoch: 66/300 batch 101/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 66/300 batch 102/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 66/300 batch 103/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 66/300 batch 104/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 66/300 batch 105/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 66/300 batch 106/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 66/300 batch 107/188  Train Loss: 0.065, Acc: 0.980\n",
      "epoch: 66/300 batch 108/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 66/300 batch 109/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 66/300 batch 110/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 66/300 batch 111/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 66/300 batch 112/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 66/300 batch 113/188  Train Loss: 0.061, Acc: 0.980\n",
      "epoch: 66/300 batch 114/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 66/300 batch 115/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 66/300 batch 116/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 66/300 batch 117/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 66/300 batch 118/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 66/300 batch 119/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 66/300 batch 120/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 66/300 batch 121/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 66/300 batch 122/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 66/300 batch 123/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 66/300 batch 124/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 66/300 batch 125/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 66/300 batch 126/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 66/300 batch 127/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 66/300 batch 128/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 66/300 batch 129/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 66/300 batch 130/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 66/300 batch 131/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 66/300 batch 132/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 66/300 batch 133/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 66/300 batch 134/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 66/300 batch 135/188  Train Loss: 0.053, Acc: 0.980\n",
      "epoch: 66/300 batch 136/188  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 66/300 batch 137/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 66/300 batch 138/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 66/300 batch 139/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 66/300 batch 140/188  Train Loss: 0.061, Acc: 0.988\n",
      "epoch: 66/300 batch 141/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 66/300 batch 142/188  Train Loss: 0.045, Acc: 0.980\n",
      "epoch: 66/300 batch 143/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 66/300 batch 144/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 66/300 batch 145/188  Train Loss: 0.052, Acc: 0.992\n",
      "epoch: 66/300 batch 146/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 66/300 batch 147/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 66/300 batch 148/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 66/300 batch 149/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 66/300 batch 150/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 66/300 batch 151/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 66/300 batch 152/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 66/300 batch 153/188  Train Loss: 0.050, Acc: 0.996\n",
      "epoch: 66/300 batch 154/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 66/300 batch 155/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 66/300 batch 156/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 66/300 batch 157/188  Train Loss: 0.033, Acc: 0.984\n",
      "epoch: 66/300 batch 158/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 66/300 batch 159/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 66/300 batch 160/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 66/300 batch 161/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 66/300 batch 162/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 66/300 batch 163/188  Train Loss: 0.068, Acc: 0.984\n",
      "epoch: 66/300 batch 164/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 66/300 batch 165/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 66/300 batch 166/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 66/300 batch 167/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 66/300 batch 168/188  Train Loss: 0.052, Acc: 0.980\n",
      "epoch: 66/300 batch 169/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 66/300 batch 170/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 66/300 batch 171/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 66/300 batch 172/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 66/300 batch 173/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 66/300 batch 174/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 66/300 batch 175/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 66/300 batch 176/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 66/300 batch 177/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 66/300 batch 178/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 66/300 batch 179/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 66/300 batch 180/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 66/300 batch 181/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 66/300 batch 182/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 66/300 batch 183/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 66/300 batch 184/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 66/300 batch 185/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 66/300 batch 186/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 66/300 batch 187/188  Train Loss: 0.020, Acc: 1.000\n",
      "Train Loss: 0.036263, Acc: 0.992\n",
      "Val Loss: 0.058130, Acc: 0.982\n",
      "epoch: 67/300 batch   0/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 67/300 batch   1/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 67/300 batch   2/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 67/300 batch   3/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 67/300 batch   4/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 67/300 batch   5/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 67/300 batch   6/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 67/300 batch   7/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 67/300 batch   8/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 67/300 batch   9/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 67/300 batch  10/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 67/300 batch  11/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 67/300 batch  12/188  Train Loss: 0.053, Acc: 0.996\n",
      "epoch: 67/300 batch  13/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 67/300 batch  14/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 67/300 batch  15/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 67/300 batch  16/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 67/300 batch  17/188  Train Loss: 0.056, Acc: 0.977\n",
      "epoch: 67/300 batch  18/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 67/300 batch  19/188  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 67/300 batch  20/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 67/300 batch  21/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 67/300 batch  22/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 67/300 batch  23/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 67/300 batch  24/188  Train Loss: 0.056, Acc: 0.988\n",
      "epoch: 67/300 batch  25/188  Train Loss: 0.057, Acc: 0.980\n",
      "epoch: 67/300 batch  26/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 67/300 batch  27/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 67/300 batch  28/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 67/300 batch  29/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 67/300 batch  30/188  Train Loss: 0.070, Acc: 0.980\n",
      "epoch: 67/300 batch  31/188  Train Loss: 0.052, Acc: 0.992\n",
      "epoch: 67/300 batch  32/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 67/300 batch  33/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 67/300 batch  34/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 67/300 batch  35/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 67/300 batch  36/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 67/300 batch  37/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 67/300 batch  38/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 67/300 batch  39/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 67/300 batch  40/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 67/300 batch  41/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 67/300 batch  42/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 67/300 batch  43/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 67/300 batch  44/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 67/300 batch  45/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 67/300 batch  46/188  Train Loss: 0.059, Acc: 0.988\n",
      "epoch: 67/300 batch  47/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 67/300 batch  48/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 67/300 batch  49/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 67/300 batch  50/188  Train Loss: 0.053, Acc: 0.980\n",
      "epoch: 67/300 batch  51/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 67/300 batch  52/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 67/300 batch  53/188  Train Loss: 0.052, Acc: 0.980\n",
      "epoch: 67/300 batch  54/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 67/300 batch  55/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 67/300 batch  56/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 67/300 batch  57/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 67/300 batch  58/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 67/300 batch  59/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 67/300 batch  60/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 67/300 batch  61/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 67/300 batch  62/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 67/300 batch  63/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 67/300 batch  64/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 67/300 batch  65/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 67/300 batch  66/188  Train Loss: 0.063, Acc: 0.977\n",
      "epoch: 67/300 batch  67/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 67/300 batch  68/188  Train Loss: 0.040, Acc: 0.977\n",
      "epoch: 67/300 batch  69/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 67/300 batch  70/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 67/300 batch  71/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 67/300 batch  72/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 67/300 batch  73/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 67/300 batch  74/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 67/300 batch  75/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 67/300 batch  76/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 67/300 batch  77/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 67/300 batch  78/188  Train Loss: 0.048, Acc: 0.977\n",
      "epoch: 67/300 batch  79/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 67/300 batch  80/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 67/300 batch  81/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 67/300 batch  82/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 67/300 batch  83/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 67/300 batch  84/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 67/300 batch  85/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 67/300 batch  86/188  Train Loss: 0.054, Acc: 0.980\n",
      "epoch: 67/300 batch  87/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 67/300 batch  88/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 67/300 batch  89/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 67/300 batch  90/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 67/300 batch  91/188  Train Loss: 0.069, Acc: 0.988\n",
      "epoch: 67/300 batch  92/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 67/300 batch  93/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 67/300 batch  94/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 67/300 batch  95/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 67/300 batch  96/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 67/300 batch  97/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 67/300 batch  98/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 67/300 batch  99/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 67/300 batch 100/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 67/300 batch 101/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 67/300 batch 102/188  Train Loss: 0.042, Acc: 0.996\n",
      "epoch: 67/300 batch 103/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 67/300 batch 104/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 67/300 batch 105/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 67/300 batch 106/188  Train Loss: 0.083, Acc: 0.980\n",
      "epoch: 67/300 batch 107/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 67/300 batch 108/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 67/300 batch 109/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 67/300 batch 110/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 67/300 batch 111/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 67/300 batch 112/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 67/300 batch 113/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 67/300 batch 114/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 67/300 batch 115/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 67/300 batch 116/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 67/300 batch 117/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 67/300 batch 118/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 67/300 batch 119/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 67/300 batch 120/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 67/300 batch 121/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 67/300 batch 122/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 67/300 batch 123/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 67/300 batch 124/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 67/300 batch 125/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 67/300 batch 126/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 67/300 batch 127/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 67/300 batch 128/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 67/300 batch 129/188  Train Loss: 0.052, Acc: 0.992\n",
      "epoch: 67/300 batch 130/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 67/300 batch 131/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 67/300 batch 132/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 67/300 batch 133/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 67/300 batch 134/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 67/300 batch 135/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 67/300 batch 136/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 67/300 batch 137/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 67/300 batch 138/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 67/300 batch 139/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 67/300 batch 140/188  Train Loss: 0.044, Acc: 0.980\n",
      "epoch: 67/300 batch 141/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 67/300 batch 142/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 67/300 batch 143/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 67/300 batch 144/188  Train Loss: 0.055, Acc: 0.992\n",
      "epoch: 67/300 batch 145/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 67/300 batch 146/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 67/300 batch 147/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 67/300 batch 148/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 67/300 batch 149/188  Train Loss: 0.065, Acc: 0.980\n",
      "epoch: 67/300 batch 150/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 67/300 batch 151/188  Train Loss: 0.042, Acc: 0.996\n",
      "epoch: 67/300 batch 152/188  Train Loss: 0.073, Acc: 0.980\n",
      "epoch: 67/300 batch 153/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 67/300 batch 154/188  Train Loss: 0.058, Acc: 0.988\n",
      "epoch: 67/300 batch 155/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 67/300 batch 156/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 67/300 batch 157/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 67/300 batch 158/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 67/300 batch 159/188  Train Loss: 0.072, Acc: 0.988\n",
      "epoch: 67/300 batch 160/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 67/300 batch 161/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 67/300 batch 162/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 67/300 batch 163/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 67/300 batch 164/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 67/300 batch 165/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 67/300 batch 166/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 67/300 batch 167/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 67/300 batch 168/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 67/300 batch 169/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 67/300 batch 170/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 67/300 batch 171/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 67/300 batch 172/188  Train Loss: 0.032, Acc: 0.984\n",
      "epoch: 67/300 batch 173/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 67/300 batch 174/188  Train Loss: 0.061, Acc: 0.992\n",
      "epoch: 67/300 batch 175/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 67/300 batch 176/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 67/300 batch 177/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 67/300 batch 178/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 67/300 batch 179/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 67/300 batch 180/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 67/300 batch 181/188  Train Loss: 0.057, Acc: 0.977\n",
      "epoch: 67/300 batch 182/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 67/300 batch 183/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 67/300 batch 184/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 67/300 batch 185/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 67/300 batch 186/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 67/300 batch 187/188  Train Loss: 0.037, Acc: 0.992\n",
      "Train Loss: 0.036347, Acc: 0.992\n",
      "Val Loss: 0.058222, Acc: 0.982\n",
      "epoch: 68/300 batch   0/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 68/300 batch   1/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 68/300 batch   2/188  Train Loss: 0.041, Acc: 0.980\n",
      "epoch: 68/300 batch   3/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 68/300 batch   4/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 68/300 batch   5/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 68/300 batch   6/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 68/300 batch   7/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 68/300 batch   8/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 68/300 batch   9/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 68/300 batch  10/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 68/300 batch  11/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 68/300 batch  12/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 68/300 batch  13/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 68/300 batch  14/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 68/300 batch  15/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 68/300 batch  16/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 68/300 batch  17/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 68/300 batch  18/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 68/300 batch  19/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 68/300 batch  20/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 68/300 batch  21/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 68/300 batch  22/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 68/300 batch  23/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 68/300 batch  24/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 68/300 batch  25/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 68/300 batch  26/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 68/300 batch  27/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 68/300 batch  28/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 68/300 batch  29/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 68/300 batch  30/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 68/300 batch  31/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 68/300 batch  32/188  Train Loss: 0.062, Acc: 0.984\n",
      "epoch: 68/300 batch  33/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 68/300 batch  34/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 68/300 batch  35/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 68/300 batch  36/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 68/300 batch  37/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 68/300 batch  38/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 68/300 batch  39/188  Train Loss: 0.069, Acc: 0.969\n",
      "epoch: 68/300 batch  40/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 68/300 batch  41/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 68/300 batch  42/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 68/300 batch  43/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 68/300 batch  44/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 68/300 batch  45/188  Train Loss: 0.067, Acc: 0.980\n",
      "epoch: 68/300 batch  46/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 68/300 batch  47/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 68/300 batch  48/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 68/300 batch  49/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 68/300 batch  50/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 68/300 batch  51/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 68/300 batch  52/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 68/300 batch  53/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 68/300 batch  54/188  Train Loss: 0.057, Acc: 0.988\n",
      "epoch: 68/300 batch  55/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 68/300 batch  56/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 68/300 batch  57/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 68/300 batch  58/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 68/300 batch  59/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 68/300 batch  60/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 68/300 batch  61/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 68/300 batch  62/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 68/300 batch  63/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 68/300 batch  64/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 68/300 batch  65/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 68/300 batch  66/188  Train Loss: 0.063, Acc: 0.984\n",
      "epoch: 68/300 batch  67/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 68/300 batch  68/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 68/300 batch  69/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 68/300 batch  70/188  Train Loss: 0.066, Acc: 0.980\n",
      "epoch: 68/300 batch  71/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 68/300 batch  72/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 68/300 batch  73/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 68/300 batch  74/188  Train Loss: 0.077, Acc: 0.973\n",
      "epoch: 68/300 batch  75/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 68/300 batch  76/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 68/300 batch  77/188  Train Loss: 0.071, Acc: 0.977\n",
      "epoch: 68/300 batch  78/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 68/300 batch  79/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 68/300 batch  80/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 68/300 batch  81/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 68/300 batch  82/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 68/300 batch  83/188  Train Loss: 0.063, Acc: 0.988\n",
      "epoch: 68/300 batch  84/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 68/300 batch  85/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 68/300 batch  86/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 68/300 batch  87/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 68/300 batch  88/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 68/300 batch  89/188  Train Loss: 0.048, Acc: 0.980\n",
      "epoch: 68/300 batch  90/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 68/300 batch  91/188  Train Loss: 0.049, Acc: 0.980\n",
      "epoch: 68/300 batch  92/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 68/300 batch  93/188  Train Loss: 0.057, Acc: 0.988\n",
      "epoch: 68/300 batch  94/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 68/300 batch  95/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 68/300 batch  96/188  Train Loss: 0.016, Acc: 0.996\n",
      "epoch: 68/300 batch  97/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 68/300 batch  98/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 68/300 batch  99/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 68/300 batch 100/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 68/300 batch 101/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 68/300 batch 102/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 68/300 batch 103/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 68/300 batch 104/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 68/300 batch 105/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 68/300 batch 106/188  Train Loss: 0.048, Acc: 0.980\n",
      "epoch: 68/300 batch 107/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 68/300 batch 108/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 68/300 batch 109/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 68/300 batch 110/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 68/300 batch 111/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 68/300 batch 112/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 68/300 batch 113/188  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 68/300 batch 114/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 68/300 batch 115/188  Train Loss: 0.046, Acc: 0.996\n",
      "epoch: 68/300 batch 116/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 68/300 batch 117/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 68/300 batch 118/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 68/300 batch 119/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 68/300 batch 120/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 68/300 batch 121/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 68/300 batch 122/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 68/300 batch 123/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 68/300 batch 124/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 68/300 batch 125/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 68/300 batch 126/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 68/300 batch 127/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 68/300 batch 128/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 68/300 batch 129/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 68/300 batch 130/188  Train Loss: 0.033, Acc: 0.984\n",
      "epoch: 68/300 batch 131/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 68/300 batch 132/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 68/300 batch 133/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 68/300 batch 134/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 68/300 batch 135/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 68/300 batch 136/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 68/300 batch 137/188  Train Loss: 0.034, Acc: 0.984\n",
      "epoch: 68/300 batch 138/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 68/300 batch 139/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 68/300 batch 140/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 68/300 batch 141/188  Train Loss: 0.056, Acc: 0.996\n",
      "epoch: 68/300 batch 142/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 68/300 batch 143/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 68/300 batch 144/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 68/300 batch 145/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 68/300 batch 146/188  Train Loss: 0.045, Acc: 0.996\n",
      "epoch: 68/300 batch 147/188  Train Loss: 0.056, Acc: 0.977\n",
      "epoch: 68/300 batch 148/188  Train Loss: 0.062, Acc: 0.973\n",
      "epoch: 68/300 batch 149/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 68/300 batch 150/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 68/300 batch 151/188  Train Loss: 0.050, Acc: 0.980\n",
      "epoch: 68/300 batch 152/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 68/300 batch 153/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 68/300 batch 154/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 68/300 batch 155/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 68/300 batch 156/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 68/300 batch 157/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 68/300 batch 158/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 68/300 batch 159/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 68/300 batch 160/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 68/300 batch 161/188  Train Loss: 0.092, Acc: 0.984\n",
      "epoch: 68/300 batch 162/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 68/300 batch 163/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 68/300 batch 164/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 68/300 batch 165/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 68/300 batch 166/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 68/300 batch 167/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 68/300 batch 168/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 68/300 batch 169/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 68/300 batch 170/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 68/300 batch 171/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 68/300 batch 172/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 68/300 batch 173/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 68/300 batch 174/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 68/300 batch 175/188  Train Loss: 0.046, Acc: 0.980\n",
      "epoch: 68/300 batch 176/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 68/300 batch 177/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 68/300 batch 178/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 68/300 batch 179/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 68/300 batch 180/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 68/300 batch 181/188  Train Loss: 0.044, Acc: 0.980\n",
      "epoch: 68/300 batch 182/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 68/300 batch 183/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 68/300 batch 184/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 68/300 batch 185/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 68/300 batch 186/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 68/300 batch 187/188  Train Loss: 0.042, Acc: 1.000\n",
      "Train Loss: 0.036325, Acc: 0.992\n",
      "Val Loss: 0.057860, Acc: 0.983\n",
      "epoch: 69/300 batch   0/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 69/300 batch   1/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 69/300 batch   2/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 69/300 batch   3/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 69/300 batch   4/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 69/300 batch   5/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 69/300 batch   6/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 69/300 batch   7/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 69/300 batch   8/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 69/300 batch   9/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 69/300 batch  10/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 69/300 batch  11/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 69/300 batch  12/188  Train Loss: 0.046, Acc: 0.996\n",
      "epoch: 69/300 batch  13/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 69/300 batch  14/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 69/300 batch  15/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 69/300 batch  16/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 69/300 batch  17/188  Train Loss: 0.061, Acc: 0.984\n",
      "epoch: 69/300 batch  18/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 69/300 batch  19/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 69/300 batch  20/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 69/300 batch  21/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 69/300 batch  22/188  Train Loss: 0.063, Acc: 0.988\n",
      "epoch: 69/300 batch  23/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 69/300 batch  24/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 69/300 batch  25/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 69/300 batch  26/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 69/300 batch  27/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 69/300 batch  28/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 69/300 batch  29/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 69/300 batch  30/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 69/300 batch  31/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 69/300 batch  32/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 69/300 batch  33/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 69/300 batch  34/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 69/300 batch  35/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 69/300 batch  36/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 69/300 batch  37/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 69/300 batch  38/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 69/300 batch  39/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 69/300 batch  40/188  Train Loss: 0.094, Acc: 0.973\n",
      "epoch: 69/300 batch  41/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 69/300 batch  42/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 69/300 batch  43/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 69/300 batch  44/188  Train Loss: 0.058, Acc: 0.988\n",
      "epoch: 69/300 batch  45/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 69/300 batch  46/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 69/300 batch  47/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 69/300 batch  48/188  Train Loss: 0.058, Acc: 0.988\n",
      "epoch: 69/300 batch  49/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 69/300 batch  50/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 69/300 batch  51/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 69/300 batch  52/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 69/300 batch  53/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 69/300 batch  54/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 69/300 batch  55/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 69/300 batch  56/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 69/300 batch  57/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 69/300 batch  58/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 69/300 batch  59/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 69/300 batch  60/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 69/300 batch  61/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 69/300 batch  62/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 69/300 batch  63/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 69/300 batch  64/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 69/300 batch  65/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 69/300 batch  66/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 69/300 batch  67/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 69/300 batch  68/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 69/300 batch  69/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 69/300 batch  70/188  Train Loss: 0.060, Acc: 0.996\n",
      "epoch: 69/300 batch  71/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 69/300 batch  72/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 69/300 batch  73/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 69/300 batch  74/188  Train Loss: 0.056, Acc: 0.988\n",
      "epoch: 69/300 batch  75/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 69/300 batch  76/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 69/300 batch  77/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 69/300 batch  78/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 69/300 batch  79/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 69/300 batch  80/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 69/300 batch  81/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 69/300 batch  82/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 69/300 batch  83/188  Train Loss: 0.053, Acc: 0.980\n",
      "epoch: 69/300 batch  84/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 69/300 batch  85/188  Train Loss: 0.044, Acc: 0.980\n",
      "epoch: 69/300 batch  86/188  Train Loss: 0.055, Acc: 0.980\n",
      "epoch: 69/300 batch  87/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 69/300 batch  88/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 69/300 batch  89/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 69/300 batch  90/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 69/300 batch  91/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 69/300 batch  92/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 69/300 batch  93/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 69/300 batch  94/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 69/300 batch  95/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 69/300 batch  96/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 69/300 batch  97/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 69/300 batch  98/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 69/300 batch  99/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 69/300 batch 100/188  Train Loss: 0.032, Acc: 1.000\n",
      "epoch: 69/300 batch 101/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 69/300 batch 102/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 69/300 batch 103/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 69/300 batch 104/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 69/300 batch 105/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 69/300 batch 106/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 69/300 batch 107/188  Train Loss: 0.057, Acc: 0.977\n",
      "epoch: 69/300 batch 108/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 69/300 batch 109/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 69/300 batch 110/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 69/300 batch 111/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 69/300 batch 112/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 69/300 batch 113/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 69/300 batch 114/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 69/300 batch 115/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 69/300 batch 116/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 69/300 batch 117/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 69/300 batch 118/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 69/300 batch 119/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 69/300 batch 120/188  Train Loss: 0.064, Acc: 0.984\n",
      "epoch: 69/300 batch 121/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 69/300 batch 122/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 69/300 batch 123/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 69/300 batch 124/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 69/300 batch 125/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 69/300 batch 126/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 69/300 batch 127/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 69/300 batch 128/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 69/300 batch 129/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 69/300 batch 130/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 69/300 batch 131/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 69/300 batch 132/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 69/300 batch 133/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 69/300 batch 134/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 69/300 batch 135/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 69/300 batch 136/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 69/300 batch 137/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 69/300 batch 138/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 69/300 batch 139/188  Train Loss: 0.072, Acc: 0.965\n",
      "epoch: 69/300 batch 140/188  Train Loss: 0.052, Acc: 0.992\n",
      "epoch: 69/300 batch 141/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 69/300 batch 142/188  Train Loss: 0.042, Acc: 0.996\n",
      "epoch: 69/300 batch 143/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 69/300 batch 144/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 69/300 batch 145/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 69/300 batch 146/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 69/300 batch 147/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 69/300 batch 148/188  Train Loss: 0.047, Acc: 0.996\n",
      "epoch: 69/300 batch 149/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 69/300 batch 150/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 69/300 batch 151/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 69/300 batch 152/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 69/300 batch 153/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 69/300 batch 154/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 69/300 batch 155/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 69/300 batch 156/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 69/300 batch 157/188  Train Loss: 0.061, Acc: 0.988\n",
      "epoch: 69/300 batch 158/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 69/300 batch 159/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 69/300 batch 160/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 69/300 batch 161/188  Train Loss: 0.060, Acc: 0.980\n",
      "epoch: 69/300 batch 162/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 69/300 batch 163/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 69/300 batch 164/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 69/300 batch 165/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 69/300 batch 166/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 69/300 batch 167/188  Train Loss: 0.060, Acc: 0.984\n",
      "epoch: 69/300 batch 168/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 69/300 batch 169/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 69/300 batch 170/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 69/300 batch 171/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 69/300 batch 172/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 69/300 batch 173/188  Train Loss: 0.076, Acc: 0.980\n",
      "epoch: 69/300 batch 174/188  Train Loss: 0.045, Acc: 0.996\n",
      "epoch: 69/300 batch 175/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 69/300 batch 176/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 69/300 batch 177/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 69/300 batch 178/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 69/300 batch 179/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 69/300 batch 180/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 69/300 batch 181/188  Train Loss: 0.047, Acc: 0.980\n",
      "epoch: 69/300 batch 182/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 69/300 batch 183/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 69/300 batch 184/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 69/300 batch 185/188  Train Loss: 0.040, Acc: 0.980\n",
      "epoch: 69/300 batch 186/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 69/300 batch 187/188  Train Loss: 0.045, Acc: 0.984\n",
      "Train Loss: 0.036272, Acc: 0.992\n",
      "Val Loss: 0.058210, Acc: 0.982\n",
      "epoch: 70/300 batch   0/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 70/300 batch   1/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 70/300 batch   2/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 70/300 batch   3/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 70/300 batch   4/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 70/300 batch   5/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 70/300 batch   6/188  Train Loss: 0.051, Acc: 0.992\n",
      "epoch: 70/300 batch   7/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 70/300 batch   8/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 70/300 batch   9/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 70/300 batch  10/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 70/300 batch  11/188  Train Loss: 0.027, Acc: 0.988\n",
      "epoch: 70/300 batch  12/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 70/300 batch  13/188  Train Loss: 0.046, Acc: 0.980\n",
      "epoch: 70/300 batch  14/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 70/300 batch  15/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 70/300 batch  16/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 70/300 batch  17/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 70/300 batch  18/188  Train Loss: 0.050, Acc: 0.996\n",
      "epoch: 70/300 batch  19/188  Train Loss: 0.053, Acc: 0.980\n",
      "epoch: 70/300 batch  20/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 70/300 batch  21/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 70/300 batch  22/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 70/300 batch  23/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 70/300 batch  24/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 70/300 batch  25/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 70/300 batch  26/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 70/300 batch  27/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 70/300 batch  28/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 70/300 batch  29/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 70/300 batch  30/188  Train Loss: 0.051, Acc: 0.992\n",
      "epoch: 70/300 batch  31/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 70/300 batch  32/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 70/300 batch  33/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 70/300 batch  34/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 70/300 batch  35/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 70/300 batch  36/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 70/300 batch  37/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 70/300 batch  38/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 70/300 batch  39/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 70/300 batch  40/188  Train Loss: 0.102, Acc: 0.969\n",
      "epoch: 70/300 batch  41/188  Train Loss: 0.062, Acc: 0.988\n",
      "epoch: 70/300 batch  42/188  Train Loss: 0.057, Acc: 0.980\n",
      "epoch: 70/300 batch  43/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 70/300 batch  44/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 70/300 batch  45/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 70/300 batch  46/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 70/300 batch  47/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 70/300 batch  48/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 70/300 batch  49/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 70/300 batch  50/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 70/300 batch  51/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 70/300 batch  52/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 70/300 batch  53/188  Train Loss: 0.056, Acc: 0.992\n",
      "epoch: 70/300 batch  54/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 70/300 batch  55/188  Train Loss: 0.026, Acc: 0.988\n",
      "epoch: 70/300 batch  56/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 70/300 batch  57/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 70/300 batch  58/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 70/300 batch  59/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 70/300 batch  60/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 70/300 batch  61/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 70/300 batch  62/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 70/300 batch  63/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 70/300 batch  64/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 70/300 batch  65/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 70/300 batch  66/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 70/300 batch  67/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 70/300 batch  68/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 70/300 batch  69/188  Train Loss: 0.056, Acc: 0.980\n",
      "epoch: 70/300 batch  70/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 70/300 batch  71/188  Train Loss: 0.047, Acc: 0.980\n",
      "epoch: 70/300 batch  72/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 70/300 batch  73/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 70/300 batch  74/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 70/300 batch  75/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 70/300 batch  76/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 70/300 batch  77/188  Train Loss: 0.081, Acc: 0.984\n",
      "epoch: 70/300 batch  78/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 70/300 batch  79/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 70/300 batch  80/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 70/300 batch  81/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 70/300 batch  82/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 70/300 batch  83/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 70/300 batch  84/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 70/300 batch  85/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 70/300 batch  86/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 70/300 batch  87/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 70/300 batch  88/188  Train Loss: 0.034, Acc: 0.984\n",
      "epoch: 70/300 batch  89/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 70/300 batch  90/188  Train Loss: 0.034, Acc: 1.000\n",
      "epoch: 70/300 batch  91/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 70/300 batch  92/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 70/300 batch  93/188  Train Loss: 0.044, Acc: 0.980\n",
      "epoch: 70/300 batch  94/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 70/300 batch  95/188  Train Loss: 0.056, Acc: 0.977\n",
      "epoch: 70/300 batch  96/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 70/300 batch  97/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 70/300 batch  98/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 70/300 batch  99/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 70/300 batch 100/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 70/300 batch 101/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 70/300 batch 102/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 70/300 batch 103/188  Train Loss: 0.068, Acc: 0.984\n",
      "epoch: 70/300 batch 104/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 70/300 batch 105/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 70/300 batch 106/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 70/300 batch 107/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 70/300 batch 108/188  Train Loss: 0.036, Acc: 1.000\n",
      "epoch: 70/300 batch 109/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 70/300 batch 110/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 70/300 batch 111/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 70/300 batch 112/188  Train Loss: 0.059, Acc: 0.988\n",
      "epoch: 70/300 batch 113/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 70/300 batch 114/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 70/300 batch 115/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 70/300 batch 116/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 70/300 batch 117/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 70/300 batch 118/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 70/300 batch 119/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 70/300 batch 120/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 70/300 batch 121/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 70/300 batch 122/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 70/300 batch 123/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 70/300 batch 124/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 70/300 batch 125/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 70/300 batch 126/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 70/300 batch 127/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 70/300 batch 128/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 70/300 batch 129/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 70/300 batch 130/188  Train Loss: 0.030, Acc: 0.984\n",
      "epoch: 70/300 batch 131/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 70/300 batch 132/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 70/300 batch 133/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 70/300 batch 134/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 70/300 batch 135/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 70/300 batch 136/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 70/300 batch 137/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 70/300 batch 138/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 70/300 batch 139/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 70/300 batch 140/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 70/300 batch 141/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 70/300 batch 142/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 70/300 batch 143/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 70/300 batch 144/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 70/300 batch 145/188  Train Loss: 0.057, Acc: 0.980\n",
      "epoch: 70/300 batch 146/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 70/300 batch 147/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 70/300 batch 148/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 70/300 batch 149/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 70/300 batch 150/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 70/300 batch 151/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 70/300 batch 152/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 70/300 batch 153/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 70/300 batch 154/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 70/300 batch 155/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 70/300 batch 156/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 70/300 batch 157/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 70/300 batch 158/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 70/300 batch 159/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 70/300 batch 160/188  Train Loss: 0.057, Acc: 0.973\n",
      "epoch: 70/300 batch 161/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 70/300 batch 162/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 70/300 batch 163/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 70/300 batch 164/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 70/300 batch 165/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 70/300 batch 166/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 70/300 batch 167/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 70/300 batch 168/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 70/300 batch 169/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 70/300 batch 170/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 70/300 batch 171/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 70/300 batch 172/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 70/300 batch 173/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 70/300 batch 174/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 70/300 batch 175/188  Train Loss: 0.057, Acc: 0.992\n",
      "epoch: 70/300 batch 176/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 70/300 batch 177/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 70/300 batch 178/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 70/300 batch 179/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 70/300 batch 180/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 70/300 batch 181/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 70/300 batch 182/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 70/300 batch 183/188  Train Loss: 0.083, Acc: 0.984\n",
      "epoch: 70/300 batch 184/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 70/300 batch 185/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 70/300 batch 186/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 70/300 batch 187/188  Train Loss: 0.034, Acc: 0.992\n",
      "Train Loss: 0.036201, Acc: 0.992\n",
      "Val Loss: 0.058123, Acc: 0.982\n",
      "epoch: 71/300 batch   0/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 71/300 batch   1/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 71/300 batch   2/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 71/300 batch   3/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 71/300 batch   4/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 71/300 batch   5/188  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 71/300 batch   6/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 71/300 batch   7/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 71/300 batch   8/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 71/300 batch   9/188  Train Loss: 0.043, Acc: 0.996\n",
      "epoch: 71/300 batch  10/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 71/300 batch  11/188  Train Loss: 0.027, Acc: 0.988\n",
      "epoch: 71/300 batch  12/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 71/300 batch  13/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 71/300 batch  14/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 71/300 batch  15/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 71/300 batch  16/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 71/300 batch  17/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 71/300 batch  18/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 71/300 batch  19/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 71/300 batch  20/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 71/300 batch  21/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 71/300 batch  22/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 71/300 batch  23/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 71/300 batch  24/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 71/300 batch  25/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 71/300 batch  26/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 71/300 batch  27/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 71/300 batch  28/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 71/300 batch  29/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 71/300 batch  30/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 71/300 batch  31/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 71/300 batch  32/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 71/300 batch  33/188  Train Loss: 0.067, Acc: 0.977\n",
      "epoch: 71/300 batch  34/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 71/300 batch  35/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 71/300 batch  36/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 71/300 batch  37/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 71/300 batch  38/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 71/300 batch  39/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 71/300 batch  40/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 71/300 batch  41/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 71/300 batch  42/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 71/300 batch  43/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 71/300 batch  44/188  Train Loss: 0.069, Acc: 0.980\n",
      "epoch: 71/300 batch  45/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 71/300 batch  46/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 71/300 batch  47/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 71/300 batch  48/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 71/300 batch  49/188  Train Loss: 0.026, Acc: 0.988\n",
      "epoch: 71/300 batch  50/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 71/300 batch  51/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 71/300 batch  52/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 71/300 batch  53/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 71/300 batch  54/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 71/300 batch  55/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 71/300 batch  56/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 71/300 batch  57/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 71/300 batch  58/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 71/300 batch  59/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 71/300 batch  60/188  Train Loss: 0.055, Acc: 0.980\n",
      "epoch: 71/300 batch  61/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 71/300 batch  62/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 71/300 batch  63/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 71/300 batch  64/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 71/300 batch  65/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 71/300 batch  66/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 71/300 batch  67/188  Train Loss: 0.049, Acc: 0.996\n",
      "epoch: 71/300 batch  68/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 71/300 batch  69/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 71/300 batch  70/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 71/300 batch  71/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 71/300 batch  72/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 71/300 batch  73/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 71/300 batch  74/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 71/300 batch  75/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 71/300 batch  76/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 71/300 batch  77/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 71/300 batch  78/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 71/300 batch  79/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 71/300 batch  80/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 71/300 batch  81/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 71/300 batch  82/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 71/300 batch  83/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 71/300 batch  84/188  Train Loss: 0.046, Acc: 0.996\n",
      "epoch: 71/300 batch  85/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 71/300 batch  86/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 71/300 batch  87/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 71/300 batch  88/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 71/300 batch  89/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 71/300 batch  90/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 71/300 batch  91/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 71/300 batch  92/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 71/300 batch  93/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 71/300 batch  94/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 71/300 batch  95/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 71/300 batch  96/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 71/300 batch  97/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 71/300 batch  98/188  Train Loss: 0.040, Acc: 0.980\n",
      "epoch: 71/300 batch  99/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 71/300 batch 100/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 71/300 batch 101/188  Train Loss: 0.047, Acc: 0.977\n",
      "epoch: 71/300 batch 102/188  Train Loss: 0.041, Acc: 0.980\n",
      "epoch: 71/300 batch 103/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 71/300 batch 104/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 71/300 batch 105/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 71/300 batch 106/188  Train Loss: 0.061, Acc: 0.984\n",
      "epoch: 71/300 batch 107/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 71/300 batch 108/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 71/300 batch 109/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 71/300 batch 110/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 71/300 batch 111/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 71/300 batch 112/188  Train Loss: 0.060, Acc: 0.980\n",
      "epoch: 71/300 batch 113/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 71/300 batch 114/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 71/300 batch 115/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 71/300 batch 116/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 71/300 batch 117/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 71/300 batch 118/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 71/300 batch 119/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 71/300 batch 120/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 71/300 batch 121/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 71/300 batch 122/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 71/300 batch 123/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 71/300 batch 124/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 71/300 batch 125/188  Train Loss: 0.058, Acc: 0.992\n",
      "epoch: 71/300 batch 126/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 71/300 batch 127/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 71/300 batch 128/188  Train Loss: 0.052, Acc: 0.992\n",
      "epoch: 71/300 batch 129/188  Train Loss: 0.058, Acc: 0.988\n",
      "epoch: 71/300 batch 130/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 71/300 batch 131/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 71/300 batch 132/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 71/300 batch 133/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 71/300 batch 134/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 71/300 batch 135/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 71/300 batch 136/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 71/300 batch 137/188  Train Loss: 0.069, Acc: 0.980\n",
      "epoch: 71/300 batch 138/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 71/300 batch 139/188  Train Loss: 0.062, Acc: 0.988\n",
      "epoch: 71/300 batch 140/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 71/300 batch 141/188  Train Loss: 0.049, Acc: 0.980\n",
      "epoch: 71/300 batch 142/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 71/300 batch 143/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 71/300 batch 144/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 71/300 batch 145/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 71/300 batch 146/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 71/300 batch 147/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 71/300 batch 148/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 71/300 batch 149/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 71/300 batch 150/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 71/300 batch 151/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 71/300 batch 152/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 71/300 batch 153/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 71/300 batch 154/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 71/300 batch 155/188  Train Loss: 0.060, Acc: 0.988\n",
      "epoch: 71/300 batch 156/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 71/300 batch 157/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 71/300 batch 158/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 71/300 batch 159/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 71/300 batch 160/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 71/300 batch 161/188  Train Loss: 0.052, Acc: 0.980\n",
      "epoch: 71/300 batch 162/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 71/300 batch 163/188  Train Loss: 0.034, Acc: 1.000\n",
      "epoch: 71/300 batch 164/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 71/300 batch 165/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 71/300 batch 166/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 71/300 batch 167/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 71/300 batch 168/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 71/300 batch 169/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 71/300 batch 170/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 71/300 batch 171/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 71/300 batch 172/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 71/300 batch 173/188  Train Loss: 0.059, Acc: 0.984\n",
      "epoch: 71/300 batch 174/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 71/300 batch 175/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 71/300 batch 176/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 71/300 batch 177/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 71/300 batch 178/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 71/300 batch 179/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 71/300 batch 180/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 71/300 batch 181/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 71/300 batch 182/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 71/300 batch 183/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 71/300 batch 184/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 71/300 batch 185/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 71/300 batch 186/188  Train Loss: 0.068, Acc: 0.984\n",
      "epoch: 71/300 batch 187/188  Train Loss: 0.063, Acc: 0.992\n",
      "Train Loss: 0.036248, Acc: 0.992\n",
      "Val Loss: 0.057903, Acc: 0.982\n",
      "epoch: 72/300 batch   0/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 72/300 batch   1/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 72/300 batch   2/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 72/300 batch   3/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 72/300 batch   4/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 72/300 batch   5/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 72/300 batch   6/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 72/300 batch   7/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 72/300 batch   8/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 72/300 batch   9/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 72/300 batch  10/188  Train Loss: 0.061, Acc: 0.984\n",
      "epoch: 72/300 batch  11/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 72/300 batch  12/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 72/300 batch  13/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 72/300 batch  14/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 72/300 batch  15/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 72/300 batch  16/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 72/300 batch  17/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 72/300 batch  18/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 72/300 batch  19/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 72/300 batch  20/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 72/300 batch  21/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 72/300 batch  22/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 72/300 batch  23/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 72/300 batch  24/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 72/300 batch  25/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 72/300 batch  26/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 72/300 batch  27/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 72/300 batch  28/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 72/300 batch  29/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 72/300 batch  30/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 72/300 batch  31/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 72/300 batch  32/188  Train Loss: 0.049, Acc: 0.980\n",
      "epoch: 72/300 batch  33/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 72/300 batch  34/188  Train Loss: 0.061, Acc: 0.992\n",
      "epoch: 72/300 batch  35/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 72/300 batch  36/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 72/300 batch  37/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 72/300 batch  38/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 72/300 batch  39/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 72/300 batch  40/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 72/300 batch  41/188  Train Loss: 0.043, Acc: 0.996\n",
      "epoch: 72/300 batch  42/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 72/300 batch  43/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 72/300 batch  44/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 72/300 batch  45/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 72/300 batch  46/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 72/300 batch  47/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 72/300 batch  48/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 72/300 batch  49/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 72/300 batch  50/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 72/300 batch  51/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 72/300 batch  52/188  Train Loss: 0.064, Acc: 0.980\n",
      "epoch: 72/300 batch  53/188  Train Loss: 0.063, Acc: 0.980\n",
      "epoch: 72/300 batch  54/188  Train Loss: 0.053, Acc: 0.992\n",
      "epoch: 72/300 batch  55/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 72/300 batch  56/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 72/300 batch  57/188  Train Loss: 0.058, Acc: 0.988\n",
      "epoch: 72/300 batch  58/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 72/300 batch  59/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 72/300 batch  60/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 72/300 batch  61/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 72/300 batch  62/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 72/300 batch  63/188  Train Loss: 0.034, Acc: 1.000\n",
      "epoch: 72/300 batch  64/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 72/300 batch  65/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 72/300 batch  66/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 72/300 batch  67/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 72/300 batch  68/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 72/300 batch  69/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 72/300 batch  70/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 72/300 batch  71/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 72/300 batch  72/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 72/300 batch  73/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 72/300 batch  74/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 72/300 batch  75/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 72/300 batch  76/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 72/300 batch  77/188  Train Loss: 0.060, Acc: 0.984\n",
      "epoch: 72/300 batch  78/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 72/300 batch  79/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 72/300 batch  80/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 72/300 batch  81/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 72/300 batch  82/188  Train Loss: 0.065, Acc: 0.984\n",
      "epoch: 72/300 batch  83/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 72/300 batch  84/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 72/300 batch  85/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 72/300 batch  86/188  Train Loss: 0.060, Acc: 0.980\n",
      "epoch: 72/300 batch  87/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 72/300 batch  88/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 72/300 batch  89/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 72/300 batch  90/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 72/300 batch  91/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 72/300 batch  92/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 72/300 batch  93/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 72/300 batch  94/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 72/300 batch  95/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 72/300 batch  96/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 72/300 batch  97/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 72/300 batch  98/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 72/300 batch  99/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 72/300 batch 100/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 72/300 batch 101/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 72/300 batch 102/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 72/300 batch 103/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 72/300 batch 104/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 72/300 batch 105/188  Train Loss: 0.052, Acc: 0.992\n",
      "epoch: 72/300 batch 106/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 72/300 batch 107/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 72/300 batch 108/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 72/300 batch 109/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 72/300 batch 110/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 72/300 batch 111/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 72/300 batch 112/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 72/300 batch 113/188  Train Loss: 0.059, Acc: 0.988\n",
      "epoch: 72/300 batch 114/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 72/300 batch 115/188  Train Loss: 0.042, Acc: 0.996\n",
      "epoch: 72/300 batch 116/188  Train Loss: 0.056, Acc: 0.977\n",
      "epoch: 72/300 batch 117/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 72/300 batch 118/188  Train Loss: 0.075, Acc: 0.984\n",
      "epoch: 72/300 batch 119/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 72/300 batch 120/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 72/300 batch 121/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 72/300 batch 122/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 72/300 batch 123/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 72/300 batch 124/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 72/300 batch 125/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 72/300 batch 126/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 72/300 batch 127/188  Train Loss: 0.057, Acc: 0.980\n",
      "epoch: 72/300 batch 128/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 72/300 batch 129/188  Train Loss: 0.068, Acc: 0.984\n",
      "epoch: 72/300 batch 130/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 72/300 batch 131/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 72/300 batch 132/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 72/300 batch 133/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 72/300 batch 134/188  Train Loss: 0.043, Acc: 0.996\n",
      "epoch: 72/300 batch 135/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 72/300 batch 136/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 72/300 batch 137/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 72/300 batch 138/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 72/300 batch 139/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 72/300 batch 140/188  Train Loss: 0.033, Acc: 0.984\n",
      "epoch: 72/300 batch 141/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 72/300 batch 142/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 72/300 batch 143/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 72/300 batch 144/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 72/300 batch 145/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 72/300 batch 146/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 72/300 batch 147/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 72/300 batch 148/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 72/300 batch 149/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 72/300 batch 150/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 72/300 batch 151/188  Train Loss: 0.080, Acc: 0.980\n",
      "epoch: 72/300 batch 152/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 72/300 batch 153/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 72/300 batch 154/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 72/300 batch 155/188  Train Loss: 0.057, Acc: 0.980\n",
      "epoch: 72/300 batch 156/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 72/300 batch 157/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 72/300 batch 158/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 72/300 batch 159/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 72/300 batch 160/188  Train Loss: 0.042, Acc: 0.996\n",
      "epoch: 72/300 batch 161/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 72/300 batch 162/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 72/300 batch 163/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 72/300 batch 164/188  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 72/300 batch 165/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 72/300 batch 166/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 72/300 batch 167/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 72/300 batch 168/188  Train Loss: 0.058, Acc: 0.992\n",
      "epoch: 72/300 batch 169/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 72/300 batch 170/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 72/300 batch 171/188  Train Loss: 0.026, Acc: 0.988\n",
      "epoch: 72/300 batch 172/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 72/300 batch 173/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 72/300 batch 174/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 72/300 batch 175/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 72/300 batch 176/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 72/300 batch 177/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 72/300 batch 178/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 72/300 batch 179/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 72/300 batch 180/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 72/300 batch 181/188  Train Loss: 0.044, Acc: 0.980\n",
      "epoch: 72/300 batch 182/188  Train Loss: 0.045, Acc: 0.980\n",
      "epoch: 72/300 batch 183/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 72/300 batch 184/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 72/300 batch 185/188  Train Loss: 0.063, Acc: 0.973\n",
      "epoch: 72/300 batch 186/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 72/300 batch 187/188  Train Loss: 0.022, Acc: 1.000\n",
      "Train Loss: 0.036092, Acc: 0.992\n",
      "Val Loss: 0.057732, Acc: 0.982\n",
      "epoch: 73/300 batch   0/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 73/300 batch   1/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 73/300 batch   2/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 73/300 batch   3/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 73/300 batch   4/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 73/300 batch   5/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 73/300 batch   6/188  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 73/300 batch   7/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 73/300 batch   8/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 73/300 batch   9/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 73/300 batch  10/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 73/300 batch  11/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 73/300 batch  12/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 73/300 batch  13/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 73/300 batch  14/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 73/300 batch  15/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 73/300 batch  16/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 73/300 batch  17/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 73/300 batch  18/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 73/300 batch  19/188  Train Loss: 0.060, Acc: 0.988\n",
      "epoch: 73/300 batch  20/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 73/300 batch  21/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 73/300 batch  22/188  Train Loss: 0.070, Acc: 0.984\n",
      "epoch: 73/300 batch  23/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 73/300 batch  24/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 73/300 batch  25/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 73/300 batch  26/188  Train Loss: 0.065, Acc: 0.984\n",
      "epoch: 73/300 batch  27/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 73/300 batch  28/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 73/300 batch  29/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 73/300 batch  30/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 73/300 batch  31/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 73/300 batch  32/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 73/300 batch  33/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 73/300 batch  34/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 73/300 batch  35/188  Train Loss: 0.056, Acc: 0.988\n",
      "epoch: 73/300 batch  36/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 73/300 batch  37/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 73/300 batch  38/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 73/300 batch  39/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 73/300 batch  40/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 73/300 batch  41/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 73/300 batch  42/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 73/300 batch  43/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 73/300 batch  44/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 73/300 batch  45/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 73/300 batch  46/188  Train Loss: 0.065, Acc: 0.984\n",
      "epoch: 73/300 batch  47/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 73/300 batch  48/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 73/300 batch  49/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 73/300 batch  50/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 73/300 batch  51/188  Train Loss: 0.031, Acc: 1.000\n",
      "epoch: 73/300 batch  52/188  Train Loss: 0.054, Acc: 0.980\n",
      "epoch: 73/300 batch  53/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 73/300 batch  54/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 73/300 batch  55/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 73/300 batch  56/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 73/300 batch  57/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 73/300 batch  58/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 73/300 batch  59/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 73/300 batch  60/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 73/300 batch  61/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 73/300 batch  62/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 73/300 batch  63/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 73/300 batch  64/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 73/300 batch  65/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 73/300 batch  66/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 73/300 batch  67/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 73/300 batch  68/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 73/300 batch  69/188  Train Loss: 0.049, Acc: 0.996\n",
      "epoch: 73/300 batch  70/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 73/300 batch  71/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 73/300 batch  72/188  Train Loss: 0.052, Acc: 0.992\n",
      "epoch: 73/300 batch  73/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 73/300 batch  74/188  Train Loss: 0.048, Acc: 0.980\n",
      "epoch: 73/300 batch  75/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 73/300 batch  76/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 73/300 batch  77/188  Train Loss: 0.059, Acc: 0.980\n",
      "epoch: 73/300 batch  78/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 73/300 batch  79/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 73/300 batch  80/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 73/300 batch  81/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 73/300 batch  82/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 73/300 batch  83/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 73/300 batch  84/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 73/300 batch  85/188  Train Loss: 0.080, Acc: 0.977\n",
      "epoch: 73/300 batch  86/188  Train Loss: 0.072, Acc: 0.980\n",
      "epoch: 73/300 batch  87/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 73/300 batch  88/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 73/300 batch  89/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 73/300 batch  90/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 73/300 batch  91/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 73/300 batch  92/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 73/300 batch  93/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 73/300 batch  94/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 73/300 batch  95/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 73/300 batch  96/188  Train Loss: 0.041, Acc: 0.980\n",
      "epoch: 73/300 batch  97/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 73/300 batch  98/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 73/300 batch  99/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 73/300 batch 100/188  Train Loss: 0.060, Acc: 0.984\n",
      "epoch: 73/300 batch 101/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 73/300 batch 102/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 73/300 batch 103/188  Train Loss: 0.056, Acc: 0.980\n",
      "epoch: 73/300 batch 104/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 73/300 batch 105/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 73/300 batch 106/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 73/300 batch 107/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 73/300 batch 108/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 73/300 batch 109/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 73/300 batch 110/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 73/300 batch 111/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 73/300 batch 112/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 73/300 batch 113/188  Train Loss: 0.033, Acc: 1.000\n",
      "epoch: 73/300 batch 114/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 73/300 batch 115/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 73/300 batch 116/188  Train Loss: 0.080, Acc: 0.984\n",
      "epoch: 73/300 batch 117/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 73/300 batch 118/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 73/300 batch 119/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 73/300 batch 120/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 73/300 batch 121/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 73/300 batch 122/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 73/300 batch 123/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 73/300 batch 124/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 73/300 batch 125/188  Train Loss: 0.080, Acc: 0.988\n",
      "epoch: 73/300 batch 126/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 73/300 batch 127/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 73/300 batch 128/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 73/300 batch 129/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 73/300 batch 130/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 73/300 batch 131/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 73/300 batch 132/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 73/300 batch 133/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 73/300 batch 134/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 73/300 batch 135/188  Train Loss: 0.059, Acc: 0.980\n",
      "epoch: 73/300 batch 136/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 73/300 batch 137/188  Train Loss: 0.052, Acc: 0.980\n",
      "epoch: 73/300 batch 138/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 73/300 batch 139/188  Train Loss: 0.053, Acc: 0.977\n",
      "epoch: 73/300 batch 140/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 73/300 batch 141/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 73/300 batch 142/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 73/300 batch 143/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 73/300 batch 144/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 73/300 batch 145/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 73/300 batch 146/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 73/300 batch 147/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 73/300 batch 148/188  Train Loss: 0.066, Acc: 0.988\n",
      "epoch: 73/300 batch 149/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 73/300 batch 150/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 73/300 batch 151/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 73/300 batch 152/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 73/300 batch 153/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 73/300 batch 154/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 73/300 batch 155/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 73/300 batch 156/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 73/300 batch 157/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 73/300 batch 158/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 73/300 batch 159/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 73/300 batch 160/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 73/300 batch 161/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 73/300 batch 162/188  Train Loss: 0.045, Acc: 0.980\n",
      "epoch: 73/300 batch 163/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 73/300 batch 164/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 73/300 batch 165/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 73/300 batch 166/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 73/300 batch 167/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 73/300 batch 168/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 73/300 batch 169/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 73/300 batch 170/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 73/300 batch 171/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 73/300 batch 172/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 73/300 batch 173/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 73/300 batch 174/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 73/300 batch 175/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 73/300 batch 176/188  Train Loss: 0.056, Acc: 0.980\n",
      "epoch: 73/300 batch 177/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 73/300 batch 178/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 73/300 batch 179/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 73/300 batch 180/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 73/300 batch 181/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 73/300 batch 182/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 73/300 batch 183/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 73/300 batch 184/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 73/300 batch 185/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 73/300 batch 186/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 73/300 batch 187/188  Train Loss: 0.024, Acc: 1.000\n",
      "Train Loss: 0.036078, Acc: 0.992\n",
      "Val Loss: 0.057904, Acc: 0.982\n",
      "epoch: 74/300 batch   0/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 74/300 batch   1/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 74/300 batch   2/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 74/300 batch   3/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 74/300 batch   4/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 74/300 batch   5/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 74/300 batch   6/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 74/300 batch   7/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 74/300 batch   8/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 74/300 batch   9/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 74/300 batch  10/188  Train Loss: 0.013, Acc: 0.996\n",
      "epoch: 74/300 batch  11/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 74/300 batch  12/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 74/300 batch  13/188  Train Loss: 0.067, Acc: 0.980\n",
      "epoch: 74/300 batch  14/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 74/300 batch  15/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 74/300 batch  16/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 74/300 batch  17/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 74/300 batch  18/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 74/300 batch  19/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 74/300 batch  20/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 74/300 batch  21/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 74/300 batch  22/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 74/300 batch  23/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 74/300 batch  24/188  Train Loss: 0.046, Acc: 0.996\n",
      "epoch: 74/300 batch  25/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 74/300 batch  26/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 74/300 batch  27/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 74/300 batch  28/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 74/300 batch  29/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 74/300 batch  30/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 74/300 batch  31/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 74/300 batch  32/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 74/300 batch  33/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 74/300 batch  34/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 74/300 batch  35/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 74/300 batch  36/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 74/300 batch  37/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 74/300 batch  38/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 74/300 batch  39/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 74/300 batch  40/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 74/300 batch  41/188  Train Loss: 0.052, Acc: 0.992\n",
      "epoch: 74/300 batch  42/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 74/300 batch  43/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 74/300 batch  44/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 74/300 batch  45/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 74/300 batch  46/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 74/300 batch  47/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 74/300 batch  48/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 74/300 batch  49/188  Train Loss: 0.033, Acc: 1.000\n",
      "epoch: 74/300 batch  50/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 74/300 batch  51/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 74/300 batch  52/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 74/300 batch  53/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 74/300 batch  54/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 74/300 batch  55/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 74/300 batch  56/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 74/300 batch  57/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 74/300 batch  58/188  Train Loss: 0.070, Acc: 0.973\n",
      "epoch: 74/300 batch  59/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 74/300 batch  60/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 74/300 batch  61/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 74/300 batch  62/188  Train Loss: 0.044, Acc: 0.996\n",
      "epoch: 74/300 batch  63/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 74/300 batch  64/188  Train Loss: 0.084, Acc: 0.973\n",
      "epoch: 74/300 batch  65/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 74/300 batch  66/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 74/300 batch  67/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 74/300 batch  68/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 74/300 batch  69/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 74/300 batch  70/188  Train Loss: 0.061, Acc: 0.984\n",
      "epoch: 74/300 batch  71/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 74/300 batch  72/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 74/300 batch  73/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 74/300 batch  74/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 74/300 batch  75/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 74/300 batch  76/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 74/300 batch  77/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 74/300 batch  78/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 74/300 batch  79/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 74/300 batch  80/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 74/300 batch  81/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 74/300 batch  82/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 74/300 batch  83/188  Train Loss: 0.054, Acc: 0.977\n",
      "epoch: 74/300 batch  84/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 74/300 batch  85/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 74/300 batch  86/188  Train Loss: 0.046, Acc: 0.977\n",
      "epoch: 74/300 batch  87/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 74/300 batch  88/188  Train Loss: 0.035, Acc: 1.000\n",
      "epoch: 74/300 batch  89/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 74/300 batch  90/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 74/300 batch  91/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 74/300 batch  92/188  Train Loss: 0.026, Acc: 0.988\n",
      "epoch: 74/300 batch  93/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 74/300 batch  94/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 74/300 batch  95/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 74/300 batch  96/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 74/300 batch  97/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 74/300 batch  98/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 74/300 batch  99/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 74/300 batch 100/188  Train Loss: 0.069, Acc: 0.988\n",
      "epoch: 74/300 batch 101/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 74/300 batch 102/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 74/300 batch 103/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 74/300 batch 104/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 74/300 batch 105/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 74/300 batch 106/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 74/300 batch 107/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 74/300 batch 108/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 74/300 batch 109/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 74/300 batch 110/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 74/300 batch 111/188  Train Loss: 0.052, Acc: 0.980\n",
      "epoch: 74/300 batch 112/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 74/300 batch 113/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 74/300 batch 114/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 74/300 batch 115/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 74/300 batch 116/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 74/300 batch 117/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 74/300 batch 118/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 74/300 batch 119/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 74/300 batch 120/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 74/300 batch 121/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 74/300 batch 122/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 74/300 batch 123/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 74/300 batch 124/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 74/300 batch 125/188  Train Loss: 0.049, Acc: 0.980\n",
      "epoch: 74/300 batch 126/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 74/300 batch 127/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 74/300 batch 128/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 74/300 batch 129/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 74/300 batch 130/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 74/300 batch 131/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 74/300 batch 132/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 74/300 batch 133/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 74/300 batch 134/188  Train Loss: 0.062, Acc: 0.988\n",
      "epoch: 74/300 batch 135/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 74/300 batch 136/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 74/300 batch 137/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 74/300 batch 138/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 74/300 batch 139/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 74/300 batch 140/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 74/300 batch 141/188  Train Loss: 0.051, Acc: 0.992\n",
      "epoch: 74/300 batch 142/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 74/300 batch 143/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 74/300 batch 144/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 74/300 batch 145/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 74/300 batch 146/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 74/300 batch 147/188  Train Loss: 0.040, Acc: 0.980\n",
      "epoch: 74/300 batch 148/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 74/300 batch 149/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 74/300 batch 150/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 74/300 batch 151/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 74/300 batch 152/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 74/300 batch 153/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 74/300 batch 154/188  Train Loss: 0.071, Acc: 0.980\n",
      "epoch: 74/300 batch 155/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 74/300 batch 156/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 74/300 batch 157/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 74/300 batch 158/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 74/300 batch 159/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 74/300 batch 160/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 74/300 batch 161/188  Train Loss: 0.015, Acc: 0.996\n",
      "epoch: 74/300 batch 162/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 74/300 batch 163/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 74/300 batch 164/188  Train Loss: 0.057, Acc: 0.988\n",
      "epoch: 74/300 batch 165/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 74/300 batch 166/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 74/300 batch 167/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 74/300 batch 168/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 74/300 batch 169/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 74/300 batch 170/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 74/300 batch 171/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 74/300 batch 172/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 74/300 batch 173/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 74/300 batch 174/188  Train Loss: 0.043, Acc: 0.980\n",
      "epoch: 74/300 batch 175/188  Train Loss: 0.053, Acc: 0.992\n",
      "epoch: 74/300 batch 176/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 74/300 batch 177/188  Train Loss: 0.044, Acc: 0.996\n",
      "epoch: 74/300 batch 178/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 74/300 batch 179/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 74/300 batch 180/188  Train Loss: 0.064, Acc: 0.977\n",
      "epoch: 74/300 batch 181/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 74/300 batch 182/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 74/300 batch 183/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 74/300 batch 184/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 74/300 batch 185/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 74/300 batch 186/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 74/300 batch 187/188  Train Loss: 0.041, Acc: 0.992\n",
      "Train Loss: 0.036043, Acc: 0.992\n",
      "Val Loss: 0.057876, Acc: 0.982\n",
      "epoch: 75/300 batch   0/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 75/300 batch   1/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 75/300 batch   2/188  Train Loss: 0.048, Acc: 0.980\n",
      "epoch: 75/300 batch   3/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 75/300 batch   4/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 75/300 batch   5/188  Train Loss: 0.045, Acc: 0.996\n",
      "epoch: 75/300 batch   6/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 75/300 batch   7/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 75/300 batch   8/188  Train Loss: 0.075, Acc: 0.980\n",
      "epoch: 75/300 batch   9/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 75/300 batch  10/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 75/300 batch  11/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 75/300 batch  12/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 75/300 batch  13/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 75/300 batch  14/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 75/300 batch  15/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 75/300 batch  16/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 75/300 batch  17/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 75/300 batch  18/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 75/300 batch  19/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 75/300 batch  20/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 75/300 batch  21/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 75/300 batch  22/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 75/300 batch  23/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 75/300 batch  24/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 75/300 batch  25/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 75/300 batch  26/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 75/300 batch  27/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 75/300 batch  28/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 75/300 batch  29/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 75/300 batch  30/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 75/300 batch  31/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 75/300 batch  32/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 75/300 batch  33/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 75/300 batch  34/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 75/300 batch  35/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 75/300 batch  36/188  Train Loss: 0.065, Acc: 0.980\n",
      "epoch: 75/300 batch  37/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 75/300 batch  38/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 75/300 batch  39/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 75/300 batch  40/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 75/300 batch  41/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 75/300 batch  42/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 75/300 batch  43/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 75/300 batch  44/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 75/300 batch  45/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 75/300 batch  46/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 75/300 batch  47/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 75/300 batch  48/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 75/300 batch  49/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 75/300 batch  50/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 75/300 batch  51/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 75/300 batch  52/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 75/300 batch  53/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 75/300 batch  54/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 75/300 batch  55/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 75/300 batch  56/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 75/300 batch  57/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 75/300 batch  58/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 75/300 batch  59/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 75/300 batch  60/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 75/300 batch  61/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 75/300 batch  62/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 75/300 batch  63/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 75/300 batch  64/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 75/300 batch  65/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 75/300 batch  66/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 75/300 batch  67/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 75/300 batch  68/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 75/300 batch  69/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 75/300 batch  70/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 75/300 batch  71/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 75/300 batch  72/188  Train Loss: 0.043, Acc: 0.980\n",
      "epoch: 75/300 batch  73/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 75/300 batch  74/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 75/300 batch  75/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 75/300 batch  76/188  Train Loss: 0.063, Acc: 0.984\n",
      "epoch: 75/300 batch  77/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 75/300 batch  78/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 75/300 batch  79/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 75/300 batch  80/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 75/300 batch  81/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 75/300 batch  82/188  Train Loss: 0.049, Acc: 0.980\n",
      "epoch: 75/300 batch  83/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 75/300 batch  84/188  Train Loss: 0.050, Acc: 0.980\n",
      "epoch: 75/300 batch  85/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 75/300 batch  86/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 75/300 batch  87/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 75/300 batch  88/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 75/300 batch  89/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 75/300 batch  90/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 75/300 batch  91/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 75/300 batch  92/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 75/300 batch  93/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 75/300 batch  94/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 75/300 batch  95/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 75/300 batch  96/188  Train Loss: 0.046, Acc: 0.996\n",
      "epoch: 75/300 batch  97/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 75/300 batch  98/188  Train Loss: 0.059, Acc: 0.984\n",
      "epoch: 75/300 batch  99/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 75/300 batch 100/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 75/300 batch 101/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 75/300 batch 102/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 75/300 batch 103/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 75/300 batch 104/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 75/300 batch 105/188  Train Loss: 0.085, Acc: 0.980\n",
      "epoch: 75/300 batch 106/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 75/300 batch 107/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 75/300 batch 108/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 75/300 batch 109/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 75/300 batch 110/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 75/300 batch 111/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 75/300 batch 112/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 75/300 batch 113/188  Train Loss: 0.032, Acc: 1.000\n",
      "epoch: 75/300 batch 114/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 75/300 batch 115/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 75/300 batch 116/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 75/300 batch 117/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 75/300 batch 118/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 75/300 batch 119/188  Train Loss: 0.059, Acc: 0.984\n",
      "epoch: 75/300 batch 120/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 75/300 batch 121/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 75/300 batch 122/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 75/300 batch 123/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 75/300 batch 124/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 75/300 batch 125/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 75/300 batch 126/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 75/300 batch 127/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 75/300 batch 128/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 75/300 batch 129/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 75/300 batch 130/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 75/300 batch 131/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 75/300 batch 132/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 75/300 batch 133/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 75/300 batch 134/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 75/300 batch 135/188  Train Loss: 0.044, Acc: 0.996\n",
      "epoch: 75/300 batch 136/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 75/300 batch 137/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 75/300 batch 138/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 75/300 batch 139/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 75/300 batch 140/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 75/300 batch 141/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 75/300 batch 142/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 75/300 batch 143/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 75/300 batch 144/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 75/300 batch 145/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 75/300 batch 146/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 75/300 batch 147/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 75/300 batch 148/188  Train Loss: 0.049, Acc: 0.980\n",
      "epoch: 75/300 batch 149/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 75/300 batch 150/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 75/300 batch 151/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 75/300 batch 152/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 75/300 batch 153/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 75/300 batch 154/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 75/300 batch 155/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 75/300 batch 156/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 75/300 batch 157/188  Train Loss: 0.065, Acc: 0.977\n",
      "epoch: 75/300 batch 158/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 75/300 batch 159/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 75/300 batch 160/188  Train Loss: 0.067, Acc: 0.984\n",
      "epoch: 75/300 batch 161/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 75/300 batch 162/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 75/300 batch 163/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 75/300 batch 164/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 75/300 batch 165/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 75/300 batch 166/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 75/300 batch 167/188  Train Loss: 0.072, Acc: 0.980\n",
      "epoch: 75/300 batch 168/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 75/300 batch 169/188  Train Loss: 0.026, Acc: 0.988\n",
      "epoch: 75/300 batch 170/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 75/300 batch 171/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 75/300 batch 172/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 75/300 batch 173/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 75/300 batch 174/188  Train Loss: 0.071, Acc: 0.980\n",
      "epoch: 75/300 batch 175/188  Train Loss: 0.070, Acc: 0.984\n",
      "epoch: 75/300 batch 176/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 75/300 batch 177/188  Train Loss: 0.057, Acc: 0.988\n",
      "epoch: 75/300 batch 178/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 75/300 batch 179/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 75/300 batch 180/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 75/300 batch 181/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 75/300 batch 182/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 75/300 batch 183/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 75/300 batch 184/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 75/300 batch 185/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 75/300 batch 186/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 75/300 batch 187/188  Train Loss: 0.052, Acc: 0.992\n",
      "Train Loss: 0.036133, Acc: 0.992\n",
      "Val Loss: 0.058085, Acc: 0.982\n",
      "epoch: 76/300 batch   0/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 76/300 batch   1/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 76/300 batch   2/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 76/300 batch   3/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 76/300 batch   4/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 76/300 batch   5/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 76/300 batch   6/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 76/300 batch   7/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 76/300 batch   8/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 76/300 batch   9/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 76/300 batch  10/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 76/300 batch  11/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 76/300 batch  12/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 76/300 batch  13/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 76/300 batch  14/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 76/300 batch  15/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 76/300 batch  16/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 76/300 batch  17/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 76/300 batch  18/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 76/300 batch  19/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 76/300 batch  20/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 76/300 batch  21/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 76/300 batch  22/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 76/300 batch  23/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 76/300 batch  24/188  Train Loss: 0.062, Acc: 0.988\n",
      "epoch: 76/300 batch  25/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 76/300 batch  26/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 76/300 batch  27/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 76/300 batch  28/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 76/300 batch  29/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 76/300 batch  30/188  Train Loss: 0.061, Acc: 0.984\n",
      "epoch: 76/300 batch  31/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 76/300 batch  32/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 76/300 batch  33/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 76/300 batch  34/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 76/300 batch  35/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 76/300 batch  36/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 76/300 batch  37/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 76/300 batch  38/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 76/300 batch  39/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 76/300 batch  40/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 76/300 batch  41/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 76/300 batch  42/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 76/300 batch  43/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 76/300 batch  44/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 76/300 batch  45/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 76/300 batch  46/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 76/300 batch  47/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 76/300 batch  48/188  Train Loss: 0.031, Acc: 1.000\n",
      "epoch: 76/300 batch  49/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 76/300 batch  50/188  Train Loss: 0.056, Acc: 0.980\n",
      "epoch: 76/300 batch  51/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 76/300 batch  52/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 76/300 batch  53/188  Train Loss: 0.060, Acc: 0.973\n",
      "epoch: 76/300 batch  54/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 76/300 batch  55/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 76/300 batch  56/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 76/300 batch  57/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 76/300 batch  58/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 76/300 batch  59/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 76/300 batch  60/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 76/300 batch  61/188  Train Loss: 0.044, Acc: 0.996\n",
      "epoch: 76/300 batch  62/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 76/300 batch  63/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 76/300 batch  64/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 76/300 batch  65/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 76/300 batch  66/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 76/300 batch  67/188  Train Loss: 0.031, Acc: 1.000\n",
      "epoch: 76/300 batch  68/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 76/300 batch  69/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 76/300 batch  70/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 76/300 batch  71/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 76/300 batch  72/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 76/300 batch  73/188  Train Loss: 0.057, Acc: 0.988\n",
      "epoch: 76/300 batch  74/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 76/300 batch  75/188  Train Loss: 0.040, Acc: 0.980\n",
      "epoch: 76/300 batch  76/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 76/300 batch  77/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 76/300 batch  78/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 76/300 batch  79/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 76/300 batch  80/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 76/300 batch  81/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 76/300 batch  82/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 76/300 batch  83/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 76/300 batch  84/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 76/300 batch  85/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 76/300 batch  86/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 76/300 batch  87/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 76/300 batch  88/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 76/300 batch  89/188  Train Loss: 0.050, Acc: 0.977\n",
      "epoch: 76/300 batch  90/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 76/300 batch  91/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 76/300 batch  92/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 76/300 batch  93/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 76/300 batch  94/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 76/300 batch  95/188  Train Loss: 0.073, Acc: 0.980\n",
      "epoch: 76/300 batch  96/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 76/300 batch  97/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 76/300 batch  98/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 76/300 batch  99/188  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 76/300 batch 100/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 76/300 batch 101/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 76/300 batch 102/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 76/300 batch 103/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 76/300 batch 104/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 76/300 batch 105/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 76/300 batch 106/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 76/300 batch 107/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 76/300 batch 108/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 76/300 batch 109/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 76/300 batch 110/188  Train Loss: 0.047, Acc: 0.977\n",
      "epoch: 76/300 batch 111/188  Train Loss: 0.034, Acc: 0.984\n",
      "epoch: 76/300 batch 112/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 76/300 batch 113/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 76/300 batch 114/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 76/300 batch 115/188  Train Loss: 0.064, Acc: 0.980\n",
      "epoch: 76/300 batch 116/188  Train Loss: 0.068, Acc: 0.992\n",
      "epoch: 76/300 batch 117/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 76/300 batch 118/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 76/300 batch 119/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 76/300 batch 120/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 76/300 batch 121/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 76/300 batch 122/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 76/300 batch 123/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 76/300 batch 124/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 76/300 batch 125/188  Train Loss: 0.068, Acc: 0.988\n",
      "epoch: 76/300 batch 126/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 76/300 batch 127/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 76/300 batch 128/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 76/300 batch 129/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 76/300 batch 130/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 76/300 batch 131/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 76/300 batch 132/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 76/300 batch 133/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 76/300 batch 134/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 76/300 batch 135/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 76/300 batch 136/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 76/300 batch 137/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 76/300 batch 138/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 76/300 batch 139/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 76/300 batch 140/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 76/300 batch 141/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 76/300 batch 142/188  Train Loss: 0.035, Acc: 1.000\n",
      "epoch: 76/300 batch 143/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 76/300 batch 144/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 76/300 batch 145/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 76/300 batch 146/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 76/300 batch 147/188  Train Loss: 0.057, Acc: 0.977\n",
      "epoch: 76/300 batch 148/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 76/300 batch 149/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 76/300 batch 150/188  Train Loss: 0.035, Acc: 0.980\n",
      "epoch: 76/300 batch 151/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 76/300 batch 152/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 76/300 batch 153/188  Train Loss: 0.052, Acc: 0.973\n",
      "epoch: 76/300 batch 154/188  Train Loss: 0.064, Acc: 0.980\n",
      "epoch: 76/300 batch 155/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 76/300 batch 156/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 76/300 batch 157/188  Train Loss: 0.071, Acc: 0.977\n",
      "epoch: 76/300 batch 158/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 76/300 batch 159/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 76/300 batch 160/188  Train Loss: 0.065, Acc: 0.984\n",
      "epoch: 76/300 batch 161/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 76/300 batch 162/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 76/300 batch 163/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 76/300 batch 164/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 76/300 batch 165/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 76/300 batch 166/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 76/300 batch 167/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 76/300 batch 168/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 76/300 batch 169/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 76/300 batch 170/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 76/300 batch 171/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 76/300 batch 172/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 76/300 batch 173/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 76/300 batch 174/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 76/300 batch 175/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 76/300 batch 176/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 76/300 batch 177/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 76/300 batch 178/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 76/300 batch 179/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 76/300 batch 180/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 76/300 batch 181/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 76/300 batch 182/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 76/300 batch 183/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 76/300 batch 184/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 76/300 batch 185/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 76/300 batch 186/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 76/300 batch 187/188  Train Loss: 0.073, Acc: 0.977\n",
      "Train Loss: 0.036006, Acc: 0.992\n",
      "Val Loss: 0.057941, Acc: 0.982\n",
      "epoch: 77/300 batch   0/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 77/300 batch   1/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 77/300 batch   2/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 77/300 batch   3/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 77/300 batch   4/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 77/300 batch   5/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 77/300 batch   6/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 77/300 batch   7/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 77/300 batch   8/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 77/300 batch   9/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 77/300 batch  10/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 77/300 batch  11/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 77/300 batch  12/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 77/300 batch  13/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 77/300 batch  14/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 77/300 batch  15/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 77/300 batch  16/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 77/300 batch  17/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 77/300 batch  18/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 77/300 batch  19/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 77/300 batch  20/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 77/300 batch  21/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 77/300 batch  22/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 77/300 batch  23/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 77/300 batch  24/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 77/300 batch  25/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 77/300 batch  26/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 77/300 batch  27/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 77/300 batch  28/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 77/300 batch  29/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 77/300 batch  30/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 77/300 batch  31/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 77/300 batch  32/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 77/300 batch  33/188  Train Loss: 0.046, Acc: 0.996\n",
      "epoch: 77/300 batch  34/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 77/300 batch  35/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 77/300 batch  36/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 77/300 batch  37/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 77/300 batch  38/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 77/300 batch  39/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 77/300 batch  40/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 77/300 batch  41/188  Train Loss: 0.054, Acc: 0.992\n",
      "epoch: 77/300 batch  42/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 77/300 batch  43/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 77/300 batch  44/188  Train Loss: 0.031, Acc: 1.000\n",
      "epoch: 77/300 batch  45/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 77/300 batch  46/188  Train Loss: 0.056, Acc: 0.988\n",
      "epoch: 77/300 batch  47/188  Train Loss: 0.032, Acc: 1.000\n",
      "epoch: 77/300 batch  48/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 77/300 batch  49/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 77/300 batch  50/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 77/300 batch  51/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 77/300 batch  52/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 77/300 batch  53/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 77/300 batch  54/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 77/300 batch  55/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 77/300 batch  56/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 77/300 batch  57/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 77/300 batch  58/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 77/300 batch  59/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 77/300 batch  60/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 77/300 batch  61/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 77/300 batch  62/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 77/300 batch  63/188  Train Loss: 0.059, Acc: 0.992\n",
      "epoch: 77/300 batch  64/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 77/300 batch  65/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 77/300 batch  66/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 77/300 batch  67/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 77/300 batch  68/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 77/300 batch  69/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 77/300 batch  70/188  Train Loss: 0.060, Acc: 0.992\n",
      "epoch: 77/300 batch  71/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 77/300 batch  72/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 77/300 batch  73/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 77/300 batch  74/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 77/300 batch  75/188  Train Loss: 0.039, Acc: 0.980\n",
      "epoch: 77/300 batch  76/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 77/300 batch  77/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 77/300 batch  78/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 77/300 batch  79/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 77/300 batch  80/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 77/300 batch  81/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 77/300 batch  82/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 77/300 batch  83/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 77/300 batch  84/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 77/300 batch  85/188  Train Loss: 0.038, Acc: 0.980\n",
      "epoch: 77/300 batch  86/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 77/300 batch  87/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 77/300 batch  88/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 77/300 batch  89/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 77/300 batch  90/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 77/300 batch  91/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 77/300 batch  92/188  Train Loss: 0.027, Acc: 0.988\n",
      "epoch: 77/300 batch  93/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 77/300 batch  94/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 77/300 batch  95/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 77/300 batch  96/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 77/300 batch  97/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 77/300 batch  98/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 77/300 batch  99/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 77/300 batch 100/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 77/300 batch 101/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 77/300 batch 102/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 77/300 batch 103/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 77/300 batch 104/188  Train Loss: 0.027, Acc: 0.988\n",
      "epoch: 77/300 batch 105/188  Train Loss: 0.046, Acc: 0.980\n",
      "epoch: 77/300 batch 106/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 77/300 batch 107/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 77/300 batch 108/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 77/300 batch 109/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 77/300 batch 110/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 77/300 batch 111/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 77/300 batch 112/188  Train Loss: 0.060, Acc: 0.980\n",
      "epoch: 77/300 batch 113/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 77/300 batch 114/188  Train Loss: 0.057, Acc: 0.988\n",
      "epoch: 77/300 batch 115/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 77/300 batch 116/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 77/300 batch 117/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 77/300 batch 118/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 77/300 batch 119/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 77/300 batch 120/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 77/300 batch 121/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 77/300 batch 122/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 77/300 batch 123/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 77/300 batch 124/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 77/300 batch 125/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 77/300 batch 126/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 77/300 batch 127/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 77/300 batch 128/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 77/300 batch 129/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 77/300 batch 130/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 77/300 batch 131/188  Train Loss: 0.056, Acc: 0.980\n",
      "epoch: 77/300 batch 132/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 77/300 batch 133/188  Train Loss: 0.058, Acc: 0.977\n",
      "epoch: 77/300 batch 134/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 77/300 batch 135/188  Train Loss: 0.043, Acc: 0.980\n",
      "epoch: 77/300 batch 136/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 77/300 batch 137/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 77/300 batch 138/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 77/300 batch 139/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 77/300 batch 140/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 77/300 batch 141/188  Train Loss: 0.085, Acc: 0.988\n",
      "epoch: 77/300 batch 142/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 77/300 batch 143/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 77/300 batch 144/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 77/300 batch 145/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 77/300 batch 146/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 77/300 batch 147/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 77/300 batch 148/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 77/300 batch 149/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 77/300 batch 150/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 77/300 batch 151/188  Train Loss: 0.058, Acc: 0.980\n",
      "epoch: 77/300 batch 152/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 77/300 batch 153/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 77/300 batch 154/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 77/300 batch 155/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 77/300 batch 156/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 77/300 batch 157/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 77/300 batch 158/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 77/300 batch 159/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 77/300 batch 160/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 77/300 batch 161/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 77/300 batch 162/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 77/300 batch 163/188  Train Loss: 0.045, Acc: 0.996\n",
      "epoch: 77/300 batch 164/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 77/300 batch 165/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 77/300 batch 166/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 77/300 batch 167/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 77/300 batch 168/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 77/300 batch 169/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 77/300 batch 170/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 77/300 batch 171/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 77/300 batch 172/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 77/300 batch 173/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 77/300 batch 174/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 77/300 batch 175/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 77/300 batch 176/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 77/300 batch 177/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 77/300 batch 178/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 77/300 batch 179/188  Train Loss: 0.066, Acc: 0.984\n",
      "epoch: 77/300 batch 180/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 77/300 batch 181/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 77/300 batch 182/188  Train Loss: 0.062, Acc: 0.996\n",
      "epoch: 77/300 batch 183/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 77/300 batch 184/188  Train Loss: 0.032, Acc: 1.000\n",
      "epoch: 77/300 batch 185/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 77/300 batch 186/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 77/300 batch 187/188  Train Loss: 0.014, Acc: 1.000\n",
      "Train Loss: 0.035910, Acc: 0.992\n",
      "Val Loss: 0.057965, Acc: 0.982\n",
      "epoch: 78/300 batch   0/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 78/300 batch   1/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 78/300 batch   2/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 78/300 batch   3/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 78/300 batch   4/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 78/300 batch   5/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 78/300 batch   6/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 78/300 batch   7/188  Train Loss: 0.038, Acc: 0.980\n",
      "epoch: 78/300 batch   8/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 78/300 batch   9/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 78/300 batch  10/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 78/300 batch  11/188  Train Loss: 0.065, Acc: 0.992\n",
      "epoch: 78/300 batch  12/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 78/300 batch  13/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 78/300 batch  14/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 78/300 batch  15/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 78/300 batch  16/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 78/300 batch  17/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 78/300 batch  18/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 78/300 batch  19/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 78/300 batch  20/188  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 78/300 batch  21/188  Train Loss: 0.056, Acc: 0.988\n",
      "epoch: 78/300 batch  22/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 78/300 batch  23/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 78/300 batch  24/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 78/300 batch  25/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 78/300 batch  26/188  Train Loss: 0.016, Acc: 0.996\n",
      "epoch: 78/300 batch  27/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 78/300 batch  28/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 78/300 batch  29/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 78/300 batch  30/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 78/300 batch  31/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 78/300 batch  32/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 78/300 batch  33/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 78/300 batch  34/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 78/300 batch  35/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 78/300 batch  36/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 78/300 batch  37/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 78/300 batch  38/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 78/300 batch  39/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 78/300 batch  40/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 78/300 batch  41/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 78/300 batch  42/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 78/300 batch  43/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 78/300 batch  44/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 78/300 batch  45/188  Train Loss: 0.074, Acc: 0.980\n",
      "epoch: 78/300 batch  46/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 78/300 batch  47/188  Train Loss: 0.055, Acc: 0.980\n",
      "epoch: 78/300 batch  48/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 78/300 batch  49/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 78/300 batch  50/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 78/300 batch  51/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 78/300 batch  52/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 78/300 batch  53/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 78/300 batch  54/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 78/300 batch  55/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 78/300 batch  56/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 78/300 batch  57/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 78/300 batch  58/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 78/300 batch  59/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 78/300 batch  60/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 78/300 batch  61/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 78/300 batch  62/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 78/300 batch  63/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 78/300 batch  64/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 78/300 batch  65/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 78/300 batch  66/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 78/300 batch  67/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 78/300 batch  68/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 78/300 batch  69/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 78/300 batch  70/188  Train Loss: 0.061, Acc: 0.988\n",
      "epoch: 78/300 batch  71/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 78/300 batch  72/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 78/300 batch  73/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 78/300 batch  74/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 78/300 batch  75/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 78/300 batch  76/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 78/300 batch  77/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 78/300 batch  78/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 78/300 batch  79/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 78/300 batch  80/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 78/300 batch  81/188  Train Loss: 0.033, Acc: 1.000\n",
      "epoch: 78/300 batch  82/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 78/300 batch  83/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 78/300 batch  84/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 78/300 batch  85/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 78/300 batch  86/188  Train Loss: 0.047, Acc: 0.977\n",
      "epoch: 78/300 batch  87/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 78/300 batch  88/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 78/300 batch  89/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 78/300 batch  90/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 78/300 batch  91/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 78/300 batch  92/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 78/300 batch  93/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 78/300 batch  94/188  Train Loss: 0.060, Acc: 0.988\n",
      "epoch: 78/300 batch  95/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 78/300 batch  96/188  Train Loss: 0.062, Acc: 0.980\n",
      "epoch: 78/300 batch  97/188  Train Loss: 0.079, Acc: 0.977\n",
      "epoch: 78/300 batch  98/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 78/300 batch  99/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 78/300 batch 100/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 78/300 batch 101/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 78/300 batch 102/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 78/300 batch 103/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 78/300 batch 104/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 78/300 batch 105/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 78/300 batch 106/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 78/300 batch 107/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 78/300 batch 108/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 78/300 batch 109/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 78/300 batch 110/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 78/300 batch 111/188  Train Loss: 0.060, Acc: 0.984\n",
      "epoch: 78/300 batch 112/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 78/300 batch 113/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 78/300 batch 114/188  Train Loss: 0.072, Acc: 0.973\n",
      "epoch: 78/300 batch 115/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 78/300 batch 116/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 78/300 batch 117/188  Train Loss: 0.071, Acc: 0.977\n",
      "epoch: 78/300 batch 118/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 78/300 batch 119/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 78/300 batch 120/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 78/300 batch 121/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 78/300 batch 122/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 78/300 batch 123/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 78/300 batch 124/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 78/300 batch 125/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 78/300 batch 126/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 78/300 batch 127/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 78/300 batch 128/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 78/300 batch 129/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 78/300 batch 130/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 78/300 batch 131/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 78/300 batch 132/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 78/300 batch 133/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 78/300 batch 134/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 78/300 batch 135/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 78/300 batch 136/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 78/300 batch 137/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 78/300 batch 138/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 78/300 batch 139/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 78/300 batch 140/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 78/300 batch 141/188  Train Loss: 0.056, Acc: 0.988\n",
      "epoch: 78/300 batch 142/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 78/300 batch 143/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 78/300 batch 144/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 78/300 batch 145/188  Train Loss: 0.064, Acc: 0.977\n",
      "epoch: 78/300 batch 146/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 78/300 batch 147/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 78/300 batch 148/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 78/300 batch 149/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 78/300 batch 150/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 78/300 batch 151/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 78/300 batch 152/188  Train Loss: 0.103, Acc: 0.969\n",
      "epoch: 78/300 batch 153/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 78/300 batch 154/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 78/300 batch 155/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 78/300 batch 156/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 78/300 batch 157/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 78/300 batch 158/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 78/300 batch 159/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 78/300 batch 160/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 78/300 batch 161/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 78/300 batch 162/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 78/300 batch 163/188  Train Loss: 0.064, Acc: 0.980\n",
      "epoch: 78/300 batch 164/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 78/300 batch 165/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 78/300 batch 166/188  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 78/300 batch 167/188  Train Loss: 0.059, Acc: 0.988\n",
      "epoch: 78/300 batch 168/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 78/300 batch 169/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 78/300 batch 170/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 78/300 batch 171/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 78/300 batch 172/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 78/300 batch 173/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 78/300 batch 174/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 78/300 batch 175/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 78/300 batch 176/188  Train Loss: 0.084, Acc: 0.984\n",
      "epoch: 78/300 batch 177/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 78/300 batch 178/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 78/300 batch 179/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 78/300 batch 180/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 78/300 batch 181/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 78/300 batch 182/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 78/300 batch 183/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 78/300 batch 184/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 78/300 batch 185/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 78/300 batch 186/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 78/300 batch 187/188  Train Loss: 0.039, Acc: 0.992\n",
      "Train Loss: 0.035961, Acc: 0.992\n",
      "Val Loss: 0.057910, Acc: 0.983\n",
      "epoch: 79/300 batch   0/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 79/300 batch   1/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 79/300 batch   2/188  Train Loss: 0.078, Acc: 0.980\n",
      "epoch: 79/300 batch   3/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 79/300 batch   4/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 79/300 batch   5/188  Train Loss: 0.046, Acc: 0.980\n",
      "epoch: 79/300 batch   6/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 79/300 batch   7/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 79/300 batch   8/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 79/300 batch   9/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 79/300 batch  10/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 79/300 batch  11/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 79/300 batch  12/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 79/300 batch  13/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 79/300 batch  14/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 79/300 batch  15/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 79/300 batch  16/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 79/300 batch  17/188  Train Loss: 0.059, Acc: 0.980\n",
      "epoch: 79/300 batch  18/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 79/300 batch  19/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 79/300 batch  20/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 79/300 batch  21/188  Train Loss: 0.027, Acc: 0.988\n",
      "epoch: 79/300 batch  22/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 79/300 batch  23/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 79/300 batch  24/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 79/300 batch  25/188  Train Loss: 0.059, Acc: 0.980\n",
      "epoch: 79/300 batch  26/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 79/300 batch  27/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 79/300 batch  28/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 79/300 batch  29/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 79/300 batch  30/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 79/300 batch  31/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 79/300 batch  32/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 79/300 batch  33/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 79/300 batch  34/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 79/300 batch  35/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 79/300 batch  36/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 79/300 batch  37/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 79/300 batch  38/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 79/300 batch  39/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 79/300 batch  40/188  Train Loss: 0.075, Acc: 0.984\n",
      "epoch: 79/300 batch  41/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 79/300 batch  42/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 79/300 batch  43/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 79/300 batch  44/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 79/300 batch  45/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 79/300 batch  46/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 79/300 batch  47/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 79/300 batch  48/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 79/300 batch  49/188  Train Loss: 0.059, Acc: 0.984\n",
      "epoch: 79/300 batch  50/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 79/300 batch  51/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 79/300 batch  52/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 79/300 batch  53/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 79/300 batch  54/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 79/300 batch  55/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 79/300 batch  56/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 79/300 batch  57/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 79/300 batch  58/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 79/300 batch  59/188  Train Loss: 0.058, Acc: 0.988\n",
      "epoch: 79/300 batch  60/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 79/300 batch  61/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 79/300 batch  62/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 79/300 batch  63/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 79/300 batch  64/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 79/300 batch  65/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 79/300 batch  66/188  Train Loss: 0.057, Acc: 0.980\n",
      "epoch: 79/300 batch  67/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 79/300 batch  68/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 79/300 batch  69/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 79/300 batch  70/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 79/300 batch  71/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 79/300 batch  72/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 79/300 batch  73/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 79/300 batch  74/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 79/300 batch  75/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 79/300 batch  76/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 79/300 batch  77/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 79/300 batch  78/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 79/300 batch  79/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 79/300 batch  80/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 79/300 batch  81/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 79/300 batch  82/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 79/300 batch  83/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 79/300 batch  84/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 79/300 batch  85/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 79/300 batch  86/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 79/300 batch  87/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 79/300 batch  88/188  Train Loss: 0.026, Acc: 0.988\n",
      "epoch: 79/300 batch  89/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 79/300 batch  90/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 79/300 batch  91/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 79/300 batch  92/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 79/300 batch  93/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 79/300 batch  94/188  Train Loss: 0.060, Acc: 0.984\n",
      "epoch: 79/300 batch  95/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 79/300 batch  96/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 79/300 batch  97/188  Train Loss: 0.033, Acc: 1.000\n",
      "epoch: 79/300 batch  98/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 79/300 batch  99/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 79/300 batch 100/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 79/300 batch 101/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 79/300 batch 102/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 79/300 batch 103/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 79/300 batch 104/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 79/300 batch 105/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 79/300 batch 106/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 79/300 batch 107/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 79/300 batch 108/188  Train Loss: 0.051, Acc: 0.980\n",
      "epoch: 79/300 batch 109/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 79/300 batch 110/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 79/300 batch 111/188  Train Loss: 0.062, Acc: 0.988\n",
      "epoch: 79/300 batch 112/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 79/300 batch 113/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 79/300 batch 114/188  Train Loss: 0.053, Acc: 0.992\n",
      "epoch: 79/300 batch 115/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 79/300 batch 116/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 79/300 batch 117/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 79/300 batch 118/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 79/300 batch 119/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 79/300 batch 120/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 79/300 batch 121/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 79/300 batch 122/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 79/300 batch 123/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 79/300 batch 124/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 79/300 batch 125/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 79/300 batch 126/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 79/300 batch 127/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 79/300 batch 128/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 79/300 batch 129/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 79/300 batch 130/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 79/300 batch 131/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 79/300 batch 132/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 79/300 batch 133/188  Train Loss: 0.026, Acc: 0.988\n",
      "epoch: 79/300 batch 134/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 79/300 batch 135/188  Train Loss: 0.056, Acc: 0.980\n",
      "epoch: 79/300 batch 136/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 79/300 batch 137/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 79/300 batch 138/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 79/300 batch 139/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 79/300 batch 140/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 79/300 batch 141/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 79/300 batch 142/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 79/300 batch 143/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 79/300 batch 144/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 79/300 batch 145/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 79/300 batch 146/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 79/300 batch 147/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 79/300 batch 148/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 79/300 batch 149/188  Train Loss: 0.065, Acc: 0.988\n",
      "epoch: 79/300 batch 150/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 79/300 batch 151/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 79/300 batch 152/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 79/300 batch 153/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 79/300 batch 154/188  Train Loss: 0.044, Acc: 0.980\n",
      "epoch: 79/300 batch 155/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 79/300 batch 156/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 79/300 batch 157/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 79/300 batch 158/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 79/300 batch 159/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 79/300 batch 160/188  Train Loss: 0.066, Acc: 0.980\n",
      "epoch: 79/300 batch 161/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 79/300 batch 162/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 79/300 batch 163/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 79/300 batch 164/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 79/300 batch 165/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 79/300 batch 166/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 79/300 batch 167/188  Train Loss: 0.050, Acc: 0.996\n",
      "epoch: 79/300 batch 168/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 79/300 batch 169/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 79/300 batch 170/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 79/300 batch 171/188  Train Loss: 0.055, Acc: 0.980\n",
      "epoch: 79/300 batch 172/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 79/300 batch 173/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 79/300 batch 174/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 79/300 batch 175/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 79/300 batch 176/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 79/300 batch 177/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 79/300 batch 178/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 79/300 batch 179/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 79/300 batch 180/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 79/300 batch 181/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 79/300 batch 182/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 79/300 batch 183/188  Train Loss: 0.060, Acc: 0.980\n",
      "epoch: 79/300 batch 184/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 79/300 batch 185/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 79/300 batch 186/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 79/300 batch 187/188  Train Loss: 0.064, Acc: 0.977\n",
      "Train Loss: 0.035938, Acc: 0.992\n",
      "Val Loss: 0.057717, Acc: 0.983\n",
      "epoch: 80/300 batch   0/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 80/300 batch   1/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 80/300 batch   2/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 80/300 batch   3/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 80/300 batch   4/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 80/300 batch   5/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 80/300 batch   6/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 80/300 batch   7/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 80/300 batch   8/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 80/300 batch   9/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 80/300 batch  10/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 80/300 batch  11/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 80/300 batch  12/188  Train Loss: 0.049, Acc: 0.980\n",
      "epoch: 80/300 batch  13/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 80/300 batch  14/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 80/300 batch  15/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 80/300 batch  16/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 80/300 batch  17/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 80/300 batch  18/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 80/300 batch  19/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 80/300 batch  20/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 80/300 batch  21/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 80/300 batch  22/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 80/300 batch  23/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 80/300 batch  24/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 80/300 batch  25/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 80/300 batch  26/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 80/300 batch  27/188  Train Loss: 0.054, Acc: 0.977\n",
      "epoch: 80/300 batch  28/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 80/300 batch  29/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 80/300 batch  30/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 80/300 batch  31/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 80/300 batch  32/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 80/300 batch  33/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 80/300 batch  34/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 80/300 batch  35/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 80/300 batch  36/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 80/300 batch  37/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 80/300 batch  38/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 80/300 batch  39/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 80/300 batch  40/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 80/300 batch  41/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 80/300 batch  42/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 80/300 batch  43/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 80/300 batch  44/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 80/300 batch  45/188  Train Loss: 0.046, Acc: 0.996\n",
      "epoch: 80/300 batch  46/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 80/300 batch  47/188  Train Loss: 0.072, Acc: 0.980\n",
      "epoch: 80/300 batch  48/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 80/300 batch  49/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 80/300 batch  50/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 80/300 batch  51/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 80/300 batch  52/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 80/300 batch  53/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 80/300 batch  54/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 80/300 batch  55/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 80/300 batch  56/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 80/300 batch  57/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 80/300 batch  58/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 80/300 batch  59/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 80/300 batch  60/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 80/300 batch  61/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 80/300 batch  62/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 80/300 batch  63/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 80/300 batch  64/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 80/300 batch  65/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 80/300 batch  66/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 80/300 batch  67/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 80/300 batch  68/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 80/300 batch  69/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 80/300 batch  70/188  Train Loss: 0.057, Acc: 0.980\n",
      "epoch: 80/300 batch  71/188  Train Loss: 0.046, Acc: 0.996\n",
      "epoch: 80/300 batch  72/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 80/300 batch  73/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 80/300 batch  74/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 80/300 batch  75/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 80/300 batch  76/188  Train Loss: 0.057, Acc: 0.977\n",
      "epoch: 80/300 batch  77/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 80/300 batch  78/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 80/300 batch  79/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 80/300 batch  80/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 80/300 batch  81/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 80/300 batch  82/188  Train Loss: 0.016, Acc: 0.996\n",
      "epoch: 80/300 batch  83/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 80/300 batch  84/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 80/300 batch  85/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 80/300 batch  86/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 80/300 batch  87/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 80/300 batch  88/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 80/300 batch  89/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 80/300 batch  90/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 80/300 batch  91/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 80/300 batch  92/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 80/300 batch  93/188  Train Loss: 0.064, Acc: 0.984\n",
      "epoch: 80/300 batch  94/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 80/300 batch  95/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 80/300 batch  96/188  Train Loss: 0.081, Acc: 0.988\n",
      "epoch: 80/300 batch  97/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 80/300 batch  98/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 80/300 batch  99/188  Train Loss: 0.051, Acc: 0.992\n",
      "epoch: 80/300 batch 100/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 80/300 batch 101/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 80/300 batch 102/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 80/300 batch 103/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 80/300 batch 104/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 80/300 batch 105/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 80/300 batch 106/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 80/300 batch 107/188  Train Loss: 0.068, Acc: 0.977\n",
      "epoch: 80/300 batch 108/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 80/300 batch 109/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 80/300 batch 110/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 80/300 batch 111/188  Train Loss: 0.051, Acc: 0.992\n",
      "epoch: 80/300 batch 112/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 80/300 batch 113/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 80/300 batch 114/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 80/300 batch 115/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 80/300 batch 116/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 80/300 batch 117/188  Train Loss: 0.033, Acc: 1.000\n",
      "epoch: 80/300 batch 118/188  Train Loss: 0.026, Acc: 0.988\n",
      "epoch: 80/300 batch 119/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 80/300 batch 120/188  Train Loss: 0.061, Acc: 0.984\n",
      "epoch: 80/300 batch 121/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 80/300 batch 122/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 80/300 batch 123/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 80/300 batch 124/188  Train Loss: 0.055, Acc: 0.977\n",
      "epoch: 80/300 batch 125/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 80/300 batch 126/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 80/300 batch 127/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 80/300 batch 128/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 80/300 batch 129/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 80/300 batch 130/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 80/300 batch 131/188  Train Loss: 0.052, Acc: 0.977\n",
      "epoch: 80/300 batch 132/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 80/300 batch 133/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 80/300 batch 134/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 80/300 batch 135/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 80/300 batch 136/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 80/300 batch 137/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 80/300 batch 138/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 80/300 batch 139/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 80/300 batch 140/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 80/300 batch 141/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 80/300 batch 142/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 80/300 batch 143/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 80/300 batch 144/188  Train Loss: 0.053, Acc: 0.992\n",
      "epoch: 80/300 batch 145/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 80/300 batch 146/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 80/300 batch 147/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 80/300 batch 148/188  Train Loss: 0.024, Acc: 0.988\n",
      "epoch: 80/300 batch 149/188  Train Loss: 0.032, Acc: 1.000\n",
      "epoch: 80/300 batch 150/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 80/300 batch 151/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 80/300 batch 152/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 80/300 batch 153/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 80/300 batch 154/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 80/300 batch 155/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 80/300 batch 156/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 80/300 batch 157/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 80/300 batch 158/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 80/300 batch 159/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 80/300 batch 160/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 80/300 batch 161/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 80/300 batch 162/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 80/300 batch 163/188  Train Loss: 0.032, Acc: 0.984\n",
      "epoch: 80/300 batch 164/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 80/300 batch 165/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 80/300 batch 166/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 80/300 batch 167/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 80/300 batch 168/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 80/300 batch 169/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 80/300 batch 170/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 80/300 batch 171/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 80/300 batch 172/188  Train Loss: 0.064, Acc: 0.984\n",
      "epoch: 80/300 batch 173/188  Train Loss: 0.069, Acc: 0.980\n",
      "epoch: 80/300 batch 174/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 80/300 batch 175/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 80/300 batch 176/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 80/300 batch 177/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 80/300 batch 178/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 80/300 batch 179/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 80/300 batch 180/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 80/300 batch 181/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 80/300 batch 182/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 80/300 batch 183/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 80/300 batch 184/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 80/300 batch 185/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 80/300 batch 186/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 80/300 batch 187/188  Train Loss: 0.024, Acc: 1.000\n",
      "Train Loss: 0.035794, Acc: 0.992\n",
      "Val Loss: 0.057786, Acc: 0.982\n",
      "epoch: 81/300 batch   0/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 81/300 batch   1/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 81/300 batch   2/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 81/300 batch   3/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 81/300 batch   4/188  Train Loss: 0.051, Acc: 0.980\n",
      "epoch: 81/300 batch   5/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 81/300 batch   6/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 81/300 batch   7/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 81/300 batch   8/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 81/300 batch   9/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 81/300 batch  10/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 81/300 batch  11/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 81/300 batch  12/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 81/300 batch  13/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 81/300 batch  14/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 81/300 batch  15/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 81/300 batch  16/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 81/300 batch  17/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 81/300 batch  18/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 81/300 batch  19/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 81/300 batch  20/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 81/300 batch  21/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 81/300 batch  22/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 81/300 batch  23/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 81/300 batch  24/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 81/300 batch  25/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 81/300 batch  26/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 81/300 batch  27/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 81/300 batch  28/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 81/300 batch  29/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 81/300 batch  30/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 81/300 batch  31/188  Train Loss: 0.055, Acc: 0.980\n",
      "epoch: 81/300 batch  32/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 81/300 batch  33/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 81/300 batch  34/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 81/300 batch  35/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 81/300 batch  36/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 81/300 batch  37/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 81/300 batch  38/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 81/300 batch  39/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 81/300 batch  40/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 81/300 batch  41/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 81/300 batch  42/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 81/300 batch  43/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 81/300 batch  44/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 81/300 batch  45/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 81/300 batch  46/188  Train Loss: 0.065, Acc: 0.984\n",
      "epoch: 81/300 batch  47/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 81/300 batch  48/188  Train Loss: 0.059, Acc: 0.984\n",
      "epoch: 81/300 batch  49/188  Train Loss: 0.059, Acc: 0.988\n",
      "epoch: 81/300 batch  50/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 81/300 batch  51/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 81/300 batch  52/188  Train Loss: 0.068, Acc: 0.992\n",
      "epoch: 81/300 batch  53/188  Train Loss: 0.064, Acc: 0.980\n",
      "epoch: 81/300 batch  54/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 81/300 batch  55/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 81/300 batch  56/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 81/300 batch  57/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 81/300 batch  58/188  Train Loss: 0.063, Acc: 0.984\n",
      "epoch: 81/300 batch  59/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 81/300 batch  60/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 81/300 batch  61/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 81/300 batch  62/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 81/300 batch  63/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 81/300 batch  64/188  Train Loss: 0.042, Acc: 0.996\n",
      "epoch: 81/300 batch  65/188  Train Loss: 0.026, Acc: 0.988\n",
      "epoch: 81/300 batch  66/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 81/300 batch  67/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 81/300 batch  68/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 81/300 batch  69/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 81/300 batch  70/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 81/300 batch  71/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 81/300 batch  72/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 81/300 batch  73/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 81/300 batch  74/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 81/300 batch  75/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 81/300 batch  76/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 81/300 batch  77/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 81/300 batch  78/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 81/300 batch  79/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 81/300 batch  80/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 81/300 batch  81/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 81/300 batch  82/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 81/300 batch  83/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 81/300 batch  84/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 81/300 batch  85/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 81/300 batch  86/188  Train Loss: 0.043, Acc: 0.996\n",
      "epoch: 81/300 batch  87/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 81/300 batch  88/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 81/300 batch  89/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 81/300 batch  90/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 81/300 batch  91/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 81/300 batch  92/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 81/300 batch  93/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 81/300 batch  94/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 81/300 batch  95/188  Train Loss: 0.046, Acc: 0.980\n",
      "epoch: 81/300 batch  96/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 81/300 batch  97/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 81/300 batch  98/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 81/300 batch  99/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 81/300 batch 100/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 81/300 batch 101/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 81/300 batch 102/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 81/300 batch 103/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 81/300 batch 104/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 81/300 batch 105/188  Train Loss: 0.095, Acc: 0.980\n",
      "epoch: 81/300 batch 106/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 81/300 batch 107/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 81/300 batch 108/188  Train Loss: 0.053, Acc: 0.992\n",
      "epoch: 81/300 batch 109/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 81/300 batch 110/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 81/300 batch 111/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 81/300 batch 112/188  Train Loss: 0.048, Acc: 0.980\n",
      "epoch: 81/300 batch 113/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 81/300 batch 114/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 81/300 batch 115/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 81/300 batch 116/188  Train Loss: 0.058, Acc: 0.973\n",
      "epoch: 81/300 batch 117/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 81/300 batch 118/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 81/300 batch 119/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 81/300 batch 120/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 81/300 batch 121/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 81/300 batch 122/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 81/300 batch 123/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 81/300 batch 124/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 81/300 batch 125/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 81/300 batch 126/188  Train Loss: 0.074, Acc: 0.988\n",
      "epoch: 81/300 batch 127/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 81/300 batch 128/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 81/300 batch 129/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 81/300 batch 130/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 81/300 batch 131/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 81/300 batch 132/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 81/300 batch 133/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 81/300 batch 134/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 81/300 batch 135/188  Train Loss: 0.057, Acc: 0.969\n",
      "epoch: 81/300 batch 136/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 81/300 batch 137/188  Train Loss: 0.043, Acc: 0.980\n",
      "epoch: 81/300 batch 138/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 81/300 batch 139/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 81/300 batch 140/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 81/300 batch 141/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 81/300 batch 142/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 81/300 batch 143/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 81/300 batch 144/188  Train Loss: 0.034, Acc: 1.000\n",
      "epoch: 81/300 batch 145/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 81/300 batch 146/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 81/300 batch 147/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 81/300 batch 148/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 81/300 batch 149/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 81/300 batch 150/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 81/300 batch 151/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 81/300 batch 152/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 81/300 batch 153/188  Train Loss: 0.052, Acc: 0.992\n",
      "epoch: 81/300 batch 154/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 81/300 batch 155/188  Train Loss: 0.066, Acc: 0.988\n",
      "epoch: 81/300 batch 156/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 81/300 batch 157/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 81/300 batch 158/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 81/300 batch 159/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 81/300 batch 160/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 81/300 batch 161/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 81/300 batch 162/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 81/300 batch 163/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 81/300 batch 164/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 81/300 batch 165/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 81/300 batch 166/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 81/300 batch 167/188  Train Loss: 0.050, Acc: 0.980\n",
      "epoch: 81/300 batch 168/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 81/300 batch 169/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 81/300 batch 170/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 81/300 batch 171/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 81/300 batch 172/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 81/300 batch 173/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 81/300 batch 174/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 81/300 batch 175/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 81/300 batch 176/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 81/300 batch 177/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 81/300 batch 178/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 81/300 batch 179/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 81/300 batch 180/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 81/300 batch 181/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 81/300 batch 182/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 81/300 batch 183/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 81/300 batch 184/188  Train Loss: 0.027, Acc: 0.988\n",
      "epoch: 81/300 batch 185/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 81/300 batch 186/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 81/300 batch 187/188  Train Loss: 0.014, Acc: 1.000\n",
      "Train Loss: 0.035752, Acc: 0.992\n",
      "Val Loss: 0.057605, Acc: 0.983\n",
      "epoch: 82/300 batch   0/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 82/300 batch   1/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 82/300 batch   2/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 82/300 batch   3/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 82/300 batch   4/188  Train Loss: 0.033, Acc: 1.000\n",
      "epoch: 82/300 batch   5/188  Train Loss: 0.060, Acc: 0.992\n",
      "epoch: 82/300 batch   6/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 82/300 batch   7/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 82/300 batch   8/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 82/300 batch   9/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 82/300 batch  10/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 82/300 batch  11/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 82/300 batch  12/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 82/300 batch  13/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 82/300 batch  14/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 82/300 batch  15/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 82/300 batch  16/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 82/300 batch  17/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 82/300 batch  18/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 82/300 batch  19/188  Train Loss: 0.025, Acc: 0.988\n",
      "epoch: 82/300 batch  20/188  Train Loss: 0.034, Acc: 0.984\n",
      "epoch: 82/300 batch  21/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 82/300 batch  22/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 82/300 batch  23/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 82/300 batch  24/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 82/300 batch  25/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 82/300 batch  26/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 82/300 batch  27/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 82/300 batch  28/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 82/300 batch  29/188  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 82/300 batch  30/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 82/300 batch  31/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 82/300 batch  32/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 82/300 batch  33/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 82/300 batch  34/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 82/300 batch  35/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 82/300 batch  36/188  Train Loss: 0.064, Acc: 0.980\n",
      "epoch: 82/300 batch  37/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 82/300 batch  38/188  Train Loss: 0.046, Acc: 0.980\n",
      "epoch: 82/300 batch  39/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 82/300 batch  40/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 82/300 batch  41/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 82/300 batch  42/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 82/300 batch  43/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 82/300 batch  44/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 82/300 batch  45/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 82/300 batch  46/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 82/300 batch  47/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 82/300 batch  48/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 82/300 batch  49/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 82/300 batch  50/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 82/300 batch  51/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 82/300 batch  52/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 82/300 batch  53/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 82/300 batch  54/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 82/300 batch  55/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 82/300 batch  56/188  Train Loss: 0.056, Acc: 0.988\n",
      "epoch: 82/300 batch  57/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 82/300 batch  58/188  Train Loss: 0.071, Acc: 0.984\n",
      "epoch: 82/300 batch  59/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 82/300 batch  60/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 82/300 batch  61/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 82/300 batch  62/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 82/300 batch  63/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 82/300 batch  64/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 82/300 batch  65/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 82/300 batch  66/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 82/300 batch  67/188  Train Loss: 0.065, Acc: 0.988\n",
      "epoch: 82/300 batch  68/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 82/300 batch  69/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 82/300 batch  70/188  Train Loss: 0.043, Acc: 0.980\n",
      "epoch: 82/300 batch  71/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 82/300 batch  72/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 82/300 batch  73/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 82/300 batch  74/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 82/300 batch  75/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 82/300 batch  76/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 82/300 batch  77/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 82/300 batch  78/188  Train Loss: 0.071, Acc: 0.984\n",
      "epoch: 82/300 batch  79/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 82/300 batch  80/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 82/300 batch  81/188  Train Loss: 0.063, Acc: 0.977\n",
      "epoch: 82/300 batch  82/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 82/300 batch  83/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 82/300 batch  84/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 82/300 batch  85/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 82/300 batch  86/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 82/300 batch  87/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 82/300 batch  88/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 82/300 batch  89/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 82/300 batch  90/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 82/300 batch  91/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 82/300 batch  92/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 82/300 batch  93/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 82/300 batch  94/188  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 82/300 batch  95/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 82/300 batch  96/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 82/300 batch  97/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 82/300 batch  98/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 82/300 batch  99/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 82/300 batch 100/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 82/300 batch 101/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 82/300 batch 102/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 82/300 batch 103/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 82/300 batch 104/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 82/300 batch 105/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 82/300 batch 106/188  Train Loss: 0.052, Acc: 0.980\n",
      "epoch: 82/300 batch 107/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 82/300 batch 108/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 82/300 batch 109/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 82/300 batch 110/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 82/300 batch 111/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 82/300 batch 112/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 82/300 batch 113/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 82/300 batch 114/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 82/300 batch 115/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 82/300 batch 116/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 82/300 batch 117/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 82/300 batch 118/188  Train Loss: 0.057, Acc: 0.988\n",
      "epoch: 82/300 batch 119/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 82/300 batch 120/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 82/300 batch 121/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 82/300 batch 122/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 82/300 batch 123/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 82/300 batch 124/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 82/300 batch 125/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 82/300 batch 126/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 82/300 batch 127/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 82/300 batch 128/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 82/300 batch 129/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 82/300 batch 130/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 82/300 batch 131/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 82/300 batch 132/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 82/300 batch 133/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 82/300 batch 134/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 82/300 batch 135/188  Train Loss: 0.067, Acc: 0.984\n",
      "epoch: 82/300 batch 136/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 82/300 batch 137/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 82/300 batch 138/188  Train Loss: 0.068, Acc: 0.984\n",
      "epoch: 82/300 batch 139/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 82/300 batch 140/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 82/300 batch 141/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 82/300 batch 142/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 82/300 batch 143/188  Train Loss: 0.046, Acc: 0.980\n",
      "epoch: 82/300 batch 144/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 82/300 batch 145/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 82/300 batch 146/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 82/300 batch 147/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 82/300 batch 148/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 82/300 batch 149/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 82/300 batch 150/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 82/300 batch 151/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 82/300 batch 152/188  Train Loss: 0.061, Acc: 0.980\n",
      "epoch: 82/300 batch 153/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 82/300 batch 154/188  Train Loss: 0.074, Acc: 0.969\n",
      "epoch: 82/300 batch 155/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 82/300 batch 156/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 82/300 batch 157/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 82/300 batch 158/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 82/300 batch 159/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 82/300 batch 160/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 82/300 batch 161/188  Train Loss: 0.057, Acc: 0.988\n",
      "epoch: 82/300 batch 162/188  Train Loss: 0.088, Acc: 0.980\n",
      "epoch: 82/300 batch 163/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 82/300 batch 164/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 82/300 batch 165/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 82/300 batch 166/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 82/300 batch 167/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 82/300 batch 168/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 82/300 batch 169/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 82/300 batch 170/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 82/300 batch 171/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 82/300 batch 172/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 82/300 batch 173/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 82/300 batch 174/188  Train Loss: 0.070, Acc: 0.980\n",
      "epoch: 82/300 batch 175/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 82/300 batch 176/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 82/300 batch 177/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 82/300 batch 178/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 82/300 batch 179/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 82/300 batch 180/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 82/300 batch 181/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 82/300 batch 182/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 82/300 batch 183/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 82/300 batch 184/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 82/300 batch 185/188  Train Loss: 0.059, Acc: 0.977\n",
      "epoch: 82/300 batch 186/188  Train Loss: 0.054, Acc: 0.992\n",
      "epoch: 82/300 batch 187/188  Train Loss: 0.029, Acc: 1.000\n",
      "Train Loss: 0.035772, Acc: 0.992\n",
      "Val Loss: 0.057916, Acc: 0.982\n",
      "epoch: 83/300 batch   0/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 83/300 batch   1/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 83/300 batch   2/188  Train Loss: 0.057, Acc: 0.988\n",
      "epoch: 83/300 batch   3/188  Train Loss: 0.055, Acc: 0.980\n",
      "epoch: 83/300 batch   4/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 83/300 batch   5/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 83/300 batch   6/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 83/300 batch   7/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 83/300 batch   8/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 83/300 batch   9/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 83/300 batch  10/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 83/300 batch  11/188  Train Loss: 0.047, Acc: 0.996\n",
      "epoch: 83/300 batch  12/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 83/300 batch  13/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 83/300 batch  14/188  Train Loss: 0.041, Acc: 0.980\n",
      "epoch: 83/300 batch  15/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 83/300 batch  16/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 83/300 batch  17/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 83/300 batch  18/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 83/300 batch  19/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 83/300 batch  20/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 83/300 batch  21/188  Train Loss: 0.051, Acc: 0.980\n",
      "epoch: 83/300 batch  22/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 83/300 batch  23/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 83/300 batch  24/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 83/300 batch  25/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 83/300 batch  26/188  Train Loss: 0.070, Acc: 0.980\n",
      "epoch: 83/300 batch  27/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 83/300 batch  28/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 83/300 batch  29/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 83/300 batch  30/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 83/300 batch  31/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 83/300 batch  32/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 83/300 batch  33/188  Train Loss: 0.063, Acc: 0.980\n",
      "epoch: 83/300 batch  34/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 83/300 batch  35/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 83/300 batch  36/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 83/300 batch  37/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 83/300 batch  38/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 83/300 batch  39/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 83/300 batch  40/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 83/300 batch  41/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 83/300 batch  42/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 83/300 batch  43/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 83/300 batch  44/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 83/300 batch  45/188  Train Loss: 0.046, Acc: 0.977\n",
      "epoch: 83/300 batch  46/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 83/300 batch  47/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 83/300 batch  48/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 83/300 batch  49/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 83/300 batch  50/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 83/300 batch  51/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 83/300 batch  52/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 83/300 batch  53/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 83/300 batch  54/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 83/300 batch  55/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 83/300 batch  56/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 83/300 batch  57/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 83/300 batch  58/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 83/300 batch  59/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 83/300 batch  60/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 83/300 batch  61/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 83/300 batch  62/188  Train Loss: 0.045, Acc: 0.980\n",
      "epoch: 83/300 batch  63/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 83/300 batch  64/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 83/300 batch  65/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 83/300 batch  66/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 83/300 batch  67/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 83/300 batch  68/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 83/300 batch  69/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 83/300 batch  70/188  Train Loss: 0.052, Acc: 0.992\n",
      "epoch: 83/300 batch  71/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 83/300 batch  72/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 83/300 batch  73/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 83/300 batch  74/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 83/300 batch  75/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 83/300 batch  76/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 83/300 batch  77/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 83/300 batch  78/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 83/300 batch  79/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 83/300 batch  80/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 83/300 batch  81/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 83/300 batch  82/188  Train Loss: 0.041, Acc: 0.980\n",
      "epoch: 83/300 batch  83/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 83/300 batch  84/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 83/300 batch  85/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 83/300 batch  86/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 83/300 batch  87/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 83/300 batch  88/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 83/300 batch  89/188  Train Loss: 0.036, Acc: 1.000\n",
      "epoch: 83/300 batch  90/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 83/300 batch  91/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 83/300 batch  92/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 83/300 batch  93/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 83/300 batch  94/188  Train Loss: 0.054, Acc: 0.980\n",
      "epoch: 83/300 batch  95/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 83/300 batch  96/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 83/300 batch  97/188  Train Loss: 0.062, Acc: 0.984\n",
      "epoch: 83/300 batch  98/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 83/300 batch  99/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 83/300 batch 100/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 83/300 batch 101/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 83/300 batch 102/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 83/300 batch 103/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 83/300 batch 104/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 83/300 batch 105/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 83/300 batch 106/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 83/300 batch 107/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 83/300 batch 108/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 83/300 batch 109/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 83/300 batch 110/188  Train Loss: 0.032, Acc: 1.000\n",
      "epoch: 83/300 batch 111/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 83/300 batch 112/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 83/300 batch 113/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 83/300 batch 114/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 83/300 batch 115/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 83/300 batch 116/188  Train Loss: 0.058, Acc: 0.988\n",
      "epoch: 83/300 batch 117/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 83/300 batch 118/188  Train Loss: 0.059, Acc: 0.984\n",
      "epoch: 83/300 batch 119/188  Train Loss: 0.044, Acc: 1.000\n",
      "epoch: 83/300 batch 120/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 83/300 batch 121/188  Train Loss: 0.046, Acc: 0.996\n",
      "epoch: 83/300 batch 122/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 83/300 batch 123/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 83/300 batch 124/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 83/300 batch 125/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 83/300 batch 126/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 83/300 batch 127/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 83/300 batch 128/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 83/300 batch 129/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 83/300 batch 130/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 83/300 batch 131/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 83/300 batch 132/188  Train Loss: 0.062, Acc: 0.988\n",
      "epoch: 83/300 batch 133/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 83/300 batch 134/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 83/300 batch 135/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 83/300 batch 136/188  Train Loss: 0.070, Acc: 0.980\n",
      "epoch: 83/300 batch 137/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 83/300 batch 138/188  Train Loss: 0.048, Acc: 0.977\n",
      "epoch: 83/300 batch 139/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 83/300 batch 140/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 83/300 batch 141/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 83/300 batch 142/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 83/300 batch 143/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 83/300 batch 144/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 83/300 batch 145/188  Train Loss: 0.046, Acc: 0.977\n",
      "epoch: 83/300 batch 146/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 83/300 batch 147/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 83/300 batch 148/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 83/300 batch 149/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 83/300 batch 150/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 83/300 batch 151/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 83/300 batch 152/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 83/300 batch 153/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 83/300 batch 154/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 83/300 batch 155/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 83/300 batch 156/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 83/300 batch 157/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 83/300 batch 158/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 83/300 batch 159/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 83/300 batch 160/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 83/300 batch 161/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 83/300 batch 162/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 83/300 batch 163/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 83/300 batch 164/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 83/300 batch 165/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 83/300 batch 166/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 83/300 batch 167/188  Train Loss: 0.047, Acc: 0.996\n",
      "epoch: 83/300 batch 168/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 83/300 batch 169/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 83/300 batch 170/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 83/300 batch 171/188  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 83/300 batch 172/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 83/300 batch 173/188  Train Loss: 0.031, Acc: 1.000\n",
      "epoch: 83/300 batch 174/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 83/300 batch 175/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 83/300 batch 176/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 83/300 batch 177/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 83/300 batch 178/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 83/300 batch 179/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 83/300 batch 180/188  Train Loss: 0.079, Acc: 0.980\n",
      "epoch: 83/300 batch 181/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 83/300 batch 182/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 83/300 batch 183/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 83/300 batch 184/188  Train Loss: 0.059, Acc: 0.992\n",
      "epoch: 83/300 batch 185/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 83/300 batch 186/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 83/300 batch 187/188  Train Loss: 0.079, Acc: 0.969\n",
      "Train Loss: 0.035872, Acc: 0.992\n",
      "Val Loss: 0.057679, Acc: 0.982\n",
      "epoch: 84/300 batch   0/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 84/300 batch   1/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 84/300 batch   2/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 84/300 batch   3/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 84/300 batch   4/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 84/300 batch   5/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 84/300 batch   6/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 84/300 batch   7/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 84/300 batch   8/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 84/300 batch   9/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 84/300 batch  10/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 84/300 batch  11/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 84/300 batch  12/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 84/300 batch  13/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 84/300 batch  14/188  Train Loss: 0.045, Acc: 0.996\n",
      "epoch: 84/300 batch  15/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 84/300 batch  16/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 84/300 batch  17/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 84/300 batch  18/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 84/300 batch  19/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 84/300 batch  20/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 84/300 batch  21/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 84/300 batch  22/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 84/300 batch  23/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 84/300 batch  24/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 84/300 batch  25/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 84/300 batch  26/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 84/300 batch  27/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 84/300 batch  28/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 84/300 batch  29/188  Train Loss: 0.016, Acc: 0.996\n",
      "epoch: 84/300 batch  30/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 84/300 batch  31/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 84/300 batch  32/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 84/300 batch  33/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 84/300 batch  34/188  Train Loss: 0.055, Acc: 0.980\n",
      "epoch: 84/300 batch  35/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 84/300 batch  36/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 84/300 batch  37/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 84/300 batch  38/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 84/300 batch  39/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 84/300 batch  40/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 84/300 batch  41/188  Train Loss: 0.055, Acc: 0.992\n",
      "epoch: 84/300 batch  42/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 84/300 batch  43/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 84/300 batch  44/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 84/300 batch  45/188  Train Loss: 0.031, Acc: 0.984\n",
      "epoch: 84/300 batch  46/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 84/300 batch  47/188  Train Loss: 0.048, Acc: 0.980\n",
      "epoch: 84/300 batch  48/188  Train Loss: 0.046, Acc: 0.980\n",
      "epoch: 84/300 batch  49/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 84/300 batch  50/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 84/300 batch  51/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 84/300 batch  52/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 84/300 batch  53/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 84/300 batch  54/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 84/300 batch  55/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 84/300 batch  56/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 84/300 batch  57/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 84/300 batch  58/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 84/300 batch  59/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 84/300 batch  60/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 84/300 batch  61/188  Train Loss: 0.031, Acc: 1.000\n",
      "epoch: 84/300 batch  62/188  Train Loss: 0.046, Acc: 0.996\n",
      "epoch: 84/300 batch  63/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 84/300 batch  64/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 84/300 batch  65/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 84/300 batch  66/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 84/300 batch  67/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 84/300 batch  68/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 84/300 batch  69/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 84/300 batch  70/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 84/300 batch  71/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 84/300 batch  72/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 84/300 batch  73/188  Train Loss: 0.050, Acc: 0.980\n",
      "epoch: 84/300 batch  74/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 84/300 batch  75/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 84/300 batch  76/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 84/300 batch  77/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 84/300 batch  78/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 84/300 batch  79/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 84/300 batch  80/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 84/300 batch  81/188  Train Loss: 0.070, Acc: 0.969\n",
      "epoch: 84/300 batch  82/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 84/300 batch  83/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 84/300 batch  84/188  Train Loss: 0.032, Acc: 1.000\n",
      "epoch: 84/300 batch  85/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 84/300 batch  86/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 84/300 batch  87/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 84/300 batch  88/188  Train Loss: 0.042, Acc: 0.996\n",
      "epoch: 84/300 batch  89/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 84/300 batch  90/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 84/300 batch  91/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 84/300 batch  92/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 84/300 batch  93/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 84/300 batch  94/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 84/300 batch  95/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 84/300 batch  96/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 84/300 batch  97/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 84/300 batch  98/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 84/300 batch  99/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 84/300 batch 100/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 84/300 batch 101/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 84/300 batch 102/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 84/300 batch 103/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 84/300 batch 104/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 84/300 batch 105/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 84/300 batch 106/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 84/300 batch 107/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 84/300 batch 108/188  Train Loss: 0.026, Acc: 0.988\n",
      "epoch: 84/300 batch 109/188  Train Loss: 0.077, Acc: 0.980\n",
      "epoch: 84/300 batch 110/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 84/300 batch 111/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 84/300 batch 112/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 84/300 batch 113/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 84/300 batch 114/188  Train Loss: 0.083, Acc: 0.973\n",
      "epoch: 84/300 batch 115/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 84/300 batch 116/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 84/300 batch 117/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 84/300 batch 118/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 84/300 batch 119/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 84/300 batch 120/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 84/300 batch 121/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 84/300 batch 122/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 84/300 batch 123/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 84/300 batch 124/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 84/300 batch 125/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 84/300 batch 126/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 84/300 batch 127/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 84/300 batch 128/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 84/300 batch 129/188  Train Loss: 0.065, Acc: 0.992\n",
      "epoch: 84/300 batch 130/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 84/300 batch 131/188  Train Loss: 0.045, Acc: 0.980\n",
      "epoch: 84/300 batch 132/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 84/300 batch 133/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 84/300 batch 134/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 84/300 batch 135/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 84/300 batch 136/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 84/300 batch 137/188  Train Loss: 0.052, Acc: 0.980\n",
      "epoch: 84/300 batch 138/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 84/300 batch 139/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 84/300 batch 140/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 84/300 batch 141/188  Train Loss: 0.064, Acc: 0.984\n",
      "epoch: 84/300 batch 142/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 84/300 batch 143/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 84/300 batch 144/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 84/300 batch 145/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 84/300 batch 146/188  Train Loss: 0.057, Acc: 0.988\n",
      "epoch: 84/300 batch 147/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 84/300 batch 148/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 84/300 batch 149/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 84/300 batch 150/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 84/300 batch 151/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 84/300 batch 152/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 84/300 batch 153/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 84/300 batch 154/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 84/300 batch 155/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 84/300 batch 156/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 84/300 batch 157/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 84/300 batch 158/188  Train Loss: 0.060, Acc: 0.984\n",
      "epoch: 84/300 batch 159/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 84/300 batch 160/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 84/300 batch 161/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 84/300 batch 162/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 84/300 batch 163/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 84/300 batch 164/188  Train Loss: 0.080, Acc: 0.977\n",
      "epoch: 84/300 batch 165/188  Train Loss: 0.057, Acc: 0.992\n",
      "epoch: 84/300 batch 166/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 84/300 batch 167/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 84/300 batch 168/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 84/300 batch 169/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 84/300 batch 170/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 84/300 batch 171/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 84/300 batch 172/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 84/300 batch 173/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 84/300 batch 174/188  Train Loss: 0.053, Acc: 0.992\n",
      "epoch: 84/300 batch 175/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 84/300 batch 176/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 84/300 batch 177/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 84/300 batch 178/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 84/300 batch 179/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 84/300 batch 180/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 84/300 batch 181/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 84/300 batch 182/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 84/300 batch 183/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 84/300 batch 184/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 84/300 batch 185/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 84/300 batch 186/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 84/300 batch 187/188  Train Loss: 0.015, Acc: 1.000\n",
      "Train Loss: 0.035707, Acc: 0.992\n",
      "Val Loss: 0.057543, Acc: 0.983\n",
      "epoch: 85/300 batch   0/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 85/300 batch   1/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 85/300 batch   2/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 85/300 batch   3/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 85/300 batch   4/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 85/300 batch   5/188  Train Loss: 0.060, Acc: 0.984\n",
      "epoch: 85/300 batch   6/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 85/300 batch   7/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 85/300 batch   8/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 85/300 batch   9/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 85/300 batch  10/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 85/300 batch  11/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 85/300 batch  12/188  Train Loss: 0.047, Acc: 0.980\n",
      "epoch: 85/300 batch  13/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 85/300 batch  14/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 85/300 batch  15/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 85/300 batch  16/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 85/300 batch  17/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 85/300 batch  18/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 85/300 batch  19/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 85/300 batch  20/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 85/300 batch  21/188  Train Loss: 0.051, Acc: 0.980\n",
      "epoch: 85/300 batch  22/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 85/300 batch  23/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 85/300 batch  24/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 85/300 batch  25/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 85/300 batch  26/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 85/300 batch  27/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 85/300 batch  28/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 85/300 batch  29/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 85/300 batch  30/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 85/300 batch  31/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 85/300 batch  32/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 85/300 batch  33/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 85/300 batch  34/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 85/300 batch  35/188  Train Loss: 0.078, Acc: 0.977\n",
      "epoch: 85/300 batch  36/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 85/300 batch  37/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 85/300 batch  38/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 85/300 batch  39/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 85/300 batch  40/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 85/300 batch  41/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 85/300 batch  42/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 85/300 batch  43/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 85/300 batch  44/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 85/300 batch  45/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 85/300 batch  46/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 85/300 batch  47/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 85/300 batch  48/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 85/300 batch  49/188  Train Loss: 0.055, Acc: 0.980\n",
      "epoch: 85/300 batch  50/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 85/300 batch  51/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 85/300 batch  52/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 85/300 batch  53/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 85/300 batch  54/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 85/300 batch  55/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 85/300 batch  56/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 85/300 batch  57/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 85/300 batch  58/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 85/300 batch  59/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 85/300 batch  60/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 85/300 batch  61/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 85/300 batch  62/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 85/300 batch  63/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 85/300 batch  64/188  Train Loss: 0.062, Acc: 0.984\n",
      "epoch: 85/300 batch  65/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 85/300 batch  66/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 85/300 batch  67/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 85/300 batch  68/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 85/300 batch  69/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 85/300 batch  70/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 85/300 batch  71/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 85/300 batch  72/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 85/300 batch  73/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 85/300 batch  74/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 85/300 batch  75/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 85/300 batch  76/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 85/300 batch  77/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 85/300 batch  78/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 85/300 batch  79/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 85/300 batch  80/188  Train Loss: 0.051, Acc: 0.977\n",
      "epoch: 85/300 batch  81/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 85/300 batch  82/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 85/300 batch  83/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 85/300 batch  84/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 85/300 batch  85/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 85/300 batch  86/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 85/300 batch  87/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 85/300 batch  88/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 85/300 batch  89/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 85/300 batch  90/188  Train Loss: 0.064, Acc: 0.984\n",
      "epoch: 85/300 batch  91/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 85/300 batch  92/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 85/300 batch  93/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 85/300 batch  94/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 85/300 batch  95/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 85/300 batch  96/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 85/300 batch  97/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 85/300 batch  98/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 85/300 batch  99/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 85/300 batch 100/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 85/300 batch 101/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 85/300 batch 102/188  Train Loss: 0.070, Acc: 0.988\n",
      "epoch: 85/300 batch 103/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 85/300 batch 104/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 85/300 batch 105/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 85/300 batch 106/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 85/300 batch 107/188  Train Loss: 0.066, Acc: 0.984\n",
      "epoch: 85/300 batch 108/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 85/300 batch 109/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 85/300 batch 110/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 85/300 batch 111/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 85/300 batch 112/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 85/300 batch 113/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 85/300 batch 114/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 85/300 batch 115/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 85/300 batch 116/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 85/300 batch 117/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 85/300 batch 118/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 85/300 batch 119/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 85/300 batch 120/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 85/300 batch 121/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 85/300 batch 122/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 85/300 batch 123/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 85/300 batch 124/188  Train Loss: 0.089, Acc: 0.977\n",
      "epoch: 85/300 batch 125/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 85/300 batch 126/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 85/300 batch 127/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 85/300 batch 128/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 85/300 batch 129/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 85/300 batch 130/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 85/300 batch 131/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 85/300 batch 132/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 85/300 batch 133/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 85/300 batch 134/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 85/300 batch 135/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 85/300 batch 136/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 85/300 batch 137/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 85/300 batch 138/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 85/300 batch 139/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 85/300 batch 140/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 85/300 batch 141/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 85/300 batch 142/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 85/300 batch 143/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 85/300 batch 144/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 85/300 batch 145/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 85/300 batch 146/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 85/300 batch 147/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 85/300 batch 148/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 85/300 batch 149/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 85/300 batch 150/188  Train Loss: 0.042, Acc: 0.996\n",
      "epoch: 85/300 batch 151/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 85/300 batch 152/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 85/300 batch 153/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 85/300 batch 154/188  Train Loss: 0.053, Acc: 0.992\n",
      "epoch: 85/300 batch 155/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 85/300 batch 156/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 85/300 batch 157/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 85/300 batch 158/188  Train Loss: 0.060, Acc: 0.984\n",
      "epoch: 85/300 batch 159/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 85/300 batch 160/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 85/300 batch 161/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 85/300 batch 162/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 85/300 batch 163/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 85/300 batch 164/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 85/300 batch 165/188  Train Loss: 0.051, Acc: 0.977\n",
      "epoch: 85/300 batch 166/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 85/300 batch 167/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 85/300 batch 168/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 85/300 batch 169/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 85/300 batch 170/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 85/300 batch 171/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 85/300 batch 172/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 85/300 batch 173/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 85/300 batch 174/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 85/300 batch 175/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 85/300 batch 176/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 85/300 batch 177/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 85/300 batch 178/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 85/300 batch 179/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 85/300 batch 180/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 85/300 batch 181/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 85/300 batch 182/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 85/300 batch 183/188  Train Loss: 0.057, Acc: 0.980\n",
      "epoch: 85/300 batch 184/188  Train Loss: 0.044, Acc: 0.996\n",
      "epoch: 85/300 batch 185/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 85/300 batch 186/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 85/300 batch 187/188  Train Loss: 0.031, Acc: 0.984\n",
      "Train Loss: 0.035630, Acc: 0.992\n",
      "Val Loss: 0.057603, Acc: 0.983\n",
      "epoch: 86/300 batch   0/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 86/300 batch   1/188  Train Loss: 0.015, Acc: 0.996\n",
      "epoch: 86/300 batch   2/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 86/300 batch   3/188  Train Loss: 0.056, Acc: 0.988\n",
      "epoch: 86/300 batch   4/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 86/300 batch   5/188  Train Loss: 0.057, Acc: 0.980\n",
      "epoch: 86/300 batch   6/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 86/300 batch   7/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 86/300 batch   8/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 86/300 batch   9/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 86/300 batch  10/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 86/300 batch  11/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 86/300 batch  12/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 86/300 batch  13/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 86/300 batch  14/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 86/300 batch  15/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 86/300 batch  16/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 86/300 batch  17/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 86/300 batch  18/188  Train Loss: 0.027, Acc: 0.988\n",
      "epoch: 86/300 batch  19/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 86/300 batch  20/188  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 86/300 batch  21/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 86/300 batch  22/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 86/300 batch  23/188  Train Loss: 0.039, Acc: 0.980\n",
      "epoch: 86/300 batch  24/188  Train Loss: 0.070, Acc: 0.984\n",
      "epoch: 86/300 batch  25/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 86/300 batch  26/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 86/300 batch  27/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 86/300 batch  28/188  Train Loss: 0.056, Acc: 0.988\n",
      "epoch: 86/300 batch  29/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 86/300 batch  30/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 86/300 batch  31/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 86/300 batch  32/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 86/300 batch  33/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 86/300 batch  34/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 86/300 batch  35/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 86/300 batch  36/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 86/300 batch  37/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 86/300 batch  38/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 86/300 batch  39/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 86/300 batch  40/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 86/300 batch  41/188  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 86/300 batch  42/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 86/300 batch  43/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 86/300 batch  44/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 86/300 batch  45/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 86/300 batch  46/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 86/300 batch  47/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 86/300 batch  48/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 86/300 batch  49/188  Train Loss: 0.084, Acc: 0.984\n",
      "epoch: 86/300 batch  50/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 86/300 batch  51/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 86/300 batch  52/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 86/300 batch  53/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 86/300 batch  54/188  Train Loss: 0.060, Acc: 0.984\n",
      "epoch: 86/300 batch  55/188  Train Loss: 0.033, Acc: 0.984\n",
      "epoch: 86/300 batch  56/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 86/300 batch  57/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 86/300 batch  58/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 86/300 batch  59/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 86/300 batch  60/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 86/300 batch  61/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 86/300 batch  62/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 86/300 batch  63/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 86/300 batch  64/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 86/300 batch  65/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 86/300 batch  66/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 86/300 batch  67/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 86/300 batch  68/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 86/300 batch  69/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 86/300 batch  70/188  Train Loss: 0.063, Acc: 0.984\n",
      "epoch: 86/300 batch  71/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 86/300 batch  72/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 86/300 batch  73/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 86/300 batch  74/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 86/300 batch  75/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 86/300 batch  76/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 86/300 batch  77/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 86/300 batch  78/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 86/300 batch  79/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 86/300 batch  80/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 86/300 batch  81/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 86/300 batch  82/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 86/300 batch  83/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 86/300 batch  84/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 86/300 batch  85/188  Train Loss: 0.089, Acc: 0.977\n",
      "epoch: 86/300 batch  86/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 86/300 batch  87/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 86/300 batch  88/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 86/300 batch  89/188  Train Loss: 0.056, Acc: 0.980\n",
      "epoch: 86/300 batch  90/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 86/300 batch  91/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 86/300 batch  92/188  Train Loss: 0.043, Acc: 0.996\n",
      "epoch: 86/300 batch  93/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 86/300 batch  94/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 86/300 batch  95/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 86/300 batch  96/188  Train Loss: 0.085, Acc: 0.980\n",
      "epoch: 86/300 batch  97/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 86/300 batch  98/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 86/300 batch  99/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 86/300 batch 100/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 86/300 batch 101/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 86/300 batch 102/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 86/300 batch 103/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 86/300 batch 104/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 86/300 batch 105/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 86/300 batch 106/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 86/300 batch 107/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 86/300 batch 108/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 86/300 batch 109/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 86/300 batch 110/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 86/300 batch 111/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 86/300 batch 112/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 86/300 batch 113/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 86/300 batch 114/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 86/300 batch 115/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 86/300 batch 116/188  Train Loss: 0.045, Acc: 0.980\n",
      "epoch: 86/300 batch 117/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 86/300 batch 118/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 86/300 batch 119/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 86/300 batch 120/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 86/300 batch 121/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 86/300 batch 122/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 86/300 batch 123/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 86/300 batch 124/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 86/300 batch 125/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 86/300 batch 126/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 86/300 batch 127/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 86/300 batch 128/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 86/300 batch 129/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 86/300 batch 130/188  Train Loss: 0.066, Acc: 0.984\n",
      "epoch: 86/300 batch 131/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 86/300 batch 132/188  Train Loss: 0.067, Acc: 0.988\n",
      "epoch: 86/300 batch 133/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 86/300 batch 134/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 86/300 batch 135/188  Train Loss: 0.054, Acc: 0.977\n",
      "epoch: 86/300 batch 136/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 86/300 batch 137/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 86/300 batch 138/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 86/300 batch 139/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 86/300 batch 140/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 86/300 batch 141/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 86/300 batch 142/188  Train Loss: 0.061, Acc: 0.977\n",
      "epoch: 86/300 batch 143/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 86/300 batch 144/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 86/300 batch 145/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 86/300 batch 146/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 86/300 batch 147/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 86/300 batch 148/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 86/300 batch 149/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 86/300 batch 150/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 86/300 batch 151/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 86/300 batch 152/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 86/300 batch 153/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 86/300 batch 154/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 86/300 batch 155/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 86/300 batch 156/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 86/300 batch 157/188  Train Loss: 0.037, Acc: 1.000\n",
      "epoch: 86/300 batch 158/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 86/300 batch 159/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 86/300 batch 160/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 86/300 batch 161/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 86/300 batch 162/188  Train Loss: 0.070, Acc: 0.973\n",
      "epoch: 86/300 batch 163/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 86/300 batch 164/188  Train Loss: 0.055, Acc: 0.992\n",
      "epoch: 86/300 batch 165/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 86/300 batch 166/188  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 86/300 batch 167/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 86/300 batch 168/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 86/300 batch 169/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 86/300 batch 170/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 86/300 batch 171/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 86/300 batch 172/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 86/300 batch 173/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 86/300 batch 174/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 86/300 batch 175/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 86/300 batch 176/188  Train Loss: 0.061, Acc: 0.984\n",
      "epoch: 86/300 batch 177/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 86/300 batch 178/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 86/300 batch 179/188  Train Loss: 0.063, Acc: 0.984\n",
      "epoch: 86/300 batch 180/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 86/300 batch 181/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 86/300 batch 182/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 86/300 batch 183/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 86/300 batch 184/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 86/300 batch 185/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 86/300 batch 186/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 86/300 batch 187/188  Train Loss: 0.038, Acc: 1.000\n",
      "Train Loss: 0.035713, Acc: 0.992\n",
      "Val Loss: 0.057558, Acc: 0.982\n",
      "epoch: 87/300 batch   0/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 87/300 batch   1/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 87/300 batch   2/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 87/300 batch   3/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 87/300 batch   4/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 87/300 batch   5/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 87/300 batch   6/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 87/300 batch   7/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 87/300 batch   8/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 87/300 batch   9/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 87/300 batch  10/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 87/300 batch  11/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 87/300 batch  12/188  Train Loss: 0.067, Acc: 0.973\n",
      "epoch: 87/300 batch  13/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 87/300 batch  14/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 87/300 batch  15/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 87/300 batch  16/188  Train Loss: 0.054, Acc: 0.992\n",
      "epoch: 87/300 batch  17/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 87/300 batch  18/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 87/300 batch  19/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 87/300 batch  20/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 87/300 batch  21/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 87/300 batch  22/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 87/300 batch  23/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 87/300 batch  24/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 87/300 batch  25/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 87/300 batch  26/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 87/300 batch  27/188  Train Loss: 0.059, Acc: 0.980\n",
      "epoch: 87/300 batch  28/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 87/300 batch  29/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 87/300 batch  30/188  Train Loss: 0.025, Acc: 0.988\n",
      "epoch: 87/300 batch  31/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 87/300 batch  32/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 87/300 batch  33/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 87/300 batch  34/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 87/300 batch  35/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 87/300 batch  36/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 87/300 batch  37/188  Train Loss: 0.054, Acc: 0.980\n",
      "epoch: 87/300 batch  38/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 87/300 batch  39/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 87/300 batch  40/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 87/300 batch  41/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 87/300 batch  42/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 87/300 batch  43/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 87/300 batch  44/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 87/300 batch  45/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 87/300 batch  46/188  Train Loss: 0.048, Acc: 0.980\n",
      "epoch: 87/300 batch  47/188  Train Loss: 0.059, Acc: 0.988\n",
      "epoch: 87/300 batch  48/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 87/300 batch  49/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 87/300 batch  50/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 87/300 batch  51/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 87/300 batch  52/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 87/300 batch  53/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 87/300 batch  54/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 87/300 batch  55/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 87/300 batch  56/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 87/300 batch  57/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 87/300 batch  58/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 87/300 batch  59/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 87/300 batch  60/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 87/300 batch  61/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 87/300 batch  62/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 87/300 batch  63/188  Train Loss: 0.067, Acc: 0.992\n",
      "epoch: 87/300 batch  64/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 87/300 batch  65/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 87/300 batch  66/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 87/300 batch  67/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 87/300 batch  68/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 87/300 batch  69/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 87/300 batch  70/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 87/300 batch  71/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 87/300 batch  72/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 87/300 batch  73/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 87/300 batch  74/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 87/300 batch  75/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 87/300 batch  76/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 87/300 batch  77/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 87/300 batch  78/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 87/300 batch  79/188  Train Loss: 0.046, Acc: 0.996\n",
      "epoch: 87/300 batch  80/188  Train Loss: 0.045, Acc: 0.980\n",
      "epoch: 87/300 batch  81/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 87/300 batch  82/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 87/300 batch  83/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 87/300 batch  84/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 87/300 batch  85/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 87/300 batch  86/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 87/300 batch  87/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 87/300 batch  88/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 87/300 batch  89/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 87/300 batch  90/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 87/300 batch  91/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 87/300 batch  92/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 87/300 batch  93/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 87/300 batch  94/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 87/300 batch  95/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 87/300 batch  96/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 87/300 batch  97/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 87/300 batch  98/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 87/300 batch  99/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 87/300 batch 100/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 87/300 batch 101/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 87/300 batch 102/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 87/300 batch 103/188  Train Loss: 0.060, Acc: 0.988\n",
      "epoch: 87/300 batch 104/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 87/300 batch 105/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 87/300 batch 106/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 87/300 batch 107/188  Train Loss: 0.059, Acc: 0.984\n",
      "epoch: 87/300 batch 108/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 87/300 batch 109/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 87/300 batch 110/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 87/300 batch 111/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 87/300 batch 112/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 87/300 batch 113/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 87/300 batch 114/188  Train Loss: 0.050, Acc: 0.980\n",
      "epoch: 87/300 batch 115/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 87/300 batch 116/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 87/300 batch 117/188  Train Loss: 0.016, Acc: 0.996\n",
      "epoch: 87/300 batch 118/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 87/300 batch 119/188  Train Loss: 0.060, Acc: 0.984\n",
      "epoch: 87/300 batch 120/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 87/300 batch 121/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 87/300 batch 122/188  Train Loss: 0.055, Acc: 0.977\n",
      "epoch: 87/300 batch 123/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 87/300 batch 124/188  Train Loss: 0.052, Acc: 0.980\n",
      "epoch: 87/300 batch 125/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 87/300 batch 126/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 87/300 batch 127/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 87/300 batch 128/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 87/300 batch 129/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 87/300 batch 130/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 87/300 batch 131/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 87/300 batch 132/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 87/300 batch 133/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 87/300 batch 134/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 87/300 batch 135/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 87/300 batch 136/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 87/300 batch 137/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 87/300 batch 138/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 87/300 batch 139/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 87/300 batch 140/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 87/300 batch 141/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 87/300 batch 142/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 87/300 batch 143/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 87/300 batch 144/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 87/300 batch 145/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 87/300 batch 146/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 87/300 batch 147/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 87/300 batch 148/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 87/300 batch 149/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 87/300 batch 150/188  Train Loss: 0.033, Acc: 1.000\n",
      "epoch: 87/300 batch 151/188  Train Loss: 0.039, Acc: 0.980\n",
      "epoch: 87/300 batch 152/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 87/300 batch 153/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 87/300 batch 154/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 87/300 batch 155/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 87/300 batch 156/188  Train Loss: 0.060, Acc: 0.980\n",
      "epoch: 87/300 batch 157/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 87/300 batch 158/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 87/300 batch 159/188  Train Loss: 0.032, Acc: 0.984\n",
      "epoch: 87/300 batch 160/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 87/300 batch 161/188  Train Loss: 0.054, Acc: 0.980\n",
      "epoch: 87/300 batch 162/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 87/300 batch 163/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 87/300 batch 164/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 87/300 batch 165/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 87/300 batch 166/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 87/300 batch 167/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 87/300 batch 168/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 87/300 batch 169/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 87/300 batch 170/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 87/300 batch 171/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 87/300 batch 172/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 87/300 batch 173/188  Train Loss: 0.059, Acc: 0.984\n",
      "epoch: 87/300 batch 174/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 87/300 batch 175/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 87/300 batch 176/188  Train Loss: 0.064, Acc: 0.984\n",
      "epoch: 87/300 batch 177/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 87/300 batch 178/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 87/300 batch 179/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 87/300 batch 180/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 87/300 batch 181/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 87/300 batch 182/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 87/300 batch 183/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 87/300 batch 184/188  Train Loss: 0.054, Acc: 0.992\n",
      "epoch: 87/300 batch 185/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 87/300 batch 186/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 87/300 batch 187/188  Train Loss: 0.022, Acc: 1.000\n",
      "Train Loss: 0.035587, Acc: 0.992\n",
      "Val Loss: 0.057544, Acc: 0.983\n",
      "epoch: 88/300 batch   0/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 88/300 batch   1/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 88/300 batch   2/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 88/300 batch   3/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 88/300 batch   4/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 88/300 batch   5/188  Train Loss: 0.065, Acc: 0.988\n",
      "epoch: 88/300 batch   6/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 88/300 batch   7/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 88/300 batch   8/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 88/300 batch   9/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 88/300 batch  10/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 88/300 batch  11/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 88/300 batch  12/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 88/300 batch  13/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 88/300 batch  14/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 88/300 batch  15/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 88/300 batch  16/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 88/300 batch  17/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 88/300 batch  18/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 88/300 batch  19/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 88/300 batch  20/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 88/300 batch  21/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 88/300 batch  22/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 88/300 batch  23/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 88/300 batch  24/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 88/300 batch  25/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 88/300 batch  26/188  Train Loss: 0.057, Acc: 0.988\n",
      "epoch: 88/300 batch  27/188  Train Loss: 0.063, Acc: 0.980\n",
      "epoch: 88/300 batch  28/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 88/300 batch  29/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 88/300 batch  30/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 88/300 batch  31/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 88/300 batch  32/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 88/300 batch  33/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 88/300 batch  34/188  Train Loss: 0.056, Acc: 0.988\n",
      "epoch: 88/300 batch  35/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 88/300 batch  36/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 88/300 batch  37/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 88/300 batch  38/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 88/300 batch  39/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 88/300 batch  40/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 88/300 batch  41/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 88/300 batch  42/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 88/300 batch  43/188  Train Loss: 0.056, Acc: 0.988\n",
      "epoch: 88/300 batch  44/188  Train Loss: 0.048, Acc: 0.980\n",
      "epoch: 88/300 batch  45/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 88/300 batch  46/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 88/300 batch  47/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 88/300 batch  48/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 88/300 batch  49/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 88/300 batch  50/188  Train Loss: 0.046, Acc: 0.996\n",
      "epoch: 88/300 batch  51/188  Train Loss: 0.045, Acc: 0.980\n",
      "epoch: 88/300 batch  52/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 88/300 batch  53/188  Train Loss: 0.042, Acc: 0.980\n",
      "epoch: 88/300 batch  54/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 88/300 batch  55/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 88/300 batch  56/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 88/300 batch  57/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 88/300 batch  58/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 88/300 batch  59/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 88/300 batch  60/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 88/300 batch  61/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 88/300 batch  62/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 88/300 batch  63/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 88/300 batch  64/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 88/300 batch  65/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 88/300 batch  66/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 88/300 batch  67/188  Train Loss: 0.056, Acc: 0.988\n",
      "epoch: 88/300 batch  68/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 88/300 batch  69/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 88/300 batch  70/188  Train Loss: 0.041, Acc: 0.980\n",
      "epoch: 88/300 batch  71/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 88/300 batch  72/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 88/300 batch  73/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 88/300 batch  74/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 88/300 batch  75/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 88/300 batch  76/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 88/300 batch  77/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 88/300 batch  78/188  Train Loss: 0.035, Acc: 0.980\n",
      "epoch: 88/300 batch  79/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 88/300 batch  80/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 88/300 batch  81/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 88/300 batch  82/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 88/300 batch  83/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 88/300 batch  84/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 88/300 batch  85/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 88/300 batch  86/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 88/300 batch  87/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 88/300 batch  88/188  Train Loss: 0.024, Acc: 0.988\n",
      "epoch: 88/300 batch  89/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 88/300 batch  90/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 88/300 batch  91/188  Train Loss: 0.057, Acc: 0.992\n",
      "epoch: 88/300 batch  92/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 88/300 batch  93/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 88/300 batch  94/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 88/300 batch  95/188  Train Loss: 0.047, Acc: 0.980\n",
      "epoch: 88/300 batch  96/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 88/300 batch  97/188  Train Loss: 0.059, Acc: 0.984\n",
      "epoch: 88/300 batch  98/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 88/300 batch  99/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 88/300 batch 100/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 88/300 batch 101/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 88/300 batch 102/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 88/300 batch 103/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 88/300 batch 104/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 88/300 batch 105/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 88/300 batch 106/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 88/300 batch 107/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 88/300 batch 108/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 88/300 batch 109/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 88/300 batch 110/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 88/300 batch 111/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 88/300 batch 112/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 88/300 batch 113/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 88/300 batch 114/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 88/300 batch 115/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 88/300 batch 116/188  Train Loss: 0.074, Acc: 0.992\n",
      "epoch: 88/300 batch 117/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 88/300 batch 118/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 88/300 batch 119/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 88/300 batch 120/188  Train Loss: 0.033, Acc: 1.000\n",
      "epoch: 88/300 batch 121/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 88/300 batch 122/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 88/300 batch 123/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 88/300 batch 124/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 88/300 batch 125/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 88/300 batch 126/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 88/300 batch 127/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 88/300 batch 128/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 88/300 batch 129/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 88/300 batch 130/188  Train Loss: 0.049, Acc: 0.977\n",
      "epoch: 88/300 batch 131/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 88/300 batch 132/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 88/300 batch 133/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 88/300 batch 134/188  Train Loss: 0.076, Acc: 0.980\n",
      "epoch: 88/300 batch 135/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 88/300 batch 136/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 88/300 batch 137/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 88/300 batch 138/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 88/300 batch 139/188  Train Loss: 0.058, Acc: 0.988\n",
      "epoch: 88/300 batch 140/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 88/300 batch 141/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 88/300 batch 142/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 88/300 batch 143/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 88/300 batch 144/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 88/300 batch 145/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 88/300 batch 146/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 88/300 batch 147/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 88/300 batch 148/188  Train Loss: 0.034, Acc: 0.984\n",
      "epoch: 88/300 batch 149/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 88/300 batch 150/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 88/300 batch 151/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 88/300 batch 152/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 88/300 batch 153/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 88/300 batch 154/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 88/300 batch 155/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 88/300 batch 156/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 88/300 batch 157/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 88/300 batch 158/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 88/300 batch 159/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 88/300 batch 160/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 88/300 batch 161/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 88/300 batch 162/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 88/300 batch 163/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 88/300 batch 164/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 88/300 batch 165/188  Train Loss: 0.057, Acc: 0.977\n",
      "epoch: 88/300 batch 166/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 88/300 batch 167/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 88/300 batch 168/188  Train Loss: 0.026, Acc: 0.988\n",
      "epoch: 88/300 batch 169/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 88/300 batch 170/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 88/300 batch 171/188  Train Loss: 0.050, Acc: 0.996\n",
      "epoch: 88/300 batch 172/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 88/300 batch 173/188  Train Loss: 0.051, Acc: 0.992\n",
      "epoch: 88/300 batch 174/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 88/300 batch 175/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 88/300 batch 176/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 88/300 batch 177/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 88/300 batch 178/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 88/300 batch 179/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 88/300 batch 180/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 88/300 batch 181/188  Train Loss: 0.058, Acc: 0.977\n",
      "epoch: 88/300 batch 182/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 88/300 batch 183/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 88/300 batch 184/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 88/300 batch 185/188  Train Loss: 0.065, Acc: 0.988\n",
      "epoch: 88/300 batch 186/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 88/300 batch 187/188  Train Loss: 0.029, Acc: 0.992\n",
      "Train Loss: 0.035586, Acc: 0.992\n",
      "Val Loss: 0.057799, Acc: 0.982\n",
      "epoch: 89/300 batch   0/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 89/300 batch   1/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 89/300 batch   2/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 89/300 batch   3/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 89/300 batch   4/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 89/300 batch   5/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 89/300 batch   6/188  Train Loss: 0.068, Acc: 0.984\n",
      "epoch: 89/300 batch   7/188  Train Loss: 0.059, Acc: 0.977\n",
      "epoch: 89/300 batch   8/188  Train Loss: 0.061, Acc: 0.984\n",
      "epoch: 89/300 batch   9/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 89/300 batch  10/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 89/300 batch  11/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 89/300 batch  12/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 89/300 batch  13/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 89/300 batch  14/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 89/300 batch  15/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 89/300 batch  16/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 89/300 batch  17/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 89/300 batch  18/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 89/300 batch  19/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 89/300 batch  20/188  Train Loss: 0.069, Acc: 0.980\n",
      "epoch: 89/300 batch  21/188  Train Loss: 0.072, Acc: 0.992\n",
      "epoch: 89/300 batch  22/188  Train Loss: 0.037, Acc: 0.980\n",
      "epoch: 89/300 batch  23/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 89/300 batch  24/188  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 89/300 batch  25/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 89/300 batch  26/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 89/300 batch  27/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 89/300 batch  28/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 89/300 batch  29/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 89/300 batch  30/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 89/300 batch  31/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 89/300 batch  32/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 89/300 batch  33/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 89/300 batch  34/188  Train Loss: 0.055, Acc: 0.980\n",
      "epoch: 89/300 batch  35/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 89/300 batch  36/188  Train Loss: 0.058, Acc: 0.980\n",
      "epoch: 89/300 batch  37/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 89/300 batch  38/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 89/300 batch  39/188  Train Loss: 0.049, Acc: 0.980\n",
      "epoch: 89/300 batch  40/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 89/300 batch  41/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 89/300 batch  42/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 89/300 batch  43/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 89/300 batch  44/188  Train Loss: 0.050, Acc: 0.980\n",
      "epoch: 89/300 batch  45/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 89/300 batch  46/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 89/300 batch  47/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 89/300 batch  48/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 89/300 batch  49/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 89/300 batch  50/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 89/300 batch  51/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 89/300 batch  52/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 89/300 batch  53/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 89/300 batch  54/188  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 89/300 batch  55/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 89/300 batch  56/188  Train Loss: 0.070, Acc: 0.977\n",
      "epoch: 89/300 batch  57/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 89/300 batch  58/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 89/300 batch  59/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 89/300 batch  60/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 89/300 batch  61/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 89/300 batch  62/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 89/300 batch  63/188  Train Loss: 0.026, Acc: 0.988\n",
      "epoch: 89/300 batch  64/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 89/300 batch  65/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 89/300 batch  66/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 89/300 batch  67/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 89/300 batch  68/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 89/300 batch  69/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 89/300 batch  70/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 89/300 batch  71/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 89/300 batch  72/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 89/300 batch  73/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 89/300 batch  74/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 89/300 batch  75/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 89/300 batch  76/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 89/300 batch  77/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 89/300 batch  78/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 89/300 batch  79/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 89/300 batch  80/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 89/300 batch  81/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 89/300 batch  82/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 89/300 batch  83/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 89/300 batch  84/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 89/300 batch  85/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 89/300 batch  86/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 89/300 batch  87/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 89/300 batch  88/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 89/300 batch  89/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 89/300 batch  90/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 89/300 batch  91/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 89/300 batch  92/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 89/300 batch  93/188  Train Loss: 0.106, Acc: 0.984\n",
      "epoch: 89/300 batch  94/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 89/300 batch  95/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 89/300 batch  96/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 89/300 batch  97/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 89/300 batch  98/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 89/300 batch  99/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 89/300 batch 100/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 89/300 batch 101/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 89/300 batch 102/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 89/300 batch 103/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 89/300 batch 104/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 89/300 batch 105/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 89/300 batch 106/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 89/300 batch 107/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 89/300 batch 108/188  Train Loss: 0.055, Acc: 0.980\n",
      "epoch: 89/300 batch 109/188  Train Loss: 0.069, Acc: 0.980\n",
      "epoch: 89/300 batch 110/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 89/300 batch 111/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 89/300 batch 112/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 89/300 batch 113/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 89/300 batch 114/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 89/300 batch 115/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 89/300 batch 116/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 89/300 batch 117/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 89/300 batch 118/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 89/300 batch 119/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 89/300 batch 120/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 89/300 batch 121/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 89/300 batch 122/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 89/300 batch 123/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 89/300 batch 124/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 89/300 batch 125/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 89/300 batch 126/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 89/300 batch 127/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 89/300 batch 128/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 89/300 batch 129/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 89/300 batch 130/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 89/300 batch 131/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 89/300 batch 132/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 89/300 batch 133/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 89/300 batch 134/188  Train Loss: 0.059, Acc: 0.992\n",
      "epoch: 89/300 batch 135/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 89/300 batch 136/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 89/300 batch 137/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 89/300 batch 138/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 89/300 batch 139/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 89/300 batch 140/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 89/300 batch 141/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 89/300 batch 142/188  Train Loss: 0.052, Acc: 0.980\n",
      "epoch: 89/300 batch 143/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 89/300 batch 144/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 89/300 batch 145/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 89/300 batch 146/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 89/300 batch 147/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 89/300 batch 148/188  Train Loss: 0.016, Acc: 0.996\n",
      "epoch: 89/300 batch 149/188  Train Loss: 0.034, Acc: 1.000\n",
      "epoch: 89/300 batch 150/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 89/300 batch 151/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 89/300 batch 152/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 89/300 batch 153/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 89/300 batch 154/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 89/300 batch 155/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 89/300 batch 156/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 89/300 batch 157/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 89/300 batch 158/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 89/300 batch 159/188  Train Loss: 0.060, Acc: 0.984\n",
      "epoch: 89/300 batch 160/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 89/300 batch 161/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 89/300 batch 162/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 89/300 batch 163/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 89/300 batch 164/188  Train Loss: 0.066, Acc: 0.984\n",
      "epoch: 89/300 batch 165/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 89/300 batch 166/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 89/300 batch 167/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 89/300 batch 168/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 89/300 batch 169/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 89/300 batch 170/188  Train Loss: 0.072, Acc: 0.988\n",
      "epoch: 89/300 batch 171/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 89/300 batch 172/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 89/300 batch 173/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 89/300 batch 174/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 89/300 batch 175/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 89/300 batch 176/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 89/300 batch 177/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 89/300 batch 178/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 89/300 batch 179/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 89/300 batch 180/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 89/300 batch 181/188  Train Loss: 0.057, Acc: 0.988\n",
      "epoch: 89/300 batch 182/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 89/300 batch 183/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 89/300 batch 184/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 89/300 batch 185/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 89/300 batch 186/188  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 89/300 batch 187/188  Train Loss: 0.047, Acc: 0.992\n",
      "Train Loss: 0.035612, Acc: 0.992\n",
      "Val Loss: 0.057687, Acc: 0.982\n",
      "epoch: 90/300 batch   0/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 90/300 batch   1/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 90/300 batch   2/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 90/300 batch   3/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 90/300 batch   4/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 90/300 batch   5/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 90/300 batch   6/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 90/300 batch   7/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 90/300 batch   8/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 90/300 batch   9/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 90/300 batch  10/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 90/300 batch  11/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 90/300 batch  12/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 90/300 batch  13/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 90/300 batch  14/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 90/300 batch  15/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 90/300 batch  16/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 90/300 batch  17/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 90/300 batch  18/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 90/300 batch  19/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 90/300 batch  20/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 90/300 batch  21/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 90/300 batch  22/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 90/300 batch  23/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 90/300 batch  24/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 90/300 batch  25/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 90/300 batch  26/188  Train Loss: 0.079, Acc: 0.980\n",
      "epoch: 90/300 batch  27/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 90/300 batch  28/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 90/300 batch  29/188  Train Loss: 0.043, Acc: 0.980\n",
      "epoch: 90/300 batch  30/188  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 90/300 batch  31/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 90/300 batch  32/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 90/300 batch  33/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 90/300 batch  34/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 90/300 batch  35/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 90/300 batch  36/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 90/300 batch  37/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 90/300 batch  38/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 90/300 batch  39/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 90/300 batch  40/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 90/300 batch  41/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 90/300 batch  42/188  Train Loss: 0.050, Acc: 0.977\n",
      "epoch: 90/300 batch  43/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 90/300 batch  44/188  Train Loss: 0.042, Acc: 0.996\n",
      "epoch: 90/300 batch  45/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 90/300 batch  46/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 90/300 batch  47/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 90/300 batch  48/188  Train Loss: 0.039, Acc: 0.980\n",
      "epoch: 90/300 batch  49/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 90/300 batch  50/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 90/300 batch  51/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 90/300 batch  52/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 90/300 batch  53/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 90/300 batch  54/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 90/300 batch  55/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 90/300 batch  56/188  Train Loss: 0.052, Acc: 0.992\n",
      "epoch: 90/300 batch  57/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 90/300 batch  58/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 90/300 batch  59/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 90/300 batch  60/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 90/300 batch  61/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 90/300 batch  62/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 90/300 batch  63/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 90/300 batch  64/188  Train Loss: 0.043, Acc: 0.996\n",
      "epoch: 90/300 batch  65/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 90/300 batch  66/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 90/300 batch  67/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 90/300 batch  68/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 90/300 batch  69/188  Train Loss: 0.061, Acc: 0.984\n",
      "epoch: 90/300 batch  70/188  Train Loss: 0.082, Acc: 0.973\n",
      "epoch: 90/300 batch  71/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 90/300 batch  72/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 90/300 batch  73/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 90/300 batch  74/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 90/300 batch  75/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 90/300 batch  76/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 90/300 batch  77/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 90/300 batch  78/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 90/300 batch  79/188  Train Loss: 0.071, Acc: 0.980\n",
      "epoch: 90/300 batch  80/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 90/300 batch  81/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 90/300 batch  82/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 90/300 batch  83/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 90/300 batch  84/188  Train Loss: 0.061, Acc: 0.984\n",
      "epoch: 90/300 batch  85/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 90/300 batch  86/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 90/300 batch  87/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 90/300 batch  88/188  Train Loss: 0.026, Acc: 0.988\n",
      "epoch: 90/300 batch  89/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 90/300 batch  90/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 90/300 batch  91/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 90/300 batch  92/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 90/300 batch  93/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 90/300 batch  94/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 90/300 batch  95/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 90/300 batch  96/188  Train Loss: 0.043, Acc: 0.980\n",
      "epoch: 90/300 batch  97/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 90/300 batch  98/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 90/300 batch  99/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 90/300 batch 100/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 90/300 batch 101/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 90/300 batch 102/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 90/300 batch 103/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 90/300 batch 104/188  Train Loss: 0.078, Acc: 0.980\n",
      "epoch: 90/300 batch 105/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 90/300 batch 106/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 90/300 batch 107/188  Train Loss: 0.067, Acc: 0.980\n",
      "epoch: 90/300 batch 108/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 90/300 batch 109/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 90/300 batch 110/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 90/300 batch 111/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 90/300 batch 112/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 90/300 batch 113/188  Train Loss: 0.048, Acc: 0.980\n",
      "epoch: 90/300 batch 114/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 90/300 batch 115/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 90/300 batch 116/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 90/300 batch 117/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 90/300 batch 118/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 90/300 batch 119/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 90/300 batch 120/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 90/300 batch 121/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 90/300 batch 122/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 90/300 batch 123/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 90/300 batch 124/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 90/300 batch 125/188  Train Loss: 0.063, Acc: 0.980\n",
      "epoch: 90/300 batch 126/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 90/300 batch 127/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 90/300 batch 128/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 90/300 batch 129/188  Train Loss: 0.048, Acc: 0.980\n",
      "epoch: 90/300 batch 130/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 90/300 batch 131/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 90/300 batch 132/188  Train Loss: 0.070, Acc: 0.973\n",
      "epoch: 90/300 batch 133/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 90/300 batch 134/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 90/300 batch 135/188  Train Loss: 0.038, Acc: 0.980\n",
      "epoch: 90/300 batch 136/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 90/300 batch 137/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 90/300 batch 138/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 90/300 batch 139/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 90/300 batch 140/188  Train Loss: 0.078, Acc: 0.984\n",
      "epoch: 90/300 batch 141/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 90/300 batch 142/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 90/300 batch 143/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 90/300 batch 144/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 90/300 batch 145/188  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 90/300 batch 146/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 90/300 batch 147/188  Train Loss: 0.058, Acc: 0.977\n",
      "epoch: 90/300 batch 148/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 90/300 batch 149/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 90/300 batch 150/188  Train Loss: 0.015, Acc: 0.996\n",
      "epoch: 90/300 batch 151/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 90/300 batch 152/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 90/300 batch 153/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 90/300 batch 154/188  Train Loss: 0.090, Acc: 0.977\n",
      "epoch: 90/300 batch 155/188  Train Loss: 0.056, Acc: 0.992\n",
      "epoch: 90/300 batch 156/188  Train Loss: 0.059, Acc: 0.977\n",
      "epoch: 90/300 batch 157/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 90/300 batch 158/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 90/300 batch 159/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 90/300 batch 160/188  Train Loss: 0.063, Acc: 0.980\n",
      "epoch: 90/300 batch 161/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 90/300 batch 162/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 90/300 batch 163/188  Train Loss: 0.045, Acc: 0.996\n",
      "epoch: 90/300 batch 164/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 90/300 batch 165/188  Train Loss: 0.060, Acc: 0.984\n",
      "epoch: 90/300 batch 166/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 90/300 batch 167/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 90/300 batch 168/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 90/300 batch 169/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 90/300 batch 170/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 90/300 batch 171/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 90/300 batch 172/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 90/300 batch 173/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 90/300 batch 174/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 90/300 batch 175/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 90/300 batch 176/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 90/300 batch 177/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 90/300 batch 178/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 90/300 batch 179/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 90/300 batch 180/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 90/300 batch 181/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 90/300 batch 182/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 90/300 batch 183/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 90/300 batch 184/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 90/300 batch 185/188  Train Loss: 0.054, Acc: 0.980\n",
      "epoch: 90/300 batch 186/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 90/300 batch 187/188  Train Loss: 0.016, Acc: 1.000\n",
      "Train Loss: 0.035477, Acc: 0.992\n",
      "Val Loss: 0.057738, Acc: 0.982\n",
      "epoch: 91/300 batch   0/188  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 91/300 batch   1/188  Train Loss: 0.022, Acc: 0.988\n",
      "epoch: 91/300 batch   2/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 91/300 batch   3/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 91/300 batch   4/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 91/300 batch   5/188  Train Loss: 0.055, Acc: 0.992\n",
      "epoch: 91/300 batch   6/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 91/300 batch   7/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 91/300 batch   8/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 91/300 batch   9/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 91/300 batch  10/188  Train Loss: 0.055, Acc: 0.980\n",
      "epoch: 91/300 batch  11/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 91/300 batch  12/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 91/300 batch  13/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 91/300 batch  14/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 91/300 batch  15/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 91/300 batch  16/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 91/300 batch  17/188  Train Loss: 0.066, Acc: 0.980\n",
      "epoch: 91/300 batch  18/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 91/300 batch  19/188  Train Loss: 0.044, Acc: 0.980\n",
      "epoch: 91/300 batch  20/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 91/300 batch  21/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 91/300 batch  22/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 91/300 batch  23/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 91/300 batch  24/188  Train Loss: 0.059, Acc: 0.988\n",
      "epoch: 91/300 batch  25/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 91/300 batch  26/188  Train Loss: 0.054, Acc: 0.980\n",
      "epoch: 91/300 batch  27/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 91/300 batch  28/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 91/300 batch  29/188  Train Loss: 0.061, Acc: 0.988\n",
      "epoch: 91/300 batch  30/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 91/300 batch  31/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 91/300 batch  32/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 91/300 batch  33/188  Train Loss: 0.033, Acc: 1.000\n",
      "epoch: 91/300 batch  34/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 91/300 batch  35/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 91/300 batch  36/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 91/300 batch  37/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 91/300 batch  38/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 91/300 batch  39/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 91/300 batch  40/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 91/300 batch  41/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 91/300 batch  42/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 91/300 batch  43/188  Train Loss: 0.047, Acc: 0.980\n",
      "epoch: 91/300 batch  44/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 91/300 batch  45/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 91/300 batch  46/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 91/300 batch  47/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 91/300 batch  48/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 91/300 batch  49/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 91/300 batch  50/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 91/300 batch  51/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 91/300 batch  52/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 91/300 batch  53/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 91/300 batch  54/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 91/300 batch  55/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 91/300 batch  56/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 91/300 batch  57/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 91/300 batch  58/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 91/300 batch  59/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 91/300 batch  60/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 91/300 batch  61/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 91/300 batch  62/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 91/300 batch  63/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 91/300 batch  64/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 91/300 batch  65/188  Train Loss: 0.054, Acc: 0.980\n",
      "epoch: 91/300 batch  66/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 91/300 batch  67/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 91/300 batch  68/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 91/300 batch  69/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 91/300 batch  70/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 91/300 batch  71/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 91/300 batch  72/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 91/300 batch  73/188  Train Loss: 0.059, Acc: 0.988\n",
      "epoch: 91/300 batch  74/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 91/300 batch  75/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 91/300 batch  76/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 91/300 batch  77/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 91/300 batch  78/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 91/300 batch  79/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 91/300 batch  80/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 91/300 batch  81/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 91/300 batch  82/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 91/300 batch  83/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 91/300 batch  84/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 91/300 batch  85/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 91/300 batch  86/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 91/300 batch  87/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 91/300 batch  88/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 91/300 batch  89/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 91/300 batch  90/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 91/300 batch  91/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 91/300 batch  92/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 91/300 batch  93/188  Train Loss: 0.026, Acc: 0.988\n",
      "epoch: 91/300 batch  94/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 91/300 batch  95/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 91/300 batch  96/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 91/300 batch  97/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 91/300 batch  98/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 91/300 batch  99/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 91/300 batch 100/188  Train Loss: 0.062, Acc: 0.988\n",
      "epoch: 91/300 batch 101/188  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 91/300 batch 102/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 91/300 batch 103/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 91/300 batch 104/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 91/300 batch 105/188  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 91/300 batch 106/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 91/300 batch 107/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 91/300 batch 108/188  Train Loss: 0.046, Acc: 0.980\n",
      "epoch: 91/300 batch 109/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 91/300 batch 110/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 91/300 batch 111/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 91/300 batch 112/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 91/300 batch 113/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 91/300 batch 114/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 91/300 batch 115/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 91/300 batch 116/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 91/300 batch 117/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 91/300 batch 118/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 91/300 batch 119/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 91/300 batch 120/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 91/300 batch 121/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 91/300 batch 122/188  Train Loss: 0.054, Acc: 0.992\n",
      "epoch: 91/300 batch 123/188  Train Loss: 0.015, Acc: 0.996\n",
      "epoch: 91/300 batch 124/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 91/300 batch 125/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 91/300 batch 126/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 91/300 batch 127/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 91/300 batch 128/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 91/300 batch 129/188  Train Loss: 0.033, Acc: 1.000\n",
      "epoch: 91/300 batch 130/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 91/300 batch 131/188  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 91/300 batch 132/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 91/300 batch 133/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 91/300 batch 134/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 91/300 batch 135/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 91/300 batch 136/188  Train Loss: 0.097, Acc: 0.988\n",
      "epoch: 91/300 batch 137/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 91/300 batch 138/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 91/300 batch 139/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 91/300 batch 140/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 91/300 batch 141/188  Train Loss: 0.071, Acc: 0.980\n",
      "epoch: 91/300 batch 142/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 91/300 batch 143/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 91/300 batch 144/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 91/300 batch 145/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 91/300 batch 146/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 91/300 batch 147/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 91/300 batch 148/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 91/300 batch 149/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 91/300 batch 150/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 91/300 batch 151/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 91/300 batch 152/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 91/300 batch 153/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 91/300 batch 154/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 91/300 batch 155/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 91/300 batch 156/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 91/300 batch 157/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 91/300 batch 158/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 91/300 batch 159/188  Train Loss: 0.057, Acc: 0.988\n",
      "epoch: 91/300 batch 160/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 91/300 batch 161/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 91/300 batch 162/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 91/300 batch 163/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 91/300 batch 164/188  Train Loss: 0.058, Acc: 0.988\n",
      "epoch: 91/300 batch 165/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 91/300 batch 166/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 91/300 batch 167/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 91/300 batch 168/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 91/300 batch 169/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 91/300 batch 170/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 91/300 batch 171/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 91/300 batch 172/188  Train Loss: 0.059, Acc: 0.980\n",
      "epoch: 91/300 batch 173/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 91/300 batch 174/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 91/300 batch 175/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 91/300 batch 176/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 91/300 batch 177/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 91/300 batch 178/188  Train Loss: 0.049, Acc: 0.980\n",
      "epoch: 91/300 batch 179/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 91/300 batch 180/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 91/300 batch 181/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 91/300 batch 182/188  Train Loss: 0.061, Acc: 0.988\n",
      "epoch: 91/300 batch 183/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 91/300 batch 184/188  Train Loss: 0.059, Acc: 0.973\n",
      "epoch: 91/300 batch 185/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 91/300 batch 186/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 91/300 batch 187/188  Train Loss: 0.022, Acc: 0.992\n",
      "Train Loss: 0.035557, Acc: 0.992\n",
      "Val Loss: 0.057608, Acc: 0.983\n",
      "epoch: 92/300 batch   0/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 92/300 batch   1/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 92/300 batch   2/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 92/300 batch   3/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 92/300 batch   4/188  Train Loss: 0.062, Acc: 0.984\n",
      "epoch: 92/300 batch   5/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 92/300 batch   6/188  Train Loss: 0.057, Acc: 0.988\n",
      "epoch: 92/300 batch   7/188  Train Loss: 0.077, Acc: 0.984\n",
      "epoch: 92/300 batch   8/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 92/300 batch   9/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 92/300 batch  10/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 92/300 batch  11/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 92/300 batch  12/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 92/300 batch  13/188  Train Loss: 0.045, Acc: 0.996\n",
      "epoch: 92/300 batch  14/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 92/300 batch  15/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 92/300 batch  16/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 92/300 batch  17/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 92/300 batch  18/188  Train Loss: 0.053, Acc: 0.992\n",
      "epoch: 92/300 batch  19/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 92/300 batch  20/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 92/300 batch  21/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 92/300 batch  22/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 92/300 batch  23/188  Train Loss: 0.060, Acc: 0.980\n",
      "epoch: 92/300 batch  24/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 92/300 batch  25/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 92/300 batch  26/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 92/300 batch  27/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 92/300 batch  28/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 92/300 batch  29/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 92/300 batch  30/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 92/300 batch  31/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 92/300 batch  32/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 92/300 batch  33/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 92/300 batch  34/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 92/300 batch  35/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 92/300 batch  36/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 92/300 batch  37/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 92/300 batch  38/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 92/300 batch  39/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 92/300 batch  40/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 92/300 batch  41/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 92/300 batch  42/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 92/300 batch  43/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 92/300 batch  44/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 92/300 batch  45/188  Train Loss: 0.032, Acc: 1.000\n",
      "epoch: 92/300 batch  46/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 92/300 batch  47/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 92/300 batch  48/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 92/300 batch  49/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 92/300 batch  50/188  Train Loss: 0.066, Acc: 0.992\n",
      "epoch: 92/300 batch  51/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 92/300 batch  52/188  Train Loss: 0.052, Acc: 0.980\n",
      "epoch: 92/300 batch  53/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 92/300 batch  54/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 92/300 batch  55/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 92/300 batch  56/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 92/300 batch  57/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 92/300 batch  58/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 92/300 batch  59/188  Train Loss: 0.049, Acc: 0.980\n",
      "epoch: 92/300 batch  60/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 92/300 batch  61/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 92/300 batch  62/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 92/300 batch  63/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 92/300 batch  64/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 92/300 batch  65/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 92/300 batch  66/188  Train Loss: 0.066, Acc: 0.984\n",
      "epoch: 92/300 batch  67/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 92/300 batch  68/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 92/300 batch  69/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 92/300 batch  70/188  Train Loss: 0.034, Acc: 0.984\n",
      "epoch: 92/300 batch  71/188  Train Loss: 0.043, Acc: 0.996\n",
      "epoch: 92/300 batch  72/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 92/300 batch  73/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 92/300 batch  74/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 92/300 batch  75/188  Train Loss: 0.056, Acc: 0.988\n",
      "epoch: 92/300 batch  76/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 92/300 batch  77/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 92/300 batch  78/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 92/300 batch  79/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 92/300 batch  80/188  Train Loss: 0.059, Acc: 0.977\n",
      "epoch: 92/300 batch  81/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 92/300 batch  82/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 92/300 batch  83/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 92/300 batch  84/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 92/300 batch  85/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 92/300 batch  86/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 92/300 batch  87/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 92/300 batch  88/188  Train Loss: 0.064, Acc: 0.980\n",
      "epoch: 92/300 batch  89/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 92/300 batch  90/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 92/300 batch  91/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 92/300 batch  92/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 92/300 batch  93/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 92/300 batch  94/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 92/300 batch  95/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 92/300 batch  96/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 92/300 batch  97/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 92/300 batch  98/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 92/300 batch  99/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 92/300 batch 100/188  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 92/300 batch 101/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 92/300 batch 102/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 92/300 batch 103/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 92/300 batch 104/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 92/300 batch 105/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 92/300 batch 106/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 92/300 batch 107/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 92/300 batch 108/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 92/300 batch 109/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 92/300 batch 110/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 92/300 batch 111/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 92/300 batch 112/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 92/300 batch 113/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 92/300 batch 114/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 92/300 batch 115/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 92/300 batch 116/188  Train Loss: 0.046, Acc: 0.996\n",
      "epoch: 92/300 batch 117/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 92/300 batch 118/188  Train Loss: 0.054, Acc: 0.977\n",
      "epoch: 92/300 batch 119/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 92/300 batch 120/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 92/300 batch 121/188  Train Loss: 0.060, Acc: 0.988\n",
      "epoch: 92/300 batch 122/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 92/300 batch 123/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 92/300 batch 124/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 92/300 batch 125/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 92/300 batch 126/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 92/300 batch 127/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 92/300 batch 128/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 92/300 batch 129/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 92/300 batch 130/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 92/300 batch 131/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 92/300 batch 132/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 92/300 batch 133/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 92/300 batch 134/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 92/300 batch 135/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 92/300 batch 136/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 92/300 batch 137/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 92/300 batch 138/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 92/300 batch 139/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 92/300 batch 140/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 92/300 batch 141/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 92/300 batch 142/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 92/300 batch 143/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 92/300 batch 144/188  Train Loss: 0.043, Acc: 0.996\n",
      "epoch: 92/300 batch 145/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 92/300 batch 146/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 92/300 batch 147/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 92/300 batch 148/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 92/300 batch 149/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 92/300 batch 150/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 92/300 batch 151/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 92/300 batch 152/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 92/300 batch 153/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 92/300 batch 154/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 92/300 batch 155/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 92/300 batch 156/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 92/300 batch 157/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 92/300 batch 158/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 92/300 batch 159/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 92/300 batch 160/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 92/300 batch 161/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 92/300 batch 162/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 92/300 batch 163/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 92/300 batch 164/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 92/300 batch 165/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 92/300 batch 166/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 92/300 batch 167/188  Train Loss: 0.054, Acc: 0.977\n",
      "epoch: 92/300 batch 168/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 92/300 batch 169/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 92/300 batch 170/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 92/300 batch 171/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 92/300 batch 172/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 92/300 batch 173/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 92/300 batch 174/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 92/300 batch 175/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 92/300 batch 176/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 92/300 batch 177/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 92/300 batch 178/188  Train Loss: 0.031, Acc: 1.000\n",
      "epoch: 92/300 batch 179/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 92/300 batch 180/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 92/300 batch 181/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 92/300 batch 182/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 92/300 batch 183/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 92/300 batch 184/188  Train Loss: 0.058, Acc: 0.992\n",
      "epoch: 92/300 batch 185/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 92/300 batch 186/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 92/300 batch 187/188  Train Loss: 0.017, Acc: 1.000\n",
      "Train Loss: 0.035387, Acc: 0.992\n",
      "Val Loss: 0.057560, Acc: 0.983\n",
      "epoch: 93/300 batch   0/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 93/300 batch   1/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 93/300 batch   2/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 93/300 batch   3/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 93/300 batch   4/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 93/300 batch   5/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 93/300 batch   6/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 93/300 batch   7/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 93/300 batch   8/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 93/300 batch   9/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 93/300 batch  10/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 93/300 batch  11/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 93/300 batch  12/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 93/300 batch  13/188  Train Loss: 0.059, Acc: 0.984\n",
      "epoch: 93/300 batch  14/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 93/300 batch  15/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 93/300 batch  16/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 93/300 batch  17/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 93/300 batch  18/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 93/300 batch  19/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 93/300 batch  20/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 93/300 batch  21/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 93/300 batch  22/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 93/300 batch  23/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 93/300 batch  24/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 93/300 batch  25/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 93/300 batch  26/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 93/300 batch  27/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 93/300 batch  28/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 93/300 batch  29/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 93/300 batch  30/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 93/300 batch  31/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 93/300 batch  32/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 93/300 batch  33/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 93/300 batch  34/188  Train Loss: 0.060, Acc: 0.988\n",
      "epoch: 93/300 batch  35/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 93/300 batch  36/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 93/300 batch  37/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 93/300 batch  38/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 93/300 batch  39/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 93/300 batch  40/188  Train Loss: 0.068, Acc: 0.984\n",
      "epoch: 93/300 batch  41/188  Train Loss: 0.085, Acc: 0.980\n",
      "epoch: 93/300 batch  42/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 93/300 batch  43/188  Train Loss: 0.048, Acc: 0.996\n",
      "epoch: 93/300 batch  44/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 93/300 batch  45/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 93/300 batch  46/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 93/300 batch  47/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 93/300 batch  48/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 93/300 batch  49/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 93/300 batch  50/188  Train Loss: 0.062, Acc: 0.980\n",
      "epoch: 93/300 batch  51/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 93/300 batch  52/188  Train Loss: 0.056, Acc: 0.992\n",
      "epoch: 93/300 batch  53/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 93/300 batch  54/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 93/300 batch  55/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 93/300 batch  56/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 93/300 batch  57/188  Train Loss: 0.050, Acc: 0.980\n",
      "epoch: 93/300 batch  58/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 93/300 batch  59/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 93/300 batch  60/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 93/300 batch  61/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 93/300 batch  62/188  Train Loss: 0.050, Acc: 0.980\n",
      "epoch: 93/300 batch  63/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 93/300 batch  64/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 93/300 batch  65/188  Train Loss: 0.079, Acc: 0.977\n",
      "epoch: 93/300 batch  66/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 93/300 batch  67/188  Train Loss: 0.033, Acc: 1.000\n",
      "epoch: 93/300 batch  68/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 93/300 batch  69/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 93/300 batch  70/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 93/300 batch  71/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 93/300 batch  72/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 93/300 batch  73/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 93/300 batch  74/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 93/300 batch  75/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 93/300 batch  76/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 93/300 batch  77/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 93/300 batch  78/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 93/300 batch  79/188  Train Loss: 0.052, Acc: 0.992\n",
      "epoch: 93/300 batch  80/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 93/300 batch  81/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 93/300 batch  82/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 93/300 batch  83/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 93/300 batch  84/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 93/300 batch  85/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 93/300 batch  86/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 93/300 batch  87/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 93/300 batch  88/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 93/300 batch  89/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 93/300 batch  90/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 93/300 batch  91/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 93/300 batch  92/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 93/300 batch  93/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 93/300 batch  94/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 93/300 batch  95/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 93/300 batch  96/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 93/300 batch  97/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 93/300 batch  98/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 93/300 batch  99/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 93/300 batch 100/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 93/300 batch 101/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 93/300 batch 102/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 93/300 batch 103/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 93/300 batch 104/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 93/300 batch 105/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 93/300 batch 106/188  Train Loss: 0.070, Acc: 0.980\n",
      "epoch: 93/300 batch 107/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 93/300 batch 108/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 93/300 batch 109/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 93/300 batch 110/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 93/300 batch 111/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 93/300 batch 112/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 93/300 batch 113/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 93/300 batch 114/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 93/300 batch 115/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 93/300 batch 116/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 93/300 batch 117/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 93/300 batch 118/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 93/300 batch 119/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 93/300 batch 120/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 93/300 batch 121/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 93/300 batch 122/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 93/300 batch 123/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 93/300 batch 124/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 93/300 batch 125/188  Train Loss: 0.061, Acc: 0.977\n",
      "epoch: 93/300 batch 126/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 93/300 batch 127/188  Train Loss: 0.066, Acc: 0.973\n",
      "epoch: 93/300 batch 128/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 93/300 batch 129/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 93/300 batch 130/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 93/300 batch 131/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 93/300 batch 132/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 93/300 batch 133/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 93/300 batch 134/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 93/300 batch 135/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 93/300 batch 136/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 93/300 batch 137/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 93/300 batch 138/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 93/300 batch 139/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 93/300 batch 140/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 93/300 batch 141/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 93/300 batch 142/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 93/300 batch 143/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 93/300 batch 144/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 93/300 batch 145/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 93/300 batch 146/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 93/300 batch 147/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 93/300 batch 148/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 93/300 batch 149/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 93/300 batch 150/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 93/300 batch 151/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 93/300 batch 152/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 93/300 batch 153/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 93/300 batch 154/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 93/300 batch 155/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 93/300 batch 156/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 93/300 batch 157/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 93/300 batch 158/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 93/300 batch 159/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 93/300 batch 160/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 93/300 batch 161/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 93/300 batch 162/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 93/300 batch 163/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 93/300 batch 164/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 93/300 batch 165/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 93/300 batch 166/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 93/300 batch 167/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 93/300 batch 168/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 93/300 batch 169/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 93/300 batch 170/188  Train Loss: 0.061, Acc: 0.988\n",
      "epoch: 93/300 batch 171/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 93/300 batch 172/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 93/300 batch 173/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 93/300 batch 174/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 93/300 batch 175/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 93/300 batch 176/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 93/300 batch 177/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 93/300 batch 178/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 93/300 batch 179/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 93/300 batch 180/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 93/300 batch 181/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 93/300 batch 182/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 93/300 batch 183/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 93/300 batch 184/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 93/300 batch 185/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 93/300 batch 186/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 93/300 batch 187/188  Train Loss: 0.060, Acc: 0.992\n",
      "Train Loss: 0.035502, Acc: 0.992\n",
      "Val Loss: 0.058004, Acc: 0.982\n",
      "epoch: 94/300 batch   0/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 94/300 batch   1/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 94/300 batch   2/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 94/300 batch   3/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 94/300 batch   4/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 94/300 batch   5/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 94/300 batch   6/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 94/300 batch   7/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 94/300 batch   8/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 94/300 batch   9/188  Train Loss: 0.033, Acc: 1.000\n",
      "epoch: 94/300 batch  10/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 94/300 batch  11/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 94/300 batch  12/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 94/300 batch  13/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 94/300 batch  14/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 94/300 batch  15/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 94/300 batch  16/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 94/300 batch  17/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 94/300 batch  18/188  Train Loss: 0.078, Acc: 0.973\n",
      "epoch: 94/300 batch  19/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 94/300 batch  20/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 94/300 batch  21/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 94/300 batch  22/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 94/300 batch  23/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 94/300 batch  24/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 94/300 batch  25/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 94/300 batch  26/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 94/300 batch  27/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 94/300 batch  28/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 94/300 batch  29/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 94/300 batch  30/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 94/300 batch  31/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 94/300 batch  32/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 94/300 batch  33/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 94/300 batch  34/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 94/300 batch  35/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 94/300 batch  36/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 94/300 batch  37/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 94/300 batch  38/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 94/300 batch  39/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 94/300 batch  40/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 94/300 batch  41/188  Train Loss: 0.043, Acc: 0.980\n",
      "epoch: 94/300 batch  42/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 94/300 batch  43/188  Train Loss: 0.078, Acc: 0.980\n",
      "epoch: 94/300 batch  44/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 94/300 batch  45/188  Train Loss: 0.015, Acc: 0.996\n",
      "epoch: 94/300 batch  46/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 94/300 batch  47/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 94/300 batch  48/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 94/300 batch  49/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 94/300 batch  50/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 94/300 batch  51/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 94/300 batch  52/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 94/300 batch  53/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 94/300 batch  54/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 94/300 batch  55/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 94/300 batch  56/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 94/300 batch  57/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 94/300 batch  58/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 94/300 batch  59/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 94/300 batch  60/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 94/300 batch  61/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 94/300 batch  62/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 94/300 batch  63/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 94/300 batch  64/188  Train Loss: 0.067, Acc: 0.980\n",
      "epoch: 94/300 batch  65/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 94/300 batch  66/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 94/300 batch  67/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 94/300 batch  68/188  Train Loss: 0.079, Acc: 0.980\n",
      "epoch: 94/300 batch  69/188  Train Loss: 0.055, Acc: 0.980\n",
      "epoch: 94/300 batch  70/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 94/300 batch  71/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 94/300 batch  72/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 94/300 batch  73/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 94/300 batch  74/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 94/300 batch  75/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 94/300 batch  76/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 94/300 batch  77/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 94/300 batch  78/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 94/300 batch  79/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 94/300 batch  80/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 94/300 batch  81/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 94/300 batch  82/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 94/300 batch  83/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 94/300 batch  84/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 94/300 batch  85/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 94/300 batch  86/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 94/300 batch  87/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 94/300 batch  88/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 94/300 batch  89/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 94/300 batch  90/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 94/300 batch  91/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 94/300 batch  92/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 94/300 batch  93/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 94/300 batch  94/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 94/300 batch  95/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 94/300 batch  96/188  Train Loss: 0.026, Acc: 0.988\n",
      "epoch: 94/300 batch  97/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 94/300 batch  98/188  Train Loss: 0.048, Acc: 0.996\n",
      "epoch: 94/300 batch  99/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 94/300 batch 100/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 94/300 batch 101/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 94/300 batch 102/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 94/300 batch 103/188  Train Loss: 0.051, Acc: 0.980\n",
      "epoch: 94/300 batch 104/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 94/300 batch 105/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 94/300 batch 106/188  Train Loss: 0.054, Acc: 0.980\n",
      "epoch: 94/300 batch 107/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 94/300 batch 108/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 94/300 batch 109/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 94/300 batch 110/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 94/300 batch 111/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 94/300 batch 112/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 94/300 batch 113/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 94/300 batch 114/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 94/300 batch 115/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 94/300 batch 116/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 94/300 batch 117/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 94/300 batch 118/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 94/300 batch 119/188  Train Loss: 0.052, Acc: 0.992\n",
      "epoch: 94/300 batch 120/188  Train Loss: 0.084, Acc: 0.980\n",
      "epoch: 94/300 batch 121/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 94/300 batch 122/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 94/300 batch 123/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 94/300 batch 124/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 94/300 batch 125/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 94/300 batch 126/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 94/300 batch 127/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 94/300 batch 128/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 94/300 batch 129/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 94/300 batch 130/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 94/300 batch 131/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 94/300 batch 132/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 94/300 batch 133/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 94/300 batch 134/188  Train Loss: 0.067, Acc: 0.984\n",
      "epoch: 94/300 batch 135/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 94/300 batch 136/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 94/300 batch 137/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 94/300 batch 138/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 94/300 batch 139/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 94/300 batch 140/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 94/300 batch 141/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 94/300 batch 142/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 94/300 batch 143/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 94/300 batch 144/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 94/300 batch 145/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 94/300 batch 146/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 94/300 batch 147/188  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 94/300 batch 148/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 94/300 batch 149/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 94/300 batch 150/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 94/300 batch 151/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 94/300 batch 152/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 94/300 batch 153/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 94/300 batch 154/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 94/300 batch 155/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 94/300 batch 156/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 94/300 batch 157/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 94/300 batch 158/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 94/300 batch 159/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 94/300 batch 160/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 94/300 batch 161/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 94/300 batch 162/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 94/300 batch 163/188  Train Loss: 0.055, Acc: 0.992\n",
      "epoch: 94/300 batch 164/188  Train Loss: 0.053, Acc: 0.992\n",
      "epoch: 94/300 batch 165/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 94/300 batch 166/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 94/300 batch 167/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 94/300 batch 168/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 94/300 batch 169/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 94/300 batch 170/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 94/300 batch 171/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 94/300 batch 172/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 94/300 batch 173/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 94/300 batch 174/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 94/300 batch 175/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 94/300 batch 176/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 94/300 batch 177/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 94/300 batch 178/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 94/300 batch 179/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 94/300 batch 180/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 94/300 batch 181/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 94/300 batch 182/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 94/300 batch 183/188  Train Loss: 0.045, Acc: 0.996\n",
      "epoch: 94/300 batch 184/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 94/300 batch 185/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 94/300 batch 186/188  Train Loss: 0.070, Acc: 0.977\n",
      "epoch: 94/300 batch 187/188  Train Loss: 0.019, Acc: 1.000\n",
      "Train Loss: 0.035329, Acc: 0.992\n",
      "Val Loss: 0.057733, Acc: 0.982\n",
      "epoch: 95/300 batch   0/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 95/300 batch   1/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 95/300 batch   2/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 95/300 batch   3/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 95/300 batch   4/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 95/300 batch   5/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 95/300 batch   6/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 95/300 batch   7/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 95/300 batch   8/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 95/300 batch   9/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 95/300 batch  10/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 95/300 batch  11/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 95/300 batch  12/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 95/300 batch  13/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 95/300 batch  14/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 95/300 batch  15/188  Train Loss: 0.054, Acc: 0.980\n",
      "epoch: 95/300 batch  16/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 95/300 batch  17/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 95/300 batch  18/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 95/300 batch  19/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 95/300 batch  20/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 95/300 batch  21/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 95/300 batch  22/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 95/300 batch  23/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 95/300 batch  24/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 95/300 batch  25/188  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 95/300 batch  26/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 95/300 batch  27/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 95/300 batch  28/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 95/300 batch  29/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 95/300 batch  30/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 95/300 batch  31/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 95/300 batch  32/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 95/300 batch  33/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 95/300 batch  34/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 95/300 batch  35/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 95/300 batch  36/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 95/300 batch  37/188  Train Loss: 0.045, Acc: 0.980\n",
      "epoch: 95/300 batch  38/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 95/300 batch  39/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 95/300 batch  40/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 95/300 batch  41/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 95/300 batch  42/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 95/300 batch  43/188  Train Loss: 0.072, Acc: 0.973\n",
      "epoch: 95/300 batch  44/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 95/300 batch  45/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 95/300 batch  46/188  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 95/300 batch  47/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 95/300 batch  48/188  Train Loss: 0.063, Acc: 0.996\n",
      "epoch: 95/300 batch  49/188  Train Loss: 0.059, Acc: 0.980\n",
      "epoch: 95/300 batch  50/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 95/300 batch  51/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 95/300 batch  52/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 95/300 batch  53/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 95/300 batch  54/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 95/300 batch  55/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 95/300 batch  56/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 95/300 batch  57/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 95/300 batch  58/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 95/300 batch  59/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 95/300 batch  60/188  Train Loss: 0.027, Acc: 0.988\n",
      "epoch: 95/300 batch  61/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 95/300 batch  62/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 95/300 batch  63/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 95/300 batch  64/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 95/300 batch  65/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 95/300 batch  66/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 95/300 batch  67/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 95/300 batch  68/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 95/300 batch  69/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 95/300 batch  70/188  Train Loss: 0.042, Acc: 0.996\n",
      "epoch: 95/300 batch  71/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 95/300 batch  72/188  Train Loss: 0.043, Acc: 0.980\n",
      "epoch: 95/300 batch  73/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 95/300 batch  74/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 95/300 batch  75/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 95/300 batch  76/188  Train Loss: 0.069, Acc: 0.984\n",
      "epoch: 95/300 batch  77/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 95/300 batch  78/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 95/300 batch  79/188  Train Loss: 0.032, Acc: 0.984\n",
      "epoch: 95/300 batch  80/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 95/300 batch  81/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 95/300 batch  82/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 95/300 batch  83/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 95/300 batch  84/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 95/300 batch  85/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 95/300 batch  86/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 95/300 batch  87/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 95/300 batch  88/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 95/300 batch  89/188  Train Loss: 0.062, Acc: 0.980\n",
      "epoch: 95/300 batch  90/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 95/300 batch  91/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 95/300 batch  92/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 95/300 batch  93/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 95/300 batch  94/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 95/300 batch  95/188  Train Loss: 0.041, Acc: 0.980\n",
      "epoch: 95/300 batch  96/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 95/300 batch  97/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 95/300 batch  98/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 95/300 batch  99/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 95/300 batch 100/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 95/300 batch 101/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 95/300 batch 102/188  Train Loss: 0.062, Acc: 0.984\n",
      "epoch: 95/300 batch 103/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 95/300 batch 104/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 95/300 batch 105/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 95/300 batch 106/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 95/300 batch 107/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 95/300 batch 108/188  Train Loss: 0.064, Acc: 0.977\n",
      "epoch: 95/300 batch 109/188  Train Loss: 0.045, Acc: 0.996\n",
      "epoch: 95/300 batch 110/188  Train Loss: 0.060, Acc: 0.984\n",
      "epoch: 95/300 batch 111/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 95/300 batch 112/188  Train Loss: 0.060, Acc: 0.984\n",
      "epoch: 95/300 batch 113/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 95/300 batch 114/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 95/300 batch 115/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 95/300 batch 116/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 95/300 batch 117/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 95/300 batch 118/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 95/300 batch 119/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 95/300 batch 120/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 95/300 batch 121/188  Train Loss: 0.058, Acc: 0.988\n",
      "epoch: 95/300 batch 122/188  Train Loss: 0.057, Acc: 0.992\n",
      "epoch: 95/300 batch 123/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 95/300 batch 124/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 95/300 batch 125/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 95/300 batch 126/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 95/300 batch 127/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 95/300 batch 128/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 95/300 batch 129/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 95/300 batch 130/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 95/300 batch 131/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 95/300 batch 132/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 95/300 batch 133/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 95/300 batch 134/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 95/300 batch 135/188  Train Loss: 0.061, Acc: 0.992\n",
      "epoch: 95/300 batch 136/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 95/300 batch 137/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 95/300 batch 138/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 95/300 batch 139/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 95/300 batch 140/188  Train Loss: 0.046, Acc: 0.996\n",
      "epoch: 95/300 batch 141/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 95/300 batch 142/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 95/300 batch 143/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 95/300 batch 144/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 95/300 batch 145/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 95/300 batch 146/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 95/300 batch 147/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 95/300 batch 148/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 95/300 batch 149/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 95/300 batch 150/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 95/300 batch 151/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 95/300 batch 152/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 95/300 batch 153/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 95/300 batch 154/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 95/300 batch 155/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 95/300 batch 156/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 95/300 batch 157/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 95/300 batch 158/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 95/300 batch 159/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 95/300 batch 160/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 95/300 batch 161/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 95/300 batch 162/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 95/300 batch 163/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 95/300 batch 164/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 95/300 batch 165/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 95/300 batch 166/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 95/300 batch 167/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 95/300 batch 168/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 95/300 batch 169/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 95/300 batch 170/188  Train Loss: 0.049, Acc: 0.977\n",
      "epoch: 95/300 batch 171/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 95/300 batch 172/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 95/300 batch 173/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 95/300 batch 174/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 95/300 batch 175/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 95/300 batch 176/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 95/300 batch 177/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 95/300 batch 178/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 95/300 batch 179/188  Train Loss: 0.057, Acc: 0.980\n",
      "epoch: 95/300 batch 180/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 95/300 batch 181/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 95/300 batch 182/188  Train Loss: 0.031, Acc: 0.984\n",
      "epoch: 95/300 batch 183/188  Train Loss: 0.033, Acc: 0.984\n",
      "epoch: 95/300 batch 184/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 95/300 batch 185/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 95/300 batch 186/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 95/300 batch 187/188  Train Loss: 0.035, Acc: 0.992\n",
      "Train Loss: 0.035358, Acc: 0.992\n",
      "Val Loss: 0.057589, Acc: 0.983\n",
      "epoch: 96/300 batch   0/188  Train Loss: 0.054, Acc: 0.980\n",
      "epoch: 96/300 batch   1/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 96/300 batch   2/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 96/300 batch   3/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 96/300 batch   4/188  Train Loss: 0.065, Acc: 0.984\n",
      "epoch: 96/300 batch   5/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 96/300 batch   6/188  Train Loss: 0.046, Acc: 0.980\n",
      "epoch: 96/300 batch   7/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 96/300 batch   8/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 96/300 batch   9/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 96/300 batch  10/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 96/300 batch  11/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 96/300 batch  12/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 96/300 batch  13/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 96/300 batch  14/188  Train Loss: 0.066, Acc: 0.980\n",
      "epoch: 96/300 batch  15/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 96/300 batch  16/188  Train Loss: 0.044, Acc: 0.980\n",
      "epoch: 96/300 batch  17/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 96/300 batch  18/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 96/300 batch  19/188  Train Loss: 0.057, Acc: 0.980\n",
      "epoch: 96/300 batch  20/188  Train Loss: 0.061, Acc: 0.992\n",
      "epoch: 96/300 batch  21/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 96/300 batch  22/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 96/300 batch  23/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 96/300 batch  24/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 96/300 batch  25/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 96/300 batch  26/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 96/300 batch  27/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 96/300 batch  28/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 96/300 batch  29/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 96/300 batch  30/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 96/300 batch  31/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 96/300 batch  32/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 96/300 batch  33/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 96/300 batch  34/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 96/300 batch  35/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 96/300 batch  36/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 96/300 batch  37/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 96/300 batch  38/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 96/300 batch  39/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 96/300 batch  40/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 96/300 batch  41/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 96/300 batch  42/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 96/300 batch  43/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 96/300 batch  44/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 96/300 batch  45/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 96/300 batch  46/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 96/300 batch  47/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 96/300 batch  48/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 96/300 batch  49/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 96/300 batch  50/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 96/300 batch  51/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 96/300 batch  52/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 96/300 batch  53/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 96/300 batch  54/188  Train Loss: 0.064, Acc: 0.984\n",
      "epoch: 96/300 batch  55/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 96/300 batch  56/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 96/300 batch  57/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 96/300 batch  58/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 96/300 batch  59/188  Train Loss: 0.065, Acc: 0.980\n",
      "epoch: 96/300 batch  60/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 96/300 batch  61/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 96/300 batch  62/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 96/300 batch  63/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 96/300 batch  64/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 96/300 batch  65/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 96/300 batch  66/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 96/300 batch  67/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 96/300 batch  68/188  Train Loss: 0.051, Acc: 0.996\n",
      "epoch: 96/300 batch  69/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 96/300 batch  70/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 96/300 batch  71/188  Train Loss: 0.057, Acc: 0.980\n",
      "epoch: 96/300 batch  72/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 96/300 batch  73/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 96/300 batch  74/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 96/300 batch  75/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 96/300 batch  76/188  Train Loss: 0.053, Acc: 0.980\n",
      "epoch: 96/300 batch  77/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 96/300 batch  78/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 96/300 batch  79/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 96/300 batch  80/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 96/300 batch  81/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 96/300 batch  82/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 96/300 batch  83/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 96/300 batch  84/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 96/300 batch  85/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 96/300 batch  86/188  Train Loss: 0.053, Acc: 0.992\n",
      "epoch: 96/300 batch  87/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 96/300 batch  88/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 96/300 batch  89/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 96/300 batch  90/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 96/300 batch  91/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 96/300 batch  92/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 96/300 batch  93/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 96/300 batch  94/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 96/300 batch  95/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 96/300 batch  96/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 96/300 batch  97/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 96/300 batch  98/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 96/300 batch  99/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 96/300 batch 100/188  Train Loss: 0.015, Acc: 0.996\n",
      "epoch: 96/300 batch 101/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 96/300 batch 102/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 96/300 batch 103/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 96/300 batch 104/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 96/300 batch 105/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 96/300 batch 106/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 96/300 batch 107/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 96/300 batch 108/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 96/300 batch 109/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 96/300 batch 110/188  Train Loss: 0.070, Acc: 0.977\n",
      "epoch: 96/300 batch 111/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 96/300 batch 112/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 96/300 batch 113/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 96/300 batch 114/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 96/300 batch 115/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 96/300 batch 116/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 96/300 batch 117/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 96/300 batch 118/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 96/300 batch 119/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 96/300 batch 120/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 96/300 batch 121/188  Train Loss: 0.050, Acc: 0.980\n",
      "epoch: 96/300 batch 122/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 96/300 batch 123/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 96/300 batch 124/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 96/300 batch 125/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 96/300 batch 126/188  Train Loss: 0.072, Acc: 0.984\n",
      "epoch: 96/300 batch 127/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 96/300 batch 128/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 96/300 batch 129/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 96/300 batch 130/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 96/300 batch 131/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 96/300 batch 132/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 96/300 batch 133/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 96/300 batch 134/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 96/300 batch 135/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 96/300 batch 136/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 96/300 batch 137/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 96/300 batch 138/188  Train Loss: 0.065, Acc: 0.980\n",
      "epoch: 96/300 batch 139/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 96/300 batch 140/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 96/300 batch 141/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 96/300 batch 142/188  Train Loss: 0.063, Acc: 0.980\n",
      "epoch: 96/300 batch 143/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 96/300 batch 144/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 96/300 batch 145/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 96/300 batch 146/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 96/300 batch 147/188  Train Loss: 0.048, Acc: 0.977\n",
      "epoch: 96/300 batch 148/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 96/300 batch 149/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 96/300 batch 150/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 96/300 batch 151/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 96/300 batch 152/188  Train Loss: 0.059, Acc: 0.977\n",
      "epoch: 96/300 batch 153/188  Train Loss: 0.036, Acc: 1.000\n",
      "epoch: 96/300 batch 154/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 96/300 batch 155/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 96/300 batch 156/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 96/300 batch 157/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 96/300 batch 158/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 96/300 batch 159/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 96/300 batch 160/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 96/300 batch 161/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 96/300 batch 162/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 96/300 batch 163/188  Train Loss: 0.059, Acc: 0.977\n",
      "epoch: 96/300 batch 164/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 96/300 batch 165/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 96/300 batch 166/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 96/300 batch 167/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 96/300 batch 168/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 96/300 batch 169/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 96/300 batch 170/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 96/300 batch 171/188  Train Loss: 0.068, Acc: 0.980\n",
      "epoch: 96/300 batch 172/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 96/300 batch 173/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 96/300 batch 174/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 96/300 batch 175/188  Train Loss: 0.060, Acc: 0.988\n",
      "epoch: 96/300 batch 176/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 96/300 batch 177/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 96/300 batch 178/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 96/300 batch 179/188  Train Loss: 0.028, Acc: 0.984\n",
      "epoch: 96/300 batch 180/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 96/300 batch 181/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 96/300 batch 182/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 96/300 batch 183/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 96/300 batch 184/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 96/300 batch 185/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 96/300 batch 186/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 96/300 batch 187/188  Train Loss: 0.040, Acc: 0.992\n",
      "Train Loss: 0.035373, Acc: 0.992\n",
      "Val Loss: 0.057628, Acc: 0.983\n",
      "epoch: 97/300 batch   0/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 97/300 batch   1/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 97/300 batch   2/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 97/300 batch   3/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 97/300 batch   4/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 97/300 batch   5/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 97/300 batch   6/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 97/300 batch   7/188  Train Loss: 0.054, Acc: 0.992\n",
      "epoch: 97/300 batch   8/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 97/300 batch   9/188  Train Loss: 0.016, Acc: 0.996\n",
      "epoch: 97/300 batch  10/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 97/300 batch  11/188  Train Loss: 0.025, Acc: 0.988\n",
      "epoch: 97/300 batch  12/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 97/300 batch  13/188  Train Loss: 0.059, Acc: 0.984\n",
      "epoch: 97/300 batch  14/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 97/300 batch  15/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 97/300 batch  16/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 97/300 batch  17/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 97/300 batch  18/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 97/300 batch  19/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 97/300 batch  20/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 97/300 batch  21/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 97/300 batch  22/188  Train Loss: 0.051, Acc: 0.996\n",
      "epoch: 97/300 batch  23/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 97/300 batch  24/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 97/300 batch  25/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 97/300 batch  26/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 97/300 batch  27/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 97/300 batch  28/188  Train Loss: 0.073, Acc: 0.980\n",
      "epoch: 97/300 batch  29/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 97/300 batch  30/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 97/300 batch  31/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 97/300 batch  32/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 97/300 batch  33/188  Train Loss: 0.026, Acc: 0.988\n",
      "epoch: 97/300 batch  34/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 97/300 batch  35/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 97/300 batch  36/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 97/300 batch  37/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 97/300 batch  38/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 97/300 batch  39/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 97/300 batch  40/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 97/300 batch  41/188  Train Loss: 0.075, Acc: 0.984\n",
      "epoch: 97/300 batch  42/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 97/300 batch  43/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 97/300 batch  44/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 97/300 batch  45/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 97/300 batch  46/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 97/300 batch  47/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 97/300 batch  48/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 97/300 batch  49/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 97/300 batch  50/188  Train Loss: 0.026, Acc: 0.988\n",
      "epoch: 97/300 batch  51/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 97/300 batch  52/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 97/300 batch  53/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 97/300 batch  54/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 97/300 batch  55/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 97/300 batch  56/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 97/300 batch  57/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 97/300 batch  58/188  Train Loss: 0.063, Acc: 0.980\n",
      "epoch: 97/300 batch  59/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 97/300 batch  60/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 97/300 batch  61/188  Train Loss: 0.058, Acc: 0.988\n",
      "epoch: 97/300 batch  62/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 97/300 batch  63/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 97/300 batch  64/188  Train Loss: 0.061, Acc: 0.980\n",
      "epoch: 97/300 batch  65/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 97/300 batch  66/188  Train Loss: 0.063, Acc: 0.988\n",
      "epoch: 97/300 batch  67/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 97/300 batch  68/188  Train Loss: 0.055, Acc: 0.980\n",
      "epoch: 97/300 batch  69/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 97/300 batch  70/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 97/300 batch  71/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 97/300 batch  72/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 97/300 batch  73/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 97/300 batch  74/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 97/300 batch  75/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 97/300 batch  76/188  Train Loss: 0.072, Acc: 0.984\n",
      "epoch: 97/300 batch  77/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 97/300 batch  78/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 97/300 batch  79/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 97/300 batch  80/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 97/300 batch  81/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 97/300 batch  82/188  Train Loss: 0.048, Acc: 0.980\n",
      "epoch: 97/300 batch  83/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 97/300 batch  84/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 97/300 batch  85/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 97/300 batch  86/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 97/300 batch  87/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 97/300 batch  88/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 97/300 batch  89/188  Train Loss: 0.058, Acc: 0.977\n",
      "epoch: 97/300 batch  90/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 97/300 batch  91/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 97/300 batch  92/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 97/300 batch  93/188  Train Loss: 0.033, Acc: 1.000\n",
      "epoch: 97/300 batch  94/188  Train Loss: 0.064, Acc: 0.980\n",
      "epoch: 97/300 batch  95/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 97/300 batch  96/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 97/300 batch  97/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 97/300 batch  98/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 97/300 batch  99/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 97/300 batch 100/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 97/300 batch 101/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 97/300 batch 102/188  Train Loss: 0.055, Acc: 0.980\n",
      "epoch: 97/300 batch 103/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 97/300 batch 104/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 97/300 batch 105/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 97/300 batch 106/188  Train Loss: 0.042, Acc: 0.980\n",
      "epoch: 97/300 batch 107/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 97/300 batch 108/188  Train Loss: 0.056, Acc: 0.988\n",
      "epoch: 97/300 batch 109/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 97/300 batch 110/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 97/300 batch 111/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 97/300 batch 112/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 97/300 batch 113/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 97/300 batch 114/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 97/300 batch 115/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 97/300 batch 116/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 97/300 batch 117/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 97/300 batch 118/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 97/300 batch 119/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 97/300 batch 120/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 97/300 batch 121/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 97/300 batch 122/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 97/300 batch 123/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 97/300 batch 124/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 97/300 batch 125/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 97/300 batch 126/188  Train Loss: 0.051, Acc: 0.992\n",
      "epoch: 97/300 batch 127/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 97/300 batch 128/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 97/300 batch 129/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 97/300 batch 130/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 97/300 batch 131/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 97/300 batch 132/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 97/300 batch 133/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 97/300 batch 134/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 97/300 batch 135/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 97/300 batch 136/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 97/300 batch 137/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 97/300 batch 138/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 97/300 batch 139/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 97/300 batch 140/188  Train Loss: 0.061, Acc: 0.984\n",
      "epoch: 97/300 batch 141/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 97/300 batch 142/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 97/300 batch 143/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 97/300 batch 144/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 97/300 batch 145/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 97/300 batch 146/188  Train Loss: 0.047, Acc: 0.980\n",
      "epoch: 97/300 batch 147/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 97/300 batch 148/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 97/300 batch 149/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 97/300 batch 150/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 97/300 batch 151/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 97/300 batch 152/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 97/300 batch 153/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 97/300 batch 154/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 97/300 batch 155/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 97/300 batch 156/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 97/300 batch 157/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 97/300 batch 158/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 97/300 batch 159/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 97/300 batch 160/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 97/300 batch 161/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 97/300 batch 162/188  Train Loss: 0.028, Acc: 0.984\n",
      "epoch: 97/300 batch 163/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 97/300 batch 164/188  Train Loss: 0.069, Acc: 0.984\n",
      "epoch: 97/300 batch 165/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 97/300 batch 166/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 97/300 batch 167/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 97/300 batch 168/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 97/300 batch 169/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 97/300 batch 170/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 97/300 batch 171/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 97/300 batch 172/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 97/300 batch 173/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 97/300 batch 174/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 97/300 batch 175/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 97/300 batch 176/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 97/300 batch 177/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 97/300 batch 178/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 97/300 batch 179/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 97/300 batch 180/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 97/300 batch 181/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 97/300 batch 182/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 97/300 batch 183/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 97/300 batch 184/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 97/300 batch 185/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 97/300 batch 186/188  Train Loss: 0.052, Acc: 0.992\n",
      "epoch: 97/300 batch 187/188  Train Loss: 0.031, Acc: 0.992\n",
      "Train Loss: 0.035331, Acc: 0.992\n",
      "Val Loss: 0.057690, Acc: 0.982\n",
      "epoch: 98/300 batch   0/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 98/300 batch   1/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 98/300 batch   2/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 98/300 batch   3/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 98/300 batch   4/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 98/300 batch   5/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 98/300 batch   6/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 98/300 batch   7/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 98/300 batch   8/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 98/300 batch   9/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 98/300 batch  10/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 98/300 batch  11/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 98/300 batch  12/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 98/300 batch  13/188  Train Loss: 0.052, Acc: 0.977\n",
      "epoch: 98/300 batch  14/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 98/300 batch  15/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 98/300 batch  16/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 98/300 batch  17/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 98/300 batch  18/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 98/300 batch  19/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 98/300 batch  20/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 98/300 batch  21/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 98/300 batch  22/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 98/300 batch  23/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 98/300 batch  24/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 98/300 batch  25/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 98/300 batch  26/188  Train Loss: 0.050, Acc: 0.977\n",
      "epoch: 98/300 batch  27/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 98/300 batch  28/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 98/300 batch  29/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 98/300 batch  30/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 98/300 batch  31/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 98/300 batch  32/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 98/300 batch  33/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 98/300 batch  34/188  Train Loss: 0.053, Acc: 0.980\n",
      "epoch: 98/300 batch  35/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 98/300 batch  36/188  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 98/300 batch  37/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 98/300 batch  38/188  Train Loss: 0.055, Acc: 0.977\n",
      "epoch: 98/300 batch  39/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 98/300 batch  40/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 98/300 batch  41/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 98/300 batch  42/188  Train Loss: 0.068, Acc: 0.977\n",
      "epoch: 98/300 batch  43/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 98/300 batch  44/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 98/300 batch  45/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 98/300 batch  46/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 98/300 batch  47/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 98/300 batch  48/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 98/300 batch  49/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 98/300 batch  50/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 98/300 batch  51/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 98/300 batch  52/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 98/300 batch  53/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 98/300 batch  54/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 98/300 batch  55/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 98/300 batch  56/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 98/300 batch  57/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 98/300 batch  58/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 98/300 batch  59/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 98/300 batch  60/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 98/300 batch  61/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 98/300 batch  62/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 98/300 batch  63/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 98/300 batch  64/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 98/300 batch  65/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 98/300 batch  66/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 98/300 batch  67/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 98/300 batch  68/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 98/300 batch  69/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 98/300 batch  70/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 98/300 batch  71/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 98/300 batch  72/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 98/300 batch  73/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 98/300 batch  74/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 98/300 batch  75/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 98/300 batch  76/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 98/300 batch  77/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 98/300 batch  78/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 98/300 batch  79/188  Train Loss: 0.083, Acc: 0.980\n",
      "epoch: 98/300 batch  80/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 98/300 batch  81/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 98/300 batch  82/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 98/300 batch  83/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 98/300 batch  84/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 98/300 batch  85/188  Train Loss: 0.057, Acc: 0.988\n",
      "epoch: 98/300 batch  86/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 98/300 batch  87/188  Train Loss: 0.043, Acc: 0.996\n",
      "epoch: 98/300 batch  88/188  Train Loss: 0.032, Acc: 1.000\n",
      "epoch: 98/300 batch  89/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 98/300 batch  90/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 98/300 batch  91/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 98/300 batch  92/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 98/300 batch  93/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 98/300 batch  94/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 98/300 batch  95/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 98/300 batch  96/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 98/300 batch  97/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 98/300 batch  98/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 98/300 batch  99/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 98/300 batch 100/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 98/300 batch 101/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 98/300 batch 102/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 98/300 batch 103/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 98/300 batch 104/188  Train Loss: 0.032, Acc: 0.984\n",
      "epoch: 98/300 batch 105/188  Train Loss: 0.066, Acc: 0.980\n",
      "epoch: 98/300 batch 106/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 98/300 batch 107/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 98/300 batch 108/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 98/300 batch 109/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 98/300 batch 110/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 98/300 batch 111/188  Train Loss: 0.064, Acc: 0.977\n",
      "epoch: 98/300 batch 112/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 98/300 batch 113/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 98/300 batch 114/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 98/300 batch 115/188  Train Loss: 0.048, Acc: 0.980\n",
      "epoch: 98/300 batch 116/188  Train Loss: 0.043, Acc: 0.980\n",
      "epoch: 98/300 batch 117/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 98/300 batch 118/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 98/300 batch 119/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 98/300 batch 120/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 98/300 batch 121/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 98/300 batch 122/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 98/300 batch 123/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 98/300 batch 124/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 98/300 batch 125/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 98/300 batch 126/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 98/300 batch 127/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 98/300 batch 128/188  Train Loss: 0.062, Acc: 0.980\n",
      "epoch: 98/300 batch 129/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 98/300 batch 130/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 98/300 batch 131/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 98/300 batch 132/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 98/300 batch 133/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 98/300 batch 134/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 98/300 batch 135/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 98/300 batch 136/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 98/300 batch 137/188  Train Loss: 0.051, Acc: 0.980\n",
      "epoch: 98/300 batch 138/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 98/300 batch 139/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 98/300 batch 140/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 98/300 batch 141/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 98/300 batch 142/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 98/300 batch 143/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 98/300 batch 144/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 98/300 batch 145/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 98/300 batch 146/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 98/300 batch 147/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 98/300 batch 148/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 98/300 batch 149/188  Train Loss: 0.061, Acc: 0.984\n",
      "epoch: 98/300 batch 150/188  Train Loss: 0.015, Acc: 0.996\n",
      "epoch: 98/300 batch 151/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 98/300 batch 152/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 98/300 batch 153/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 98/300 batch 154/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 98/300 batch 155/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 98/300 batch 156/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 98/300 batch 157/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 98/300 batch 158/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 98/300 batch 159/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 98/300 batch 160/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 98/300 batch 161/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 98/300 batch 162/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 98/300 batch 163/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 98/300 batch 164/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 98/300 batch 165/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 98/300 batch 166/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 98/300 batch 167/188  Train Loss: 0.049, Acc: 0.980\n",
      "epoch: 98/300 batch 168/188  Train Loss: 0.066, Acc: 0.973\n",
      "epoch: 98/300 batch 169/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 98/300 batch 170/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 98/300 batch 171/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 98/300 batch 172/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 98/300 batch 173/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 98/300 batch 174/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 98/300 batch 175/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 98/300 batch 176/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 98/300 batch 177/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 98/300 batch 178/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 98/300 batch 179/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 98/300 batch 180/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 98/300 batch 181/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 98/300 batch 182/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 98/300 batch 183/188  Train Loss: 0.059, Acc: 0.992\n",
      "epoch: 98/300 batch 184/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 98/300 batch 185/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 98/300 batch 186/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 98/300 batch 187/188  Train Loss: 0.028, Acc: 1.000\n",
      "Train Loss: 0.035249, Acc: 0.992\n",
      "Val Loss: 0.057651, Acc: 0.982\n",
      "epoch: 99/300 batch   0/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 99/300 batch   1/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 99/300 batch   2/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 99/300 batch   3/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 99/300 batch   4/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 99/300 batch   5/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 99/300 batch   6/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 99/300 batch   7/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 99/300 batch   8/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 99/300 batch   9/188  Train Loss: 0.052, Acc: 0.992\n",
      "epoch: 99/300 batch  10/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 99/300 batch  11/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 99/300 batch  12/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 99/300 batch  13/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 99/300 batch  14/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 99/300 batch  15/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 99/300 batch  16/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 99/300 batch  17/188  Train Loss: 0.057, Acc: 0.988\n",
      "epoch: 99/300 batch  18/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 99/300 batch  19/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 99/300 batch  20/188  Train Loss: 0.047, Acc: 0.980\n",
      "epoch: 99/300 batch  21/188  Train Loss: 0.047, Acc: 0.980\n",
      "epoch: 99/300 batch  22/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 99/300 batch  23/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 99/300 batch  24/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 99/300 batch  25/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 99/300 batch  26/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 99/300 batch  27/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 99/300 batch  28/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 99/300 batch  29/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 99/300 batch  30/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 99/300 batch  31/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 99/300 batch  32/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 99/300 batch  33/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 99/300 batch  34/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 99/300 batch  35/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 99/300 batch  36/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 99/300 batch  37/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 99/300 batch  38/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 99/300 batch  39/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 99/300 batch  40/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 99/300 batch  41/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 99/300 batch  42/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 99/300 batch  43/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 99/300 batch  44/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 99/300 batch  45/188  Train Loss: 0.069, Acc: 0.984\n",
      "epoch: 99/300 batch  46/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 99/300 batch  47/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 99/300 batch  48/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 99/300 batch  49/188  Train Loss: 0.027, Acc: 0.988\n",
      "epoch: 99/300 batch  50/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 99/300 batch  51/188  Train Loss: 0.063, Acc: 0.988\n",
      "epoch: 99/300 batch  52/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 99/300 batch  53/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 99/300 batch  54/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 99/300 batch  55/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 99/300 batch  56/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 99/300 batch  57/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 99/300 batch  58/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 99/300 batch  59/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 99/300 batch  60/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 99/300 batch  61/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 99/300 batch  62/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 99/300 batch  63/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 99/300 batch  64/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 99/300 batch  65/188  Train Loss: 0.047, Acc: 0.996\n",
      "epoch: 99/300 batch  66/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 99/300 batch  67/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 99/300 batch  68/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 99/300 batch  69/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 99/300 batch  70/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 99/300 batch  71/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 99/300 batch  72/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 99/300 batch  73/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 99/300 batch  74/188  Train Loss: 0.075, Acc: 0.984\n",
      "epoch: 99/300 batch  75/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 99/300 batch  76/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 99/300 batch  77/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 99/300 batch  78/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 99/300 batch  79/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 99/300 batch  80/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 99/300 batch  81/188  Train Loss: 0.059, Acc: 0.984\n",
      "epoch: 99/300 batch  82/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 99/300 batch  83/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 99/300 batch  84/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 99/300 batch  85/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 99/300 batch  86/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 99/300 batch  87/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 99/300 batch  88/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 99/300 batch  89/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 99/300 batch  90/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 99/300 batch  91/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 99/300 batch  92/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 99/300 batch  93/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 99/300 batch  94/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 99/300 batch  95/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 99/300 batch  96/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 99/300 batch  97/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 99/300 batch  98/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 99/300 batch  99/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 99/300 batch 100/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 99/300 batch 101/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 99/300 batch 102/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 99/300 batch 103/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 99/300 batch 104/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 99/300 batch 105/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 99/300 batch 106/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 99/300 batch 107/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 99/300 batch 108/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 99/300 batch 109/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 99/300 batch 110/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 99/300 batch 111/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 99/300 batch 112/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 99/300 batch 113/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 99/300 batch 114/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 99/300 batch 115/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 99/300 batch 116/188  Train Loss: 0.016, Acc: 0.996\n",
      "epoch: 99/300 batch 117/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 99/300 batch 118/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 99/300 batch 119/188  Train Loss: 0.043, Acc: 0.996\n",
      "epoch: 99/300 batch 120/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 99/300 batch 121/188  Train Loss: 0.060, Acc: 0.984\n",
      "epoch: 99/300 batch 122/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 99/300 batch 123/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 99/300 batch 124/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 99/300 batch 125/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 99/300 batch 126/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 99/300 batch 127/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 99/300 batch 128/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 99/300 batch 129/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 99/300 batch 130/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 99/300 batch 131/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 99/300 batch 132/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 99/300 batch 133/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 99/300 batch 134/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 99/300 batch 135/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 99/300 batch 136/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 99/300 batch 137/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 99/300 batch 138/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 99/300 batch 139/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 99/300 batch 140/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 99/300 batch 141/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 99/300 batch 142/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 99/300 batch 143/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 99/300 batch 144/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 99/300 batch 145/188  Train Loss: 0.046, Acc: 0.996\n",
      "epoch: 99/300 batch 146/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 99/300 batch 147/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 99/300 batch 148/188  Train Loss: 0.068, Acc: 0.977\n",
      "epoch: 99/300 batch 149/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 99/300 batch 150/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 99/300 batch 151/188  Train Loss: 0.038, Acc: 0.980\n",
      "epoch: 99/300 batch 152/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 99/300 batch 153/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 99/300 batch 154/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 99/300 batch 155/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 99/300 batch 156/188  Train Loss: 0.059, Acc: 0.984\n",
      "epoch: 99/300 batch 157/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 99/300 batch 158/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 99/300 batch 159/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 99/300 batch 160/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 99/300 batch 161/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 99/300 batch 162/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 99/300 batch 163/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 99/300 batch 164/188  Train Loss: 0.059, Acc: 0.980\n",
      "epoch: 99/300 batch 165/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 99/300 batch 166/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 99/300 batch 167/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 99/300 batch 168/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 99/300 batch 169/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 99/300 batch 170/188  Train Loss: 0.047, Acc: 0.980\n",
      "epoch: 99/300 batch 171/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 99/300 batch 172/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 99/300 batch 173/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 99/300 batch 174/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 99/300 batch 175/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 99/300 batch 176/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 99/300 batch 177/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 99/300 batch 178/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 99/300 batch 179/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 99/300 batch 180/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 99/300 batch 181/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 99/300 batch 182/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 99/300 batch 183/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 99/300 batch 184/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 99/300 batch 185/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 99/300 batch 186/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 99/300 batch 187/188  Train Loss: 0.021, Acc: 1.000\n",
      "Train Loss: 0.035185, Acc: 0.992\n",
      "Val Loss: 0.057539, Acc: 0.982\n",
      "epoch: 100/300 batch   0/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 100/300 batch   1/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 100/300 batch   2/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 100/300 batch   3/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 100/300 batch   4/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 100/300 batch   5/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 100/300 batch   6/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 100/300 batch   7/188  Train Loss: 0.046, Acc: 0.980\n",
      "epoch: 100/300 batch   8/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 100/300 batch   9/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 100/300 batch  10/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 100/300 batch  11/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 100/300 batch  12/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 100/300 batch  13/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 100/300 batch  14/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 100/300 batch  15/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 100/300 batch  16/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 100/300 batch  17/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 100/300 batch  18/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 100/300 batch  19/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 100/300 batch  20/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 100/300 batch  21/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 100/300 batch  22/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 100/300 batch  23/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 100/300 batch  24/188  Train Loss: 0.051, Acc: 0.980\n",
      "epoch: 100/300 batch  25/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 100/300 batch  26/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 100/300 batch  27/188  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 100/300 batch  28/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 100/300 batch  29/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 100/300 batch  30/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 100/300 batch  31/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 100/300 batch  32/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 100/300 batch  33/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 100/300 batch  34/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 100/300 batch  35/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 100/300 batch  36/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 100/300 batch  37/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 100/300 batch  38/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 100/300 batch  39/188  Train Loss: 0.061, Acc: 0.984\n",
      "epoch: 100/300 batch  40/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 100/300 batch  41/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 100/300 batch  42/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 100/300 batch  43/188  Train Loss: 0.070, Acc: 0.984\n",
      "epoch: 100/300 batch  44/188  Train Loss: 0.026, Acc: 0.988\n",
      "epoch: 100/300 batch  45/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 100/300 batch  46/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 100/300 batch  47/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 100/300 batch  48/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 100/300 batch  49/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 100/300 batch  50/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 100/300 batch  51/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 100/300 batch  52/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 100/300 batch  53/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 100/300 batch  54/188  Train Loss: 0.027, Acc: 0.988\n",
      "epoch: 100/300 batch  55/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 100/300 batch  56/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 100/300 batch  57/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 100/300 batch  58/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 100/300 batch  59/188  Train Loss: 0.066, Acc: 0.984\n",
      "epoch: 100/300 batch  60/188  Train Loss: 0.032, Acc: 0.984\n",
      "epoch: 100/300 batch  61/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 100/300 batch  62/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 100/300 batch  63/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 100/300 batch  64/188  Train Loss: 0.058, Acc: 0.980\n",
      "epoch: 100/300 batch  65/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 100/300 batch  66/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 100/300 batch  67/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 100/300 batch  68/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 100/300 batch  69/188  Train Loss: 0.068, Acc: 0.988\n",
      "epoch: 100/300 batch  70/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 100/300 batch  71/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 100/300 batch  72/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 100/300 batch  73/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 100/300 batch  74/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 100/300 batch  75/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 100/300 batch  76/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 100/300 batch  77/188  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 100/300 batch  78/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 100/300 batch  79/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 100/300 batch  80/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 100/300 batch  81/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 100/300 batch  82/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 100/300 batch  83/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 100/300 batch  84/188  Train Loss: 0.026, Acc: 0.988\n",
      "epoch: 100/300 batch  85/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 100/300 batch  86/188  Train Loss: 0.057, Acc: 0.988\n",
      "epoch: 100/300 batch  87/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 100/300 batch  88/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 100/300 batch  89/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 100/300 batch  90/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 100/300 batch  91/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 100/300 batch  92/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 100/300 batch  93/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 100/300 batch  94/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 100/300 batch  95/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 100/300 batch  96/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 100/300 batch  97/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 100/300 batch  98/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 100/300 batch  99/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 100/300 batch 100/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 100/300 batch 101/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 100/300 batch 102/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 100/300 batch 103/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 100/300 batch 104/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 100/300 batch 105/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 100/300 batch 106/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 100/300 batch 107/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 100/300 batch 108/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 100/300 batch 109/188  Train Loss: 0.058, Acc: 0.988\n",
      "epoch: 100/300 batch 110/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 100/300 batch 111/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 100/300 batch 112/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 100/300 batch 113/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 100/300 batch 114/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 100/300 batch 115/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 100/300 batch 116/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 100/300 batch 117/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 100/300 batch 118/188  Train Loss: 0.051, Acc: 0.992\n",
      "epoch: 100/300 batch 119/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 100/300 batch 120/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 100/300 batch 121/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 100/300 batch 122/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 100/300 batch 123/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 100/300 batch 124/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 100/300 batch 125/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 100/300 batch 126/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 100/300 batch 127/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 100/300 batch 128/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 100/300 batch 129/188  Train Loss: 0.078, Acc: 0.977\n",
      "epoch: 100/300 batch 130/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 100/300 batch 131/188  Train Loss: 0.054, Acc: 0.980\n",
      "epoch: 100/300 batch 132/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 100/300 batch 133/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 100/300 batch 134/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 100/300 batch 135/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 100/300 batch 136/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 100/300 batch 137/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 100/300 batch 138/188  Train Loss: 0.053, Acc: 0.973\n",
      "epoch: 100/300 batch 139/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 100/300 batch 140/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 100/300 batch 141/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 100/300 batch 142/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 100/300 batch 143/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 100/300 batch 144/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 100/300 batch 145/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 100/300 batch 146/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 100/300 batch 147/188  Train Loss: 0.055, Acc: 0.980\n",
      "epoch: 100/300 batch 148/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 100/300 batch 149/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 100/300 batch 150/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 100/300 batch 151/188  Train Loss: 0.061, Acc: 0.977\n",
      "epoch: 100/300 batch 152/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 100/300 batch 153/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 100/300 batch 154/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 100/300 batch 155/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 100/300 batch 156/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 100/300 batch 157/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 100/300 batch 158/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 100/300 batch 159/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 100/300 batch 160/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 100/300 batch 161/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 100/300 batch 162/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 100/300 batch 163/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 100/300 batch 164/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 100/300 batch 165/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 100/300 batch 166/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 100/300 batch 167/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 100/300 batch 168/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 100/300 batch 169/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 100/300 batch 170/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 100/300 batch 171/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 100/300 batch 172/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 100/300 batch 173/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 100/300 batch 174/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 100/300 batch 175/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 100/300 batch 176/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 100/300 batch 177/188  Train Loss: 0.016, Acc: 0.996\n",
      "epoch: 100/300 batch 178/188  Train Loss: 0.059, Acc: 0.984\n",
      "epoch: 100/300 batch 179/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 100/300 batch 180/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 100/300 batch 181/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 100/300 batch 182/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 100/300 batch 183/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 100/300 batch 184/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 100/300 batch 185/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 100/300 batch 186/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 100/300 batch 187/188  Train Loss: 0.016, Acc: 1.000\n",
      "Train Loss: 0.035159, Acc: 0.992\n",
      "Val Loss: 0.057611, Acc: 0.982\n",
      "epoch: 101/300 batch   0/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 101/300 batch   1/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 101/300 batch   2/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 101/300 batch   3/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 101/300 batch   4/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 101/300 batch   5/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 101/300 batch   6/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 101/300 batch   7/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 101/300 batch   8/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 101/300 batch   9/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 101/300 batch  10/188  Train Loss: 0.043, Acc: 0.996\n",
      "epoch: 101/300 batch  11/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 101/300 batch  12/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 101/300 batch  13/188  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 101/300 batch  14/188  Train Loss: 0.043, Acc: 0.980\n",
      "epoch: 101/300 batch  15/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 101/300 batch  16/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 101/300 batch  17/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 101/300 batch  18/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 101/300 batch  19/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 101/300 batch  20/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 101/300 batch  21/188  Train Loss: 0.026, Acc: 0.988\n",
      "epoch: 101/300 batch  22/188  Train Loss: 0.046, Acc: 0.996\n",
      "epoch: 101/300 batch  23/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 101/300 batch  24/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 101/300 batch  25/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 101/300 batch  26/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 101/300 batch  27/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 101/300 batch  28/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 101/300 batch  29/188  Train Loss: 0.077, Acc: 0.988\n",
      "epoch: 101/300 batch  30/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 101/300 batch  31/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 101/300 batch  32/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 101/300 batch  33/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 101/300 batch  34/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 101/300 batch  35/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 101/300 batch  36/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 101/300 batch  37/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 101/300 batch  38/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 101/300 batch  39/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 101/300 batch  40/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 101/300 batch  41/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 101/300 batch  42/188  Train Loss: 0.066, Acc: 0.984\n",
      "epoch: 101/300 batch  43/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 101/300 batch  44/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 101/300 batch  45/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 101/300 batch  46/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 101/300 batch  47/188  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 101/300 batch  48/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 101/300 batch  49/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 101/300 batch  50/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 101/300 batch  51/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 101/300 batch  52/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 101/300 batch  53/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 101/300 batch  54/188  Train Loss: 0.052, Acc: 0.980\n",
      "epoch: 101/300 batch  55/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 101/300 batch  56/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 101/300 batch  57/188  Train Loss: 0.058, Acc: 0.980\n",
      "epoch: 101/300 batch  58/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 101/300 batch  59/188  Train Loss: 0.046, Acc: 0.996\n",
      "epoch: 101/300 batch  60/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 101/300 batch  61/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 101/300 batch  62/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 101/300 batch  63/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 101/300 batch  64/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 101/300 batch  65/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 101/300 batch  66/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 101/300 batch  67/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 101/300 batch  68/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 101/300 batch  69/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 101/300 batch  70/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 101/300 batch  71/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 101/300 batch  72/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 101/300 batch  73/188  Train Loss: 0.041, Acc: 0.980\n",
      "epoch: 101/300 batch  74/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 101/300 batch  75/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 101/300 batch  76/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 101/300 batch  77/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 101/300 batch  78/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 101/300 batch  79/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 101/300 batch  80/188  Train Loss: 0.066, Acc: 0.980\n",
      "epoch: 101/300 batch  81/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 101/300 batch  82/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 101/300 batch  83/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 101/300 batch  84/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 101/300 batch  85/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 101/300 batch  86/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 101/300 batch  87/188  Train Loss: 0.042, Acc: 0.996\n",
      "epoch: 101/300 batch  88/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 101/300 batch  89/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 101/300 batch  90/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 101/300 batch  91/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 101/300 batch  92/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 101/300 batch  93/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 101/300 batch  94/188  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 101/300 batch  95/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 101/300 batch  96/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 101/300 batch  97/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 101/300 batch  98/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 101/300 batch  99/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 101/300 batch 100/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 101/300 batch 101/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 101/300 batch 102/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 101/300 batch 103/188  Train Loss: 0.047, Acc: 0.977\n",
      "epoch: 101/300 batch 104/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 101/300 batch 105/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 101/300 batch 106/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 101/300 batch 107/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 101/300 batch 108/188  Train Loss: 0.065, Acc: 0.988\n",
      "epoch: 101/300 batch 109/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 101/300 batch 110/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 101/300 batch 111/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 101/300 batch 112/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 101/300 batch 113/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 101/300 batch 114/188  Train Loss: 0.061, Acc: 0.980\n",
      "epoch: 101/300 batch 115/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 101/300 batch 116/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 101/300 batch 117/188  Train Loss: 0.034, Acc: 1.000\n",
      "epoch: 101/300 batch 118/188  Train Loss: 0.053, Acc: 0.992\n",
      "epoch: 101/300 batch 119/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 101/300 batch 120/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 101/300 batch 121/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 101/300 batch 122/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 101/300 batch 123/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 101/300 batch 124/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 101/300 batch 125/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 101/300 batch 126/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 101/300 batch 127/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 101/300 batch 128/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 101/300 batch 129/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 101/300 batch 130/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 101/300 batch 131/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 101/300 batch 132/188  Train Loss: 0.054, Acc: 0.980\n",
      "epoch: 101/300 batch 133/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 101/300 batch 134/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 101/300 batch 135/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 101/300 batch 136/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 101/300 batch 137/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 101/300 batch 138/188  Train Loss: 0.062, Acc: 0.977\n",
      "epoch: 101/300 batch 139/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 101/300 batch 140/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 101/300 batch 141/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 101/300 batch 142/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 101/300 batch 143/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 101/300 batch 144/188  Train Loss: 0.052, Acc: 0.980\n",
      "epoch: 101/300 batch 145/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 101/300 batch 146/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 101/300 batch 147/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 101/300 batch 148/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 101/300 batch 149/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 101/300 batch 150/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 101/300 batch 151/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 101/300 batch 152/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 101/300 batch 153/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 101/300 batch 154/188  Train Loss: 0.041, Acc: 0.980\n",
      "epoch: 101/300 batch 155/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 101/300 batch 156/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 101/300 batch 157/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 101/300 batch 158/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 101/300 batch 159/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 101/300 batch 160/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 101/300 batch 161/188  Train Loss: 0.045, Acc: 0.980\n",
      "epoch: 101/300 batch 162/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 101/300 batch 163/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 101/300 batch 164/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 101/300 batch 165/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 101/300 batch 166/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 101/300 batch 167/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 101/300 batch 168/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 101/300 batch 169/188  Train Loss: 0.072, Acc: 0.984\n",
      "epoch: 101/300 batch 170/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 101/300 batch 171/188  Train Loss: 0.070, Acc: 0.980\n",
      "epoch: 101/300 batch 172/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 101/300 batch 173/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 101/300 batch 174/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 101/300 batch 175/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 101/300 batch 176/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 101/300 batch 177/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 101/300 batch 178/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 101/300 batch 179/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 101/300 batch 180/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 101/300 batch 181/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 101/300 batch 182/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 101/300 batch 183/188  Train Loss: 0.067, Acc: 0.980\n",
      "epoch: 101/300 batch 184/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 101/300 batch 185/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 101/300 batch 186/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 101/300 batch 187/188  Train Loss: 0.020, Acc: 1.000\n",
      "Train Loss: 0.035259, Acc: 0.992\n",
      "Val Loss: 0.057753, Acc: 0.982\n",
      "epoch: 102/300 batch   0/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 102/300 batch   1/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 102/300 batch   2/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 102/300 batch   3/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 102/300 batch   4/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 102/300 batch   5/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 102/300 batch   6/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 102/300 batch   7/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 102/300 batch   8/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 102/300 batch   9/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 102/300 batch  10/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 102/300 batch  11/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 102/300 batch  12/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 102/300 batch  13/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 102/300 batch  14/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 102/300 batch  15/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 102/300 batch  16/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 102/300 batch  17/188  Train Loss: 0.070, Acc: 0.984\n",
      "epoch: 102/300 batch  18/188  Train Loss: 0.032, Acc: 1.000\n",
      "epoch: 102/300 batch  19/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 102/300 batch  20/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 102/300 batch  21/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 102/300 batch  22/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 102/300 batch  23/188  Train Loss: 0.051, Acc: 0.980\n",
      "epoch: 102/300 batch  24/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 102/300 batch  25/188  Train Loss: 0.063, Acc: 0.984\n",
      "epoch: 102/300 batch  26/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 102/300 batch  27/188  Train Loss: 0.072, Acc: 0.977\n",
      "epoch: 102/300 batch  28/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 102/300 batch  29/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 102/300 batch  30/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 102/300 batch  31/188  Train Loss: 0.051, Acc: 0.980\n",
      "epoch: 102/300 batch  32/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 102/300 batch  33/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 102/300 batch  34/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 102/300 batch  35/188  Train Loss: 0.062, Acc: 0.984\n",
      "epoch: 102/300 batch  36/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 102/300 batch  37/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 102/300 batch  38/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 102/300 batch  39/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 102/300 batch  40/188  Train Loss: 0.044, Acc: 0.996\n",
      "epoch: 102/300 batch  41/188  Train Loss: 0.027, Acc: 0.988\n",
      "epoch: 102/300 batch  42/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 102/300 batch  43/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 102/300 batch  44/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 102/300 batch  45/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 102/300 batch  46/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 102/300 batch  47/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 102/300 batch  48/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 102/300 batch  49/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 102/300 batch  50/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 102/300 batch  51/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 102/300 batch  52/188  Train Loss: 0.042, Acc: 0.980\n",
      "epoch: 102/300 batch  53/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 102/300 batch  54/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 102/300 batch  55/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 102/300 batch  56/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 102/300 batch  57/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 102/300 batch  58/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 102/300 batch  59/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 102/300 batch  60/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 102/300 batch  61/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 102/300 batch  62/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 102/300 batch  63/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 102/300 batch  64/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 102/300 batch  65/188  Train Loss: 0.061, Acc: 0.984\n",
      "epoch: 102/300 batch  66/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 102/300 batch  67/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 102/300 batch  68/188  Train Loss: 0.047, Acc: 0.996\n",
      "epoch: 102/300 batch  69/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 102/300 batch  70/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 102/300 batch  71/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 102/300 batch  72/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 102/300 batch  73/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 102/300 batch  74/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 102/300 batch  75/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 102/300 batch  76/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 102/300 batch  77/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 102/300 batch  78/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 102/300 batch  79/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 102/300 batch  80/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 102/300 batch  81/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 102/300 batch  82/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 102/300 batch  83/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 102/300 batch  84/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 102/300 batch  85/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 102/300 batch  86/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 102/300 batch  87/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 102/300 batch  88/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 102/300 batch  89/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 102/300 batch  90/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 102/300 batch  91/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 102/300 batch  92/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 102/300 batch  93/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 102/300 batch  94/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 102/300 batch  95/188  Train Loss: 0.027, Acc: 0.988\n",
      "epoch: 102/300 batch  96/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 102/300 batch  97/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 102/300 batch  98/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 102/300 batch  99/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 102/300 batch 100/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 102/300 batch 101/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 102/300 batch 102/188  Train Loss: 0.051, Acc: 0.977\n",
      "epoch: 102/300 batch 103/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 102/300 batch 104/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 102/300 batch 105/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 102/300 batch 106/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 102/300 batch 107/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 102/300 batch 108/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 102/300 batch 109/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 102/300 batch 110/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 102/300 batch 111/188  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 102/300 batch 112/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 102/300 batch 113/188  Train Loss: 0.043, Acc: 0.980\n",
      "epoch: 102/300 batch 114/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 102/300 batch 115/188  Train Loss: 0.058, Acc: 0.988\n",
      "epoch: 102/300 batch 116/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 102/300 batch 117/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 102/300 batch 118/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 102/300 batch 119/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 102/300 batch 120/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 102/300 batch 121/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 102/300 batch 122/188  Train Loss: 0.078, Acc: 0.984\n",
      "epoch: 102/300 batch 123/188  Train Loss: 0.057, Acc: 0.980\n",
      "epoch: 102/300 batch 124/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 102/300 batch 125/188  Train Loss: 0.070, Acc: 0.984\n",
      "epoch: 102/300 batch 126/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 102/300 batch 127/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 102/300 batch 128/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 102/300 batch 129/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 102/300 batch 130/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 102/300 batch 131/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 102/300 batch 132/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 102/300 batch 133/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 102/300 batch 134/188  Train Loss: 0.048, Acc: 0.980\n",
      "epoch: 102/300 batch 135/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 102/300 batch 136/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 102/300 batch 137/188  Train Loss: 0.054, Acc: 0.992\n",
      "epoch: 102/300 batch 138/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 102/300 batch 139/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 102/300 batch 140/188  Train Loss: 0.058, Acc: 0.992\n",
      "epoch: 102/300 batch 141/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 102/300 batch 142/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 102/300 batch 143/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 102/300 batch 144/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 102/300 batch 145/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 102/300 batch 146/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 102/300 batch 147/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 102/300 batch 148/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 102/300 batch 149/188  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 102/300 batch 150/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 102/300 batch 151/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 102/300 batch 152/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 102/300 batch 153/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 102/300 batch 154/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 102/300 batch 155/188  Train Loss: 0.120, Acc: 0.969\n",
      "epoch: 102/300 batch 156/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 102/300 batch 157/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 102/300 batch 158/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 102/300 batch 159/188  Train Loss: 0.053, Acc: 0.992\n",
      "epoch: 102/300 batch 160/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 102/300 batch 161/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 102/300 batch 162/188  Train Loss: 0.047, Acc: 0.996\n",
      "epoch: 102/300 batch 163/188  Train Loss: 0.059, Acc: 0.984\n",
      "epoch: 102/300 batch 164/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 102/300 batch 165/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 102/300 batch 166/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 102/300 batch 167/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 102/300 batch 168/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 102/300 batch 169/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 102/300 batch 170/188  Train Loss: 0.051, Acc: 0.980\n",
      "epoch: 102/300 batch 171/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 102/300 batch 172/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 102/300 batch 173/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 102/300 batch 174/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 102/300 batch 175/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 102/300 batch 176/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 102/300 batch 177/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 102/300 batch 178/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 102/300 batch 179/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 102/300 batch 180/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 102/300 batch 181/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 102/300 batch 182/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 102/300 batch 183/188  Train Loss: 0.080, Acc: 0.984\n",
      "epoch: 102/300 batch 184/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 102/300 batch 185/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 102/300 batch 186/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 102/300 batch 187/188  Train Loss: 0.017, Acc: 1.000\n",
      "Train Loss: 0.035098, Acc: 0.992\n",
      "Val Loss: 0.057708, Acc: 0.983\n",
      "epoch: 103/300 batch   0/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 103/300 batch   1/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 103/300 batch   2/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 103/300 batch   3/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 103/300 batch   4/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 103/300 batch   5/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 103/300 batch   6/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 103/300 batch   7/188  Train Loss: 0.055, Acc: 0.980\n",
      "epoch: 103/300 batch   8/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 103/300 batch   9/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 103/300 batch  10/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 103/300 batch  11/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 103/300 batch  12/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 103/300 batch  13/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 103/300 batch  14/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 103/300 batch  15/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 103/300 batch  16/188  Train Loss: 0.081, Acc: 0.973\n",
      "epoch: 103/300 batch  17/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 103/300 batch  18/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 103/300 batch  19/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 103/300 batch  20/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 103/300 batch  21/188  Train Loss: 0.064, Acc: 0.980\n",
      "epoch: 103/300 batch  22/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 103/300 batch  23/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 103/300 batch  24/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 103/300 batch  25/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 103/300 batch  26/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 103/300 batch  27/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 103/300 batch  28/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 103/300 batch  29/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 103/300 batch  30/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 103/300 batch  31/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 103/300 batch  32/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 103/300 batch  33/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 103/300 batch  34/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 103/300 batch  35/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 103/300 batch  36/188  Train Loss: 0.052, Acc: 0.980\n",
      "epoch: 103/300 batch  37/188  Train Loss: 0.037, Acc: 0.980\n",
      "epoch: 103/300 batch  38/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 103/300 batch  39/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 103/300 batch  40/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 103/300 batch  41/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 103/300 batch  42/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 103/300 batch  43/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 103/300 batch  44/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 103/300 batch  45/188  Train Loss: 0.032, Acc: 1.000\n",
      "epoch: 103/300 batch  46/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 103/300 batch  47/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 103/300 batch  48/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 103/300 batch  49/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 103/300 batch  50/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 103/300 batch  51/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 103/300 batch  52/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 103/300 batch  53/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 103/300 batch  54/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 103/300 batch  55/188  Train Loss: 0.063, Acc: 0.988\n",
      "epoch: 103/300 batch  56/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 103/300 batch  57/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 103/300 batch  58/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 103/300 batch  59/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 103/300 batch  60/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 103/300 batch  61/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 103/300 batch  62/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 103/300 batch  63/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 103/300 batch  64/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 103/300 batch  65/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 103/300 batch  66/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 103/300 batch  67/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 103/300 batch  68/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 103/300 batch  69/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 103/300 batch  70/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 103/300 batch  71/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 103/300 batch  72/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 103/300 batch  73/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 103/300 batch  74/188  Train Loss: 0.040, Acc: 0.980\n",
      "epoch: 103/300 batch  75/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 103/300 batch  76/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 103/300 batch  77/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 103/300 batch  78/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 103/300 batch  79/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 103/300 batch  80/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 103/300 batch  81/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 103/300 batch  82/188  Train Loss: 0.048, Acc: 0.980\n",
      "epoch: 103/300 batch  83/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 103/300 batch  84/188  Train Loss: 0.055, Acc: 0.980\n",
      "epoch: 103/300 batch  85/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 103/300 batch  86/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 103/300 batch  87/188  Train Loss: 0.047, Acc: 0.996\n",
      "epoch: 103/300 batch  88/188  Train Loss: 0.052, Acc: 0.977\n",
      "epoch: 103/300 batch  89/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 103/300 batch  90/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 103/300 batch  91/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 103/300 batch  92/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 103/300 batch  93/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 103/300 batch  94/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 103/300 batch  95/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 103/300 batch  96/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 103/300 batch  97/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 103/300 batch  98/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 103/300 batch  99/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 103/300 batch 100/188  Train Loss: 0.050, Acc: 0.980\n",
      "epoch: 103/300 batch 101/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 103/300 batch 102/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 103/300 batch 103/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 103/300 batch 104/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 103/300 batch 105/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 103/300 batch 106/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 103/300 batch 107/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 103/300 batch 108/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 103/300 batch 109/188  Train Loss: 0.048, Acc: 0.977\n",
      "epoch: 103/300 batch 110/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 103/300 batch 111/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 103/300 batch 112/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 103/300 batch 113/188  Train Loss: 0.055, Acc: 0.977\n",
      "epoch: 103/300 batch 114/188  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 103/300 batch 115/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 103/300 batch 116/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 103/300 batch 117/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 103/300 batch 118/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 103/300 batch 119/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 103/300 batch 120/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 103/300 batch 121/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 103/300 batch 122/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 103/300 batch 123/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 103/300 batch 124/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 103/300 batch 125/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 103/300 batch 126/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 103/300 batch 127/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 103/300 batch 128/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 103/300 batch 129/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 103/300 batch 130/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 103/300 batch 131/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 103/300 batch 132/188  Train Loss: 0.032, Acc: 1.000\n",
      "epoch: 103/300 batch 133/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 103/300 batch 134/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 103/300 batch 135/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 103/300 batch 136/188  Train Loss: 0.056, Acc: 0.992\n",
      "epoch: 103/300 batch 137/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 103/300 batch 138/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 103/300 batch 139/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 103/300 batch 140/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 103/300 batch 141/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 103/300 batch 142/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 103/300 batch 143/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 103/300 batch 144/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 103/300 batch 145/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 103/300 batch 146/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 103/300 batch 147/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 103/300 batch 148/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 103/300 batch 149/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 103/300 batch 150/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 103/300 batch 151/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 103/300 batch 152/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 103/300 batch 153/188  Train Loss: 0.070, Acc: 0.977\n",
      "epoch: 103/300 batch 154/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 103/300 batch 155/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 103/300 batch 156/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 103/300 batch 157/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 103/300 batch 158/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 103/300 batch 159/188  Train Loss: 0.060, Acc: 0.977\n",
      "epoch: 103/300 batch 160/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 103/300 batch 161/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 103/300 batch 162/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 103/300 batch 163/188  Train Loss: 0.084, Acc: 0.977\n",
      "epoch: 103/300 batch 164/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 103/300 batch 165/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 103/300 batch 166/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 103/300 batch 167/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 103/300 batch 168/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 103/300 batch 169/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 103/300 batch 170/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 103/300 batch 171/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 103/300 batch 172/188  Train Loss: 0.054, Acc: 0.992\n",
      "epoch: 103/300 batch 173/188  Train Loss: 0.063, Acc: 0.984\n",
      "epoch: 103/300 batch 174/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 103/300 batch 175/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 103/300 batch 176/188  Train Loss: 0.073, Acc: 0.988\n",
      "epoch: 103/300 batch 177/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 103/300 batch 178/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 103/300 batch 179/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 103/300 batch 180/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 103/300 batch 181/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 103/300 batch 182/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 103/300 batch 183/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 103/300 batch 184/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 103/300 batch 185/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 103/300 batch 186/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 103/300 batch 187/188  Train Loss: 0.015, Acc: 1.000\n",
      "Train Loss: 0.035117, Acc: 0.992\n",
      "Val Loss: 0.057630, Acc: 0.982\n",
      "epoch: 104/300 batch   0/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 104/300 batch   1/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 104/300 batch   2/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 104/300 batch   3/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 104/300 batch   4/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 104/300 batch   5/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 104/300 batch   6/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 104/300 batch   7/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 104/300 batch   8/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 104/300 batch   9/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 104/300 batch  10/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 104/300 batch  11/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 104/300 batch  12/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 104/300 batch  13/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 104/300 batch  14/188  Train Loss: 0.087, Acc: 0.973\n",
      "epoch: 104/300 batch  15/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 104/300 batch  16/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 104/300 batch  17/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 104/300 batch  18/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 104/300 batch  19/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 104/300 batch  20/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 104/300 batch  21/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 104/300 batch  22/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 104/300 batch  23/188  Train Loss: 0.058, Acc: 0.988\n",
      "epoch: 104/300 batch  24/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 104/300 batch  25/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 104/300 batch  26/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 104/300 batch  27/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 104/300 batch  28/188  Train Loss: 0.061, Acc: 0.980\n",
      "epoch: 104/300 batch  29/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 104/300 batch  30/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 104/300 batch  31/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 104/300 batch  32/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 104/300 batch  33/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 104/300 batch  34/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 104/300 batch  35/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 104/300 batch  36/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 104/300 batch  37/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 104/300 batch  38/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 104/300 batch  39/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 104/300 batch  40/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 104/300 batch  41/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 104/300 batch  42/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 104/300 batch  43/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 104/300 batch  44/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 104/300 batch  45/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 104/300 batch  46/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 104/300 batch  47/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 104/300 batch  48/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 104/300 batch  49/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 104/300 batch  50/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 104/300 batch  51/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 104/300 batch  52/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 104/300 batch  53/188  Train Loss: 0.025, Acc: 0.988\n",
      "epoch: 104/300 batch  54/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 104/300 batch  55/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 104/300 batch  56/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 104/300 batch  57/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 104/300 batch  58/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 104/300 batch  59/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 104/300 batch  60/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 104/300 batch  61/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 104/300 batch  62/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 104/300 batch  63/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 104/300 batch  64/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 104/300 batch  65/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 104/300 batch  66/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 104/300 batch  67/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 104/300 batch  68/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 104/300 batch  69/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 104/300 batch  70/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 104/300 batch  71/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 104/300 batch  72/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 104/300 batch  73/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 104/300 batch  74/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 104/300 batch  75/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 104/300 batch  76/188  Train Loss: 0.047, Acc: 0.980\n",
      "epoch: 104/300 batch  77/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 104/300 batch  78/188  Train Loss: 0.058, Acc: 0.992\n",
      "epoch: 104/300 batch  79/188  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 104/300 batch  80/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 104/300 batch  81/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 104/300 batch  82/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 104/300 batch  83/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 104/300 batch  84/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 104/300 batch  85/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 104/300 batch  86/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 104/300 batch  87/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 104/300 batch  88/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 104/300 batch  89/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 104/300 batch  90/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 104/300 batch  91/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 104/300 batch  92/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 104/300 batch  93/188  Train Loss: 0.059, Acc: 0.992\n",
      "epoch: 104/300 batch  94/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 104/300 batch  95/188  Train Loss: 0.080, Acc: 0.965\n",
      "epoch: 104/300 batch  96/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 104/300 batch  97/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 104/300 batch  98/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 104/300 batch  99/188  Train Loss: 0.061, Acc: 0.988\n",
      "epoch: 104/300 batch 100/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 104/300 batch 101/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 104/300 batch 102/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 104/300 batch 103/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 104/300 batch 104/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 104/300 batch 105/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 104/300 batch 106/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 104/300 batch 107/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 104/300 batch 108/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 104/300 batch 109/188  Train Loss: 0.050, Acc: 0.977\n",
      "epoch: 104/300 batch 110/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 104/300 batch 111/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 104/300 batch 112/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 104/300 batch 113/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 104/300 batch 114/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 104/300 batch 115/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 104/300 batch 116/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 104/300 batch 117/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 104/300 batch 118/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 104/300 batch 119/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 104/300 batch 120/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 104/300 batch 121/188  Train Loss: 0.032, Acc: 1.000\n",
      "epoch: 104/300 batch 122/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 104/300 batch 123/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 104/300 batch 124/188  Train Loss: 0.069, Acc: 0.980\n",
      "epoch: 104/300 batch 125/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 104/300 batch 126/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 104/300 batch 127/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 104/300 batch 128/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 104/300 batch 129/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 104/300 batch 130/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 104/300 batch 131/188  Train Loss: 0.042, Acc: 0.980\n",
      "epoch: 104/300 batch 132/188  Train Loss: 0.061, Acc: 0.988\n",
      "epoch: 104/300 batch 133/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 104/300 batch 134/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 104/300 batch 135/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 104/300 batch 136/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 104/300 batch 137/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 104/300 batch 138/188  Train Loss: 0.048, Acc: 0.996\n",
      "epoch: 104/300 batch 139/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 104/300 batch 140/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 104/300 batch 141/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 104/300 batch 142/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 104/300 batch 143/188  Train Loss: 0.047, Acc: 0.980\n",
      "epoch: 104/300 batch 144/188  Train Loss: 0.065, Acc: 0.984\n",
      "epoch: 104/300 batch 145/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 104/300 batch 146/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 104/300 batch 147/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 104/300 batch 148/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 104/300 batch 149/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 104/300 batch 150/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 104/300 batch 151/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 104/300 batch 152/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 104/300 batch 153/188  Train Loss: 0.052, Acc: 0.992\n",
      "epoch: 104/300 batch 154/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 104/300 batch 155/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 104/300 batch 156/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 104/300 batch 157/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 104/300 batch 158/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 104/300 batch 159/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 104/300 batch 160/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 104/300 batch 161/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 104/300 batch 162/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 104/300 batch 163/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 104/300 batch 164/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 104/300 batch 165/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 104/300 batch 166/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 104/300 batch 167/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 104/300 batch 168/188  Train Loss: 0.059, Acc: 0.980\n",
      "epoch: 104/300 batch 169/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 104/300 batch 170/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 104/300 batch 171/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 104/300 batch 172/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 104/300 batch 173/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 104/300 batch 174/188  Train Loss: 0.046, Acc: 0.980\n",
      "epoch: 104/300 batch 175/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 104/300 batch 176/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 104/300 batch 177/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 104/300 batch 178/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 104/300 batch 179/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 104/300 batch 180/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 104/300 batch 181/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 104/300 batch 182/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 104/300 batch 183/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 104/300 batch 184/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 104/300 batch 185/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 104/300 batch 186/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 104/300 batch 187/188  Train Loss: 0.033, Acc: 0.992\n",
      "Train Loss: 0.035141, Acc: 0.992\n",
      "Val Loss: 0.057565, Acc: 0.983\n",
      "epoch: 105/300 batch   0/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 105/300 batch   1/188  Train Loss: 0.026, Acc: 0.988\n",
      "epoch: 105/300 batch   2/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 105/300 batch   3/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 105/300 batch   4/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 105/300 batch   5/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 105/300 batch   6/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 105/300 batch   7/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 105/300 batch   8/188  Train Loss: 0.043, Acc: 0.996\n",
      "epoch: 105/300 batch   9/188  Train Loss: 0.038, Acc: 1.000\n",
      "epoch: 105/300 batch  10/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 105/300 batch  11/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 105/300 batch  12/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 105/300 batch  13/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 105/300 batch  14/188  Train Loss: 0.045, Acc: 0.980\n",
      "epoch: 105/300 batch  15/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 105/300 batch  16/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 105/300 batch  17/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 105/300 batch  18/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 105/300 batch  19/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 105/300 batch  20/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 105/300 batch  21/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 105/300 batch  22/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 105/300 batch  23/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 105/300 batch  24/188  Train Loss: 0.053, Acc: 0.992\n",
      "epoch: 105/300 batch  25/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 105/300 batch  26/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 105/300 batch  27/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 105/300 batch  28/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 105/300 batch  29/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 105/300 batch  30/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 105/300 batch  31/188  Train Loss: 0.060, Acc: 0.980\n",
      "epoch: 105/300 batch  32/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 105/300 batch  33/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 105/300 batch  34/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 105/300 batch  35/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 105/300 batch  36/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 105/300 batch  37/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 105/300 batch  38/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 105/300 batch  39/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 105/300 batch  40/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 105/300 batch  41/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 105/300 batch  42/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 105/300 batch  43/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 105/300 batch  44/188  Train Loss: 0.063, Acc: 0.984\n",
      "epoch: 105/300 batch  45/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 105/300 batch  46/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 105/300 batch  47/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 105/300 batch  48/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 105/300 batch  49/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 105/300 batch  50/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 105/300 batch  51/188  Train Loss: 0.048, Acc: 0.980\n",
      "epoch: 105/300 batch  52/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 105/300 batch  53/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 105/300 batch  54/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 105/300 batch  55/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 105/300 batch  56/188  Train Loss: 0.061, Acc: 0.980\n",
      "epoch: 105/300 batch  57/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 105/300 batch  58/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 105/300 batch  59/188  Train Loss: 0.052, Acc: 0.977\n",
      "epoch: 105/300 batch  60/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 105/300 batch  61/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 105/300 batch  62/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 105/300 batch  63/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 105/300 batch  64/188  Train Loss: 0.045, Acc: 0.996\n",
      "epoch: 105/300 batch  65/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 105/300 batch  66/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 105/300 batch  67/188  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 105/300 batch  68/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 105/300 batch  69/188  Train Loss: 0.042, Acc: 0.996\n",
      "epoch: 105/300 batch  70/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 105/300 batch  71/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 105/300 batch  72/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 105/300 batch  73/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 105/300 batch  74/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 105/300 batch  75/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 105/300 batch  76/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 105/300 batch  77/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 105/300 batch  78/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 105/300 batch  79/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 105/300 batch  80/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 105/300 batch  81/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 105/300 batch  82/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 105/300 batch  83/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 105/300 batch  84/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 105/300 batch  85/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 105/300 batch  86/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 105/300 batch  87/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 105/300 batch  88/188  Train Loss: 0.042, Acc: 0.996\n",
      "epoch: 105/300 batch  89/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 105/300 batch  90/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 105/300 batch  91/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 105/300 batch  92/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 105/300 batch  93/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 105/300 batch  94/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 105/300 batch  95/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 105/300 batch  96/188  Train Loss: 0.056, Acc: 0.988\n",
      "epoch: 105/300 batch  97/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 105/300 batch  98/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 105/300 batch  99/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 105/300 batch 100/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 105/300 batch 101/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 105/300 batch 102/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 105/300 batch 103/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 105/300 batch 104/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 105/300 batch 105/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 105/300 batch 106/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 105/300 batch 107/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 105/300 batch 108/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 105/300 batch 109/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 105/300 batch 110/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 105/300 batch 111/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 105/300 batch 112/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 105/300 batch 113/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 105/300 batch 114/188  Train Loss: 0.059, Acc: 0.988\n",
      "epoch: 105/300 batch 115/188  Train Loss: 0.057, Acc: 0.980\n",
      "epoch: 105/300 batch 116/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 105/300 batch 117/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 105/300 batch 118/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 105/300 batch 119/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 105/300 batch 120/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 105/300 batch 121/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 105/300 batch 122/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 105/300 batch 123/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 105/300 batch 124/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 105/300 batch 125/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 105/300 batch 126/188  Train Loss: 0.077, Acc: 0.977\n",
      "epoch: 105/300 batch 127/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 105/300 batch 128/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 105/300 batch 129/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 105/300 batch 130/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 105/300 batch 131/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 105/300 batch 132/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 105/300 batch 133/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 105/300 batch 134/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 105/300 batch 135/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 105/300 batch 136/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 105/300 batch 137/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 105/300 batch 138/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 105/300 batch 139/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 105/300 batch 140/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 105/300 batch 141/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 105/300 batch 142/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 105/300 batch 143/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 105/300 batch 144/188  Train Loss: 0.060, Acc: 0.977\n",
      "epoch: 105/300 batch 145/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 105/300 batch 146/188  Train Loss: 0.046, Acc: 0.996\n",
      "epoch: 105/300 batch 147/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 105/300 batch 148/188  Train Loss: 0.072, Acc: 0.980\n",
      "epoch: 105/300 batch 149/188  Train Loss: 0.043, Acc: 0.980\n",
      "epoch: 105/300 batch 150/188  Train Loss: 0.049, Acc: 0.977\n",
      "epoch: 105/300 batch 151/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 105/300 batch 152/188  Train Loss: 0.053, Acc: 0.980\n",
      "epoch: 105/300 batch 153/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 105/300 batch 154/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 105/300 batch 155/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 105/300 batch 156/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 105/300 batch 157/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 105/300 batch 158/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 105/300 batch 159/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 105/300 batch 160/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 105/300 batch 161/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 105/300 batch 162/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 105/300 batch 163/188  Train Loss: 0.052, Acc: 0.977\n",
      "epoch: 105/300 batch 164/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 105/300 batch 165/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 105/300 batch 166/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 105/300 batch 167/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 105/300 batch 168/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 105/300 batch 169/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 105/300 batch 170/188  Train Loss: 0.036, Acc: 1.000\n",
      "epoch: 105/300 batch 171/188  Train Loss: 0.069, Acc: 0.988\n",
      "epoch: 105/300 batch 172/188  Train Loss: 0.032, Acc: 1.000\n",
      "epoch: 105/300 batch 173/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 105/300 batch 174/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 105/300 batch 175/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 105/300 batch 176/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 105/300 batch 177/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 105/300 batch 178/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 105/300 batch 179/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 105/300 batch 180/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 105/300 batch 181/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 105/300 batch 182/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 105/300 batch 183/188  Train Loss: 0.065, Acc: 0.992\n",
      "epoch: 105/300 batch 184/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 105/300 batch 185/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 105/300 batch 186/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 105/300 batch 187/188  Train Loss: 0.021, Acc: 1.000\n",
      "Train Loss: 0.035010, Acc: 0.992\n",
      "Val Loss: 0.057808, Acc: 0.982\n",
      "epoch: 106/300 batch   0/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 106/300 batch   1/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 106/300 batch   2/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 106/300 batch   3/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 106/300 batch   4/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 106/300 batch   5/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 106/300 batch   6/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 106/300 batch   7/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 106/300 batch   8/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 106/300 batch   9/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 106/300 batch  10/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 106/300 batch  11/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 106/300 batch  12/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 106/300 batch  13/188  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 106/300 batch  14/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 106/300 batch  15/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 106/300 batch  16/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 106/300 batch  17/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 106/300 batch  18/188  Train Loss: 0.051, Acc: 0.992\n",
      "epoch: 106/300 batch  19/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 106/300 batch  20/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 106/300 batch  21/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 106/300 batch  22/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 106/300 batch  23/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 106/300 batch  24/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 106/300 batch  25/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 106/300 batch  26/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 106/300 batch  27/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 106/300 batch  28/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 106/300 batch  29/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 106/300 batch  30/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 106/300 batch  31/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 106/300 batch  32/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 106/300 batch  33/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 106/300 batch  34/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 106/300 batch  35/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 106/300 batch  36/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 106/300 batch  37/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 106/300 batch  38/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 106/300 batch  39/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 106/300 batch  40/188  Train Loss: 0.059, Acc: 0.988\n",
      "epoch: 106/300 batch  41/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 106/300 batch  42/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 106/300 batch  43/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 106/300 batch  44/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 106/300 batch  45/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 106/300 batch  46/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 106/300 batch  47/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 106/300 batch  48/188  Train Loss: 0.033, Acc: 1.000\n",
      "epoch: 106/300 batch  49/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 106/300 batch  50/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 106/300 batch  51/188  Train Loss: 0.062, Acc: 0.988\n",
      "epoch: 106/300 batch  52/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 106/300 batch  53/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 106/300 batch  54/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 106/300 batch  55/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 106/300 batch  56/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 106/300 batch  57/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 106/300 batch  58/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 106/300 batch  59/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 106/300 batch  60/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 106/300 batch  61/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 106/300 batch  62/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 106/300 batch  63/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 106/300 batch  64/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 106/300 batch  65/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 106/300 batch  66/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 106/300 batch  67/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 106/300 batch  68/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 106/300 batch  69/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 106/300 batch  70/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 106/300 batch  71/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 106/300 batch  72/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 106/300 batch  73/188  Train Loss: 0.057, Acc: 0.992\n",
      "epoch: 106/300 batch  74/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 106/300 batch  75/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 106/300 batch  76/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 106/300 batch  77/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 106/300 batch  78/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 106/300 batch  79/188  Train Loss: 0.065, Acc: 0.984\n",
      "epoch: 106/300 batch  80/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 106/300 batch  81/188  Train Loss: 0.052, Acc: 0.980\n",
      "epoch: 106/300 batch  82/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 106/300 batch  83/188  Train Loss: 0.056, Acc: 0.988\n",
      "epoch: 106/300 batch  84/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 106/300 batch  85/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 106/300 batch  86/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 106/300 batch  87/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 106/300 batch  88/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 106/300 batch  89/188  Train Loss: 0.043, Acc: 0.980\n",
      "epoch: 106/300 batch  90/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 106/300 batch  91/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 106/300 batch  92/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 106/300 batch  93/188  Train Loss: 0.056, Acc: 0.988\n",
      "epoch: 106/300 batch  94/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 106/300 batch  95/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 106/300 batch  96/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 106/300 batch  97/188  Train Loss: 0.025, Acc: 0.988\n",
      "epoch: 106/300 batch  98/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 106/300 batch  99/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 106/300 batch 100/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 106/300 batch 101/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 106/300 batch 102/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 106/300 batch 103/188  Train Loss: 0.048, Acc: 0.980\n",
      "epoch: 106/300 batch 104/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 106/300 batch 105/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 106/300 batch 106/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 106/300 batch 107/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 106/300 batch 108/188  Train Loss: 0.067, Acc: 0.977\n",
      "epoch: 106/300 batch 109/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 106/300 batch 110/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 106/300 batch 111/188  Train Loss: 0.081, Acc: 0.977\n",
      "epoch: 106/300 batch 112/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 106/300 batch 113/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 106/300 batch 114/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 106/300 batch 115/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 106/300 batch 116/188  Train Loss: 0.066, Acc: 0.980\n",
      "epoch: 106/300 batch 117/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 106/300 batch 118/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 106/300 batch 119/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 106/300 batch 120/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 106/300 batch 121/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 106/300 batch 122/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 106/300 batch 123/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 106/300 batch 124/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 106/300 batch 125/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 106/300 batch 126/188  Train Loss: 0.081, Acc: 0.965\n",
      "epoch: 106/300 batch 127/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 106/300 batch 128/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 106/300 batch 129/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 106/300 batch 130/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 106/300 batch 131/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 106/300 batch 132/188  Train Loss: 0.031, Acc: 1.000\n",
      "epoch: 106/300 batch 133/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 106/300 batch 134/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 106/300 batch 135/188  Train Loss: 0.033, Acc: 1.000\n",
      "epoch: 106/300 batch 136/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 106/300 batch 137/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 106/300 batch 138/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 106/300 batch 139/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 106/300 batch 140/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 106/300 batch 141/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 106/300 batch 142/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 106/300 batch 143/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 106/300 batch 144/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 106/300 batch 145/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 106/300 batch 146/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 106/300 batch 147/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 106/300 batch 148/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 106/300 batch 149/188  Train Loss: 0.060, Acc: 0.980\n",
      "epoch: 106/300 batch 150/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 106/300 batch 151/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 106/300 batch 152/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 106/300 batch 153/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 106/300 batch 154/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 106/300 batch 155/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 106/300 batch 156/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 106/300 batch 157/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 106/300 batch 158/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 106/300 batch 159/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 106/300 batch 160/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 106/300 batch 161/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 106/300 batch 162/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 106/300 batch 163/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 106/300 batch 164/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 106/300 batch 165/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 106/300 batch 166/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 106/300 batch 167/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 106/300 batch 168/188  Train Loss: 0.081, Acc: 0.988\n",
      "epoch: 106/300 batch 169/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 106/300 batch 170/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 106/300 batch 171/188  Train Loss: 0.081, Acc: 0.969\n",
      "epoch: 106/300 batch 172/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 106/300 batch 173/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 106/300 batch 174/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 106/300 batch 175/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 106/300 batch 176/188  Train Loss: 0.031, Acc: 1.000\n",
      "epoch: 106/300 batch 177/188  Train Loss: 0.045, Acc: 0.980\n",
      "epoch: 106/300 batch 178/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 106/300 batch 179/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 106/300 batch 180/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 106/300 batch 181/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 106/300 batch 182/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 106/300 batch 183/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 106/300 batch 184/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 106/300 batch 185/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 106/300 batch 186/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 106/300 batch 187/188  Train Loss: 0.020, Acc: 1.000\n",
      "Train Loss: 0.035075, Acc: 0.992\n",
      "Val Loss: 0.057714, Acc: 0.982\n",
      "epoch: 107/300 batch   0/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 107/300 batch   1/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 107/300 batch   2/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 107/300 batch   3/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 107/300 batch   4/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 107/300 batch   5/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 107/300 batch   6/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 107/300 batch   7/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 107/300 batch   8/188  Train Loss: 0.035, Acc: 1.000\n",
      "epoch: 107/300 batch   9/188  Train Loss: 0.071, Acc: 0.992\n",
      "epoch: 107/300 batch  10/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 107/300 batch  11/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 107/300 batch  12/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 107/300 batch  13/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 107/300 batch  14/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 107/300 batch  15/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 107/300 batch  16/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 107/300 batch  17/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 107/300 batch  18/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 107/300 batch  19/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 107/300 batch  20/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 107/300 batch  21/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 107/300 batch  22/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 107/300 batch  23/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 107/300 batch  24/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 107/300 batch  25/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 107/300 batch  26/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 107/300 batch  27/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 107/300 batch  28/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 107/300 batch  29/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 107/300 batch  30/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 107/300 batch  31/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 107/300 batch  32/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 107/300 batch  33/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 107/300 batch  34/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 107/300 batch  35/188  Train Loss: 0.071, Acc: 0.988\n",
      "epoch: 107/300 batch  36/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 107/300 batch  37/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 107/300 batch  38/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 107/300 batch  39/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 107/300 batch  40/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 107/300 batch  41/188  Train Loss: 0.033, Acc: 1.000\n",
      "epoch: 107/300 batch  42/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 107/300 batch  43/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 107/300 batch  44/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 107/300 batch  45/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 107/300 batch  46/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 107/300 batch  47/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 107/300 batch  48/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 107/300 batch  49/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 107/300 batch  50/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 107/300 batch  51/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 107/300 batch  52/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 107/300 batch  53/188  Train Loss: 0.054, Acc: 0.992\n",
      "epoch: 107/300 batch  54/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 107/300 batch  55/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 107/300 batch  56/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 107/300 batch  57/188  Train Loss: 0.045, Acc: 0.980\n",
      "epoch: 107/300 batch  58/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 107/300 batch  59/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 107/300 batch  60/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 107/300 batch  61/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 107/300 batch  62/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 107/300 batch  63/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 107/300 batch  64/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 107/300 batch  65/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 107/300 batch  66/188  Train Loss: 0.066, Acc: 0.988\n",
      "epoch: 107/300 batch  67/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 107/300 batch  68/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 107/300 batch  69/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 107/300 batch  70/188  Train Loss: 0.024, Acc: 0.988\n",
      "epoch: 107/300 batch  71/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 107/300 batch  72/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 107/300 batch  73/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 107/300 batch  74/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 107/300 batch  75/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 107/300 batch  76/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 107/300 batch  77/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 107/300 batch  78/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 107/300 batch  79/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 107/300 batch  80/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 107/300 batch  81/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 107/300 batch  82/188  Train Loss: 0.059, Acc: 0.980\n",
      "epoch: 107/300 batch  83/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 107/300 batch  84/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 107/300 batch  85/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 107/300 batch  86/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 107/300 batch  87/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 107/300 batch  88/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 107/300 batch  89/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 107/300 batch  90/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 107/300 batch  91/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 107/300 batch  92/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 107/300 batch  93/188  Train Loss: 0.051, Acc: 0.996\n",
      "epoch: 107/300 batch  94/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 107/300 batch  95/188  Train Loss: 0.059, Acc: 0.977\n",
      "epoch: 107/300 batch  96/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 107/300 batch  97/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 107/300 batch  98/188  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 107/300 batch  99/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 107/300 batch 100/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 107/300 batch 101/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 107/300 batch 102/188  Train Loss: 0.052, Acc: 0.973\n",
      "epoch: 107/300 batch 103/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 107/300 batch 104/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 107/300 batch 105/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 107/300 batch 106/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 107/300 batch 107/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 107/300 batch 108/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 107/300 batch 109/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 107/300 batch 110/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 107/300 batch 111/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 107/300 batch 112/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 107/300 batch 113/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 107/300 batch 114/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 107/300 batch 115/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 107/300 batch 116/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 107/300 batch 117/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 107/300 batch 118/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 107/300 batch 119/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 107/300 batch 120/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 107/300 batch 121/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 107/300 batch 122/188  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 107/300 batch 123/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 107/300 batch 124/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 107/300 batch 125/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 107/300 batch 126/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 107/300 batch 127/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 107/300 batch 128/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 107/300 batch 129/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 107/300 batch 130/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 107/300 batch 131/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 107/300 batch 132/188  Train Loss: 0.068, Acc: 0.977\n",
      "epoch: 107/300 batch 133/188  Train Loss: 0.063, Acc: 0.984\n",
      "epoch: 107/300 batch 134/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 107/300 batch 135/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 107/300 batch 136/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 107/300 batch 137/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 107/300 batch 138/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 107/300 batch 139/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 107/300 batch 140/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 107/300 batch 141/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 107/300 batch 142/188  Train Loss: 0.086, Acc: 0.984\n",
      "epoch: 107/300 batch 143/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 107/300 batch 144/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 107/300 batch 145/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 107/300 batch 146/188  Train Loss: 0.077, Acc: 0.969\n",
      "epoch: 107/300 batch 147/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 107/300 batch 148/188  Train Loss: 0.027, Acc: 0.988\n",
      "epoch: 107/300 batch 149/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 107/300 batch 150/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 107/300 batch 151/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 107/300 batch 152/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 107/300 batch 153/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 107/300 batch 154/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 107/300 batch 155/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 107/300 batch 156/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 107/300 batch 157/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 107/300 batch 158/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 107/300 batch 159/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 107/300 batch 160/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 107/300 batch 161/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 107/300 batch 162/188  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 107/300 batch 163/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 107/300 batch 164/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 107/300 batch 165/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 107/300 batch 166/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 107/300 batch 167/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 107/300 batch 168/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 107/300 batch 169/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 107/300 batch 170/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 107/300 batch 171/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 107/300 batch 172/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 107/300 batch 173/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 107/300 batch 174/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 107/300 batch 175/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 107/300 batch 176/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 107/300 batch 177/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 107/300 batch 178/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 107/300 batch 179/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 107/300 batch 180/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 107/300 batch 181/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 107/300 batch 182/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 107/300 batch 183/188  Train Loss: 0.067, Acc: 0.977\n",
      "epoch: 107/300 batch 184/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 107/300 batch 185/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 107/300 batch 186/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 107/300 batch 187/188  Train Loss: 0.026, Acc: 1.000\n",
      "Train Loss: 0.034989, Acc: 0.992\n",
      "Val Loss: 0.057560, Acc: 0.982\n",
      "epoch: 108/300 batch   0/188  Train Loss: 0.069, Acc: 0.973\n",
      "epoch: 108/300 batch   1/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 108/300 batch   2/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 108/300 batch   3/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 108/300 batch   4/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 108/300 batch   5/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 108/300 batch   6/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 108/300 batch   7/188  Train Loss: 0.052, Acc: 0.980\n",
      "epoch: 108/300 batch   8/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 108/300 batch   9/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 108/300 batch  10/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 108/300 batch  11/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 108/300 batch  12/188  Train Loss: 0.069, Acc: 0.980\n",
      "epoch: 108/300 batch  13/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 108/300 batch  14/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 108/300 batch  15/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 108/300 batch  16/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 108/300 batch  17/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 108/300 batch  18/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 108/300 batch  19/188  Train Loss: 0.060, Acc: 0.977\n",
      "epoch: 108/300 batch  20/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 108/300 batch  21/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 108/300 batch  22/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 108/300 batch  23/188  Train Loss: 0.068, Acc: 0.984\n",
      "epoch: 108/300 batch  24/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 108/300 batch  25/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 108/300 batch  26/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 108/300 batch  27/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 108/300 batch  28/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 108/300 batch  29/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 108/300 batch  30/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 108/300 batch  31/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 108/300 batch  32/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 108/300 batch  33/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 108/300 batch  34/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 108/300 batch  35/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 108/300 batch  36/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 108/300 batch  37/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 108/300 batch  38/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 108/300 batch  39/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 108/300 batch  40/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 108/300 batch  41/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 108/300 batch  42/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 108/300 batch  43/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 108/300 batch  44/188  Train Loss: 0.075, Acc: 0.988\n",
      "epoch: 108/300 batch  45/188  Train Loss: 0.047, Acc: 0.977\n",
      "epoch: 108/300 batch  46/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 108/300 batch  47/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 108/300 batch  48/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 108/300 batch  49/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 108/300 batch  50/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 108/300 batch  51/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 108/300 batch  52/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 108/300 batch  53/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 108/300 batch  54/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 108/300 batch  55/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 108/300 batch  56/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 108/300 batch  57/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 108/300 batch  58/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 108/300 batch  59/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 108/300 batch  60/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 108/300 batch  61/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 108/300 batch  62/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 108/300 batch  63/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 108/300 batch  64/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 108/300 batch  65/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 108/300 batch  66/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 108/300 batch  67/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 108/300 batch  68/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 108/300 batch  69/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 108/300 batch  70/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 108/300 batch  71/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 108/300 batch  72/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 108/300 batch  73/188  Train Loss: 0.075, Acc: 0.984\n",
      "epoch: 108/300 batch  74/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 108/300 batch  75/188  Train Loss: 0.053, Acc: 0.980\n",
      "epoch: 108/300 batch  76/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 108/300 batch  77/188  Train Loss: 0.056, Acc: 0.988\n",
      "epoch: 108/300 batch  78/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 108/300 batch  79/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 108/300 batch  80/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 108/300 batch  81/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 108/300 batch  82/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 108/300 batch  83/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 108/300 batch  84/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 108/300 batch  85/188  Train Loss: 0.052, Acc: 0.980\n",
      "epoch: 108/300 batch  86/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 108/300 batch  87/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 108/300 batch  88/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 108/300 batch  89/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 108/300 batch  90/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 108/300 batch  91/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 108/300 batch  92/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 108/300 batch  93/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 108/300 batch  94/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 108/300 batch  95/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 108/300 batch  96/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 108/300 batch  97/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 108/300 batch  98/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 108/300 batch  99/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 108/300 batch 100/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 108/300 batch 101/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 108/300 batch 102/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 108/300 batch 103/188  Train Loss: 0.088, Acc: 0.969\n",
      "epoch: 108/300 batch 104/188  Train Loss: 0.057, Acc: 0.980\n",
      "epoch: 108/300 batch 105/188  Train Loss: 0.044, Acc: 0.980\n",
      "epoch: 108/300 batch 106/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 108/300 batch 107/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 108/300 batch 108/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 108/300 batch 109/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 108/300 batch 110/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 108/300 batch 111/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 108/300 batch 112/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 108/300 batch 113/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 108/300 batch 114/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 108/300 batch 115/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 108/300 batch 116/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 108/300 batch 117/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 108/300 batch 118/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 108/300 batch 119/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 108/300 batch 120/188  Train Loss: 0.072, Acc: 0.977\n",
      "epoch: 108/300 batch 121/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 108/300 batch 122/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 108/300 batch 123/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 108/300 batch 124/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 108/300 batch 125/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 108/300 batch 126/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 108/300 batch 127/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 108/300 batch 128/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 108/300 batch 129/188  Train Loss: 0.058, Acc: 0.980\n",
      "epoch: 108/300 batch 130/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 108/300 batch 131/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 108/300 batch 132/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 108/300 batch 133/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 108/300 batch 134/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 108/300 batch 135/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 108/300 batch 136/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 108/300 batch 137/188  Train Loss: 0.066, Acc: 0.980\n",
      "epoch: 108/300 batch 138/188  Train Loss: 0.043, Acc: 0.996\n",
      "epoch: 108/300 batch 139/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 108/300 batch 140/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 108/300 batch 141/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 108/300 batch 142/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 108/300 batch 143/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 108/300 batch 144/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 108/300 batch 145/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 108/300 batch 146/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 108/300 batch 147/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 108/300 batch 148/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 108/300 batch 149/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 108/300 batch 150/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 108/300 batch 151/188  Train Loss: 0.060, Acc: 0.977\n",
      "epoch: 108/300 batch 152/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 108/300 batch 153/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 108/300 batch 154/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 108/300 batch 155/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 108/300 batch 156/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 108/300 batch 157/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 108/300 batch 158/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 108/300 batch 159/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 108/300 batch 160/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 108/300 batch 161/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 108/300 batch 162/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 108/300 batch 163/188  Train Loss: 0.051, Acc: 0.977\n",
      "epoch: 108/300 batch 164/188  Train Loss: 0.054, Acc: 0.980\n",
      "epoch: 108/300 batch 165/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 108/300 batch 166/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 108/300 batch 167/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 108/300 batch 168/188  Train Loss: 0.030, Acc: 0.984\n",
      "epoch: 108/300 batch 169/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 108/300 batch 170/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 108/300 batch 171/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 108/300 batch 172/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 108/300 batch 173/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 108/300 batch 174/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 108/300 batch 175/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 108/300 batch 176/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 108/300 batch 177/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 108/300 batch 178/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 108/300 batch 179/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 108/300 batch 180/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 108/300 batch 181/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 108/300 batch 182/188  Train Loss: 0.063, Acc: 0.980\n",
      "epoch: 108/300 batch 183/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 108/300 batch 184/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 108/300 batch 185/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 108/300 batch 186/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 108/300 batch 187/188  Train Loss: 0.027, Acc: 1.000\n",
      "Train Loss: 0.034976, Acc: 0.992\n",
      "Val Loss: 0.057843, Acc: 0.982\n",
      "epoch: 109/300 batch   0/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 109/300 batch   1/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 109/300 batch   2/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 109/300 batch   3/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 109/300 batch   4/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 109/300 batch   5/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 109/300 batch   6/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 109/300 batch   7/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 109/300 batch   8/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 109/300 batch   9/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 109/300 batch  10/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 109/300 batch  11/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 109/300 batch  12/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 109/300 batch  13/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 109/300 batch  14/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 109/300 batch  15/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 109/300 batch  16/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 109/300 batch  17/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 109/300 batch  18/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 109/300 batch  19/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 109/300 batch  20/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 109/300 batch  21/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 109/300 batch  22/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 109/300 batch  23/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 109/300 batch  24/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 109/300 batch  25/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 109/300 batch  26/188  Train Loss: 0.056, Acc: 0.992\n",
      "epoch: 109/300 batch  27/188  Train Loss: 0.071, Acc: 0.984\n",
      "epoch: 109/300 batch  28/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 109/300 batch  29/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 109/300 batch  30/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 109/300 batch  31/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 109/300 batch  32/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 109/300 batch  33/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 109/300 batch  34/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 109/300 batch  35/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 109/300 batch  36/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 109/300 batch  37/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 109/300 batch  38/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 109/300 batch  39/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 109/300 batch  40/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 109/300 batch  41/188  Train Loss: 0.058, Acc: 0.977\n",
      "epoch: 109/300 batch  42/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 109/300 batch  43/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 109/300 batch  44/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 109/300 batch  45/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 109/300 batch  46/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 109/300 batch  47/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 109/300 batch  48/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 109/300 batch  49/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 109/300 batch  50/188  Train Loss: 0.037, Acc: 1.000\n",
      "epoch: 109/300 batch  51/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 109/300 batch  52/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 109/300 batch  53/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 109/300 batch  54/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 109/300 batch  55/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 109/300 batch  56/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 109/300 batch  57/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 109/300 batch  58/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 109/300 batch  59/188  Train Loss: 0.070, Acc: 0.992\n",
      "epoch: 109/300 batch  60/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 109/300 batch  61/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 109/300 batch  62/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 109/300 batch  63/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 109/300 batch  64/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 109/300 batch  65/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 109/300 batch  66/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 109/300 batch  67/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 109/300 batch  68/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 109/300 batch  69/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 109/300 batch  70/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 109/300 batch  71/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 109/300 batch  72/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 109/300 batch  73/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 109/300 batch  74/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 109/300 batch  75/188  Train Loss: 0.053, Acc: 0.977\n",
      "epoch: 109/300 batch  76/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 109/300 batch  77/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 109/300 batch  78/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 109/300 batch  79/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 109/300 batch  80/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 109/300 batch  81/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 109/300 batch  82/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 109/300 batch  83/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 109/300 batch  84/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 109/300 batch  85/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 109/300 batch  86/188  Train Loss: 0.046, Acc: 0.973\n",
      "epoch: 109/300 batch  87/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 109/300 batch  88/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 109/300 batch  89/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 109/300 batch  90/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 109/300 batch  91/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 109/300 batch  92/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 109/300 batch  93/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 109/300 batch  94/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 109/300 batch  95/188  Train Loss: 0.062, Acc: 0.980\n",
      "epoch: 109/300 batch  96/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 109/300 batch  97/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 109/300 batch  98/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 109/300 batch  99/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 109/300 batch 100/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 109/300 batch 101/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 109/300 batch 102/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 109/300 batch 103/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 109/300 batch 104/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 109/300 batch 105/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 109/300 batch 106/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 109/300 batch 107/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 109/300 batch 108/188  Train Loss: 0.060, Acc: 0.984\n",
      "epoch: 109/300 batch 109/188  Train Loss: 0.054, Acc: 0.980\n",
      "epoch: 109/300 batch 110/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 109/300 batch 111/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 109/300 batch 112/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 109/300 batch 113/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 109/300 batch 114/188  Train Loss: 0.068, Acc: 0.984\n",
      "epoch: 109/300 batch 115/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 109/300 batch 116/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 109/300 batch 117/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 109/300 batch 118/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 109/300 batch 119/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 109/300 batch 120/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 109/300 batch 121/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 109/300 batch 122/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 109/300 batch 123/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 109/300 batch 124/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 109/300 batch 125/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 109/300 batch 126/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 109/300 batch 127/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 109/300 batch 128/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 109/300 batch 129/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 109/300 batch 130/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 109/300 batch 131/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 109/300 batch 132/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 109/300 batch 133/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 109/300 batch 134/188  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 109/300 batch 135/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 109/300 batch 136/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 109/300 batch 137/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 109/300 batch 138/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 109/300 batch 139/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 109/300 batch 140/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 109/300 batch 141/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 109/300 batch 142/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 109/300 batch 143/188  Train Loss: 0.059, Acc: 0.988\n",
      "epoch: 109/300 batch 144/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 109/300 batch 145/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 109/300 batch 146/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 109/300 batch 147/188  Train Loss: 0.035, Acc: 1.000\n",
      "epoch: 109/300 batch 148/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 109/300 batch 149/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 109/300 batch 150/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 109/300 batch 151/188  Train Loss: 0.044, Acc: 0.980\n",
      "epoch: 109/300 batch 152/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 109/300 batch 153/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 109/300 batch 154/188  Train Loss: 0.033, Acc: 0.984\n",
      "epoch: 109/300 batch 155/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 109/300 batch 156/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 109/300 batch 157/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 109/300 batch 158/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 109/300 batch 159/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 109/300 batch 160/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 109/300 batch 161/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 109/300 batch 162/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 109/300 batch 163/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 109/300 batch 164/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 109/300 batch 165/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 109/300 batch 166/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 109/300 batch 167/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 109/300 batch 168/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 109/300 batch 169/188  Train Loss: 0.073, Acc: 0.980\n",
      "epoch: 109/300 batch 170/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 109/300 batch 171/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 109/300 batch 172/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 109/300 batch 173/188  Train Loss: 0.061, Acc: 0.984\n",
      "epoch: 109/300 batch 174/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 109/300 batch 175/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 109/300 batch 176/188  Train Loss: 0.047, Acc: 0.980\n",
      "epoch: 109/300 batch 177/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 109/300 batch 178/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 109/300 batch 179/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 109/300 batch 180/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 109/300 batch 181/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 109/300 batch 182/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 109/300 batch 183/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 109/300 batch 184/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 109/300 batch 185/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 109/300 batch 186/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 109/300 batch 187/188  Train Loss: 0.045, Acc: 0.977\n",
      "Train Loss: 0.035005, Acc: 0.992\n",
      "Val Loss: 0.057546, Acc: 0.983\n",
      "epoch: 110/300 batch   0/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 110/300 batch   1/188  Train Loss: 0.062, Acc: 0.984\n",
      "epoch: 110/300 batch   2/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 110/300 batch   3/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 110/300 batch   4/188  Train Loss: 0.031, Acc: 1.000\n",
      "epoch: 110/300 batch   5/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 110/300 batch   6/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 110/300 batch   7/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 110/300 batch   8/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 110/300 batch   9/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 110/300 batch  10/188  Train Loss: 0.045, Acc: 0.996\n",
      "epoch: 110/300 batch  11/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 110/300 batch  12/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 110/300 batch  13/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 110/300 batch  14/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 110/300 batch  15/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 110/300 batch  16/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 110/300 batch  17/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 110/300 batch  18/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 110/300 batch  19/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 110/300 batch  20/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 110/300 batch  21/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 110/300 batch  22/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 110/300 batch  23/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 110/300 batch  24/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 110/300 batch  25/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 110/300 batch  26/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 110/300 batch  27/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 110/300 batch  28/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 110/300 batch  29/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 110/300 batch  30/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 110/300 batch  31/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 110/300 batch  32/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 110/300 batch  33/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 110/300 batch  34/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 110/300 batch  35/188  Train Loss: 0.066, Acc: 0.977\n",
      "epoch: 110/300 batch  36/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 110/300 batch  37/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 110/300 batch  38/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 110/300 batch  39/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 110/300 batch  40/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 110/300 batch  41/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 110/300 batch  42/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 110/300 batch  43/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 110/300 batch  44/188  Train Loss: 0.016, Acc: 0.996\n",
      "epoch: 110/300 batch  45/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 110/300 batch  46/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 110/300 batch  47/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 110/300 batch  48/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 110/300 batch  49/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 110/300 batch  50/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 110/300 batch  51/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 110/300 batch  52/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 110/300 batch  53/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 110/300 batch  54/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 110/300 batch  55/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 110/300 batch  56/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 110/300 batch  57/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 110/300 batch  58/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 110/300 batch  59/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 110/300 batch  60/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 110/300 batch  61/188  Train Loss: 0.060, Acc: 0.984\n",
      "epoch: 110/300 batch  62/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 110/300 batch  63/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 110/300 batch  64/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 110/300 batch  65/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 110/300 batch  66/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 110/300 batch  67/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 110/300 batch  68/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 110/300 batch  69/188  Train Loss: 0.061, Acc: 0.984\n",
      "epoch: 110/300 batch  70/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 110/300 batch  71/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 110/300 batch  72/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 110/300 batch  73/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 110/300 batch  74/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 110/300 batch  75/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 110/300 batch  76/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 110/300 batch  77/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 110/300 batch  78/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 110/300 batch  79/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 110/300 batch  80/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 110/300 batch  81/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 110/300 batch  82/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 110/300 batch  83/188  Train Loss: 0.047, Acc: 0.980\n",
      "epoch: 110/300 batch  84/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 110/300 batch  85/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 110/300 batch  86/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 110/300 batch  87/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 110/300 batch  88/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 110/300 batch  89/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 110/300 batch  90/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 110/300 batch  91/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 110/300 batch  92/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 110/300 batch  93/188  Train Loss: 0.072, Acc: 0.980\n",
      "epoch: 110/300 batch  94/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 110/300 batch  95/188  Train Loss: 0.059, Acc: 0.980\n",
      "epoch: 110/300 batch  96/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 110/300 batch  97/188  Train Loss: 0.054, Acc: 0.980\n",
      "epoch: 110/300 batch  98/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 110/300 batch  99/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 110/300 batch 100/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 110/300 batch 101/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 110/300 batch 102/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 110/300 batch 103/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 110/300 batch 104/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 110/300 batch 105/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 110/300 batch 106/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 110/300 batch 107/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 110/300 batch 108/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 110/300 batch 109/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 110/300 batch 110/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 110/300 batch 111/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 110/300 batch 112/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 110/300 batch 113/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 110/300 batch 114/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 110/300 batch 115/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 110/300 batch 116/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 110/300 batch 117/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 110/300 batch 118/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 110/300 batch 119/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 110/300 batch 120/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 110/300 batch 121/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 110/300 batch 122/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 110/300 batch 123/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 110/300 batch 124/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 110/300 batch 125/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 110/300 batch 126/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 110/300 batch 127/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 110/300 batch 128/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 110/300 batch 129/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 110/300 batch 130/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 110/300 batch 131/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 110/300 batch 132/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 110/300 batch 133/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 110/300 batch 134/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 110/300 batch 135/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 110/300 batch 136/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 110/300 batch 137/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 110/300 batch 138/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 110/300 batch 139/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 110/300 batch 140/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 110/300 batch 141/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 110/300 batch 142/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 110/300 batch 143/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 110/300 batch 144/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 110/300 batch 145/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 110/300 batch 146/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 110/300 batch 147/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 110/300 batch 148/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 110/300 batch 149/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 110/300 batch 150/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 110/300 batch 151/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 110/300 batch 152/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 110/300 batch 153/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 110/300 batch 154/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 110/300 batch 155/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 110/300 batch 156/188  Train Loss: 0.063, Acc: 0.973\n",
      "epoch: 110/300 batch 157/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 110/300 batch 158/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 110/300 batch 159/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 110/300 batch 160/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 110/300 batch 161/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 110/300 batch 162/188  Train Loss: 0.080, Acc: 0.977\n",
      "epoch: 110/300 batch 163/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 110/300 batch 164/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 110/300 batch 165/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 110/300 batch 166/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 110/300 batch 167/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 110/300 batch 168/188  Train Loss: 0.042, Acc: 0.980\n",
      "epoch: 110/300 batch 169/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 110/300 batch 170/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 110/300 batch 171/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 110/300 batch 172/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 110/300 batch 173/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 110/300 batch 174/188  Train Loss: 0.064, Acc: 0.988\n",
      "epoch: 110/300 batch 175/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 110/300 batch 176/188  Train Loss: 0.057, Acc: 0.992\n",
      "epoch: 110/300 batch 177/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 110/300 batch 178/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 110/300 batch 179/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 110/300 batch 180/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 110/300 batch 181/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 110/300 batch 182/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 110/300 batch 183/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 110/300 batch 184/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 110/300 batch 185/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 110/300 batch 186/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 110/300 batch 187/188  Train Loss: 0.032, Acc: 0.984\n",
      "Train Loss: 0.034975, Acc: 0.992\n",
      "Val Loss: 0.057639, Acc: 0.982\n",
      "epoch: 111/300 batch   0/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 111/300 batch   1/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 111/300 batch   2/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 111/300 batch   3/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 111/300 batch   4/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 111/300 batch   5/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 111/300 batch   6/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 111/300 batch   7/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 111/300 batch   8/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 111/300 batch   9/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 111/300 batch  10/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 111/300 batch  11/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 111/300 batch  12/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 111/300 batch  13/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 111/300 batch  14/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 111/300 batch  15/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 111/300 batch  16/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 111/300 batch  17/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 111/300 batch  18/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 111/300 batch  19/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 111/300 batch  20/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 111/300 batch  21/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 111/300 batch  22/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 111/300 batch  23/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 111/300 batch  24/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 111/300 batch  25/188  Train Loss: 0.063, Acc: 0.984\n",
      "epoch: 111/300 batch  26/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 111/300 batch  27/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 111/300 batch  28/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 111/300 batch  29/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 111/300 batch  30/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 111/300 batch  31/188  Train Loss: 0.070, Acc: 0.984\n",
      "epoch: 111/300 batch  32/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 111/300 batch  33/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 111/300 batch  34/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 111/300 batch  35/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 111/300 batch  36/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 111/300 batch  37/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 111/300 batch  38/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 111/300 batch  39/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 111/300 batch  40/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 111/300 batch  41/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 111/300 batch  42/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 111/300 batch  43/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 111/300 batch  44/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 111/300 batch  45/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 111/300 batch  46/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 111/300 batch  47/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 111/300 batch  48/188  Train Loss: 0.060, Acc: 0.992\n",
      "epoch: 111/300 batch  49/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 111/300 batch  50/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 111/300 batch  51/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 111/300 batch  52/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 111/300 batch  53/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 111/300 batch  54/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 111/300 batch  55/188  Train Loss: 0.046, Acc: 0.996\n",
      "epoch: 111/300 batch  56/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 111/300 batch  57/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 111/300 batch  58/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 111/300 batch  59/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 111/300 batch  60/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 111/300 batch  61/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 111/300 batch  62/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 111/300 batch  63/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 111/300 batch  64/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 111/300 batch  65/188  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 111/300 batch  66/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 111/300 batch  67/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 111/300 batch  68/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 111/300 batch  69/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 111/300 batch  70/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 111/300 batch  71/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 111/300 batch  72/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 111/300 batch  73/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 111/300 batch  74/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 111/300 batch  75/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 111/300 batch  76/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 111/300 batch  77/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 111/300 batch  78/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 111/300 batch  79/188  Train Loss: 0.059, Acc: 0.984\n",
      "epoch: 111/300 batch  80/188  Train Loss: 0.056, Acc: 0.992\n",
      "epoch: 111/300 batch  81/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 111/300 batch  82/188  Train Loss: 0.063, Acc: 0.980\n",
      "epoch: 111/300 batch  83/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 111/300 batch  84/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 111/300 batch  85/188  Train Loss: 0.046, Acc: 0.977\n",
      "epoch: 111/300 batch  86/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 111/300 batch  87/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 111/300 batch  88/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 111/300 batch  89/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 111/300 batch  90/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 111/300 batch  91/188  Train Loss: 0.029, Acc: 0.984\n",
      "epoch: 111/300 batch  92/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 111/300 batch  93/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 111/300 batch  94/188  Train Loss: 0.053, Acc: 0.980\n",
      "epoch: 111/300 batch  95/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 111/300 batch  96/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 111/300 batch  97/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 111/300 batch  98/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 111/300 batch  99/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 111/300 batch 100/188  Train Loss: 0.058, Acc: 0.992\n",
      "epoch: 111/300 batch 101/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 111/300 batch 102/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 111/300 batch 103/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 111/300 batch 104/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 111/300 batch 105/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 111/300 batch 106/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 111/300 batch 107/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 111/300 batch 108/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 111/300 batch 109/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 111/300 batch 110/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 111/300 batch 111/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 111/300 batch 112/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 111/300 batch 113/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 111/300 batch 114/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 111/300 batch 115/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 111/300 batch 116/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 111/300 batch 117/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 111/300 batch 118/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 111/300 batch 119/188  Train Loss: 0.047, Acc: 0.980\n",
      "epoch: 111/300 batch 120/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 111/300 batch 121/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 111/300 batch 122/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 111/300 batch 123/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 111/300 batch 124/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 111/300 batch 125/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 111/300 batch 126/188  Train Loss: 0.051, Acc: 0.980\n",
      "epoch: 111/300 batch 127/188  Train Loss: 0.030, Acc: 0.984\n",
      "epoch: 111/300 batch 128/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 111/300 batch 129/188  Train Loss: 0.061, Acc: 0.988\n",
      "epoch: 111/300 batch 130/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 111/300 batch 131/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 111/300 batch 132/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 111/300 batch 133/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 111/300 batch 134/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 111/300 batch 135/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 111/300 batch 136/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 111/300 batch 137/188  Train Loss: 0.026, Acc: 0.988\n",
      "epoch: 111/300 batch 138/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 111/300 batch 139/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 111/300 batch 140/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 111/300 batch 141/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 111/300 batch 142/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 111/300 batch 143/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 111/300 batch 144/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 111/300 batch 145/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 111/300 batch 146/188  Train Loss: 0.061, Acc: 0.973\n",
      "epoch: 111/300 batch 147/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 111/300 batch 148/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 111/300 batch 149/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 111/300 batch 150/188  Train Loss: 0.073, Acc: 0.973\n",
      "epoch: 111/300 batch 151/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 111/300 batch 152/188  Train Loss: 0.052, Acc: 0.992\n",
      "epoch: 111/300 batch 153/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 111/300 batch 154/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 111/300 batch 155/188  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 111/300 batch 156/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 111/300 batch 157/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 111/300 batch 158/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 111/300 batch 159/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 111/300 batch 160/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 111/300 batch 161/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 111/300 batch 162/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 111/300 batch 163/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 111/300 batch 164/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 111/300 batch 165/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 111/300 batch 166/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 111/300 batch 167/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 111/300 batch 168/188  Train Loss: 0.058, Acc: 0.988\n",
      "epoch: 111/300 batch 169/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 111/300 batch 170/188  Train Loss: 0.077, Acc: 0.973\n",
      "epoch: 111/300 batch 171/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 111/300 batch 172/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 111/300 batch 173/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 111/300 batch 174/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 111/300 batch 175/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 111/300 batch 176/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 111/300 batch 177/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 111/300 batch 178/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 111/300 batch 179/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 111/300 batch 180/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 111/300 batch 181/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 111/300 batch 182/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 111/300 batch 183/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 111/300 batch 184/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 111/300 batch 185/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 111/300 batch 186/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 111/300 batch 187/188  Train Loss: 0.034, Acc: 0.984\n",
      "Train Loss: 0.034927, Acc: 0.992\n",
      "Val Loss: 0.057500, Acc: 0.983\n",
      "epoch: 112/300 batch   0/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 112/300 batch   1/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 112/300 batch   2/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 112/300 batch   3/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 112/300 batch   4/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 112/300 batch   5/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 112/300 batch   6/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 112/300 batch   7/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 112/300 batch   8/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 112/300 batch   9/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 112/300 batch  10/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 112/300 batch  11/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 112/300 batch  12/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 112/300 batch  13/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 112/300 batch  14/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 112/300 batch  15/188  Train Loss: 0.031, Acc: 1.000\n",
      "epoch: 112/300 batch  16/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 112/300 batch  17/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 112/300 batch  18/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 112/300 batch  19/188  Train Loss: 0.060, Acc: 0.988\n",
      "epoch: 112/300 batch  20/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 112/300 batch  21/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 112/300 batch  22/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 112/300 batch  23/188  Train Loss: 0.053, Acc: 0.980\n",
      "epoch: 112/300 batch  24/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 112/300 batch  25/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 112/300 batch  26/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 112/300 batch  27/188  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 112/300 batch  28/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 112/300 batch  29/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 112/300 batch  30/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 112/300 batch  31/188  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 112/300 batch  32/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 112/300 batch  33/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 112/300 batch  34/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 112/300 batch  35/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 112/300 batch  36/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 112/300 batch  37/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 112/300 batch  38/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 112/300 batch  39/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 112/300 batch  40/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 112/300 batch  41/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 112/300 batch  42/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 112/300 batch  43/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 112/300 batch  44/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 112/300 batch  45/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 112/300 batch  46/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 112/300 batch  47/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 112/300 batch  48/188  Train Loss: 0.058, Acc: 0.980\n",
      "epoch: 112/300 batch  49/188  Train Loss: 0.049, Acc: 0.980\n",
      "epoch: 112/300 batch  50/188  Train Loss: 0.080, Acc: 0.980\n",
      "epoch: 112/300 batch  51/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 112/300 batch  52/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 112/300 batch  53/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 112/300 batch  54/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 112/300 batch  55/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 112/300 batch  56/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 112/300 batch  57/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 112/300 batch  58/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 112/300 batch  59/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 112/300 batch  60/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 112/300 batch  61/188  Train Loss: 0.032, Acc: 0.984\n",
      "epoch: 112/300 batch  62/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 112/300 batch  63/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 112/300 batch  64/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 112/300 batch  65/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 112/300 batch  66/188  Train Loss: 0.051, Acc: 0.980\n",
      "epoch: 112/300 batch  67/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 112/300 batch  68/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 112/300 batch  69/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 112/300 batch  70/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 112/300 batch  71/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 112/300 batch  72/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 112/300 batch  73/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 112/300 batch  74/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 112/300 batch  75/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 112/300 batch  76/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 112/300 batch  77/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 112/300 batch  78/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 112/300 batch  79/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 112/300 batch  80/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 112/300 batch  81/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 112/300 batch  82/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 112/300 batch  83/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 112/300 batch  84/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 112/300 batch  85/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 112/300 batch  86/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 112/300 batch  87/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 112/300 batch  88/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 112/300 batch  89/188  Train Loss: 0.056, Acc: 0.980\n",
      "epoch: 112/300 batch  90/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 112/300 batch  91/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 112/300 batch  92/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 112/300 batch  93/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 112/300 batch  94/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 112/300 batch  95/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 112/300 batch  96/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 112/300 batch  97/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 112/300 batch  98/188  Train Loss: 0.054, Acc: 0.977\n",
      "epoch: 112/300 batch  99/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 112/300 batch 100/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 112/300 batch 101/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 112/300 batch 102/188  Train Loss: 0.043, Acc: 0.996\n",
      "epoch: 112/300 batch 103/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 112/300 batch 104/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 112/300 batch 105/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 112/300 batch 106/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 112/300 batch 107/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 112/300 batch 108/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 112/300 batch 109/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 112/300 batch 110/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 112/300 batch 111/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 112/300 batch 112/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 112/300 batch 113/188  Train Loss: 0.026, Acc: 0.988\n",
      "epoch: 112/300 batch 114/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 112/300 batch 115/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 112/300 batch 116/188  Train Loss: 0.074, Acc: 0.977\n",
      "epoch: 112/300 batch 117/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 112/300 batch 118/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 112/300 batch 119/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 112/300 batch 120/188  Train Loss: 0.059, Acc: 0.988\n",
      "epoch: 112/300 batch 121/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 112/300 batch 122/188  Train Loss: 0.034, Acc: 0.984\n",
      "epoch: 112/300 batch 123/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 112/300 batch 124/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 112/300 batch 125/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 112/300 batch 126/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 112/300 batch 127/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 112/300 batch 128/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 112/300 batch 129/188  Train Loss: 0.067, Acc: 0.988\n",
      "epoch: 112/300 batch 130/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 112/300 batch 131/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 112/300 batch 132/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 112/300 batch 133/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 112/300 batch 134/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 112/300 batch 135/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 112/300 batch 136/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 112/300 batch 137/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 112/300 batch 138/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 112/300 batch 139/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 112/300 batch 140/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 112/300 batch 141/188  Train Loss: 0.071, Acc: 0.977\n",
      "epoch: 112/300 batch 142/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 112/300 batch 143/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 112/300 batch 144/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 112/300 batch 145/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 112/300 batch 146/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 112/300 batch 147/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 112/300 batch 148/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 112/300 batch 149/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 112/300 batch 150/188  Train Loss: 0.054, Acc: 0.980\n",
      "epoch: 112/300 batch 151/188  Train Loss: 0.020, Acc: 0.988\n",
      "epoch: 112/300 batch 152/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 112/300 batch 153/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 112/300 batch 154/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 112/300 batch 155/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 112/300 batch 156/188  Train Loss: 0.043, Acc: 0.996\n",
      "epoch: 112/300 batch 157/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 112/300 batch 158/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 112/300 batch 159/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 112/300 batch 160/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 112/300 batch 161/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 112/300 batch 162/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 112/300 batch 163/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 112/300 batch 164/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 112/300 batch 165/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 112/300 batch 166/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 112/300 batch 167/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 112/300 batch 168/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 112/300 batch 169/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 112/300 batch 170/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 112/300 batch 171/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 112/300 batch 172/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 112/300 batch 173/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 112/300 batch 174/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 112/300 batch 175/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 112/300 batch 176/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 112/300 batch 177/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 112/300 batch 178/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 112/300 batch 179/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 112/300 batch 180/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 112/300 batch 181/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 112/300 batch 182/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 112/300 batch 183/188  Train Loss: 0.053, Acc: 0.992\n",
      "epoch: 112/300 batch 184/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 112/300 batch 185/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 112/300 batch 186/188  Train Loss: 0.056, Acc: 0.973\n",
      "epoch: 112/300 batch 187/188  Train Loss: 0.034, Acc: 0.992\n",
      "Train Loss: 0.034925, Acc: 0.992\n",
      "Val Loss: 0.057830, Acc: 0.982\n",
      "epoch: 113/300 batch   0/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 113/300 batch   1/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 113/300 batch   2/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 113/300 batch   3/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 113/300 batch   4/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 113/300 batch   5/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 113/300 batch   6/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 113/300 batch   7/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 113/300 batch   8/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 113/300 batch   9/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 113/300 batch  10/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 113/300 batch  11/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 113/300 batch  12/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 113/300 batch  13/188  Train Loss: 0.042, Acc: 0.996\n",
      "epoch: 113/300 batch  14/188  Train Loss: 0.044, Acc: 0.996\n",
      "epoch: 113/300 batch  15/188  Train Loss: 0.072, Acc: 0.988\n",
      "epoch: 113/300 batch  16/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 113/300 batch  17/188  Train Loss: 0.063, Acc: 0.984\n",
      "epoch: 113/300 batch  18/188  Train Loss: 0.056, Acc: 0.988\n",
      "epoch: 113/300 batch  19/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 113/300 batch  20/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 113/300 batch  21/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 113/300 batch  22/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 113/300 batch  23/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 113/300 batch  24/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 113/300 batch  25/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 113/300 batch  26/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 113/300 batch  27/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 113/300 batch  28/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 113/300 batch  29/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 113/300 batch  30/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 113/300 batch  31/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 113/300 batch  32/188  Train Loss: 0.052, Acc: 0.996\n",
      "epoch: 113/300 batch  33/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 113/300 batch  34/188  Train Loss: 0.046, Acc: 0.980\n",
      "epoch: 113/300 batch  35/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 113/300 batch  36/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 113/300 batch  37/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 113/300 batch  38/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 113/300 batch  39/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 113/300 batch  40/188  Train Loss: 0.034, Acc: 1.000\n",
      "epoch: 113/300 batch  41/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 113/300 batch  42/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 113/300 batch  43/188  Train Loss: 0.081, Acc: 0.988\n",
      "epoch: 113/300 batch  44/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 113/300 batch  45/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 113/300 batch  46/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 113/300 batch  47/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 113/300 batch  48/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 113/300 batch  49/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 113/300 batch  50/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 113/300 batch  51/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 113/300 batch  52/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 113/300 batch  53/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 113/300 batch  54/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 113/300 batch  55/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 113/300 batch  56/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 113/300 batch  57/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 113/300 batch  58/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 113/300 batch  59/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 113/300 batch  60/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 113/300 batch  61/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 113/300 batch  62/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 113/300 batch  63/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 113/300 batch  64/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 113/300 batch  65/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 113/300 batch  66/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 113/300 batch  67/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 113/300 batch  68/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 113/300 batch  69/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 113/300 batch  70/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 113/300 batch  71/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 113/300 batch  72/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 113/300 batch  73/188  Train Loss: 0.054, Acc: 0.992\n",
      "epoch: 113/300 batch  74/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 113/300 batch  75/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 113/300 batch  76/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 113/300 batch  77/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 113/300 batch  78/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 113/300 batch  79/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 113/300 batch  80/188  Train Loss: 0.046, Acc: 0.996\n",
      "epoch: 113/300 batch  81/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 113/300 batch  82/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 113/300 batch  83/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 113/300 batch  84/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 113/300 batch  85/188  Train Loss: 0.045, Acc: 0.996\n",
      "epoch: 113/300 batch  86/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 113/300 batch  87/188  Train Loss: 0.053, Acc: 0.980\n",
      "epoch: 113/300 batch  88/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 113/300 batch  89/188  Train Loss: 0.042, Acc: 0.980\n",
      "epoch: 113/300 batch  90/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 113/300 batch  91/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 113/300 batch  92/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 113/300 batch  93/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 113/300 batch  94/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 113/300 batch  95/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 113/300 batch  96/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 113/300 batch  97/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 113/300 batch  98/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 113/300 batch  99/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 113/300 batch 100/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 113/300 batch 101/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 113/300 batch 102/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 113/300 batch 103/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 113/300 batch 104/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 113/300 batch 105/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 113/300 batch 106/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 113/300 batch 107/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 113/300 batch 108/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 113/300 batch 109/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 113/300 batch 110/188  Train Loss: 0.059, Acc: 0.992\n",
      "epoch: 113/300 batch 111/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 113/300 batch 112/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 113/300 batch 113/188  Train Loss: 0.044, Acc: 0.996\n",
      "epoch: 113/300 batch 114/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 113/300 batch 115/188  Train Loss: 0.065, Acc: 0.973\n",
      "epoch: 113/300 batch 116/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 113/300 batch 117/188  Train Loss: 0.057, Acc: 0.988\n",
      "epoch: 113/300 batch 118/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 113/300 batch 119/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 113/300 batch 120/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 113/300 batch 121/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 113/300 batch 122/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 113/300 batch 123/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 113/300 batch 124/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 113/300 batch 125/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 113/300 batch 126/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 113/300 batch 127/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 113/300 batch 128/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 113/300 batch 129/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 113/300 batch 130/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 113/300 batch 131/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 113/300 batch 132/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 113/300 batch 133/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 113/300 batch 134/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 113/300 batch 135/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 113/300 batch 136/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 113/300 batch 137/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 113/300 batch 138/188  Train Loss: 0.061, Acc: 0.984\n",
      "epoch: 113/300 batch 139/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 113/300 batch 140/188  Train Loss: 0.062, Acc: 0.973\n",
      "epoch: 113/300 batch 141/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 113/300 batch 142/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 113/300 batch 143/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 113/300 batch 144/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 113/300 batch 145/188  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 113/300 batch 146/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 113/300 batch 147/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 113/300 batch 148/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 113/300 batch 149/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 113/300 batch 150/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 113/300 batch 151/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 113/300 batch 152/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 113/300 batch 153/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 113/300 batch 154/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 113/300 batch 155/188  Train Loss: 0.052, Acc: 0.980\n",
      "epoch: 113/300 batch 156/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 113/300 batch 157/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 113/300 batch 158/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 113/300 batch 159/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 113/300 batch 160/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 113/300 batch 161/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 113/300 batch 162/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 113/300 batch 163/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 113/300 batch 164/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 113/300 batch 165/188  Train Loss: 0.052, Acc: 0.992\n",
      "epoch: 113/300 batch 166/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 113/300 batch 167/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 113/300 batch 168/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 113/300 batch 169/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 113/300 batch 170/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 113/300 batch 171/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 113/300 batch 172/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 113/300 batch 173/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 113/300 batch 174/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 113/300 batch 175/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 113/300 batch 176/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 113/300 batch 177/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 113/300 batch 178/188  Train Loss: 0.062, Acc: 0.977\n",
      "epoch: 113/300 batch 179/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 113/300 batch 180/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 113/300 batch 181/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 113/300 batch 182/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 113/300 batch 183/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 113/300 batch 184/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 113/300 batch 185/188  Train Loss: 0.053, Acc: 0.980\n",
      "epoch: 113/300 batch 186/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 113/300 batch 187/188  Train Loss: 0.015, Acc: 1.000\n",
      "Train Loss: 0.034771, Acc: 0.992\n",
      "Val Loss: 0.057560, Acc: 0.982\n",
      "epoch: 114/300 batch   0/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 114/300 batch   1/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 114/300 batch   2/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 114/300 batch   3/188  Train Loss: 0.072, Acc: 0.973\n",
      "epoch: 114/300 batch   4/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 114/300 batch   5/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 114/300 batch   6/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 114/300 batch   7/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 114/300 batch   8/188  Train Loss: 0.055, Acc: 0.980\n",
      "epoch: 114/300 batch   9/188  Train Loss: 0.050, Acc: 0.980\n",
      "epoch: 114/300 batch  10/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 114/300 batch  11/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 114/300 batch  12/188  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 114/300 batch  13/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 114/300 batch  14/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 114/300 batch  15/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 114/300 batch  16/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 114/300 batch  17/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 114/300 batch  18/188  Train Loss: 0.033, Acc: 0.980\n",
      "epoch: 114/300 batch  19/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 114/300 batch  20/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 114/300 batch  21/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 114/300 batch  22/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 114/300 batch  23/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 114/300 batch  24/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 114/300 batch  25/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 114/300 batch  26/188  Train Loss: 0.061, Acc: 0.969\n",
      "epoch: 114/300 batch  27/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 114/300 batch  28/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 114/300 batch  29/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 114/300 batch  30/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 114/300 batch  31/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 114/300 batch  32/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 114/300 batch  33/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 114/300 batch  34/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 114/300 batch  35/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 114/300 batch  36/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 114/300 batch  37/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 114/300 batch  38/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 114/300 batch  39/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 114/300 batch  40/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 114/300 batch  41/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 114/300 batch  42/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 114/300 batch  43/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 114/300 batch  44/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 114/300 batch  45/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 114/300 batch  46/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 114/300 batch  47/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 114/300 batch  48/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 114/300 batch  49/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 114/300 batch  50/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 114/300 batch  51/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 114/300 batch  52/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 114/300 batch  53/188  Train Loss: 0.059, Acc: 0.984\n",
      "epoch: 114/300 batch  54/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 114/300 batch  55/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 114/300 batch  56/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 114/300 batch  57/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 114/300 batch  58/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 114/300 batch  59/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 114/300 batch  60/188  Train Loss: 0.054, Acc: 0.980\n",
      "epoch: 114/300 batch  61/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 114/300 batch  62/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 114/300 batch  63/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 114/300 batch  64/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 114/300 batch  65/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 114/300 batch  66/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 114/300 batch  67/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 114/300 batch  68/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 114/300 batch  69/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 114/300 batch  70/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 114/300 batch  71/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 114/300 batch  72/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 114/300 batch  73/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 114/300 batch  74/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 114/300 batch  75/188  Train Loss: 0.055, Acc: 0.980\n",
      "epoch: 114/300 batch  76/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 114/300 batch  77/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 114/300 batch  78/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 114/300 batch  79/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 114/300 batch  80/188  Train Loss: 0.042, Acc: 0.996\n",
      "epoch: 114/300 batch  81/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 114/300 batch  82/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 114/300 batch  83/188  Train Loss: 0.064, Acc: 0.973\n",
      "epoch: 114/300 batch  84/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 114/300 batch  85/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 114/300 batch  86/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 114/300 batch  87/188  Train Loss: 0.062, Acc: 0.980\n",
      "epoch: 114/300 batch  88/188  Train Loss: 0.029, Acc: 0.984\n",
      "epoch: 114/300 batch  89/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 114/300 batch  90/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 114/300 batch  91/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 114/300 batch  92/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 114/300 batch  93/188  Train Loss: 0.043, Acc: 0.980\n",
      "epoch: 114/300 batch  94/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 114/300 batch  95/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 114/300 batch  96/188  Train Loss: 0.016, Acc: 0.996\n",
      "epoch: 114/300 batch  97/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 114/300 batch  98/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 114/300 batch  99/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 114/300 batch 100/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 114/300 batch 101/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 114/300 batch 102/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 114/300 batch 103/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 114/300 batch 104/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 114/300 batch 105/188  Train Loss: 0.047, Acc: 0.980\n",
      "epoch: 114/300 batch 106/188  Train Loss: 0.054, Acc: 0.992\n",
      "epoch: 114/300 batch 107/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 114/300 batch 108/188  Train Loss: 0.057, Acc: 0.980\n",
      "epoch: 114/300 batch 109/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 114/300 batch 110/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 114/300 batch 111/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 114/300 batch 112/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 114/300 batch 113/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 114/300 batch 114/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 114/300 batch 115/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 114/300 batch 116/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 114/300 batch 117/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 114/300 batch 118/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 114/300 batch 119/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 114/300 batch 120/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 114/300 batch 121/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 114/300 batch 122/188  Train Loss: 0.027, Acc: 0.988\n",
      "epoch: 114/300 batch 123/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 114/300 batch 124/188  Train Loss: 0.043, Acc: 0.980\n",
      "epoch: 114/300 batch 125/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 114/300 batch 126/188  Train Loss: 0.043, Acc: 0.980\n",
      "epoch: 114/300 batch 127/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 114/300 batch 128/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 114/300 batch 129/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 114/300 batch 130/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 114/300 batch 131/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 114/300 batch 132/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 114/300 batch 133/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 114/300 batch 134/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 114/300 batch 135/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 114/300 batch 136/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 114/300 batch 137/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 114/300 batch 138/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 114/300 batch 139/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 114/300 batch 140/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 114/300 batch 141/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 114/300 batch 142/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 114/300 batch 143/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 114/300 batch 144/188  Train Loss: 0.061, Acc: 0.980\n",
      "epoch: 114/300 batch 145/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 114/300 batch 146/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 114/300 batch 147/188  Train Loss: 0.065, Acc: 0.980\n",
      "epoch: 114/300 batch 148/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 114/300 batch 149/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 114/300 batch 150/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 114/300 batch 151/188  Train Loss: 0.062, Acc: 0.977\n",
      "epoch: 114/300 batch 152/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 114/300 batch 153/188  Train Loss: 0.065, Acc: 0.984\n",
      "epoch: 114/300 batch 154/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 114/300 batch 155/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 114/300 batch 156/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 114/300 batch 157/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 114/300 batch 158/188  Train Loss: 0.058, Acc: 0.996\n",
      "epoch: 114/300 batch 159/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 114/300 batch 160/188  Train Loss: 0.057, Acc: 0.980\n",
      "epoch: 114/300 batch 161/188  Train Loss: 0.051, Acc: 0.992\n",
      "epoch: 114/300 batch 162/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 114/300 batch 163/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 114/300 batch 164/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 114/300 batch 165/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 114/300 batch 166/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 114/300 batch 167/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 114/300 batch 168/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 114/300 batch 169/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 114/300 batch 170/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 114/300 batch 171/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 114/300 batch 172/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 114/300 batch 173/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 114/300 batch 174/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 114/300 batch 175/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 114/300 batch 176/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 114/300 batch 177/188  Train Loss: 0.072, Acc: 0.984\n",
      "epoch: 114/300 batch 178/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 114/300 batch 179/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 114/300 batch 180/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 114/300 batch 181/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 114/300 batch 182/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 114/300 batch 183/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 114/300 batch 184/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 114/300 batch 185/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 114/300 batch 186/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 114/300 batch 187/188  Train Loss: 0.012, Acc: 1.000\n",
      "Train Loss: 0.034762, Acc: 0.992\n",
      "Val Loss: 0.057580, Acc: 0.983\n",
      "epoch: 115/300 batch   0/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 115/300 batch   1/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 115/300 batch   2/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 115/300 batch   3/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 115/300 batch   4/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 115/300 batch   5/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 115/300 batch   6/188  Train Loss: 0.061, Acc: 0.988\n",
      "epoch: 115/300 batch   7/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 115/300 batch   8/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 115/300 batch   9/188  Train Loss: 0.063, Acc: 0.977\n",
      "epoch: 115/300 batch  10/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 115/300 batch  11/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 115/300 batch  12/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 115/300 batch  13/188  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 115/300 batch  14/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 115/300 batch  15/188  Train Loss: 0.067, Acc: 0.992\n",
      "epoch: 115/300 batch  16/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 115/300 batch  17/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 115/300 batch  18/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 115/300 batch  19/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 115/300 batch  20/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 115/300 batch  21/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 115/300 batch  22/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 115/300 batch  23/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 115/300 batch  24/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 115/300 batch  25/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 115/300 batch  26/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 115/300 batch  27/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 115/300 batch  28/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 115/300 batch  29/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 115/300 batch  30/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 115/300 batch  31/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 115/300 batch  32/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 115/300 batch  33/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 115/300 batch  34/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 115/300 batch  35/188  Train Loss: 0.062, Acc: 0.980\n",
      "epoch: 115/300 batch  36/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 115/300 batch  37/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 115/300 batch  38/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 115/300 batch  39/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 115/300 batch  40/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 115/300 batch  41/188  Train Loss: 0.045, Acc: 0.980\n",
      "epoch: 115/300 batch  42/188  Train Loss: 0.049, Acc: 0.980\n",
      "epoch: 115/300 batch  43/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 115/300 batch  44/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 115/300 batch  45/188  Train Loss: 0.045, Acc: 0.977\n",
      "epoch: 115/300 batch  46/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 115/300 batch  47/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 115/300 batch  48/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 115/300 batch  49/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 115/300 batch  50/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 115/300 batch  51/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 115/300 batch  52/188  Train Loss: 0.063, Acc: 0.984\n",
      "epoch: 115/300 batch  53/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 115/300 batch  54/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 115/300 batch  55/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 115/300 batch  56/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 115/300 batch  57/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 115/300 batch  58/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 115/300 batch  59/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 115/300 batch  60/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 115/300 batch  61/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 115/300 batch  62/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 115/300 batch  63/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 115/300 batch  64/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 115/300 batch  65/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 115/300 batch  66/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 115/300 batch  67/188  Train Loss: 0.062, Acc: 0.984\n",
      "epoch: 115/300 batch  68/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 115/300 batch  69/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 115/300 batch  70/188  Train Loss: 0.054, Acc: 0.980\n",
      "epoch: 115/300 batch  71/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 115/300 batch  72/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 115/300 batch  73/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 115/300 batch  74/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 115/300 batch  75/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 115/300 batch  76/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 115/300 batch  77/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 115/300 batch  78/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 115/300 batch  79/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 115/300 batch  80/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 115/300 batch  81/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 115/300 batch  82/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 115/300 batch  83/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 115/300 batch  84/188  Train Loss: 0.044, Acc: 0.996\n",
      "epoch: 115/300 batch  85/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 115/300 batch  86/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 115/300 batch  87/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 115/300 batch  88/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 115/300 batch  89/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 115/300 batch  90/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 115/300 batch  91/188  Train Loss: 0.077, Acc: 0.977\n",
      "epoch: 115/300 batch  92/188  Train Loss: 0.042, Acc: 0.996\n",
      "epoch: 115/300 batch  93/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 115/300 batch  94/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 115/300 batch  95/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 115/300 batch  96/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 115/300 batch  97/188  Train Loss: 0.033, Acc: 0.984\n",
      "epoch: 115/300 batch  98/188  Train Loss: 0.061, Acc: 0.980\n",
      "epoch: 115/300 batch  99/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 115/300 batch 100/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 115/300 batch 101/188  Train Loss: 0.012, Acc: 0.996\n",
      "epoch: 115/300 batch 102/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 115/300 batch 103/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 115/300 batch 104/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 115/300 batch 105/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 115/300 batch 106/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 115/300 batch 107/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 115/300 batch 108/188  Train Loss: 0.051, Acc: 0.980\n",
      "epoch: 115/300 batch 109/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 115/300 batch 110/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 115/300 batch 111/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 115/300 batch 112/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 115/300 batch 113/188  Train Loss: 0.060, Acc: 0.984\n",
      "epoch: 115/300 batch 114/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 115/300 batch 115/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 115/300 batch 116/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 115/300 batch 117/188  Train Loss: 0.059, Acc: 0.980\n",
      "epoch: 115/300 batch 118/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 115/300 batch 119/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 115/300 batch 120/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 115/300 batch 121/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 115/300 batch 122/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 115/300 batch 123/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 115/300 batch 124/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 115/300 batch 125/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 115/300 batch 126/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 115/300 batch 127/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 115/300 batch 128/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 115/300 batch 129/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 115/300 batch 130/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 115/300 batch 131/188  Train Loss: 0.073, Acc: 0.984\n",
      "epoch: 115/300 batch 132/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 115/300 batch 133/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 115/300 batch 134/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 115/300 batch 135/188  Train Loss: 0.056, Acc: 0.988\n",
      "epoch: 115/300 batch 136/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 115/300 batch 137/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 115/300 batch 138/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 115/300 batch 139/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 115/300 batch 140/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 115/300 batch 141/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 115/300 batch 142/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 115/300 batch 143/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 115/300 batch 144/188  Train Loss: 0.048, Acc: 0.996\n",
      "epoch: 115/300 batch 145/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 115/300 batch 146/188  Train Loss: 0.070, Acc: 0.992\n",
      "epoch: 115/300 batch 147/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 115/300 batch 148/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 115/300 batch 149/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 115/300 batch 150/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 115/300 batch 151/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 115/300 batch 152/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 115/300 batch 153/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 115/300 batch 154/188  Train Loss: 0.058, Acc: 0.980\n",
      "epoch: 115/300 batch 155/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 115/300 batch 156/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 115/300 batch 157/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 115/300 batch 158/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 115/300 batch 159/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 115/300 batch 160/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 115/300 batch 161/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 115/300 batch 162/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 115/300 batch 163/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 115/300 batch 164/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 115/300 batch 165/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 115/300 batch 166/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 115/300 batch 167/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 115/300 batch 168/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 115/300 batch 169/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 115/300 batch 170/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 115/300 batch 171/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 115/300 batch 172/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 115/300 batch 173/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 115/300 batch 174/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 115/300 batch 175/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 115/300 batch 176/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 115/300 batch 177/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 115/300 batch 178/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 115/300 batch 179/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 115/300 batch 180/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 115/300 batch 181/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 115/300 batch 182/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 115/300 batch 183/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 115/300 batch 184/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 115/300 batch 185/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 115/300 batch 186/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 115/300 batch 187/188  Train Loss: 0.022, Acc: 1.000\n",
      "Train Loss: 0.034851, Acc: 0.992\n",
      "Val Loss: 0.057308, Acc: 0.982\n",
      "epoch: 116/300 batch   0/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 116/300 batch   1/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 116/300 batch   2/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 116/300 batch   3/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 116/300 batch   4/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 116/300 batch   5/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 116/300 batch   6/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 116/300 batch   7/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 116/300 batch   8/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 116/300 batch   9/188  Train Loss: 0.055, Acc: 0.992\n",
      "epoch: 116/300 batch  10/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 116/300 batch  11/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 116/300 batch  12/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 116/300 batch  13/188  Train Loss: 0.076, Acc: 0.977\n",
      "epoch: 116/300 batch  14/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 116/300 batch  15/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 116/300 batch  16/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 116/300 batch  17/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 116/300 batch  18/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 116/300 batch  19/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 116/300 batch  20/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 116/300 batch  21/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 116/300 batch  22/188  Train Loss: 0.059, Acc: 0.988\n",
      "epoch: 116/300 batch  23/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 116/300 batch  24/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 116/300 batch  25/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 116/300 batch  26/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 116/300 batch  27/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 116/300 batch  28/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 116/300 batch  29/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 116/300 batch  30/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 116/300 batch  31/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 116/300 batch  32/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 116/300 batch  33/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 116/300 batch  34/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 116/300 batch  35/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 116/300 batch  36/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 116/300 batch  37/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 116/300 batch  38/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 116/300 batch  39/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 116/300 batch  40/188  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 116/300 batch  41/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 116/300 batch  42/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 116/300 batch  43/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 116/300 batch  44/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 116/300 batch  45/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 116/300 batch  46/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 116/300 batch  47/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 116/300 batch  48/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 116/300 batch  49/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 116/300 batch  50/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 116/300 batch  51/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 116/300 batch  52/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 116/300 batch  53/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 116/300 batch  54/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 116/300 batch  55/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 116/300 batch  56/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 116/300 batch  57/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 116/300 batch  58/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 116/300 batch  59/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 116/300 batch  60/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 116/300 batch  61/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 116/300 batch  62/188  Train Loss: 0.054, Acc: 0.992\n",
      "epoch: 116/300 batch  63/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 116/300 batch  64/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 116/300 batch  65/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 116/300 batch  66/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 116/300 batch  67/188  Train Loss: 0.057, Acc: 0.988\n",
      "epoch: 116/300 batch  68/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 116/300 batch  69/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 116/300 batch  70/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 116/300 batch  71/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 116/300 batch  72/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 116/300 batch  73/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 116/300 batch  74/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 116/300 batch  75/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 116/300 batch  76/188  Train Loss: 0.052, Acc: 0.977\n",
      "epoch: 116/300 batch  77/188  Train Loss: 0.061, Acc: 0.977\n",
      "epoch: 116/300 batch  78/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 116/300 batch  79/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 116/300 batch  80/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 116/300 batch  81/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 116/300 batch  82/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 116/300 batch  83/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 116/300 batch  84/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 116/300 batch  85/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 116/300 batch  86/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 116/300 batch  87/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 116/300 batch  88/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 116/300 batch  89/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 116/300 batch  90/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 116/300 batch  91/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 116/300 batch  92/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 116/300 batch  93/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 116/300 batch  94/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 116/300 batch  95/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 116/300 batch  96/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 116/300 batch  97/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 116/300 batch  98/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 116/300 batch  99/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 116/300 batch 100/188  Train Loss: 0.064, Acc: 0.988\n",
      "epoch: 116/300 batch 101/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 116/300 batch 102/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 116/300 batch 103/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 116/300 batch 104/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 116/300 batch 105/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 116/300 batch 106/188  Train Loss: 0.057, Acc: 0.988\n",
      "epoch: 116/300 batch 107/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 116/300 batch 108/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 116/300 batch 109/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 116/300 batch 110/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 116/300 batch 111/188  Train Loss: 0.104, Acc: 0.973\n",
      "epoch: 116/300 batch 112/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 116/300 batch 113/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 116/300 batch 114/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 116/300 batch 115/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 116/300 batch 116/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 116/300 batch 117/188  Train Loss: 0.059, Acc: 0.984\n",
      "epoch: 116/300 batch 118/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 116/300 batch 119/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 116/300 batch 120/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 116/300 batch 121/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 116/300 batch 122/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 116/300 batch 123/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 116/300 batch 124/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 116/300 batch 125/188  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 116/300 batch 126/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 116/300 batch 127/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 116/300 batch 128/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 116/300 batch 129/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 116/300 batch 130/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 116/300 batch 131/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 116/300 batch 132/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 116/300 batch 133/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 116/300 batch 134/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 116/300 batch 135/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 116/300 batch 136/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 116/300 batch 137/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 116/300 batch 138/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 116/300 batch 139/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 116/300 batch 140/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 116/300 batch 141/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 116/300 batch 142/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 116/300 batch 143/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 116/300 batch 144/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 116/300 batch 145/188  Train Loss: 0.060, Acc: 0.977\n",
      "epoch: 116/300 batch 146/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 116/300 batch 147/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 116/300 batch 148/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 116/300 batch 149/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 116/300 batch 150/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 116/300 batch 151/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 116/300 batch 152/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 116/300 batch 153/188  Train Loss: 0.032, Acc: 0.984\n",
      "epoch: 116/300 batch 154/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 116/300 batch 155/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 116/300 batch 156/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 116/300 batch 157/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 116/300 batch 158/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 116/300 batch 159/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 116/300 batch 160/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 116/300 batch 161/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 116/300 batch 162/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 116/300 batch 163/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 116/300 batch 164/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 116/300 batch 165/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 116/300 batch 166/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 116/300 batch 167/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 116/300 batch 168/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 116/300 batch 169/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 116/300 batch 170/188  Train Loss: 0.082, Acc: 0.973\n",
      "epoch: 116/300 batch 171/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 116/300 batch 172/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 116/300 batch 173/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 116/300 batch 174/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 116/300 batch 175/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 116/300 batch 176/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 116/300 batch 177/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 116/300 batch 178/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 116/300 batch 179/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 116/300 batch 180/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 116/300 batch 181/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 116/300 batch 182/188  Train Loss: 0.091, Acc: 0.977\n",
      "epoch: 116/300 batch 183/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 116/300 batch 184/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 116/300 batch 185/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 116/300 batch 186/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 116/300 batch 187/188  Train Loss: 0.035, Acc: 0.984\n",
      "Train Loss: 0.034756, Acc: 0.992\n",
      "Val Loss: 0.057996, Acc: 0.982\n",
      "epoch: 117/300 batch   0/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 117/300 batch   1/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 117/300 batch   2/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 117/300 batch   3/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 117/300 batch   4/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 117/300 batch   5/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 117/300 batch   6/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 117/300 batch   7/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 117/300 batch   8/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 117/300 batch   9/188  Train Loss: 0.059, Acc: 0.980\n",
      "epoch: 117/300 batch  10/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 117/300 batch  11/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 117/300 batch  12/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 117/300 batch  13/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 117/300 batch  14/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 117/300 batch  15/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 117/300 batch  16/188  Train Loss: 0.049, Acc: 0.977\n",
      "epoch: 117/300 batch  17/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 117/300 batch  18/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 117/300 batch  19/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 117/300 batch  20/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 117/300 batch  21/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 117/300 batch  22/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 117/300 batch  23/188  Train Loss: 0.043, Acc: 0.996\n",
      "epoch: 117/300 batch  24/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 117/300 batch  25/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 117/300 batch  26/188  Train Loss: 0.056, Acc: 0.996\n",
      "epoch: 117/300 batch  27/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 117/300 batch  28/188  Train Loss: 0.043, Acc: 0.996\n",
      "epoch: 117/300 batch  29/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 117/300 batch  30/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 117/300 batch  31/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 117/300 batch  32/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 117/300 batch  33/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 117/300 batch  34/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 117/300 batch  35/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 117/300 batch  36/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 117/300 batch  37/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 117/300 batch  38/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 117/300 batch  39/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 117/300 batch  40/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 117/300 batch  41/188  Train Loss: 0.041, Acc: 0.980\n",
      "epoch: 117/300 batch  42/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 117/300 batch  43/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 117/300 batch  44/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 117/300 batch  45/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 117/300 batch  46/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 117/300 batch  47/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 117/300 batch  48/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 117/300 batch  49/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 117/300 batch  50/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 117/300 batch  51/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 117/300 batch  52/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 117/300 batch  53/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 117/300 batch  54/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 117/300 batch  55/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 117/300 batch  56/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 117/300 batch  57/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 117/300 batch  58/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 117/300 batch  59/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 117/300 batch  60/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 117/300 batch  61/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 117/300 batch  62/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 117/300 batch  63/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 117/300 batch  64/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 117/300 batch  65/188  Train Loss: 0.043, Acc: 0.980\n",
      "epoch: 117/300 batch  66/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 117/300 batch  67/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 117/300 batch  68/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 117/300 batch  69/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 117/300 batch  70/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 117/300 batch  71/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 117/300 batch  72/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 117/300 batch  73/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 117/300 batch  74/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 117/300 batch  75/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 117/300 batch  76/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 117/300 batch  77/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 117/300 batch  78/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 117/300 batch  79/188  Train Loss: 0.042, Acc: 0.996\n",
      "epoch: 117/300 batch  80/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 117/300 batch  81/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 117/300 batch  82/188  Train Loss: 0.043, Acc: 0.980\n",
      "epoch: 117/300 batch  83/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 117/300 batch  84/188  Train Loss: 0.053, Acc: 0.980\n",
      "epoch: 117/300 batch  85/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 117/300 batch  86/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 117/300 batch  87/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 117/300 batch  88/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 117/300 batch  89/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 117/300 batch  90/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 117/300 batch  91/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 117/300 batch  92/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 117/300 batch  93/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 117/300 batch  94/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 117/300 batch  95/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 117/300 batch  96/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 117/300 batch  97/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 117/300 batch  98/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 117/300 batch  99/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 117/300 batch 100/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 117/300 batch 101/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 117/300 batch 102/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 117/300 batch 103/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 117/300 batch 104/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 117/300 batch 105/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 117/300 batch 106/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 117/300 batch 107/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 117/300 batch 108/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 117/300 batch 109/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 117/300 batch 110/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 117/300 batch 111/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 117/300 batch 112/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 117/300 batch 113/188  Train Loss: 0.038, Acc: 1.000\n",
      "epoch: 117/300 batch 114/188  Train Loss: 0.060, Acc: 0.992\n",
      "epoch: 117/300 batch 115/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 117/300 batch 116/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 117/300 batch 117/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 117/300 batch 118/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 117/300 batch 119/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 117/300 batch 120/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 117/300 batch 121/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 117/300 batch 122/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 117/300 batch 123/188  Train Loss: 0.088, Acc: 0.980\n",
      "epoch: 117/300 batch 124/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 117/300 batch 125/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 117/300 batch 126/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 117/300 batch 127/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 117/300 batch 128/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 117/300 batch 129/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 117/300 batch 130/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 117/300 batch 131/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 117/300 batch 132/188  Train Loss: 0.026, Acc: 0.988\n",
      "epoch: 117/300 batch 133/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 117/300 batch 134/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 117/300 batch 135/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 117/300 batch 136/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 117/300 batch 137/188  Train Loss: 0.050, Acc: 0.977\n",
      "epoch: 117/300 batch 138/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 117/300 batch 139/188  Train Loss: 0.049, Acc: 0.977\n",
      "epoch: 117/300 batch 140/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 117/300 batch 141/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 117/300 batch 142/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 117/300 batch 143/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 117/300 batch 144/188  Train Loss: 0.057, Acc: 0.977\n",
      "epoch: 117/300 batch 145/188  Train Loss: 0.049, Acc: 0.980\n",
      "epoch: 117/300 batch 146/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 117/300 batch 147/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 117/300 batch 148/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 117/300 batch 149/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 117/300 batch 150/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 117/300 batch 151/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 117/300 batch 152/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 117/300 batch 153/188  Train Loss: 0.052, Acc: 0.977\n",
      "epoch: 117/300 batch 154/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 117/300 batch 155/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 117/300 batch 156/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 117/300 batch 157/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 117/300 batch 158/188  Train Loss: 0.072, Acc: 0.984\n",
      "epoch: 117/300 batch 159/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 117/300 batch 160/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 117/300 batch 161/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 117/300 batch 162/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 117/300 batch 163/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 117/300 batch 164/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 117/300 batch 165/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 117/300 batch 166/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 117/300 batch 167/188  Train Loss: 0.040, Acc: 0.980\n",
      "epoch: 117/300 batch 168/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 117/300 batch 169/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 117/300 batch 170/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 117/300 batch 171/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 117/300 batch 172/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 117/300 batch 173/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 117/300 batch 174/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 117/300 batch 175/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 117/300 batch 176/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 117/300 batch 177/188  Train Loss: 0.053, Acc: 0.992\n",
      "epoch: 117/300 batch 178/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 117/300 batch 179/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 117/300 batch 180/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 117/300 batch 181/188  Train Loss: 0.047, Acc: 0.980\n",
      "epoch: 117/300 batch 182/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 117/300 batch 183/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 117/300 batch 184/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 117/300 batch 185/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 117/300 batch 186/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 117/300 batch 187/188  Train Loss: 0.031, Acc: 1.000\n",
      "Train Loss: 0.034766, Acc: 0.992\n",
      "Val Loss: 0.057903, Acc: 0.982\n",
      "epoch: 118/300 batch   0/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 118/300 batch   1/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 118/300 batch   2/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 118/300 batch   3/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 118/300 batch   4/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 118/300 batch   5/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 118/300 batch   6/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 118/300 batch   7/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 118/300 batch   8/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 118/300 batch   9/188  Train Loss: 0.076, Acc: 0.977\n",
      "epoch: 118/300 batch  10/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 118/300 batch  11/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 118/300 batch  12/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 118/300 batch  13/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 118/300 batch  14/188  Train Loss: 0.082, Acc: 0.973\n",
      "epoch: 118/300 batch  15/188  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 118/300 batch  16/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 118/300 batch  17/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 118/300 batch  18/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 118/300 batch  19/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 118/300 batch  20/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 118/300 batch  21/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 118/300 batch  22/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 118/300 batch  23/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 118/300 batch  24/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 118/300 batch  25/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 118/300 batch  26/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 118/300 batch  27/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 118/300 batch  28/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 118/300 batch  29/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 118/300 batch  30/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 118/300 batch  31/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 118/300 batch  32/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 118/300 batch  33/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 118/300 batch  34/188  Train Loss: 0.032, Acc: 0.984\n",
      "epoch: 118/300 batch  35/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 118/300 batch  36/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 118/300 batch  37/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 118/300 batch  38/188  Train Loss: 0.077, Acc: 0.984\n",
      "epoch: 118/300 batch  39/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 118/300 batch  40/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 118/300 batch  41/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 118/300 batch  42/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 118/300 batch  43/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 118/300 batch  44/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 118/300 batch  45/188  Train Loss: 0.042, Acc: 0.977\n",
      "epoch: 118/300 batch  46/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 118/300 batch  47/188  Train Loss: 0.033, Acc: 0.984\n",
      "epoch: 118/300 batch  48/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 118/300 batch  49/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 118/300 batch  50/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 118/300 batch  51/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 118/300 batch  52/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 118/300 batch  53/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 118/300 batch  54/188  Train Loss: 0.060, Acc: 0.980\n",
      "epoch: 118/300 batch  55/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 118/300 batch  56/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 118/300 batch  57/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 118/300 batch  58/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 118/300 batch  59/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 118/300 batch  60/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 118/300 batch  61/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 118/300 batch  62/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 118/300 batch  63/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 118/300 batch  64/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 118/300 batch  65/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 118/300 batch  66/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 118/300 batch  67/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 118/300 batch  68/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 118/300 batch  69/188  Train Loss: 0.038, Acc: 0.980\n",
      "epoch: 118/300 batch  70/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 118/300 batch  71/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 118/300 batch  72/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 118/300 batch  73/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 118/300 batch  74/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 118/300 batch  75/188  Train Loss: 0.063, Acc: 0.977\n",
      "epoch: 118/300 batch  76/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 118/300 batch  77/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 118/300 batch  78/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 118/300 batch  79/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 118/300 batch  80/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 118/300 batch  81/188  Train Loss: 0.053, Acc: 0.996\n",
      "epoch: 118/300 batch  82/188  Train Loss: 0.065, Acc: 0.984\n",
      "epoch: 118/300 batch  83/188  Train Loss: 0.044, Acc: 0.996\n",
      "epoch: 118/300 batch  84/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 118/300 batch  85/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 118/300 batch  86/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 118/300 batch  87/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 118/300 batch  88/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 118/300 batch  89/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 118/300 batch  90/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 118/300 batch  91/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 118/300 batch  92/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 118/300 batch  93/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 118/300 batch  94/188  Train Loss: 0.061, Acc: 0.984\n",
      "epoch: 118/300 batch  95/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 118/300 batch  96/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 118/300 batch  97/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 118/300 batch  98/188  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 118/300 batch  99/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 118/300 batch 100/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 118/300 batch 101/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 118/300 batch 102/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 118/300 batch 103/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 118/300 batch 104/188  Train Loss: 0.026, Acc: 0.988\n",
      "epoch: 118/300 batch 105/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 118/300 batch 106/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 118/300 batch 107/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 118/300 batch 108/188  Train Loss: 0.061, Acc: 0.980\n",
      "epoch: 118/300 batch 109/188  Train Loss: 0.051, Acc: 0.992\n",
      "epoch: 118/300 batch 110/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 118/300 batch 111/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 118/300 batch 112/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 118/300 batch 113/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 118/300 batch 114/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 118/300 batch 115/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 118/300 batch 116/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 118/300 batch 117/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 118/300 batch 118/188  Train Loss: 0.050, Acc: 0.996\n",
      "epoch: 118/300 batch 119/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 118/300 batch 120/188  Train Loss: 0.059, Acc: 0.980\n",
      "epoch: 118/300 batch 121/188  Train Loss: 0.052, Acc: 0.980\n",
      "epoch: 118/300 batch 122/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 118/300 batch 123/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 118/300 batch 124/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 118/300 batch 125/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 118/300 batch 126/188  Train Loss: 0.051, Acc: 0.992\n",
      "epoch: 118/300 batch 127/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 118/300 batch 128/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 118/300 batch 129/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 118/300 batch 130/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 118/300 batch 131/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 118/300 batch 132/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 118/300 batch 133/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 118/300 batch 134/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 118/300 batch 135/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 118/300 batch 136/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 118/300 batch 137/188  Train Loss: 0.033, Acc: 0.984\n",
      "epoch: 118/300 batch 138/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 118/300 batch 139/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 118/300 batch 140/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 118/300 batch 141/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 118/300 batch 142/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 118/300 batch 143/188  Train Loss: 0.068, Acc: 0.973\n",
      "epoch: 118/300 batch 144/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 118/300 batch 145/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 118/300 batch 146/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 118/300 batch 147/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 118/300 batch 148/188  Train Loss: 0.037, Acc: 1.000\n",
      "epoch: 118/300 batch 149/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 118/300 batch 150/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 118/300 batch 151/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 118/300 batch 152/188  Train Loss: 0.070, Acc: 0.988\n",
      "epoch: 118/300 batch 153/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 118/300 batch 154/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 118/300 batch 155/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 118/300 batch 156/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 118/300 batch 157/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 118/300 batch 158/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 118/300 batch 159/188  Train Loss: 0.042, Acc: 0.996\n",
      "epoch: 118/300 batch 160/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 118/300 batch 161/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 118/300 batch 162/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 118/300 batch 163/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 118/300 batch 164/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 118/300 batch 165/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 118/300 batch 166/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 118/300 batch 167/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 118/300 batch 168/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 118/300 batch 169/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 118/300 batch 170/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 118/300 batch 171/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 118/300 batch 172/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 118/300 batch 173/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 118/300 batch 174/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 118/300 batch 175/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 118/300 batch 176/188  Train Loss: 0.058, Acc: 0.977\n",
      "epoch: 118/300 batch 177/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 118/300 batch 178/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 118/300 batch 179/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 118/300 batch 180/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 118/300 batch 181/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 118/300 batch 182/188  Train Loss: 0.063, Acc: 0.984\n",
      "epoch: 118/300 batch 183/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 118/300 batch 184/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 118/300 batch 185/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 118/300 batch 186/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 118/300 batch 187/188  Train Loss: 0.031, Acc: 0.992\n",
      "Train Loss: 0.034762, Acc: 0.992\n",
      "Val Loss: 0.057703, Acc: 0.982\n",
      "epoch: 119/300 batch   0/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 119/300 batch   1/188  Train Loss: 0.061, Acc: 0.977\n",
      "epoch: 119/300 batch   2/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 119/300 batch   3/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 119/300 batch   4/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 119/300 batch   5/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 119/300 batch   6/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 119/300 batch   7/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 119/300 batch   8/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 119/300 batch   9/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 119/300 batch  10/188  Train Loss: 0.052, Acc: 0.977\n",
      "epoch: 119/300 batch  11/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 119/300 batch  12/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 119/300 batch  13/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 119/300 batch  14/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 119/300 batch  15/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 119/300 batch  16/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 119/300 batch  17/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 119/300 batch  18/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 119/300 batch  19/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 119/300 batch  20/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 119/300 batch  21/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 119/300 batch  22/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 119/300 batch  23/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 119/300 batch  24/188  Train Loss: 0.058, Acc: 0.980\n",
      "epoch: 119/300 batch  25/188  Train Loss: 0.032, Acc: 0.984\n",
      "epoch: 119/300 batch  26/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 119/300 batch  27/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 119/300 batch  28/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 119/300 batch  29/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 119/300 batch  30/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 119/300 batch  31/188  Train Loss: 0.031, Acc: 1.000\n",
      "epoch: 119/300 batch  32/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 119/300 batch  33/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 119/300 batch  34/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 119/300 batch  35/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 119/300 batch  36/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 119/300 batch  37/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 119/300 batch  38/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 119/300 batch  39/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 119/300 batch  40/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 119/300 batch  41/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 119/300 batch  42/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 119/300 batch  43/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 119/300 batch  44/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 119/300 batch  45/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 119/300 batch  46/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 119/300 batch  47/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 119/300 batch  48/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 119/300 batch  49/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 119/300 batch  50/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 119/300 batch  51/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 119/300 batch  52/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 119/300 batch  53/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 119/300 batch  54/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 119/300 batch  55/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 119/300 batch  56/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 119/300 batch  57/188  Train Loss: 0.058, Acc: 0.988\n",
      "epoch: 119/300 batch  58/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 119/300 batch  59/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 119/300 batch  60/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 119/300 batch  61/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 119/300 batch  62/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 119/300 batch  63/188  Train Loss: 0.052, Acc: 0.992\n",
      "epoch: 119/300 batch  64/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 119/300 batch  65/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 119/300 batch  66/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 119/300 batch  67/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 119/300 batch  68/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 119/300 batch  69/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 119/300 batch  70/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 119/300 batch  71/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 119/300 batch  72/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 119/300 batch  73/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 119/300 batch  74/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 119/300 batch  75/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 119/300 batch  76/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 119/300 batch  77/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 119/300 batch  78/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 119/300 batch  79/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 119/300 batch  80/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 119/300 batch  81/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 119/300 batch  82/188  Train Loss: 0.043, Acc: 0.996\n",
      "epoch: 119/300 batch  83/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 119/300 batch  84/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 119/300 batch  85/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 119/300 batch  86/188  Train Loss: 0.060, Acc: 0.980\n",
      "epoch: 119/300 batch  87/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 119/300 batch  88/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 119/300 batch  89/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 119/300 batch  90/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 119/300 batch  91/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 119/300 batch  92/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 119/300 batch  93/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 119/300 batch  94/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 119/300 batch  95/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 119/300 batch  96/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 119/300 batch  97/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 119/300 batch  98/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 119/300 batch  99/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 119/300 batch 100/188  Train Loss: 0.016, Acc: 0.996\n",
      "epoch: 119/300 batch 101/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 119/300 batch 102/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 119/300 batch 103/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 119/300 batch 104/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 119/300 batch 105/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 119/300 batch 106/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 119/300 batch 107/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 119/300 batch 108/188  Train Loss: 0.050, Acc: 0.980\n",
      "epoch: 119/300 batch 109/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 119/300 batch 110/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 119/300 batch 111/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 119/300 batch 112/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 119/300 batch 113/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 119/300 batch 114/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 119/300 batch 115/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 119/300 batch 116/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 119/300 batch 117/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 119/300 batch 118/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 119/300 batch 119/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 119/300 batch 120/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 119/300 batch 121/188  Train Loss: 0.061, Acc: 0.980\n",
      "epoch: 119/300 batch 122/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 119/300 batch 123/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 119/300 batch 124/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 119/300 batch 125/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 119/300 batch 126/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 119/300 batch 127/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 119/300 batch 128/188  Train Loss: 0.058, Acc: 0.992\n",
      "epoch: 119/300 batch 129/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 119/300 batch 130/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 119/300 batch 131/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 119/300 batch 132/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 119/300 batch 133/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 119/300 batch 134/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 119/300 batch 135/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 119/300 batch 136/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 119/300 batch 137/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 119/300 batch 138/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 119/300 batch 139/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 119/300 batch 140/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 119/300 batch 141/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 119/300 batch 142/188  Train Loss: 0.049, Acc: 0.980\n",
      "epoch: 119/300 batch 143/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 119/300 batch 144/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 119/300 batch 145/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 119/300 batch 146/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 119/300 batch 147/188  Train Loss: 0.060, Acc: 0.984\n",
      "epoch: 119/300 batch 148/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 119/300 batch 149/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 119/300 batch 150/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 119/300 batch 151/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 119/300 batch 152/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 119/300 batch 153/188  Train Loss: 0.070, Acc: 0.973\n",
      "epoch: 119/300 batch 154/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 119/300 batch 155/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 119/300 batch 156/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 119/300 batch 157/188  Train Loss: 0.045, Acc: 0.996\n",
      "epoch: 119/300 batch 158/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 119/300 batch 159/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 119/300 batch 160/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 119/300 batch 161/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 119/300 batch 162/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 119/300 batch 163/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 119/300 batch 164/188  Train Loss: 0.037, Acc: 0.980\n",
      "epoch: 119/300 batch 165/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 119/300 batch 166/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 119/300 batch 167/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 119/300 batch 168/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 119/300 batch 169/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 119/300 batch 170/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 119/300 batch 171/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 119/300 batch 172/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 119/300 batch 173/188  Train Loss: 0.031, Acc: 1.000\n",
      "epoch: 119/300 batch 174/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 119/300 batch 175/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 119/300 batch 176/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 119/300 batch 177/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 119/300 batch 178/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 119/300 batch 179/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 119/300 batch 180/188  Train Loss: 0.052, Acc: 0.977\n",
      "epoch: 119/300 batch 181/188  Train Loss: 0.031, Acc: 1.000\n",
      "epoch: 119/300 batch 182/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 119/300 batch 183/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 119/300 batch 184/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 119/300 batch 185/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 119/300 batch 186/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 119/300 batch 187/188  Train Loss: 0.076, Acc: 0.992\n",
      "Train Loss: 0.034841, Acc: 0.992\n",
      "Val Loss: 0.057528, Acc: 0.982\n",
      "epoch: 120/300 batch   0/188  Train Loss: 0.082, Acc: 0.980\n",
      "epoch: 120/300 batch   1/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 120/300 batch   2/188  Train Loss: 0.034, Acc: 1.000\n",
      "epoch: 120/300 batch   3/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 120/300 batch   4/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 120/300 batch   5/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 120/300 batch   6/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 120/300 batch   7/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 120/300 batch   8/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 120/300 batch   9/188  Train Loss: 0.062, Acc: 0.980\n",
      "epoch: 120/300 batch  10/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 120/300 batch  11/188  Train Loss: 0.058, Acc: 0.988\n",
      "epoch: 120/300 batch  12/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 120/300 batch  13/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 120/300 batch  14/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 120/300 batch  15/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 120/300 batch  16/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 120/300 batch  17/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 120/300 batch  18/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 120/300 batch  19/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 120/300 batch  20/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 120/300 batch  21/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 120/300 batch  22/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 120/300 batch  23/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 120/300 batch  24/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 120/300 batch  25/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 120/300 batch  26/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 120/300 batch  27/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 120/300 batch  28/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 120/300 batch  29/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 120/300 batch  30/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 120/300 batch  31/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 120/300 batch  32/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 120/300 batch  33/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 120/300 batch  34/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 120/300 batch  35/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 120/300 batch  36/188  Train Loss: 0.051, Acc: 0.980\n",
      "epoch: 120/300 batch  37/188  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 120/300 batch  38/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 120/300 batch  39/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 120/300 batch  40/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 120/300 batch  41/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 120/300 batch  42/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 120/300 batch  43/188  Train Loss: 0.059, Acc: 0.984\n",
      "epoch: 120/300 batch  44/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 120/300 batch  45/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 120/300 batch  46/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 120/300 batch  47/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 120/300 batch  48/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 120/300 batch  49/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 120/300 batch  50/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 120/300 batch  51/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 120/300 batch  52/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 120/300 batch  53/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 120/300 batch  54/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 120/300 batch  55/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 120/300 batch  56/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 120/300 batch  57/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 120/300 batch  58/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 120/300 batch  59/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 120/300 batch  60/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 120/300 batch  61/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 120/300 batch  62/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 120/300 batch  63/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 120/300 batch  64/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 120/300 batch  65/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 120/300 batch  66/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 120/300 batch  67/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 120/300 batch  68/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 120/300 batch  69/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 120/300 batch  70/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 120/300 batch  71/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 120/300 batch  72/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 120/300 batch  73/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 120/300 batch  74/188  Train Loss: 0.066, Acc: 0.984\n",
      "epoch: 120/300 batch  75/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 120/300 batch  76/188  Train Loss: 0.055, Acc: 0.977\n",
      "epoch: 120/300 batch  77/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 120/300 batch  78/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 120/300 batch  79/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 120/300 batch  80/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 120/300 batch  81/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 120/300 batch  82/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 120/300 batch  83/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 120/300 batch  84/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 120/300 batch  85/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 120/300 batch  86/188  Train Loss: 0.061, Acc: 0.977\n",
      "epoch: 120/300 batch  87/188  Train Loss: 0.016, Acc: 0.996\n",
      "epoch: 120/300 batch  88/188  Train Loss: 0.067, Acc: 0.984\n",
      "epoch: 120/300 batch  89/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 120/300 batch  90/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 120/300 batch  91/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 120/300 batch  92/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 120/300 batch  93/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 120/300 batch  94/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 120/300 batch  95/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 120/300 batch  96/188  Train Loss: 0.087, Acc: 0.973\n",
      "epoch: 120/300 batch  97/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 120/300 batch  98/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 120/300 batch  99/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 120/300 batch 100/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 120/300 batch 101/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 120/300 batch 102/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 120/300 batch 103/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 120/300 batch 104/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 120/300 batch 105/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 120/300 batch 106/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 120/300 batch 107/188  Train Loss: 0.040, Acc: 0.980\n",
      "epoch: 120/300 batch 108/188  Train Loss: 0.058, Acc: 0.977\n",
      "epoch: 120/300 batch 109/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 120/300 batch 110/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 120/300 batch 111/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 120/300 batch 112/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 120/300 batch 113/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 120/300 batch 114/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 120/300 batch 115/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 120/300 batch 116/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 120/300 batch 117/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 120/300 batch 118/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 120/300 batch 119/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 120/300 batch 120/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 120/300 batch 121/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 120/300 batch 122/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 120/300 batch 123/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 120/300 batch 124/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 120/300 batch 125/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 120/300 batch 126/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 120/300 batch 127/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 120/300 batch 128/188  Train Loss: 0.049, Acc: 0.980\n",
      "epoch: 120/300 batch 129/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 120/300 batch 130/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 120/300 batch 131/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 120/300 batch 132/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 120/300 batch 133/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 120/300 batch 134/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 120/300 batch 135/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 120/300 batch 136/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 120/300 batch 137/188  Train Loss: 0.057, Acc: 0.988\n",
      "epoch: 120/300 batch 138/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 120/300 batch 139/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 120/300 batch 140/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 120/300 batch 141/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 120/300 batch 142/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 120/300 batch 143/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 120/300 batch 144/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 120/300 batch 145/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 120/300 batch 146/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 120/300 batch 147/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 120/300 batch 148/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 120/300 batch 149/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 120/300 batch 150/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 120/300 batch 151/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 120/300 batch 152/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 120/300 batch 153/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 120/300 batch 154/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 120/300 batch 155/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 120/300 batch 156/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 120/300 batch 157/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 120/300 batch 158/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 120/300 batch 159/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 120/300 batch 160/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 120/300 batch 161/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 120/300 batch 162/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 120/300 batch 163/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 120/300 batch 164/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 120/300 batch 165/188  Train Loss: 0.032, Acc: 1.000\n",
      "epoch: 120/300 batch 166/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 120/300 batch 167/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 120/300 batch 168/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 120/300 batch 169/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 120/300 batch 170/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 120/300 batch 171/188  Train Loss: 0.066, Acc: 0.988\n",
      "epoch: 120/300 batch 172/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 120/300 batch 173/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 120/300 batch 174/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 120/300 batch 175/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 120/300 batch 176/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 120/300 batch 177/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 120/300 batch 178/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 120/300 batch 179/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 120/300 batch 180/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 120/300 batch 181/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 120/300 batch 182/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 120/300 batch 183/188  Train Loss: 0.066, Acc: 0.984\n",
      "epoch: 120/300 batch 184/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 120/300 batch 185/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 120/300 batch 186/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 120/300 batch 187/188  Train Loss: 0.064, Acc: 0.984\n",
      "Train Loss: 0.034763, Acc: 0.992\n",
      "Val Loss: 0.057488, Acc: 0.983\n",
      "epoch: 121/300 batch   0/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 121/300 batch   1/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 121/300 batch   2/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 121/300 batch   3/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 121/300 batch   4/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 121/300 batch   5/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 121/300 batch   6/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 121/300 batch   7/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 121/300 batch   8/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 121/300 batch   9/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 121/300 batch  10/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 121/300 batch  11/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 121/300 batch  12/188  Train Loss: 0.036, Acc: 0.980\n",
      "epoch: 121/300 batch  13/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 121/300 batch  14/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 121/300 batch  15/188  Train Loss: 0.032, Acc: 1.000\n",
      "epoch: 121/300 batch  16/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 121/300 batch  17/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 121/300 batch  18/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 121/300 batch  19/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 121/300 batch  20/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 121/300 batch  21/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 121/300 batch  22/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 121/300 batch  23/188  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 121/300 batch  24/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 121/300 batch  25/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 121/300 batch  26/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 121/300 batch  27/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 121/300 batch  28/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 121/300 batch  29/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 121/300 batch  30/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 121/300 batch  31/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 121/300 batch  32/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 121/300 batch  33/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 121/300 batch  34/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 121/300 batch  35/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 121/300 batch  36/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 121/300 batch  37/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 121/300 batch  38/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 121/300 batch  39/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 121/300 batch  40/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 121/300 batch  41/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 121/300 batch  42/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 121/300 batch  43/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 121/300 batch  44/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 121/300 batch  45/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 121/300 batch  46/188  Train Loss: 0.056, Acc: 0.988\n",
      "epoch: 121/300 batch  47/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 121/300 batch  48/188  Train Loss: 0.071, Acc: 0.980\n",
      "epoch: 121/300 batch  49/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 121/300 batch  50/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 121/300 batch  51/188  Train Loss: 0.058, Acc: 0.988\n",
      "epoch: 121/300 batch  52/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 121/300 batch  53/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 121/300 batch  54/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 121/300 batch  55/188  Train Loss: 0.054, Acc: 0.980\n",
      "epoch: 121/300 batch  56/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 121/300 batch  57/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 121/300 batch  58/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 121/300 batch  59/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 121/300 batch  60/188  Train Loss: 0.083, Acc: 0.977\n",
      "epoch: 121/300 batch  61/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 121/300 batch  62/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 121/300 batch  63/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 121/300 batch  64/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 121/300 batch  65/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 121/300 batch  66/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 121/300 batch  67/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 121/300 batch  68/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 121/300 batch  69/188  Train Loss: 0.064, Acc: 0.984\n",
      "epoch: 121/300 batch  70/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 121/300 batch  71/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 121/300 batch  72/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 121/300 batch  73/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 121/300 batch  74/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 121/300 batch  75/188  Train Loss: 0.055, Acc: 0.980\n",
      "epoch: 121/300 batch  76/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 121/300 batch  77/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 121/300 batch  78/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 121/300 batch  79/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 121/300 batch  80/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 121/300 batch  81/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 121/300 batch  82/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 121/300 batch  83/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 121/300 batch  84/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 121/300 batch  85/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 121/300 batch  86/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 121/300 batch  87/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 121/300 batch  88/188  Train Loss: 0.053, Acc: 0.977\n",
      "epoch: 121/300 batch  89/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 121/300 batch  90/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 121/300 batch  91/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 121/300 batch  92/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 121/300 batch  93/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 121/300 batch  94/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 121/300 batch  95/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 121/300 batch  96/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 121/300 batch  97/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 121/300 batch  98/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 121/300 batch  99/188  Train Loss: 0.076, Acc: 0.980\n",
      "epoch: 121/300 batch 100/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 121/300 batch 101/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 121/300 batch 102/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 121/300 batch 103/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 121/300 batch 104/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 121/300 batch 105/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 121/300 batch 106/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 121/300 batch 107/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 121/300 batch 108/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 121/300 batch 109/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 121/300 batch 110/188  Train Loss: 0.074, Acc: 0.965\n",
      "epoch: 121/300 batch 111/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 121/300 batch 112/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 121/300 batch 113/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 121/300 batch 114/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 121/300 batch 115/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 121/300 batch 116/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 121/300 batch 117/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 121/300 batch 118/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 121/300 batch 119/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 121/300 batch 120/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 121/300 batch 121/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 121/300 batch 122/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 121/300 batch 123/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 121/300 batch 124/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 121/300 batch 125/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 121/300 batch 126/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 121/300 batch 127/188  Train Loss: 0.053, Acc: 0.992\n",
      "epoch: 121/300 batch 128/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 121/300 batch 129/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 121/300 batch 130/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 121/300 batch 131/188  Train Loss: 0.057, Acc: 0.980\n",
      "epoch: 121/300 batch 132/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 121/300 batch 133/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 121/300 batch 134/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 121/300 batch 135/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 121/300 batch 136/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 121/300 batch 137/188  Train Loss: 0.103, Acc: 0.980\n",
      "epoch: 121/300 batch 138/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 121/300 batch 139/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 121/300 batch 140/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 121/300 batch 141/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 121/300 batch 142/188  Train Loss: 0.056, Acc: 0.988\n",
      "epoch: 121/300 batch 143/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 121/300 batch 144/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 121/300 batch 145/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 121/300 batch 146/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 121/300 batch 147/188  Train Loss: 0.045, Acc: 0.996\n",
      "epoch: 121/300 batch 148/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 121/300 batch 149/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 121/300 batch 150/188  Train Loss: 0.048, Acc: 0.980\n",
      "epoch: 121/300 batch 151/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 121/300 batch 152/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 121/300 batch 153/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 121/300 batch 154/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 121/300 batch 155/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 121/300 batch 156/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 121/300 batch 157/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 121/300 batch 158/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 121/300 batch 159/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 121/300 batch 160/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 121/300 batch 161/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 121/300 batch 162/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 121/300 batch 163/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 121/300 batch 164/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 121/300 batch 165/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 121/300 batch 166/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 121/300 batch 167/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 121/300 batch 168/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 121/300 batch 169/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 121/300 batch 170/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 121/300 batch 171/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 121/300 batch 172/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 121/300 batch 173/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 121/300 batch 174/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 121/300 batch 175/188  Train Loss: 0.027, Acc: 0.988\n",
      "epoch: 121/300 batch 176/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 121/300 batch 177/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 121/300 batch 178/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 121/300 batch 179/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 121/300 batch 180/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 121/300 batch 181/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 121/300 batch 182/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 121/300 batch 183/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 121/300 batch 184/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 121/300 batch 185/188  Train Loss: 0.031, Acc: 0.984\n",
      "epoch: 121/300 batch 186/188  Train Loss: 0.027, Acc: 0.988\n",
      "epoch: 121/300 batch 187/188  Train Loss: 0.036, Acc: 0.977\n",
      "Train Loss: 0.034674, Acc: 0.992\n",
      "Val Loss: 0.057457, Acc: 0.983\n",
      "epoch: 122/300 batch   0/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 122/300 batch   1/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 122/300 batch   2/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 122/300 batch   3/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 122/300 batch   4/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 122/300 batch   5/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 122/300 batch   6/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 122/300 batch   7/188  Train Loss: 0.025, Acc: 0.988\n",
      "epoch: 122/300 batch   8/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 122/300 batch   9/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 122/300 batch  10/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 122/300 batch  11/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 122/300 batch  12/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 122/300 batch  13/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 122/300 batch  14/188  Train Loss: 0.067, Acc: 0.980\n",
      "epoch: 122/300 batch  15/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 122/300 batch  16/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 122/300 batch  17/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 122/300 batch  18/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 122/300 batch  19/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 122/300 batch  20/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 122/300 batch  21/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 122/300 batch  22/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 122/300 batch  23/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 122/300 batch  24/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 122/300 batch  25/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 122/300 batch  26/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 122/300 batch  27/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 122/300 batch  28/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 122/300 batch  29/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 122/300 batch  30/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 122/300 batch  31/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 122/300 batch  32/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 122/300 batch  33/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 122/300 batch  34/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 122/300 batch  35/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 122/300 batch  36/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 122/300 batch  37/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 122/300 batch  38/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 122/300 batch  39/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 122/300 batch  40/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 122/300 batch  41/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 122/300 batch  42/188  Train Loss: 0.056, Acc: 0.980\n",
      "epoch: 122/300 batch  43/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 122/300 batch  44/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 122/300 batch  45/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 122/300 batch  46/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 122/300 batch  47/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 122/300 batch  48/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 122/300 batch  49/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 122/300 batch  50/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 122/300 batch  51/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 122/300 batch  52/188  Train Loss: 0.032, Acc: 1.000\n",
      "epoch: 122/300 batch  53/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 122/300 batch  54/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 122/300 batch  55/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 122/300 batch  56/188  Train Loss: 0.058, Acc: 0.977\n",
      "epoch: 122/300 batch  57/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 122/300 batch  58/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 122/300 batch  59/188  Train Loss: 0.057, Acc: 0.988\n",
      "epoch: 122/300 batch  60/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 122/300 batch  61/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 122/300 batch  62/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 122/300 batch  63/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 122/300 batch  64/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 122/300 batch  65/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 122/300 batch  66/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 122/300 batch  67/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 122/300 batch  68/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 122/300 batch  69/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 122/300 batch  70/188  Train Loss: 0.054, Acc: 0.977\n",
      "epoch: 122/300 batch  71/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 122/300 batch  72/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 122/300 batch  73/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 122/300 batch  74/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 122/300 batch  75/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 122/300 batch  76/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 122/300 batch  77/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 122/300 batch  78/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 122/300 batch  79/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 122/300 batch  80/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 122/300 batch  81/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 122/300 batch  82/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 122/300 batch  83/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 122/300 batch  84/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 122/300 batch  85/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 122/300 batch  86/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 122/300 batch  87/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 122/300 batch  88/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 122/300 batch  89/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 122/300 batch  90/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 122/300 batch  91/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 122/300 batch  92/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 122/300 batch  93/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 122/300 batch  94/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 122/300 batch  95/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 122/300 batch  96/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 122/300 batch  97/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 122/300 batch  98/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 122/300 batch  99/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 122/300 batch 100/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 122/300 batch 101/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 122/300 batch 102/188  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 122/300 batch 103/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 122/300 batch 104/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 122/300 batch 105/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 122/300 batch 106/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 122/300 batch 107/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 122/300 batch 108/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 122/300 batch 109/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 122/300 batch 110/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 122/300 batch 111/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 122/300 batch 112/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 122/300 batch 113/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 122/300 batch 114/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 122/300 batch 115/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 122/300 batch 116/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 122/300 batch 117/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 122/300 batch 118/188  Train Loss: 0.058, Acc: 0.988\n",
      "epoch: 122/300 batch 119/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 122/300 batch 120/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 122/300 batch 121/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 122/300 batch 122/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 122/300 batch 123/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 122/300 batch 124/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 122/300 batch 125/188  Train Loss: 0.032, Acc: 1.000\n",
      "epoch: 122/300 batch 126/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 122/300 batch 127/188  Train Loss: 0.074, Acc: 0.973\n",
      "epoch: 122/300 batch 128/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 122/300 batch 129/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 122/300 batch 130/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 122/300 batch 131/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 122/300 batch 132/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 122/300 batch 133/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 122/300 batch 134/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 122/300 batch 135/188  Train Loss: 0.101, Acc: 0.969\n",
      "epoch: 122/300 batch 136/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 122/300 batch 137/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 122/300 batch 138/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 122/300 batch 139/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 122/300 batch 140/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 122/300 batch 141/188  Train Loss: 0.057, Acc: 0.980\n",
      "epoch: 122/300 batch 142/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 122/300 batch 143/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 122/300 batch 144/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 122/300 batch 145/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 122/300 batch 146/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 122/300 batch 147/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 122/300 batch 148/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 122/300 batch 149/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 122/300 batch 150/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 122/300 batch 151/188  Train Loss: 0.034, Acc: 1.000\n",
      "epoch: 122/300 batch 152/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 122/300 batch 153/188  Train Loss: 0.016, Acc: 0.996\n",
      "epoch: 122/300 batch 154/188  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 122/300 batch 155/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 122/300 batch 156/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 122/300 batch 157/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 122/300 batch 158/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 122/300 batch 159/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 122/300 batch 160/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 122/300 batch 161/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 122/300 batch 162/188  Train Loss: 0.051, Acc: 0.992\n",
      "epoch: 122/300 batch 163/188  Train Loss: 0.072, Acc: 0.992\n",
      "epoch: 122/300 batch 164/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 122/300 batch 165/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 122/300 batch 166/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 122/300 batch 167/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 122/300 batch 168/188  Train Loss: 0.081, Acc: 0.973\n",
      "epoch: 122/300 batch 169/188  Train Loss: 0.063, Acc: 0.980\n",
      "epoch: 122/300 batch 170/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 122/300 batch 171/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 122/300 batch 172/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 122/300 batch 173/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 122/300 batch 174/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 122/300 batch 175/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 122/300 batch 176/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 122/300 batch 177/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 122/300 batch 178/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 122/300 batch 179/188  Train Loss: 0.057, Acc: 0.980\n",
      "epoch: 122/300 batch 180/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 122/300 batch 181/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 122/300 batch 182/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 122/300 batch 183/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 122/300 batch 184/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 122/300 batch 185/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 122/300 batch 186/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 122/300 batch 187/188  Train Loss: 0.029, Acc: 0.992\n",
      "Train Loss: 0.034659, Acc: 0.992\n",
      "Val Loss: 0.057822, Acc: 0.982\n",
      "epoch: 123/300 batch   0/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 123/300 batch   1/188  Train Loss: 0.056, Acc: 0.977\n",
      "epoch: 123/300 batch   2/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 123/300 batch   3/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 123/300 batch   4/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 123/300 batch   5/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 123/300 batch   6/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 123/300 batch   7/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 123/300 batch   8/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 123/300 batch   9/188  Train Loss: 0.053, Acc: 0.996\n",
      "epoch: 123/300 batch  10/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 123/300 batch  11/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 123/300 batch  12/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 123/300 batch  13/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 123/300 batch  14/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 123/300 batch  15/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 123/300 batch  16/188  Train Loss: 0.035, Acc: 0.980\n",
      "epoch: 123/300 batch  17/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 123/300 batch  18/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 123/300 batch  19/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 123/300 batch  20/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 123/300 batch  21/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 123/300 batch  22/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 123/300 batch  23/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 123/300 batch  24/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 123/300 batch  25/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 123/300 batch  26/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 123/300 batch  27/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 123/300 batch  28/188  Train Loss: 0.049, Acc: 0.980\n",
      "epoch: 123/300 batch  29/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 123/300 batch  30/188  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 123/300 batch  31/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 123/300 batch  32/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 123/300 batch  33/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 123/300 batch  34/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 123/300 batch  35/188  Train Loss: 0.050, Acc: 0.980\n",
      "epoch: 123/300 batch  36/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 123/300 batch  37/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 123/300 batch  38/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 123/300 batch  39/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 123/300 batch  40/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 123/300 batch  41/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 123/300 batch  42/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 123/300 batch  43/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 123/300 batch  44/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 123/300 batch  45/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 123/300 batch  46/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 123/300 batch  47/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 123/300 batch  48/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 123/300 batch  49/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 123/300 batch  50/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 123/300 batch  51/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 123/300 batch  52/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 123/300 batch  53/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 123/300 batch  54/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 123/300 batch  55/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 123/300 batch  56/188  Train Loss: 0.059, Acc: 0.988\n",
      "epoch: 123/300 batch  57/188  Train Loss: 0.059, Acc: 0.977\n",
      "epoch: 123/300 batch  58/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 123/300 batch  59/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 123/300 batch  60/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 123/300 batch  61/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 123/300 batch  62/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 123/300 batch  63/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 123/300 batch  64/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 123/300 batch  65/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 123/300 batch  66/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 123/300 batch  67/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 123/300 batch  68/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 123/300 batch  69/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 123/300 batch  70/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 123/300 batch  71/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 123/300 batch  72/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 123/300 batch  73/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 123/300 batch  74/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 123/300 batch  75/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 123/300 batch  76/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 123/300 batch  77/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 123/300 batch  78/188  Train Loss: 0.064, Acc: 0.992\n",
      "epoch: 123/300 batch  79/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 123/300 batch  80/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 123/300 batch  81/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 123/300 batch  82/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 123/300 batch  83/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 123/300 batch  84/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 123/300 batch  85/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 123/300 batch  86/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 123/300 batch  87/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 123/300 batch  88/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 123/300 batch  89/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 123/300 batch  90/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 123/300 batch  91/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 123/300 batch  92/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 123/300 batch  93/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 123/300 batch  94/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 123/300 batch  95/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 123/300 batch  96/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 123/300 batch  97/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 123/300 batch  98/188  Train Loss: 0.061, Acc: 0.980\n",
      "epoch: 123/300 batch  99/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 123/300 batch 100/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 123/300 batch 101/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 123/300 batch 102/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 123/300 batch 103/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 123/300 batch 104/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 123/300 batch 105/188  Train Loss: 0.052, Acc: 0.977\n",
      "epoch: 123/300 batch 106/188  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 123/300 batch 107/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 123/300 batch 108/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 123/300 batch 109/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 123/300 batch 110/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 123/300 batch 111/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 123/300 batch 112/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 123/300 batch 113/188  Train Loss: 0.038, Acc: 0.977\n",
      "epoch: 123/300 batch 114/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 123/300 batch 115/188  Train Loss: 0.038, Acc: 0.980\n",
      "epoch: 123/300 batch 116/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 123/300 batch 117/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 123/300 batch 118/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 123/300 batch 119/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 123/300 batch 120/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 123/300 batch 121/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 123/300 batch 122/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 123/300 batch 123/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 123/300 batch 124/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 123/300 batch 125/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 123/300 batch 126/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 123/300 batch 127/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 123/300 batch 128/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 123/300 batch 129/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 123/300 batch 130/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 123/300 batch 131/188  Train Loss: 0.048, Acc: 0.980\n",
      "epoch: 123/300 batch 132/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 123/300 batch 133/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 123/300 batch 134/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 123/300 batch 135/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 123/300 batch 136/188  Train Loss: 0.053, Acc: 0.980\n",
      "epoch: 123/300 batch 137/188  Train Loss: 0.071, Acc: 0.980\n",
      "epoch: 123/300 batch 138/188  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 123/300 batch 139/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 123/300 batch 140/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 123/300 batch 141/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 123/300 batch 142/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 123/300 batch 143/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 123/300 batch 144/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 123/300 batch 145/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 123/300 batch 146/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 123/300 batch 147/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 123/300 batch 148/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 123/300 batch 149/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 123/300 batch 150/188  Train Loss: 0.059, Acc: 0.980\n",
      "epoch: 123/300 batch 151/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 123/300 batch 152/188  Train Loss: 0.085, Acc: 0.984\n",
      "epoch: 123/300 batch 153/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 123/300 batch 154/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 123/300 batch 155/188  Train Loss: 0.048, Acc: 0.996\n",
      "epoch: 123/300 batch 156/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 123/300 batch 157/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 123/300 batch 158/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 123/300 batch 159/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 123/300 batch 160/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 123/300 batch 161/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 123/300 batch 162/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 123/300 batch 163/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 123/300 batch 164/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 123/300 batch 165/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 123/300 batch 166/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 123/300 batch 167/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 123/300 batch 168/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 123/300 batch 169/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 123/300 batch 170/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 123/300 batch 171/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 123/300 batch 172/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 123/300 batch 173/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 123/300 batch 174/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 123/300 batch 175/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 123/300 batch 176/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 123/300 batch 177/188  Train Loss: 0.070, Acc: 0.984\n",
      "epoch: 123/300 batch 178/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 123/300 batch 179/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 123/300 batch 180/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 123/300 batch 181/188  Train Loss: 0.052, Acc: 0.980\n",
      "epoch: 123/300 batch 182/188  Train Loss: 0.047, Acc: 0.996\n",
      "epoch: 123/300 batch 183/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 123/300 batch 184/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 123/300 batch 185/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 123/300 batch 186/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 123/300 batch 187/188  Train Loss: 0.069, Acc: 0.969\n",
      "Train Loss: 0.034714, Acc: 0.992\n",
      "Val Loss: 0.057552, Acc: 0.982\n",
      "epoch: 124/300 batch   0/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 124/300 batch   1/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 124/300 batch   2/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 124/300 batch   3/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 124/300 batch   4/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 124/300 batch   5/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 124/300 batch   6/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 124/300 batch   7/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 124/300 batch   8/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 124/300 batch   9/188  Train Loss: 0.051, Acc: 0.980\n",
      "epoch: 124/300 batch  10/188  Train Loss: 0.059, Acc: 0.984\n",
      "epoch: 124/300 batch  11/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 124/300 batch  12/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 124/300 batch  13/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 124/300 batch  14/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 124/300 batch  15/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 124/300 batch  16/188  Train Loss: 0.049, Acc: 0.980\n",
      "epoch: 124/300 batch  17/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 124/300 batch  18/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 124/300 batch  19/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 124/300 batch  20/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 124/300 batch  21/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 124/300 batch  22/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 124/300 batch  23/188  Train Loss: 0.054, Acc: 0.977\n",
      "epoch: 124/300 batch  24/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 124/300 batch  25/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 124/300 batch  26/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 124/300 batch  27/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 124/300 batch  28/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 124/300 batch  29/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 124/300 batch  30/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 124/300 batch  31/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 124/300 batch  32/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 124/300 batch  33/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 124/300 batch  34/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 124/300 batch  35/188  Train Loss: 0.060, Acc: 0.980\n",
      "epoch: 124/300 batch  36/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 124/300 batch  37/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 124/300 batch  38/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 124/300 batch  39/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 124/300 batch  40/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 124/300 batch  41/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 124/300 batch  42/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 124/300 batch  43/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 124/300 batch  44/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 124/300 batch  45/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 124/300 batch  46/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 124/300 batch  47/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 124/300 batch  48/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 124/300 batch  49/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 124/300 batch  50/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 124/300 batch  51/188  Train Loss: 0.055, Acc: 0.980\n",
      "epoch: 124/300 batch  52/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 124/300 batch  53/188  Train Loss: 0.060, Acc: 0.984\n",
      "epoch: 124/300 batch  54/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 124/300 batch  55/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 124/300 batch  56/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 124/300 batch  57/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 124/300 batch  58/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 124/300 batch  59/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 124/300 batch  60/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 124/300 batch  61/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 124/300 batch  62/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 124/300 batch  63/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 124/300 batch  64/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 124/300 batch  65/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 124/300 batch  66/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 124/300 batch  67/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 124/300 batch  68/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 124/300 batch  69/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 124/300 batch  70/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 124/300 batch  71/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 124/300 batch  72/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 124/300 batch  73/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 124/300 batch  74/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 124/300 batch  75/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 124/300 batch  76/188  Train Loss: 0.015, Acc: 0.996\n",
      "epoch: 124/300 batch  77/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 124/300 batch  78/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 124/300 batch  79/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 124/300 batch  80/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 124/300 batch  81/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 124/300 batch  82/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 124/300 batch  83/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 124/300 batch  84/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 124/300 batch  85/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 124/300 batch  86/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 124/300 batch  87/188  Train Loss: 0.056, Acc: 0.980\n",
      "epoch: 124/300 batch  88/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 124/300 batch  89/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 124/300 batch  90/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 124/300 batch  91/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 124/300 batch  92/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 124/300 batch  93/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 124/300 batch  94/188  Train Loss: 0.046, Acc: 0.996\n",
      "epoch: 124/300 batch  95/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 124/300 batch  96/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 124/300 batch  97/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 124/300 batch  98/188  Train Loss: 0.078, Acc: 0.980\n",
      "epoch: 124/300 batch  99/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 124/300 batch 100/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 124/300 batch 101/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 124/300 batch 102/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 124/300 batch 103/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 124/300 batch 104/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 124/300 batch 105/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 124/300 batch 106/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 124/300 batch 107/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 124/300 batch 108/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 124/300 batch 109/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 124/300 batch 110/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 124/300 batch 111/188  Train Loss: 0.060, Acc: 0.984\n",
      "epoch: 124/300 batch 112/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 124/300 batch 113/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 124/300 batch 114/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 124/300 batch 115/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 124/300 batch 116/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 124/300 batch 117/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 124/300 batch 118/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 124/300 batch 119/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 124/300 batch 120/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 124/300 batch 121/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 124/300 batch 122/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 124/300 batch 123/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 124/300 batch 124/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 124/300 batch 125/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 124/300 batch 126/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 124/300 batch 127/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 124/300 batch 128/188  Train Loss: 0.063, Acc: 0.984\n",
      "epoch: 124/300 batch 129/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 124/300 batch 130/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 124/300 batch 131/188  Train Loss: 0.059, Acc: 0.984\n",
      "epoch: 124/300 batch 132/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 124/300 batch 133/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 124/300 batch 134/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 124/300 batch 135/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 124/300 batch 136/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 124/300 batch 137/188  Train Loss: 0.052, Acc: 0.996\n",
      "epoch: 124/300 batch 138/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 124/300 batch 139/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 124/300 batch 140/188  Train Loss: 0.058, Acc: 0.980\n",
      "epoch: 124/300 batch 141/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 124/300 batch 142/188  Train Loss: 0.025, Acc: 0.988\n",
      "epoch: 124/300 batch 143/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 124/300 batch 144/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 124/300 batch 145/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 124/300 batch 146/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 124/300 batch 147/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 124/300 batch 148/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 124/300 batch 149/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 124/300 batch 150/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 124/300 batch 151/188  Train Loss: 0.104, Acc: 0.973\n",
      "epoch: 124/300 batch 152/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 124/300 batch 153/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 124/300 batch 154/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 124/300 batch 155/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 124/300 batch 156/188  Train Loss: 0.055, Acc: 0.980\n",
      "epoch: 124/300 batch 157/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 124/300 batch 158/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 124/300 batch 159/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 124/300 batch 160/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 124/300 batch 161/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 124/300 batch 162/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 124/300 batch 163/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 124/300 batch 164/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 124/300 batch 165/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 124/300 batch 166/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 124/300 batch 167/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 124/300 batch 168/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 124/300 batch 169/188  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 124/300 batch 170/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 124/300 batch 171/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 124/300 batch 172/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 124/300 batch 173/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 124/300 batch 174/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 124/300 batch 175/188  Train Loss: 0.048, Acc: 0.980\n",
      "epoch: 124/300 batch 176/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 124/300 batch 177/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 124/300 batch 178/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 124/300 batch 179/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 124/300 batch 180/188  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 124/300 batch 181/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 124/300 batch 182/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 124/300 batch 183/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 124/300 batch 184/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 124/300 batch 185/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 124/300 batch 186/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 124/300 batch 187/188  Train Loss: 0.051, Acc: 0.992\n",
      "Train Loss: 0.034636, Acc: 0.992\n",
      "Val Loss: 0.057418, Acc: 0.983\n",
      "epoch: 125/300 batch   0/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 125/300 batch   1/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 125/300 batch   2/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 125/300 batch   3/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 125/300 batch   4/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 125/300 batch   5/188  Train Loss: 0.063, Acc: 0.973\n",
      "epoch: 125/300 batch   6/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 125/300 batch   7/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 125/300 batch   8/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 125/300 batch   9/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 125/300 batch  10/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 125/300 batch  11/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 125/300 batch  12/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 125/300 batch  13/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 125/300 batch  14/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 125/300 batch  15/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 125/300 batch  16/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 125/300 batch  17/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 125/300 batch  18/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 125/300 batch  19/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 125/300 batch  20/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 125/300 batch  21/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 125/300 batch  22/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 125/300 batch  23/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 125/300 batch  24/188  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 125/300 batch  25/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 125/300 batch  26/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 125/300 batch  27/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 125/300 batch  28/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 125/300 batch  29/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 125/300 batch  30/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 125/300 batch  31/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 125/300 batch  32/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 125/300 batch  33/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 125/300 batch  34/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 125/300 batch  35/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 125/300 batch  36/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 125/300 batch  37/188  Train Loss: 0.056, Acc: 0.992\n",
      "epoch: 125/300 batch  38/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 125/300 batch  39/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 125/300 batch  40/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 125/300 batch  41/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 125/300 batch  42/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 125/300 batch  43/188  Train Loss: 0.051, Acc: 0.992\n",
      "epoch: 125/300 batch  44/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 125/300 batch  45/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 125/300 batch  46/188  Train Loss: 0.059, Acc: 0.988\n",
      "epoch: 125/300 batch  47/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 125/300 batch  48/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 125/300 batch  49/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 125/300 batch  50/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 125/300 batch  51/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 125/300 batch  52/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 125/300 batch  53/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 125/300 batch  54/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 125/300 batch  55/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 125/300 batch  56/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 125/300 batch  57/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 125/300 batch  58/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 125/300 batch  59/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 125/300 batch  60/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 125/300 batch  61/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 125/300 batch  62/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 125/300 batch  63/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 125/300 batch  64/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 125/300 batch  65/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 125/300 batch  66/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 125/300 batch  67/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 125/300 batch  68/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 125/300 batch  69/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 125/300 batch  70/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 125/300 batch  71/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 125/300 batch  72/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 125/300 batch  73/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 125/300 batch  74/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 125/300 batch  75/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 125/300 batch  76/188  Train Loss: 0.054, Acc: 0.980\n",
      "epoch: 125/300 batch  77/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 125/300 batch  78/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 125/300 batch  79/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 125/300 batch  80/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 125/300 batch  81/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 125/300 batch  82/188  Train Loss: 0.066, Acc: 0.977\n",
      "epoch: 125/300 batch  83/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 125/300 batch  84/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 125/300 batch  85/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 125/300 batch  86/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 125/300 batch  87/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 125/300 batch  88/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 125/300 batch  89/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 125/300 batch  90/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 125/300 batch  91/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 125/300 batch  92/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 125/300 batch  93/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 125/300 batch  94/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 125/300 batch  95/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 125/300 batch  96/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 125/300 batch  97/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 125/300 batch  98/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 125/300 batch  99/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 125/300 batch 100/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 125/300 batch 101/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 125/300 batch 102/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 125/300 batch 103/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 125/300 batch 104/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 125/300 batch 105/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 125/300 batch 106/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 125/300 batch 107/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 125/300 batch 108/188  Train Loss: 0.052, Acc: 0.992\n",
      "epoch: 125/300 batch 109/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 125/300 batch 110/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 125/300 batch 111/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 125/300 batch 112/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 125/300 batch 113/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 125/300 batch 114/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 125/300 batch 115/188  Train Loss: 0.055, Acc: 0.973\n",
      "epoch: 125/300 batch 116/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 125/300 batch 117/188  Train Loss: 0.027, Acc: 0.988\n",
      "epoch: 125/300 batch 118/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 125/300 batch 119/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 125/300 batch 120/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 125/300 batch 121/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 125/300 batch 122/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 125/300 batch 123/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 125/300 batch 124/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 125/300 batch 125/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 125/300 batch 126/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 125/300 batch 127/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 125/300 batch 128/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 125/300 batch 129/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 125/300 batch 130/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 125/300 batch 131/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 125/300 batch 132/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 125/300 batch 133/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 125/300 batch 134/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 125/300 batch 135/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 125/300 batch 136/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 125/300 batch 137/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 125/300 batch 138/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 125/300 batch 139/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 125/300 batch 140/188  Train Loss: 0.043, Acc: 0.980\n",
      "epoch: 125/300 batch 141/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 125/300 batch 142/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 125/300 batch 143/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 125/300 batch 144/188  Train Loss: 0.042, Acc: 0.980\n",
      "epoch: 125/300 batch 145/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 125/300 batch 146/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 125/300 batch 147/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 125/300 batch 148/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 125/300 batch 149/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 125/300 batch 150/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 125/300 batch 151/188  Train Loss: 0.067, Acc: 0.977\n",
      "epoch: 125/300 batch 152/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 125/300 batch 153/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 125/300 batch 154/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 125/300 batch 155/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 125/300 batch 156/188  Train Loss: 0.055, Acc: 0.980\n",
      "epoch: 125/300 batch 157/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 125/300 batch 158/188  Train Loss: 0.066, Acc: 0.980\n",
      "epoch: 125/300 batch 159/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 125/300 batch 160/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 125/300 batch 161/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 125/300 batch 162/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 125/300 batch 163/188  Train Loss: 0.065, Acc: 0.988\n",
      "epoch: 125/300 batch 164/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 125/300 batch 165/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 125/300 batch 166/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 125/300 batch 167/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 125/300 batch 168/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 125/300 batch 169/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 125/300 batch 170/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 125/300 batch 171/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 125/300 batch 172/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 125/300 batch 173/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 125/300 batch 174/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 125/300 batch 175/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 125/300 batch 176/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 125/300 batch 177/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 125/300 batch 178/188  Train Loss: 0.074, Acc: 0.980\n",
      "epoch: 125/300 batch 179/188  Train Loss: 0.020, Acc: 0.988\n",
      "epoch: 125/300 batch 180/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 125/300 batch 181/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 125/300 batch 182/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 125/300 batch 183/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 125/300 batch 184/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 125/300 batch 185/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 125/300 batch 186/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 125/300 batch 187/188  Train Loss: 0.018, Acc: 1.000\n",
      "Train Loss: 0.034552, Acc: 0.992\n",
      "Val Loss: 0.057564, Acc: 0.983\n",
      "epoch: 126/300 batch   0/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 126/300 batch   1/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 126/300 batch   2/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 126/300 batch   3/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 126/300 batch   4/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 126/300 batch   5/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 126/300 batch   6/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 126/300 batch   7/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 126/300 batch   8/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 126/300 batch   9/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 126/300 batch  10/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 126/300 batch  11/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 126/300 batch  12/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 126/300 batch  13/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 126/300 batch  14/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 126/300 batch  15/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 126/300 batch  16/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 126/300 batch  17/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 126/300 batch  18/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 126/300 batch  19/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 126/300 batch  20/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 126/300 batch  21/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 126/300 batch  22/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 126/300 batch  23/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 126/300 batch  24/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 126/300 batch  25/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 126/300 batch  26/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 126/300 batch  27/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 126/300 batch  28/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 126/300 batch  29/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 126/300 batch  30/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 126/300 batch  31/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 126/300 batch  32/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 126/300 batch  33/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 126/300 batch  34/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 126/300 batch  35/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 126/300 batch  36/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 126/300 batch  37/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 126/300 batch  38/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 126/300 batch  39/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 126/300 batch  40/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 126/300 batch  41/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 126/300 batch  42/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 126/300 batch  43/188  Train Loss: 0.075, Acc: 0.984\n",
      "epoch: 126/300 batch  44/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 126/300 batch  45/188  Train Loss: 0.066, Acc: 0.977\n",
      "epoch: 126/300 batch  46/188  Train Loss: 0.057, Acc: 0.988\n",
      "epoch: 126/300 batch  47/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 126/300 batch  48/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 126/300 batch  49/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 126/300 batch  50/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 126/300 batch  51/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 126/300 batch  52/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 126/300 batch  53/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 126/300 batch  54/188  Train Loss: 0.014, Acc: 0.996\n",
      "epoch: 126/300 batch  55/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 126/300 batch  56/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 126/300 batch  57/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 126/300 batch  58/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 126/300 batch  59/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 126/300 batch  60/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 126/300 batch  61/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 126/300 batch  62/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 126/300 batch  63/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 126/300 batch  64/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 126/300 batch  65/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 126/300 batch  66/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 126/300 batch  67/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 126/300 batch  68/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 126/300 batch  69/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 126/300 batch  70/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 126/300 batch  71/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 126/300 batch  72/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 126/300 batch  73/188  Train Loss: 0.064, Acc: 0.988\n",
      "epoch: 126/300 batch  74/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 126/300 batch  75/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 126/300 batch  76/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 126/300 batch  77/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 126/300 batch  78/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 126/300 batch  79/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 126/300 batch  80/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 126/300 batch  81/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 126/300 batch  82/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 126/300 batch  83/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 126/300 batch  84/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 126/300 batch  85/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 126/300 batch  86/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 126/300 batch  87/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 126/300 batch  88/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 126/300 batch  89/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 126/300 batch  90/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 126/300 batch  91/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 126/300 batch  92/188  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 126/300 batch  93/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 126/300 batch  94/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 126/300 batch  95/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 126/300 batch  96/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 126/300 batch  97/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 126/300 batch  98/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 126/300 batch  99/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 126/300 batch 100/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 126/300 batch 101/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 126/300 batch 102/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 126/300 batch 103/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 126/300 batch 104/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 126/300 batch 105/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 126/300 batch 106/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 126/300 batch 107/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 126/300 batch 108/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 126/300 batch 109/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 126/300 batch 110/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 126/300 batch 111/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 126/300 batch 112/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 126/300 batch 113/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 126/300 batch 114/188  Train Loss: 0.053, Acc: 0.980\n",
      "epoch: 126/300 batch 115/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 126/300 batch 116/188  Train Loss: 0.067, Acc: 0.980\n",
      "epoch: 126/300 batch 117/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 126/300 batch 118/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 126/300 batch 119/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 126/300 batch 120/188  Train Loss: 0.043, Acc: 0.996\n",
      "epoch: 126/300 batch 121/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 126/300 batch 122/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 126/300 batch 123/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 126/300 batch 124/188  Train Loss: 0.063, Acc: 0.980\n",
      "epoch: 126/300 batch 125/188  Train Loss: 0.051, Acc: 0.980\n",
      "epoch: 126/300 batch 126/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 126/300 batch 127/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 126/300 batch 128/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 126/300 batch 129/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 126/300 batch 130/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 126/300 batch 131/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 126/300 batch 132/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 126/300 batch 133/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 126/300 batch 134/188  Train Loss: 0.054, Acc: 0.980\n",
      "epoch: 126/300 batch 135/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 126/300 batch 136/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 126/300 batch 137/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 126/300 batch 138/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 126/300 batch 139/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 126/300 batch 140/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 126/300 batch 141/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 126/300 batch 142/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 126/300 batch 143/188  Train Loss: 0.024, Acc: 0.988\n",
      "epoch: 126/300 batch 144/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 126/300 batch 145/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 126/300 batch 146/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 126/300 batch 147/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 126/300 batch 148/188  Train Loss: 0.025, Acc: 0.988\n",
      "epoch: 126/300 batch 149/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 126/300 batch 150/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 126/300 batch 151/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 126/300 batch 152/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 126/300 batch 153/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 126/300 batch 154/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 126/300 batch 155/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 126/300 batch 156/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 126/300 batch 157/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 126/300 batch 158/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 126/300 batch 159/188  Train Loss: 0.043, Acc: 0.980\n",
      "epoch: 126/300 batch 160/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 126/300 batch 161/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 126/300 batch 162/188  Train Loss: 0.023, Acc: 0.988\n",
      "epoch: 126/300 batch 163/188  Train Loss: 0.047, Acc: 0.996\n",
      "epoch: 126/300 batch 164/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 126/300 batch 165/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 126/300 batch 166/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 126/300 batch 167/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 126/300 batch 168/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 126/300 batch 169/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 126/300 batch 170/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 126/300 batch 171/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 126/300 batch 172/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 126/300 batch 173/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 126/300 batch 174/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 126/300 batch 175/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 126/300 batch 176/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 126/300 batch 177/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 126/300 batch 178/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 126/300 batch 179/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 126/300 batch 180/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 126/300 batch 181/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 126/300 batch 182/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 126/300 batch 183/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 126/300 batch 184/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 126/300 batch 185/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 126/300 batch 186/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 126/300 batch 187/188  Train Loss: 0.025, Acc: 1.000\n",
      "Train Loss: 0.034518, Acc: 0.992\n",
      "Val Loss: 0.057466, Acc: 0.982\n",
      "epoch: 127/300 batch   0/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 127/300 batch   1/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 127/300 batch   2/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 127/300 batch   3/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 127/300 batch   4/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 127/300 batch   5/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 127/300 batch   6/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 127/300 batch   7/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 127/300 batch   8/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 127/300 batch   9/188  Train Loss: 0.046, Acc: 0.996\n",
      "epoch: 127/300 batch  10/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 127/300 batch  11/188  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 127/300 batch  12/188  Train Loss: 0.085, Acc: 0.984\n",
      "epoch: 127/300 batch  13/188  Train Loss: 0.066, Acc: 0.980\n",
      "epoch: 127/300 batch  14/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 127/300 batch  15/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 127/300 batch  16/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 127/300 batch  17/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 127/300 batch  18/188  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 127/300 batch  19/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 127/300 batch  20/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 127/300 batch  21/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 127/300 batch  22/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 127/300 batch  23/188  Train Loss: 0.056, Acc: 0.980\n",
      "epoch: 127/300 batch  24/188  Train Loss: 0.067, Acc: 0.980\n",
      "epoch: 127/300 batch  25/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 127/300 batch  26/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 127/300 batch  27/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 127/300 batch  28/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 127/300 batch  29/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 127/300 batch  30/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 127/300 batch  31/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 127/300 batch  32/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 127/300 batch  33/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 127/300 batch  34/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 127/300 batch  35/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 127/300 batch  36/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 127/300 batch  37/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 127/300 batch  38/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 127/300 batch  39/188  Train Loss: 0.024, Acc: 0.988\n",
      "epoch: 127/300 batch  40/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 127/300 batch  41/188  Train Loss: 0.056, Acc: 0.992\n",
      "epoch: 127/300 batch  42/188  Train Loss: 0.064, Acc: 0.980\n",
      "epoch: 127/300 batch  43/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 127/300 batch  44/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 127/300 batch  45/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 127/300 batch  46/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 127/300 batch  47/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 127/300 batch  48/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 127/300 batch  49/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 127/300 batch  50/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 127/300 batch  51/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 127/300 batch  52/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 127/300 batch  53/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 127/300 batch  54/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 127/300 batch  55/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 127/300 batch  56/188  Train Loss: 0.034, Acc: 0.984\n",
      "epoch: 127/300 batch  57/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 127/300 batch  58/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 127/300 batch  59/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 127/300 batch  60/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 127/300 batch  61/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 127/300 batch  62/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 127/300 batch  63/188  Train Loss: 0.053, Acc: 0.977\n",
      "epoch: 127/300 batch  64/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 127/300 batch  65/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 127/300 batch  66/188  Train Loss: 0.047, Acc: 0.980\n",
      "epoch: 127/300 batch  67/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 127/300 batch  68/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 127/300 batch  69/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 127/300 batch  70/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 127/300 batch  71/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 127/300 batch  72/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 127/300 batch  73/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 127/300 batch  74/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 127/300 batch  75/188  Train Loss: 0.033, Acc: 1.000\n",
      "epoch: 127/300 batch  76/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 127/300 batch  77/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 127/300 batch  78/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 127/300 batch  79/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 127/300 batch  80/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 127/300 batch  81/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 127/300 batch  82/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 127/300 batch  83/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 127/300 batch  84/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 127/300 batch  85/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 127/300 batch  86/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 127/300 batch  87/188  Train Loss: 0.061, Acc: 0.984\n",
      "epoch: 127/300 batch  88/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 127/300 batch  89/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 127/300 batch  90/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 127/300 batch  91/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 127/300 batch  92/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 127/300 batch  93/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 127/300 batch  94/188  Train Loss: 0.044, Acc: 0.996\n",
      "epoch: 127/300 batch  95/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 127/300 batch  96/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 127/300 batch  97/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 127/300 batch  98/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 127/300 batch  99/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 127/300 batch 100/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 127/300 batch 101/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 127/300 batch 102/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 127/300 batch 103/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 127/300 batch 104/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 127/300 batch 105/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 127/300 batch 106/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 127/300 batch 107/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 127/300 batch 108/188  Train Loss: 0.055, Acc: 0.977\n",
      "epoch: 127/300 batch 109/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 127/300 batch 110/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 127/300 batch 111/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 127/300 batch 112/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 127/300 batch 113/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 127/300 batch 114/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 127/300 batch 115/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 127/300 batch 116/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 127/300 batch 117/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 127/300 batch 118/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 127/300 batch 119/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 127/300 batch 120/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 127/300 batch 121/188  Train Loss: 0.033, Acc: 1.000\n",
      "epoch: 127/300 batch 122/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 127/300 batch 123/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 127/300 batch 124/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 127/300 batch 125/188  Train Loss: 0.063, Acc: 0.984\n",
      "epoch: 127/300 batch 126/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 127/300 batch 127/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 127/300 batch 128/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 127/300 batch 129/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 127/300 batch 130/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 127/300 batch 131/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 127/300 batch 132/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 127/300 batch 133/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 127/300 batch 134/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 127/300 batch 135/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 127/300 batch 136/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 127/300 batch 137/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 127/300 batch 138/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 127/300 batch 139/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 127/300 batch 140/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 127/300 batch 141/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 127/300 batch 142/188  Train Loss: 0.051, Acc: 0.980\n",
      "epoch: 127/300 batch 143/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 127/300 batch 144/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 127/300 batch 145/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 127/300 batch 146/188  Train Loss: 0.033, Acc: 1.000\n",
      "epoch: 127/300 batch 147/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 127/300 batch 148/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 127/300 batch 149/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 127/300 batch 150/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 127/300 batch 151/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 127/300 batch 152/188  Train Loss: 0.047, Acc: 0.996\n",
      "epoch: 127/300 batch 153/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 127/300 batch 154/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 127/300 batch 155/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 127/300 batch 156/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 127/300 batch 157/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 127/300 batch 158/188  Train Loss: 0.053, Acc: 0.980\n",
      "epoch: 127/300 batch 159/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 127/300 batch 160/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 127/300 batch 161/188  Train Loss: 0.040, Acc: 0.980\n",
      "epoch: 127/300 batch 162/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 127/300 batch 163/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 127/300 batch 164/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 127/300 batch 165/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 127/300 batch 166/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 127/300 batch 167/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 127/300 batch 168/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 127/300 batch 169/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 127/300 batch 170/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 127/300 batch 171/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 127/300 batch 172/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 127/300 batch 173/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 127/300 batch 174/188  Train Loss: 0.060, Acc: 0.977\n",
      "epoch: 127/300 batch 175/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 127/300 batch 176/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 127/300 batch 177/188  Train Loss: 0.061, Acc: 0.984\n",
      "epoch: 127/300 batch 178/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 127/300 batch 179/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 127/300 batch 180/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 127/300 batch 181/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 127/300 batch 182/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 127/300 batch 183/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 127/300 batch 184/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 127/300 batch 185/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 127/300 batch 186/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 127/300 batch 187/188  Train Loss: 0.019, Acc: 1.000\n",
      "Train Loss: 0.034514, Acc: 0.992\n",
      "Val Loss: 0.057401, Acc: 0.983\n",
      "epoch: 128/300 batch   0/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 128/300 batch   1/188  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 128/300 batch   2/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 128/300 batch   3/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 128/300 batch   4/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 128/300 batch   5/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 128/300 batch   6/188  Train Loss: 0.062, Acc: 0.977\n",
      "epoch: 128/300 batch   7/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 128/300 batch   8/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 128/300 batch   9/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 128/300 batch  10/188  Train Loss: 0.063, Acc: 0.992\n",
      "epoch: 128/300 batch  11/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 128/300 batch  12/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 128/300 batch  13/188  Train Loss: 0.059, Acc: 0.988\n",
      "epoch: 128/300 batch  14/188  Train Loss: 0.029, Acc: 0.984\n",
      "epoch: 128/300 batch  15/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 128/300 batch  16/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 128/300 batch  17/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 128/300 batch  18/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 128/300 batch  19/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 128/300 batch  20/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 128/300 batch  21/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 128/300 batch  22/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 128/300 batch  23/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 128/300 batch  24/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 128/300 batch  25/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 128/300 batch  26/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 128/300 batch  27/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 128/300 batch  28/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 128/300 batch  29/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 128/300 batch  30/188  Train Loss: 0.052, Acc: 0.977\n",
      "epoch: 128/300 batch  31/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 128/300 batch  32/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 128/300 batch  33/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 128/300 batch  34/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 128/300 batch  35/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 128/300 batch  36/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 128/300 batch  37/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 128/300 batch  38/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 128/300 batch  39/188  Train Loss: 0.074, Acc: 0.980\n",
      "epoch: 128/300 batch  40/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 128/300 batch  41/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 128/300 batch  42/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 128/300 batch  43/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 128/300 batch  44/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 128/300 batch  45/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 128/300 batch  46/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 128/300 batch  47/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 128/300 batch  48/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 128/300 batch  49/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 128/300 batch  50/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 128/300 batch  51/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 128/300 batch  52/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 128/300 batch  53/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 128/300 batch  54/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 128/300 batch  55/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 128/300 batch  56/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 128/300 batch  57/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 128/300 batch  58/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 128/300 batch  59/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 128/300 batch  60/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 128/300 batch  61/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 128/300 batch  62/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 128/300 batch  63/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 128/300 batch  64/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 128/300 batch  65/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 128/300 batch  66/188  Train Loss: 0.059, Acc: 0.980\n",
      "epoch: 128/300 batch  67/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 128/300 batch  68/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 128/300 batch  69/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 128/300 batch  70/188  Train Loss: 0.056, Acc: 0.980\n",
      "epoch: 128/300 batch  71/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 128/300 batch  72/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 128/300 batch  73/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 128/300 batch  74/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 128/300 batch  75/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 128/300 batch  76/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 128/300 batch  77/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 128/300 batch  78/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 128/300 batch  79/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 128/300 batch  80/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 128/300 batch  81/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 128/300 batch  82/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 128/300 batch  83/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 128/300 batch  84/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 128/300 batch  85/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 128/300 batch  86/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 128/300 batch  87/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 128/300 batch  88/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 128/300 batch  89/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 128/300 batch  90/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 128/300 batch  91/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 128/300 batch  92/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 128/300 batch  93/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 128/300 batch  94/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 128/300 batch  95/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 128/300 batch  96/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 128/300 batch  97/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 128/300 batch  98/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 128/300 batch  99/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 128/300 batch 100/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 128/300 batch 101/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 128/300 batch 102/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 128/300 batch 103/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 128/300 batch 104/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 128/300 batch 105/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 128/300 batch 106/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 128/300 batch 107/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 128/300 batch 108/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 128/300 batch 109/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 128/300 batch 110/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 128/300 batch 111/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 128/300 batch 112/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 128/300 batch 113/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 128/300 batch 114/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 128/300 batch 115/188  Train Loss: 0.057, Acc: 0.980\n",
      "epoch: 128/300 batch 116/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 128/300 batch 117/188  Train Loss: 0.057, Acc: 0.977\n",
      "epoch: 128/300 batch 118/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 128/300 batch 119/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 128/300 batch 120/188  Train Loss: 0.045, Acc: 0.996\n",
      "epoch: 128/300 batch 121/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 128/300 batch 122/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 128/300 batch 123/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 128/300 batch 124/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 128/300 batch 125/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 128/300 batch 126/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 128/300 batch 127/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 128/300 batch 128/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 128/300 batch 129/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 128/300 batch 130/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 128/300 batch 131/188  Train Loss: 0.065, Acc: 0.984\n",
      "epoch: 128/300 batch 132/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 128/300 batch 133/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 128/300 batch 134/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 128/300 batch 135/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 128/300 batch 136/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 128/300 batch 137/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 128/300 batch 138/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 128/300 batch 139/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 128/300 batch 140/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 128/300 batch 141/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 128/300 batch 142/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 128/300 batch 143/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 128/300 batch 144/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 128/300 batch 145/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 128/300 batch 146/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 128/300 batch 147/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 128/300 batch 148/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 128/300 batch 149/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 128/300 batch 150/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 128/300 batch 151/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 128/300 batch 152/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 128/300 batch 153/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 128/300 batch 154/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 128/300 batch 155/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 128/300 batch 156/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 128/300 batch 157/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 128/300 batch 158/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 128/300 batch 159/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 128/300 batch 160/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 128/300 batch 161/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 128/300 batch 162/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 128/300 batch 163/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 128/300 batch 164/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 128/300 batch 165/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 128/300 batch 166/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 128/300 batch 167/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 128/300 batch 168/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 128/300 batch 169/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 128/300 batch 170/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 128/300 batch 171/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 128/300 batch 172/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 128/300 batch 173/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 128/300 batch 174/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 128/300 batch 175/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 128/300 batch 176/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 128/300 batch 177/188  Train Loss: 0.034, Acc: 1.000\n",
      "epoch: 128/300 batch 178/188  Train Loss: 0.041, Acc: 0.980\n",
      "epoch: 128/300 batch 179/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 128/300 batch 180/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 128/300 batch 181/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 128/300 batch 182/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 128/300 batch 183/188  Train Loss: 0.040, Acc: 0.980\n",
      "epoch: 128/300 batch 184/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 128/300 batch 185/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 128/300 batch 186/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 128/300 batch 187/188  Train Loss: 0.028, Acc: 1.000\n",
      "Train Loss: 0.034561, Acc: 0.992\n",
      "Val Loss: 0.057698, Acc: 0.982\n",
      "epoch: 129/300 batch   0/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 129/300 batch   1/188  Train Loss: 0.077, Acc: 0.988\n",
      "epoch: 129/300 batch   2/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 129/300 batch   3/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 129/300 batch   4/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 129/300 batch   5/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 129/300 batch   6/188  Train Loss: 0.056, Acc: 0.988\n",
      "epoch: 129/300 batch   7/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 129/300 batch   8/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 129/300 batch   9/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 129/300 batch  10/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 129/300 batch  11/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 129/300 batch  12/188  Train Loss: 0.048, Acc: 0.980\n",
      "epoch: 129/300 batch  13/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 129/300 batch  14/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 129/300 batch  15/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 129/300 batch  16/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 129/300 batch  17/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 129/300 batch  18/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 129/300 batch  19/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 129/300 batch  20/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 129/300 batch  21/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 129/300 batch  22/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 129/300 batch  23/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 129/300 batch  24/188  Train Loss: 0.065, Acc: 0.977\n",
      "epoch: 129/300 batch  25/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 129/300 batch  26/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 129/300 batch  27/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 129/300 batch  28/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 129/300 batch  29/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 129/300 batch  30/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 129/300 batch  31/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 129/300 batch  32/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 129/300 batch  33/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 129/300 batch  34/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 129/300 batch  35/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 129/300 batch  36/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 129/300 batch  37/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 129/300 batch  38/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 129/300 batch  39/188  Train Loss: 0.054, Acc: 0.980\n",
      "epoch: 129/300 batch  40/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 129/300 batch  41/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 129/300 batch  42/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 129/300 batch  43/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 129/300 batch  44/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 129/300 batch  45/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 129/300 batch  46/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 129/300 batch  47/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 129/300 batch  48/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 129/300 batch  49/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 129/300 batch  50/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 129/300 batch  51/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 129/300 batch  52/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 129/300 batch  53/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 129/300 batch  54/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 129/300 batch  55/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 129/300 batch  56/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 129/300 batch  57/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 129/300 batch  58/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 129/300 batch  59/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 129/300 batch  60/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 129/300 batch  61/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 129/300 batch  62/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 129/300 batch  63/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 129/300 batch  64/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 129/300 batch  65/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 129/300 batch  66/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 129/300 batch  67/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 129/300 batch  68/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 129/300 batch  69/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 129/300 batch  70/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 129/300 batch  71/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 129/300 batch  72/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 129/300 batch  73/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 129/300 batch  74/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 129/300 batch  75/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 129/300 batch  76/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 129/300 batch  77/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 129/300 batch  78/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 129/300 batch  79/188  Train Loss: 0.057, Acc: 0.988\n",
      "epoch: 129/300 batch  80/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 129/300 batch  81/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 129/300 batch  82/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 129/300 batch  83/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 129/300 batch  84/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 129/300 batch  85/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 129/300 batch  86/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 129/300 batch  87/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 129/300 batch  88/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 129/300 batch  89/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 129/300 batch  90/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 129/300 batch  91/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 129/300 batch  92/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 129/300 batch  93/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 129/300 batch  94/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 129/300 batch  95/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 129/300 batch  96/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 129/300 batch  97/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 129/300 batch  98/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 129/300 batch  99/188  Train Loss: 0.065, Acc: 0.988\n",
      "epoch: 129/300 batch 100/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 129/300 batch 101/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 129/300 batch 102/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 129/300 batch 103/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 129/300 batch 104/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 129/300 batch 105/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 129/300 batch 106/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 129/300 batch 107/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 129/300 batch 108/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 129/300 batch 109/188  Train Loss: 0.052, Acc: 0.980\n",
      "epoch: 129/300 batch 110/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 129/300 batch 111/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 129/300 batch 112/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 129/300 batch 113/188  Train Loss: 0.053, Acc: 0.992\n",
      "epoch: 129/300 batch 114/188  Train Loss: 0.042, Acc: 0.996\n",
      "epoch: 129/300 batch 115/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 129/300 batch 116/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 129/300 batch 117/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 129/300 batch 118/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 129/300 batch 119/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 129/300 batch 120/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 129/300 batch 121/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 129/300 batch 122/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 129/300 batch 123/188  Train Loss: 0.057, Acc: 0.988\n",
      "epoch: 129/300 batch 124/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 129/300 batch 125/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 129/300 batch 126/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 129/300 batch 127/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 129/300 batch 128/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 129/300 batch 129/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 129/300 batch 130/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 129/300 batch 131/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 129/300 batch 132/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 129/300 batch 133/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 129/300 batch 134/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 129/300 batch 135/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 129/300 batch 136/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 129/300 batch 137/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 129/300 batch 138/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 129/300 batch 139/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 129/300 batch 140/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 129/300 batch 141/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 129/300 batch 142/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 129/300 batch 143/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 129/300 batch 144/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 129/300 batch 145/188  Train Loss: 0.070, Acc: 0.977\n",
      "epoch: 129/300 batch 146/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 129/300 batch 147/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 129/300 batch 148/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 129/300 batch 149/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 129/300 batch 150/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 129/300 batch 151/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 129/300 batch 152/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 129/300 batch 153/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 129/300 batch 154/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 129/300 batch 155/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 129/300 batch 156/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 129/300 batch 157/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 129/300 batch 158/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 129/300 batch 159/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 129/300 batch 160/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 129/300 batch 161/188  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 129/300 batch 162/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 129/300 batch 163/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 129/300 batch 164/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 129/300 batch 165/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 129/300 batch 166/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 129/300 batch 167/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 129/300 batch 168/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 129/300 batch 169/188  Train Loss: 0.061, Acc: 0.977\n",
      "epoch: 129/300 batch 170/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 129/300 batch 171/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 129/300 batch 172/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 129/300 batch 173/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 129/300 batch 174/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 129/300 batch 175/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 129/300 batch 176/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 129/300 batch 177/188  Train Loss: 0.065, Acc: 0.977\n",
      "epoch: 129/300 batch 178/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 129/300 batch 179/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 129/300 batch 180/188  Train Loss: 0.074, Acc: 0.980\n",
      "epoch: 129/300 batch 181/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 129/300 batch 182/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 129/300 batch 183/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 129/300 batch 184/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 129/300 batch 185/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 129/300 batch 186/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 129/300 batch 187/188  Train Loss: 0.058, Acc: 0.977\n",
      "Train Loss: 0.034585, Acc: 0.992\n",
      "Val Loss: 0.057362, Acc: 0.983\n",
      "epoch: 130/300 batch   0/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 130/300 batch   1/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 130/300 batch   2/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 130/300 batch   3/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 130/300 batch   4/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 130/300 batch   5/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 130/300 batch   6/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 130/300 batch   7/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 130/300 batch   8/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 130/300 batch   9/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 130/300 batch  10/188  Train Loss: 0.053, Acc: 0.992\n",
      "epoch: 130/300 batch  11/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 130/300 batch  12/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 130/300 batch  13/188  Train Loss: 0.059, Acc: 0.984\n",
      "epoch: 130/300 batch  14/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 130/300 batch  15/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 130/300 batch  16/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 130/300 batch  17/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 130/300 batch  18/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 130/300 batch  19/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 130/300 batch  20/188  Train Loss: 0.042, Acc: 0.980\n",
      "epoch: 130/300 batch  21/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 130/300 batch  22/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 130/300 batch  23/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 130/300 batch  24/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 130/300 batch  25/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 130/300 batch  26/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 130/300 batch  27/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 130/300 batch  28/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 130/300 batch  29/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 130/300 batch  30/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 130/300 batch  31/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 130/300 batch  32/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 130/300 batch  33/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 130/300 batch  34/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 130/300 batch  35/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 130/300 batch  36/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 130/300 batch  37/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 130/300 batch  38/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 130/300 batch  39/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 130/300 batch  40/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 130/300 batch  41/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 130/300 batch  42/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 130/300 batch  43/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 130/300 batch  44/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 130/300 batch  45/188  Train Loss: 0.032, Acc: 1.000\n",
      "epoch: 130/300 batch  46/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 130/300 batch  47/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 130/300 batch  48/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 130/300 batch  49/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 130/300 batch  50/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 130/300 batch  51/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 130/300 batch  52/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 130/300 batch  53/188  Train Loss: 0.067, Acc: 0.973\n",
      "epoch: 130/300 batch  54/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 130/300 batch  55/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 130/300 batch  56/188  Train Loss: 0.051, Acc: 0.992\n",
      "epoch: 130/300 batch  57/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 130/300 batch  58/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 130/300 batch  59/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 130/300 batch  60/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 130/300 batch  61/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 130/300 batch  62/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 130/300 batch  63/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 130/300 batch  64/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 130/300 batch  65/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 130/300 batch  66/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 130/300 batch  67/188  Train Loss: 0.027, Acc: 0.988\n",
      "epoch: 130/300 batch  68/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 130/300 batch  69/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 130/300 batch  70/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 130/300 batch  71/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 130/300 batch  72/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 130/300 batch  73/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 130/300 batch  74/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 130/300 batch  75/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 130/300 batch  76/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 130/300 batch  77/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 130/300 batch  78/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 130/300 batch  79/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 130/300 batch  80/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 130/300 batch  81/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 130/300 batch  82/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 130/300 batch  83/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 130/300 batch  84/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 130/300 batch  85/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 130/300 batch  86/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 130/300 batch  87/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 130/300 batch  88/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 130/300 batch  89/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 130/300 batch  90/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 130/300 batch  91/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 130/300 batch  92/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 130/300 batch  93/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 130/300 batch  94/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 130/300 batch  95/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 130/300 batch  96/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 130/300 batch  97/188  Train Loss: 0.048, Acc: 0.996\n",
      "epoch: 130/300 batch  98/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 130/300 batch  99/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 130/300 batch 100/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 130/300 batch 101/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 130/300 batch 102/188  Train Loss: 0.059, Acc: 0.984\n",
      "epoch: 130/300 batch 103/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 130/300 batch 104/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 130/300 batch 105/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 130/300 batch 106/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 130/300 batch 107/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 130/300 batch 108/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 130/300 batch 109/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 130/300 batch 110/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 130/300 batch 111/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 130/300 batch 112/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 130/300 batch 113/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 130/300 batch 114/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 130/300 batch 115/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 130/300 batch 116/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 130/300 batch 117/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 130/300 batch 118/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 130/300 batch 119/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 130/300 batch 120/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 130/300 batch 121/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 130/300 batch 122/188  Train Loss: 0.054, Acc: 0.992\n",
      "epoch: 130/300 batch 123/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 130/300 batch 124/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 130/300 batch 125/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 130/300 batch 126/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 130/300 batch 127/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 130/300 batch 128/188  Train Loss: 0.068, Acc: 0.973\n",
      "epoch: 130/300 batch 129/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 130/300 batch 130/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 130/300 batch 131/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 130/300 batch 132/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 130/300 batch 133/188  Train Loss: 0.042, Acc: 0.980\n",
      "epoch: 130/300 batch 134/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 130/300 batch 135/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 130/300 batch 136/188  Train Loss: 0.060, Acc: 0.984\n",
      "epoch: 130/300 batch 137/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 130/300 batch 138/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 130/300 batch 139/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 130/300 batch 140/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 130/300 batch 141/188  Train Loss: 0.083, Acc: 0.984\n",
      "epoch: 130/300 batch 142/188  Train Loss: 0.069, Acc: 0.973\n",
      "epoch: 130/300 batch 143/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 130/300 batch 144/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 130/300 batch 145/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 130/300 batch 146/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 130/300 batch 147/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 130/300 batch 148/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 130/300 batch 149/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 130/300 batch 150/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 130/300 batch 151/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 130/300 batch 152/188  Train Loss: 0.053, Acc: 0.992\n",
      "epoch: 130/300 batch 153/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 130/300 batch 154/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 130/300 batch 155/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 130/300 batch 156/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 130/300 batch 157/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 130/300 batch 158/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 130/300 batch 159/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 130/300 batch 160/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 130/300 batch 161/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 130/300 batch 162/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 130/300 batch 163/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 130/300 batch 164/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 130/300 batch 165/188  Train Loss: 0.032, Acc: 0.984\n",
      "epoch: 130/300 batch 166/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 130/300 batch 167/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 130/300 batch 168/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 130/300 batch 169/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 130/300 batch 170/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 130/300 batch 171/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 130/300 batch 172/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 130/300 batch 173/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 130/300 batch 174/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 130/300 batch 175/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 130/300 batch 176/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 130/300 batch 177/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 130/300 batch 178/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 130/300 batch 179/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 130/300 batch 180/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 130/300 batch 181/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 130/300 batch 182/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 130/300 batch 183/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 130/300 batch 184/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 130/300 batch 185/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 130/300 batch 186/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 130/300 batch 187/188  Train Loss: 0.010, Acc: 1.000\n",
      "Train Loss: 0.034346, Acc: 0.992\n",
      "Val Loss: 0.057539, Acc: 0.982\n",
      "epoch: 131/300 batch   0/188  Train Loss: 0.061, Acc: 0.988\n",
      "epoch: 131/300 batch   1/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 131/300 batch   2/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 131/300 batch   3/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 131/300 batch   4/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 131/300 batch   5/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 131/300 batch   6/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 131/300 batch   7/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 131/300 batch   8/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 131/300 batch   9/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 131/300 batch  10/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 131/300 batch  11/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 131/300 batch  12/188  Train Loss: 0.044, Acc: 0.996\n",
      "epoch: 131/300 batch  13/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 131/300 batch  14/188  Train Loss: 0.044, Acc: 0.977\n",
      "epoch: 131/300 batch  15/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 131/300 batch  16/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 131/300 batch  17/188  Train Loss: 0.051, Acc: 0.980\n",
      "epoch: 131/300 batch  18/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 131/300 batch  19/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 131/300 batch  20/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 131/300 batch  21/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 131/300 batch  22/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 131/300 batch  23/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 131/300 batch  24/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 131/300 batch  25/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 131/300 batch  26/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 131/300 batch  27/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 131/300 batch  28/188  Train Loss: 0.034, Acc: 0.984\n",
      "epoch: 131/300 batch  29/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 131/300 batch  30/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 131/300 batch  31/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 131/300 batch  32/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 131/300 batch  33/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 131/300 batch  34/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 131/300 batch  35/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 131/300 batch  36/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 131/300 batch  37/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 131/300 batch  38/188  Train Loss: 0.032, Acc: 1.000\n",
      "epoch: 131/300 batch  39/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 131/300 batch  40/188  Train Loss: 0.046, Acc: 0.980\n",
      "epoch: 131/300 batch  41/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 131/300 batch  42/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 131/300 batch  43/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 131/300 batch  44/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 131/300 batch  45/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 131/300 batch  46/188  Train Loss: 0.055, Acc: 0.980\n",
      "epoch: 131/300 batch  47/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 131/300 batch  48/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 131/300 batch  49/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 131/300 batch  50/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 131/300 batch  51/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 131/300 batch  52/188  Train Loss: 0.045, Acc: 0.996\n",
      "epoch: 131/300 batch  53/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 131/300 batch  54/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 131/300 batch  55/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 131/300 batch  56/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 131/300 batch  57/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 131/300 batch  58/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 131/300 batch  59/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 131/300 batch  60/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 131/300 batch  61/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 131/300 batch  62/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 131/300 batch  63/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 131/300 batch  64/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 131/300 batch  65/188  Train Loss: 0.046, Acc: 0.996\n",
      "epoch: 131/300 batch  66/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 131/300 batch  67/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 131/300 batch  68/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 131/300 batch  69/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 131/300 batch  70/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 131/300 batch  71/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 131/300 batch  72/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 131/300 batch  73/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 131/300 batch  74/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 131/300 batch  75/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 131/300 batch  76/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 131/300 batch  77/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 131/300 batch  78/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 131/300 batch  79/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 131/300 batch  80/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 131/300 batch  81/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 131/300 batch  82/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 131/300 batch  83/188  Train Loss: 0.110, Acc: 0.977\n",
      "epoch: 131/300 batch  84/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 131/300 batch  85/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 131/300 batch  86/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 131/300 batch  87/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 131/300 batch  88/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 131/300 batch  89/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 131/300 batch  90/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 131/300 batch  91/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 131/300 batch  92/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 131/300 batch  93/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 131/300 batch  94/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 131/300 batch  95/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 131/300 batch  96/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 131/300 batch  97/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 131/300 batch  98/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 131/300 batch  99/188  Train Loss: 0.056, Acc: 0.977\n",
      "epoch: 131/300 batch 100/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 131/300 batch 101/188  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 131/300 batch 102/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 131/300 batch 103/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 131/300 batch 104/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 131/300 batch 105/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 131/300 batch 106/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 131/300 batch 107/188  Train Loss: 0.049, Acc: 0.980\n",
      "epoch: 131/300 batch 108/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 131/300 batch 109/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 131/300 batch 110/188  Train Loss: 0.055, Acc: 0.992\n",
      "epoch: 131/300 batch 111/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 131/300 batch 112/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 131/300 batch 113/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 131/300 batch 114/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 131/300 batch 115/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 131/300 batch 116/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 131/300 batch 117/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 131/300 batch 118/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 131/300 batch 119/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 131/300 batch 120/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 131/300 batch 121/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 131/300 batch 122/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 131/300 batch 123/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 131/300 batch 124/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 131/300 batch 125/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 131/300 batch 126/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 131/300 batch 127/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 131/300 batch 128/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 131/300 batch 129/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 131/300 batch 130/188  Train Loss: 0.045, Acc: 0.980\n",
      "epoch: 131/300 batch 131/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 131/300 batch 132/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 131/300 batch 133/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 131/300 batch 134/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 131/300 batch 135/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 131/300 batch 136/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 131/300 batch 137/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 131/300 batch 138/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 131/300 batch 139/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 131/300 batch 140/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 131/300 batch 141/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 131/300 batch 142/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 131/300 batch 143/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 131/300 batch 144/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 131/300 batch 145/188  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 131/300 batch 146/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 131/300 batch 147/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 131/300 batch 148/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 131/300 batch 149/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 131/300 batch 150/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 131/300 batch 151/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 131/300 batch 152/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 131/300 batch 153/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 131/300 batch 154/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 131/300 batch 155/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 131/300 batch 156/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 131/300 batch 157/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 131/300 batch 158/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 131/300 batch 159/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 131/300 batch 160/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 131/300 batch 161/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 131/300 batch 162/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 131/300 batch 163/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 131/300 batch 164/188  Train Loss: 0.027, Acc: 0.988\n",
      "epoch: 131/300 batch 165/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 131/300 batch 166/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 131/300 batch 167/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 131/300 batch 168/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 131/300 batch 169/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 131/300 batch 170/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 131/300 batch 171/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 131/300 batch 172/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 131/300 batch 173/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 131/300 batch 174/188  Train Loss: 0.052, Acc: 0.992\n",
      "epoch: 131/300 batch 175/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 131/300 batch 176/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 131/300 batch 177/188  Train Loss: 0.032, Acc: 1.000\n",
      "epoch: 131/300 batch 178/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 131/300 batch 179/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 131/300 batch 180/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 131/300 batch 181/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 131/300 batch 182/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 131/300 batch 183/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 131/300 batch 184/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 131/300 batch 185/188  Train Loss: 0.061, Acc: 0.980\n",
      "epoch: 131/300 batch 186/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 131/300 batch 187/188  Train Loss: 0.035, Acc: 1.000\n",
      "Train Loss: 0.034412, Acc: 0.992\n",
      "Val Loss: 0.057532, Acc: 0.982\n",
      "epoch: 132/300 batch   0/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 132/300 batch   1/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 132/300 batch   2/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 132/300 batch   3/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 132/300 batch   4/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 132/300 batch   5/188  Train Loss: 0.058, Acc: 0.980\n",
      "epoch: 132/300 batch   6/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 132/300 batch   7/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 132/300 batch   8/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 132/300 batch   9/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 132/300 batch  10/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 132/300 batch  11/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 132/300 batch  12/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 132/300 batch  13/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 132/300 batch  14/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 132/300 batch  15/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 132/300 batch  16/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 132/300 batch  17/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 132/300 batch  18/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 132/300 batch  19/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 132/300 batch  20/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 132/300 batch  21/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 132/300 batch  22/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 132/300 batch  23/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 132/300 batch  24/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 132/300 batch  25/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 132/300 batch  26/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 132/300 batch  27/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 132/300 batch  28/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 132/300 batch  29/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 132/300 batch  30/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 132/300 batch  31/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 132/300 batch  32/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 132/300 batch  33/188  Train Loss: 0.080, Acc: 0.984\n",
      "epoch: 132/300 batch  34/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 132/300 batch  35/188  Train Loss: 0.053, Acc: 0.992\n",
      "epoch: 132/300 batch  36/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 132/300 batch  37/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 132/300 batch  38/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 132/300 batch  39/188  Train Loss: 0.055, Acc: 0.977\n",
      "epoch: 132/300 batch  40/188  Train Loss: 0.043, Acc: 0.996\n",
      "epoch: 132/300 batch  41/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 132/300 batch  42/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 132/300 batch  43/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 132/300 batch  44/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 132/300 batch  45/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 132/300 batch  46/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 132/300 batch  47/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 132/300 batch  48/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 132/300 batch  49/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 132/300 batch  50/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 132/300 batch  51/188  Train Loss: 0.048, Acc: 0.996\n",
      "epoch: 132/300 batch  52/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 132/300 batch  53/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 132/300 batch  54/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 132/300 batch  55/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 132/300 batch  56/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 132/300 batch  57/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 132/300 batch  58/188  Train Loss: 0.049, Acc: 0.977\n",
      "epoch: 132/300 batch  59/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 132/300 batch  60/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 132/300 batch  61/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 132/300 batch  62/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 132/300 batch  63/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 132/300 batch  64/188  Train Loss: 0.033, Acc: 1.000\n",
      "epoch: 132/300 batch  65/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 132/300 batch  66/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 132/300 batch  67/188  Train Loss: 0.027, Acc: 0.988\n",
      "epoch: 132/300 batch  68/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 132/300 batch  69/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 132/300 batch  70/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 132/300 batch  71/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 132/300 batch  72/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 132/300 batch  73/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 132/300 batch  74/188  Train Loss: 0.048, Acc: 0.980\n",
      "epoch: 132/300 batch  75/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 132/300 batch  76/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 132/300 batch  77/188  Train Loss: 0.041, Acc: 0.980\n",
      "epoch: 132/300 batch  78/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 132/300 batch  79/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 132/300 batch  80/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 132/300 batch  81/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 132/300 batch  82/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 132/300 batch  83/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 132/300 batch  84/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 132/300 batch  85/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 132/300 batch  86/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 132/300 batch  87/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 132/300 batch  88/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 132/300 batch  89/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 132/300 batch  90/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 132/300 batch  91/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 132/300 batch  92/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 132/300 batch  93/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 132/300 batch  94/188  Train Loss: 0.064, Acc: 0.980\n",
      "epoch: 132/300 batch  95/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 132/300 batch  96/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 132/300 batch  97/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 132/300 batch  98/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 132/300 batch  99/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 132/300 batch 100/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 132/300 batch 101/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 132/300 batch 102/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 132/300 batch 103/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 132/300 batch 104/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 132/300 batch 105/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 132/300 batch 106/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 132/300 batch 107/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 132/300 batch 108/188  Train Loss: 0.052, Acc: 0.980\n",
      "epoch: 132/300 batch 109/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 132/300 batch 110/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 132/300 batch 111/188  Train Loss: 0.025, Acc: 0.988\n",
      "epoch: 132/300 batch 112/188  Train Loss: 0.075, Acc: 0.980\n",
      "epoch: 132/300 batch 113/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 132/300 batch 114/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 132/300 batch 115/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 132/300 batch 116/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 132/300 batch 117/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 132/300 batch 118/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 132/300 batch 119/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 132/300 batch 120/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 132/300 batch 121/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 132/300 batch 122/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 132/300 batch 123/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 132/300 batch 124/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 132/300 batch 125/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 132/300 batch 126/188  Train Loss: 0.063, Acc: 0.980\n",
      "epoch: 132/300 batch 127/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 132/300 batch 128/188  Train Loss: 0.088, Acc: 0.984\n",
      "epoch: 132/300 batch 129/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 132/300 batch 130/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 132/300 batch 131/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 132/300 batch 132/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 132/300 batch 133/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 132/300 batch 134/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 132/300 batch 135/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 132/300 batch 136/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 132/300 batch 137/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 132/300 batch 138/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 132/300 batch 139/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 132/300 batch 140/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 132/300 batch 141/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 132/300 batch 142/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 132/300 batch 143/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 132/300 batch 144/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 132/300 batch 145/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 132/300 batch 146/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 132/300 batch 147/188  Train Loss: 0.052, Acc: 0.980\n",
      "epoch: 132/300 batch 148/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 132/300 batch 149/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 132/300 batch 150/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 132/300 batch 151/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 132/300 batch 152/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 132/300 batch 153/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 132/300 batch 154/188  Train Loss: 0.050, Acc: 0.980\n",
      "epoch: 132/300 batch 155/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 132/300 batch 156/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 132/300 batch 157/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 132/300 batch 158/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 132/300 batch 159/188  Train Loss: 0.034, Acc: 1.000\n",
      "epoch: 132/300 batch 160/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 132/300 batch 161/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 132/300 batch 162/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 132/300 batch 163/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 132/300 batch 164/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 132/300 batch 165/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 132/300 batch 166/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 132/300 batch 167/188  Train Loss: 0.086, Acc: 0.980\n",
      "epoch: 132/300 batch 168/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 132/300 batch 169/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 132/300 batch 170/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 132/300 batch 171/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 132/300 batch 172/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 132/300 batch 173/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 132/300 batch 174/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 132/300 batch 175/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 132/300 batch 176/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 132/300 batch 177/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 132/300 batch 178/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 132/300 batch 179/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 132/300 batch 180/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 132/300 batch 181/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 132/300 batch 182/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 132/300 batch 183/188  Train Loss: 0.065, Acc: 0.984\n",
      "epoch: 132/300 batch 184/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 132/300 batch 185/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 132/300 batch 186/188  Train Loss: 0.064, Acc: 0.988\n",
      "epoch: 132/300 batch 187/188  Train Loss: 0.015, Acc: 1.000\n",
      "Train Loss: 0.034393, Acc: 0.992\n",
      "Val Loss: 0.057759, Acc: 0.982\n",
      "epoch: 133/300 batch   0/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 133/300 batch   1/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 133/300 batch   2/188  Train Loss: 0.070, Acc: 0.980\n",
      "epoch: 133/300 batch   3/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 133/300 batch   4/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 133/300 batch   5/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 133/300 batch   6/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 133/300 batch   7/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 133/300 batch   8/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 133/300 batch   9/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 133/300 batch  10/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 133/300 batch  11/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 133/300 batch  12/188  Train Loss: 0.043, Acc: 0.980\n",
      "epoch: 133/300 batch  13/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 133/300 batch  14/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 133/300 batch  15/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 133/300 batch  16/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 133/300 batch  17/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 133/300 batch  18/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 133/300 batch  19/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 133/300 batch  20/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 133/300 batch  21/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 133/300 batch  22/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 133/300 batch  23/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 133/300 batch  24/188  Train Loss: 0.034, Acc: 0.984\n",
      "epoch: 133/300 batch  25/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 133/300 batch  26/188  Train Loss: 0.078, Acc: 0.988\n",
      "epoch: 133/300 batch  27/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 133/300 batch  28/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 133/300 batch  29/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 133/300 batch  30/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 133/300 batch  31/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 133/300 batch  32/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 133/300 batch  33/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 133/300 batch  34/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 133/300 batch  35/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 133/300 batch  36/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 133/300 batch  37/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 133/300 batch  38/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 133/300 batch  39/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 133/300 batch  40/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 133/300 batch  41/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 133/300 batch  42/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 133/300 batch  43/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 133/300 batch  44/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 133/300 batch  45/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 133/300 batch  46/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 133/300 batch  47/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 133/300 batch  48/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 133/300 batch  49/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 133/300 batch  50/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 133/300 batch  51/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 133/300 batch  52/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 133/300 batch  53/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 133/300 batch  54/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 133/300 batch  55/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 133/300 batch  56/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 133/300 batch  57/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 133/300 batch  58/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 133/300 batch  59/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 133/300 batch  60/188  Train Loss: 0.056, Acc: 0.988\n",
      "epoch: 133/300 batch  61/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 133/300 batch  62/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 133/300 batch  63/188  Train Loss: 0.049, Acc: 0.980\n",
      "epoch: 133/300 batch  64/188  Train Loss: 0.045, Acc: 0.980\n",
      "epoch: 133/300 batch  65/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 133/300 batch  66/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 133/300 batch  67/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 133/300 batch  68/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 133/300 batch  69/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 133/300 batch  70/188  Train Loss: 0.026, Acc: 0.988\n",
      "epoch: 133/300 batch  71/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 133/300 batch  72/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 133/300 batch  73/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 133/300 batch  74/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 133/300 batch  75/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 133/300 batch  76/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 133/300 batch  77/188  Train Loss: 0.053, Acc: 0.980\n",
      "epoch: 133/300 batch  78/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 133/300 batch  79/188  Train Loss: 0.032, Acc: 1.000\n",
      "epoch: 133/300 batch  80/188  Train Loss: 0.042, Acc: 0.996\n",
      "epoch: 133/300 batch  81/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 133/300 batch  82/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 133/300 batch  83/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 133/300 batch  84/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 133/300 batch  85/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 133/300 batch  86/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 133/300 batch  87/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 133/300 batch  88/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 133/300 batch  89/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 133/300 batch  90/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 133/300 batch  91/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 133/300 batch  92/188  Train Loss: 0.046, Acc: 0.996\n",
      "epoch: 133/300 batch  93/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 133/300 batch  94/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 133/300 batch  95/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 133/300 batch  96/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 133/300 batch  97/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 133/300 batch  98/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 133/300 batch  99/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 133/300 batch 100/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 133/300 batch 101/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 133/300 batch 102/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 133/300 batch 103/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 133/300 batch 104/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 133/300 batch 105/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 133/300 batch 106/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 133/300 batch 107/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 133/300 batch 108/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 133/300 batch 109/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 133/300 batch 110/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 133/300 batch 111/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 133/300 batch 112/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 133/300 batch 113/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 133/300 batch 114/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 133/300 batch 115/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 133/300 batch 116/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 133/300 batch 117/188  Train Loss: 0.044, Acc: 0.980\n",
      "epoch: 133/300 batch 118/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 133/300 batch 119/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 133/300 batch 120/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 133/300 batch 121/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 133/300 batch 122/188  Train Loss: 0.046, Acc: 0.980\n",
      "epoch: 133/300 batch 123/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 133/300 batch 124/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 133/300 batch 125/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 133/300 batch 126/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 133/300 batch 127/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 133/300 batch 128/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 133/300 batch 129/188  Train Loss: 0.043, Acc: 0.996\n",
      "epoch: 133/300 batch 130/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 133/300 batch 131/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 133/300 batch 132/188  Train Loss: 0.051, Acc: 0.992\n",
      "epoch: 133/300 batch 133/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 133/300 batch 134/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 133/300 batch 135/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 133/300 batch 136/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 133/300 batch 137/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 133/300 batch 138/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 133/300 batch 139/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 133/300 batch 140/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 133/300 batch 141/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 133/300 batch 142/188  Train Loss: 0.070, Acc: 0.988\n",
      "epoch: 133/300 batch 143/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 133/300 batch 144/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 133/300 batch 145/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 133/300 batch 146/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 133/300 batch 147/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 133/300 batch 148/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 133/300 batch 149/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 133/300 batch 150/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 133/300 batch 151/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 133/300 batch 152/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 133/300 batch 153/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 133/300 batch 154/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 133/300 batch 155/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 133/300 batch 156/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 133/300 batch 157/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 133/300 batch 158/188  Train Loss: 0.024, Acc: 0.988\n",
      "epoch: 133/300 batch 159/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 133/300 batch 160/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 133/300 batch 161/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 133/300 batch 162/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 133/300 batch 163/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 133/300 batch 164/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 133/300 batch 165/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 133/300 batch 166/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 133/300 batch 167/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 133/300 batch 168/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 133/300 batch 169/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 133/300 batch 170/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 133/300 batch 171/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 133/300 batch 172/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 133/300 batch 173/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 133/300 batch 174/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 133/300 batch 175/188  Train Loss: 0.064, Acc: 0.973\n",
      "epoch: 133/300 batch 176/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 133/300 batch 177/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 133/300 batch 178/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 133/300 batch 179/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 133/300 batch 180/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 133/300 batch 181/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 133/300 batch 182/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 133/300 batch 183/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 133/300 batch 184/188  Train Loss: 0.054, Acc: 0.980\n",
      "epoch: 133/300 batch 185/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 133/300 batch 186/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 133/300 batch 187/188  Train Loss: 0.040, Acc: 0.992\n",
      "Train Loss: 0.034419, Acc: 0.992\n",
      "Val Loss: 0.057332, Acc: 0.983\n",
      "epoch: 134/300 batch   0/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 134/300 batch   1/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 134/300 batch   2/188  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 134/300 batch   3/188  Train Loss: 0.058, Acc: 0.996\n",
      "epoch: 134/300 batch   4/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 134/300 batch   5/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 134/300 batch   6/188  Train Loss: 0.057, Acc: 0.977\n",
      "epoch: 134/300 batch   7/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 134/300 batch   8/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 134/300 batch   9/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 134/300 batch  10/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 134/300 batch  11/188  Train Loss: 0.033, Acc: 0.984\n",
      "epoch: 134/300 batch  12/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 134/300 batch  13/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 134/300 batch  14/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 134/300 batch  15/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 134/300 batch  16/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 134/300 batch  17/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 134/300 batch  18/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 134/300 batch  19/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 134/300 batch  20/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 134/300 batch  21/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 134/300 batch  22/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 134/300 batch  23/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 134/300 batch  24/188  Train Loss: 0.066, Acc: 0.977\n",
      "epoch: 134/300 batch  25/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 134/300 batch  26/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 134/300 batch  27/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 134/300 batch  28/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 134/300 batch  29/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 134/300 batch  30/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 134/300 batch  31/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 134/300 batch  32/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 134/300 batch  33/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 134/300 batch  34/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 134/300 batch  35/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 134/300 batch  36/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 134/300 batch  37/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 134/300 batch  38/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 134/300 batch  39/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 134/300 batch  40/188  Train Loss: 0.052, Acc: 0.992\n",
      "epoch: 134/300 batch  41/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 134/300 batch  42/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 134/300 batch  43/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 134/300 batch  44/188  Train Loss: 0.058, Acc: 0.988\n",
      "epoch: 134/300 batch  45/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 134/300 batch  46/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 134/300 batch  47/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 134/300 batch  48/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 134/300 batch  49/188  Train Loss: 0.015, Acc: 0.996\n",
      "epoch: 134/300 batch  50/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 134/300 batch  51/188  Train Loss: 0.073, Acc: 0.980\n",
      "epoch: 134/300 batch  52/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 134/300 batch  53/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 134/300 batch  54/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 134/300 batch  55/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 134/300 batch  56/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 134/300 batch  57/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 134/300 batch  58/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 134/300 batch  59/188  Train Loss: 0.049, Acc: 0.996\n",
      "epoch: 134/300 batch  60/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 134/300 batch  61/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 134/300 batch  62/188  Train Loss: 0.059, Acc: 0.988\n",
      "epoch: 134/300 batch  63/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 134/300 batch  64/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 134/300 batch  65/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 134/300 batch  66/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 134/300 batch  67/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 134/300 batch  68/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 134/300 batch  69/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 134/300 batch  70/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 134/300 batch  71/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 134/300 batch  72/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 134/300 batch  73/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 134/300 batch  74/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 134/300 batch  75/188  Train Loss: 0.079, Acc: 0.973\n",
      "epoch: 134/300 batch  76/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 134/300 batch  77/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 134/300 batch  78/188  Train Loss: 0.049, Acc: 0.980\n",
      "epoch: 134/300 batch  79/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 134/300 batch  80/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 134/300 batch  81/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 134/300 batch  82/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 134/300 batch  83/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 134/300 batch  84/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 134/300 batch  85/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 134/300 batch  86/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 134/300 batch  87/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 134/300 batch  88/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 134/300 batch  89/188  Train Loss: 0.060, Acc: 0.980\n",
      "epoch: 134/300 batch  90/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 134/300 batch  91/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 134/300 batch  92/188  Train Loss: 0.046, Acc: 0.980\n",
      "epoch: 134/300 batch  93/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 134/300 batch  94/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 134/300 batch  95/188  Train Loss: 0.027, Acc: 0.988\n",
      "epoch: 134/300 batch  96/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 134/300 batch  97/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 134/300 batch  98/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 134/300 batch  99/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 134/300 batch 100/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 134/300 batch 101/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 134/300 batch 102/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 134/300 batch 103/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 134/300 batch 104/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 134/300 batch 105/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 134/300 batch 106/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 134/300 batch 107/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 134/300 batch 108/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 134/300 batch 109/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 134/300 batch 110/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 134/300 batch 111/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 134/300 batch 112/188  Train Loss: 0.068, Acc: 0.977\n",
      "epoch: 134/300 batch 113/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 134/300 batch 114/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 134/300 batch 115/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 134/300 batch 116/188  Train Loss: 0.061, Acc: 0.988\n",
      "epoch: 134/300 batch 117/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 134/300 batch 118/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 134/300 batch 119/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 134/300 batch 120/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 134/300 batch 121/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 134/300 batch 122/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 134/300 batch 123/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 134/300 batch 124/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 134/300 batch 125/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 134/300 batch 126/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 134/300 batch 127/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 134/300 batch 128/188  Train Loss: 0.043, Acc: 0.980\n",
      "epoch: 134/300 batch 129/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 134/300 batch 130/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 134/300 batch 131/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 134/300 batch 132/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 134/300 batch 133/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 134/300 batch 134/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 134/300 batch 135/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 134/300 batch 136/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 134/300 batch 137/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 134/300 batch 138/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 134/300 batch 139/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 134/300 batch 140/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 134/300 batch 141/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 134/300 batch 142/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 134/300 batch 143/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 134/300 batch 144/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 134/300 batch 145/188  Train Loss: 0.068, Acc: 0.980\n",
      "epoch: 134/300 batch 146/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 134/300 batch 147/188  Train Loss: 0.031, Acc: 1.000\n",
      "epoch: 134/300 batch 148/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 134/300 batch 149/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 134/300 batch 150/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 134/300 batch 151/188  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 134/300 batch 152/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 134/300 batch 153/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 134/300 batch 154/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 134/300 batch 155/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 134/300 batch 156/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 134/300 batch 157/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 134/300 batch 158/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 134/300 batch 159/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 134/300 batch 160/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 134/300 batch 161/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 134/300 batch 162/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 134/300 batch 163/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 134/300 batch 164/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 134/300 batch 165/188  Train Loss: 0.057, Acc: 0.980\n",
      "epoch: 134/300 batch 166/188  Train Loss: 0.025, Acc: 0.988\n",
      "epoch: 134/300 batch 167/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 134/300 batch 168/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 134/300 batch 169/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 134/300 batch 170/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 134/300 batch 171/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 134/300 batch 172/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 134/300 batch 173/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 134/300 batch 174/188  Train Loss: 0.043, Acc: 0.996\n",
      "epoch: 134/300 batch 175/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 134/300 batch 176/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 134/300 batch 177/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 134/300 batch 178/188  Train Loss: 0.016, Acc: 0.996\n",
      "epoch: 134/300 batch 179/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 134/300 batch 180/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 134/300 batch 181/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 134/300 batch 182/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 134/300 batch 183/188  Train Loss: 0.058, Acc: 0.988\n",
      "epoch: 134/300 batch 184/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 134/300 batch 185/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 134/300 batch 186/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 134/300 batch 187/188  Train Loss: 0.058, Acc: 0.969\n",
      "Train Loss: 0.034425, Acc: 0.992\n",
      "Val Loss: 0.057323, Acc: 0.982\n",
      "epoch: 135/300 batch   0/188  Train Loss: 0.050, Acc: 0.980\n",
      "epoch: 135/300 batch   1/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 135/300 batch   2/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 135/300 batch   3/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 135/300 batch   4/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 135/300 batch   5/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 135/300 batch   6/188  Train Loss: 0.042, Acc: 0.996\n",
      "epoch: 135/300 batch   7/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 135/300 batch   8/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 135/300 batch   9/188  Train Loss: 0.070, Acc: 0.992\n",
      "epoch: 135/300 batch  10/188  Train Loss: 0.056, Acc: 0.980\n",
      "epoch: 135/300 batch  11/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 135/300 batch  12/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 135/300 batch  13/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 135/300 batch  14/188  Train Loss: 0.031, Acc: 0.984\n",
      "epoch: 135/300 batch  15/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 135/300 batch  16/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 135/300 batch  17/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 135/300 batch  18/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 135/300 batch  19/188  Train Loss: 0.057, Acc: 0.988\n",
      "epoch: 135/300 batch  20/188  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 135/300 batch  21/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 135/300 batch  22/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 135/300 batch  23/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 135/300 batch  24/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 135/300 batch  25/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 135/300 batch  26/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 135/300 batch  27/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 135/300 batch  28/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 135/300 batch  29/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 135/300 batch  30/188  Train Loss: 0.048, Acc: 0.980\n",
      "epoch: 135/300 batch  31/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 135/300 batch  32/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 135/300 batch  33/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 135/300 batch  34/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 135/300 batch  35/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 135/300 batch  36/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 135/300 batch  37/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 135/300 batch  38/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 135/300 batch  39/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 135/300 batch  40/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 135/300 batch  41/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 135/300 batch  42/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 135/300 batch  43/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 135/300 batch  44/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 135/300 batch  45/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 135/300 batch  46/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 135/300 batch  47/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 135/300 batch  48/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 135/300 batch  49/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 135/300 batch  50/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 135/300 batch  51/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 135/300 batch  52/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 135/300 batch  53/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 135/300 batch  54/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 135/300 batch  55/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 135/300 batch  56/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 135/300 batch  57/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 135/300 batch  58/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 135/300 batch  59/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 135/300 batch  60/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 135/300 batch  61/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 135/300 batch  62/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 135/300 batch  63/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 135/300 batch  64/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 135/300 batch  65/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 135/300 batch  66/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 135/300 batch  67/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 135/300 batch  68/188  Train Loss: 0.063, Acc: 0.980\n",
      "epoch: 135/300 batch  69/188  Train Loss: 0.065, Acc: 0.984\n",
      "epoch: 135/300 batch  70/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 135/300 batch  71/188  Train Loss: 0.063, Acc: 0.980\n",
      "epoch: 135/300 batch  72/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 135/300 batch  73/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 135/300 batch  74/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 135/300 batch  75/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 135/300 batch  76/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 135/300 batch  77/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 135/300 batch  78/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 135/300 batch  79/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 135/300 batch  80/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 135/300 batch  81/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 135/300 batch  82/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 135/300 batch  83/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 135/300 batch  84/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 135/300 batch  85/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 135/300 batch  86/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 135/300 batch  87/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 135/300 batch  88/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 135/300 batch  89/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 135/300 batch  90/188  Train Loss: 0.049, Acc: 0.980\n",
      "epoch: 135/300 batch  91/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 135/300 batch  92/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 135/300 batch  93/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 135/300 batch  94/188  Train Loss: 0.058, Acc: 0.996\n",
      "epoch: 135/300 batch  95/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 135/300 batch  96/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 135/300 batch  97/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 135/300 batch  98/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 135/300 batch  99/188  Train Loss: 0.030, Acc: 0.984\n",
      "epoch: 135/300 batch 100/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 135/300 batch 101/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 135/300 batch 102/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 135/300 batch 103/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 135/300 batch 104/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 135/300 batch 105/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 135/300 batch 106/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 135/300 batch 107/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 135/300 batch 108/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 135/300 batch 109/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 135/300 batch 110/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 135/300 batch 111/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 135/300 batch 112/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 135/300 batch 113/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 135/300 batch 114/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 135/300 batch 115/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 135/300 batch 116/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 135/300 batch 117/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 135/300 batch 118/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 135/300 batch 119/188  Train Loss: 0.044, Acc: 0.980\n",
      "epoch: 135/300 batch 120/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 135/300 batch 121/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 135/300 batch 122/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 135/300 batch 123/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 135/300 batch 124/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 135/300 batch 125/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 135/300 batch 126/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 135/300 batch 127/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 135/300 batch 128/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 135/300 batch 129/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 135/300 batch 130/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 135/300 batch 131/188  Train Loss: 0.059, Acc: 0.977\n",
      "epoch: 135/300 batch 132/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 135/300 batch 133/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 135/300 batch 134/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 135/300 batch 135/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 135/300 batch 136/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 135/300 batch 137/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 135/300 batch 138/188  Train Loss: 0.067, Acc: 0.973\n",
      "epoch: 135/300 batch 139/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 135/300 batch 140/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 135/300 batch 141/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 135/300 batch 142/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 135/300 batch 143/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 135/300 batch 144/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 135/300 batch 145/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 135/300 batch 146/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 135/300 batch 147/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 135/300 batch 148/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 135/300 batch 149/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 135/300 batch 150/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 135/300 batch 151/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 135/300 batch 152/188  Train Loss: 0.056, Acc: 0.992\n",
      "epoch: 135/300 batch 153/188  Train Loss: 0.066, Acc: 0.980\n",
      "epoch: 135/300 batch 154/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 135/300 batch 155/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 135/300 batch 156/188  Train Loss: 0.064, Acc: 0.988\n",
      "epoch: 135/300 batch 157/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 135/300 batch 158/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 135/300 batch 159/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 135/300 batch 160/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 135/300 batch 161/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 135/300 batch 162/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 135/300 batch 163/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 135/300 batch 164/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 135/300 batch 165/188  Train Loss: 0.056, Acc: 0.977\n",
      "epoch: 135/300 batch 166/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 135/300 batch 167/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 135/300 batch 168/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 135/300 batch 169/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 135/300 batch 170/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 135/300 batch 171/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 135/300 batch 172/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 135/300 batch 173/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 135/300 batch 174/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 135/300 batch 175/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 135/300 batch 176/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 135/300 batch 177/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 135/300 batch 178/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 135/300 batch 179/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 135/300 batch 180/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 135/300 batch 181/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 135/300 batch 182/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 135/300 batch 183/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 135/300 batch 184/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 135/300 batch 185/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 135/300 batch 186/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 135/300 batch 187/188  Train Loss: 0.015, Acc: 1.000\n",
      "Train Loss: 0.034311, Acc: 0.992\n",
      "Val Loss: 0.057598, Acc: 0.982\n",
      "epoch: 136/300 batch   0/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 136/300 batch   1/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 136/300 batch   2/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 136/300 batch   3/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 136/300 batch   4/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 136/300 batch   5/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 136/300 batch   6/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 136/300 batch   7/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 136/300 batch   8/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 136/300 batch   9/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 136/300 batch  10/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 136/300 batch  11/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 136/300 batch  12/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 136/300 batch  13/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 136/300 batch  14/188  Train Loss: 0.027, Acc: 0.988\n",
      "epoch: 136/300 batch  15/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 136/300 batch  16/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 136/300 batch  17/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 136/300 batch  18/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 136/300 batch  19/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 136/300 batch  20/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 136/300 batch  21/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 136/300 batch  22/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 136/300 batch  23/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 136/300 batch  24/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 136/300 batch  25/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 136/300 batch  26/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 136/300 batch  27/188  Train Loss: 0.043, Acc: 0.996\n",
      "epoch: 136/300 batch  28/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 136/300 batch  29/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 136/300 batch  30/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 136/300 batch  31/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 136/300 batch  32/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 136/300 batch  33/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 136/300 batch  34/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 136/300 batch  35/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 136/300 batch  36/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 136/300 batch  37/188  Train Loss: 0.037, Acc: 0.980\n",
      "epoch: 136/300 batch  38/188  Train Loss: 0.059, Acc: 0.969\n",
      "epoch: 136/300 batch  39/188  Train Loss: 0.046, Acc: 0.996\n",
      "epoch: 136/300 batch  40/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 136/300 batch  41/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 136/300 batch  42/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 136/300 batch  43/188  Train Loss: 0.063, Acc: 0.984\n",
      "epoch: 136/300 batch  44/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 136/300 batch  45/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 136/300 batch  46/188  Train Loss: 0.082, Acc: 0.988\n",
      "epoch: 136/300 batch  47/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 136/300 batch  48/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 136/300 batch  49/188  Train Loss: 0.059, Acc: 0.980\n",
      "epoch: 136/300 batch  50/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 136/300 batch  51/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 136/300 batch  52/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 136/300 batch  53/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 136/300 batch  54/188  Train Loss: 0.057, Acc: 0.992\n",
      "epoch: 136/300 batch  55/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 136/300 batch  56/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 136/300 batch  57/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 136/300 batch  58/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 136/300 batch  59/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 136/300 batch  60/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 136/300 batch  61/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 136/300 batch  62/188  Train Loss: 0.020, Acc: 0.988\n",
      "epoch: 136/300 batch  63/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 136/300 batch  64/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 136/300 batch  65/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 136/300 batch  66/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 136/300 batch  67/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 136/300 batch  68/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 136/300 batch  69/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 136/300 batch  70/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 136/300 batch  71/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 136/300 batch  72/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 136/300 batch  73/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 136/300 batch  74/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 136/300 batch  75/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 136/300 batch  76/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 136/300 batch  77/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 136/300 batch  78/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 136/300 batch  79/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 136/300 batch  80/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 136/300 batch  81/188  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 136/300 batch  82/188  Train Loss: 0.045, Acc: 0.980\n",
      "epoch: 136/300 batch  83/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 136/300 batch  84/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 136/300 batch  85/188  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 136/300 batch  86/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 136/300 batch  87/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 136/300 batch  88/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 136/300 batch  89/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 136/300 batch  90/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 136/300 batch  91/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 136/300 batch  92/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 136/300 batch  93/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 136/300 batch  94/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 136/300 batch  95/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 136/300 batch  96/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 136/300 batch  97/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 136/300 batch  98/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 136/300 batch  99/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 136/300 batch 100/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 136/300 batch 101/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 136/300 batch 102/188  Train Loss: 0.056, Acc: 0.988\n",
      "epoch: 136/300 batch 103/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 136/300 batch 104/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 136/300 batch 105/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 136/300 batch 106/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 136/300 batch 107/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 136/300 batch 108/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 136/300 batch 109/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 136/300 batch 110/188  Train Loss: 0.052, Acc: 0.980\n",
      "epoch: 136/300 batch 111/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 136/300 batch 112/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 136/300 batch 113/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 136/300 batch 114/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 136/300 batch 115/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 136/300 batch 116/188  Train Loss: 0.059, Acc: 0.988\n",
      "epoch: 136/300 batch 117/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 136/300 batch 118/188  Train Loss: 0.025, Acc: 0.988\n",
      "epoch: 136/300 batch 119/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 136/300 batch 120/188  Train Loss: 0.031, Acc: 1.000\n",
      "epoch: 136/300 batch 121/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 136/300 batch 122/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 136/300 batch 123/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 136/300 batch 124/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 136/300 batch 125/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 136/300 batch 126/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 136/300 batch 127/188  Train Loss: 0.053, Acc: 0.980\n",
      "epoch: 136/300 batch 128/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 136/300 batch 129/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 136/300 batch 130/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 136/300 batch 131/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 136/300 batch 132/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 136/300 batch 133/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 136/300 batch 134/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 136/300 batch 135/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 136/300 batch 136/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 136/300 batch 137/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 136/300 batch 138/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 136/300 batch 139/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 136/300 batch 140/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 136/300 batch 141/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 136/300 batch 142/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 136/300 batch 143/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 136/300 batch 144/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 136/300 batch 145/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 136/300 batch 146/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 136/300 batch 147/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 136/300 batch 148/188  Train Loss: 0.044, Acc: 0.996\n",
      "epoch: 136/300 batch 149/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 136/300 batch 150/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 136/300 batch 151/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 136/300 batch 152/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 136/300 batch 153/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 136/300 batch 154/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 136/300 batch 155/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 136/300 batch 156/188  Train Loss: 0.062, Acc: 0.984\n",
      "epoch: 136/300 batch 157/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 136/300 batch 158/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 136/300 batch 159/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 136/300 batch 160/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 136/300 batch 161/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 136/300 batch 162/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 136/300 batch 163/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 136/300 batch 164/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 136/300 batch 165/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 136/300 batch 166/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 136/300 batch 167/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 136/300 batch 168/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 136/300 batch 169/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 136/300 batch 170/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 136/300 batch 171/188  Train Loss: 0.058, Acc: 0.988\n",
      "epoch: 136/300 batch 172/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 136/300 batch 173/188  Train Loss: 0.044, Acc: 0.996\n",
      "epoch: 136/300 batch 174/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 136/300 batch 175/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 136/300 batch 176/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 136/300 batch 177/188  Train Loss: 0.061, Acc: 0.988\n",
      "epoch: 136/300 batch 178/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 136/300 batch 179/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 136/300 batch 180/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 136/300 batch 181/188  Train Loss: 0.016, Acc: 0.996\n",
      "epoch: 136/300 batch 182/188  Train Loss: 0.058, Acc: 0.988\n",
      "epoch: 136/300 batch 183/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 136/300 batch 184/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 136/300 batch 185/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 136/300 batch 186/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 136/300 batch 187/188  Train Loss: 0.027, Acc: 1.000\n",
      "Train Loss: 0.034267, Acc: 0.992\n",
      "Val Loss: 0.057310, Acc: 0.983\n",
      "epoch: 137/300 batch   0/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 137/300 batch   1/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 137/300 batch   2/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 137/300 batch   3/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 137/300 batch   4/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 137/300 batch   5/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 137/300 batch   6/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 137/300 batch   7/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 137/300 batch   8/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 137/300 batch   9/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 137/300 batch  10/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 137/300 batch  11/188  Train Loss: 0.043, Acc: 0.980\n",
      "epoch: 137/300 batch  12/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 137/300 batch  13/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 137/300 batch  14/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 137/300 batch  15/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 137/300 batch  16/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 137/300 batch  17/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 137/300 batch  18/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 137/300 batch  19/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 137/300 batch  20/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 137/300 batch  21/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 137/300 batch  22/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 137/300 batch  23/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 137/300 batch  24/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 137/300 batch  25/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 137/300 batch  26/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 137/300 batch  27/188  Train Loss: 0.047, Acc: 0.996\n",
      "epoch: 137/300 batch  28/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 137/300 batch  29/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 137/300 batch  30/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 137/300 batch  31/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 137/300 batch  32/188  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 137/300 batch  33/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 137/300 batch  34/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 137/300 batch  35/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 137/300 batch  36/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 137/300 batch  37/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 137/300 batch  38/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 137/300 batch  39/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 137/300 batch  40/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 137/300 batch  41/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 137/300 batch  42/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 137/300 batch  43/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 137/300 batch  44/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 137/300 batch  45/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 137/300 batch  46/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 137/300 batch  47/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 137/300 batch  48/188  Train Loss: 0.073, Acc: 0.980\n",
      "epoch: 137/300 batch  49/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 137/300 batch  50/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 137/300 batch  51/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 137/300 batch  52/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 137/300 batch  53/188  Train Loss: 0.044, Acc: 0.996\n",
      "epoch: 137/300 batch  54/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 137/300 batch  55/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 137/300 batch  56/188  Train Loss: 0.044, Acc: 0.980\n",
      "epoch: 137/300 batch  57/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 137/300 batch  58/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 137/300 batch  59/188  Train Loss: 0.046, Acc: 0.980\n",
      "epoch: 137/300 batch  60/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 137/300 batch  61/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 137/300 batch  62/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 137/300 batch  63/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 137/300 batch  64/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 137/300 batch  65/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 137/300 batch  66/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 137/300 batch  67/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 137/300 batch  68/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 137/300 batch  69/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 137/300 batch  70/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 137/300 batch  71/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 137/300 batch  72/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 137/300 batch  73/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 137/300 batch  74/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 137/300 batch  75/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 137/300 batch  76/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 137/300 batch  77/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 137/300 batch  78/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 137/300 batch  79/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 137/300 batch  80/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 137/300 batch  81/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 137/300 batch  82/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 137/300 batch  83/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 137/300 batch  84/188  Train Loss: 0.045, Acc: 0.980\n",
      "epoch: 137/300 batch  85/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 137/300 batch  86/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 137/300 batch  87/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 137/300 batch  88/188  Train Loss: 0.055, Acc: 0.980\n",
      "epoch: 137/300 batch  89/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 137/300 batch  90/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 137/300 batch  91/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 137/300 batch  92/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 137/300 batch  93/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 137/300 batch  94/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 137/300 batch  95/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 137/300 batch  96/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 137/300 batch  97/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 137/300 batch  98/188  Train Loss: 0.031, Acc: 1.000\n",
      "epoch: 137/300 batch  99/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 137/300 batch 100/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 137/300 batch 101/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 137/300 batch 102/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 137/300 batch 103/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 137/300 batch 104/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 137/300 batch 105/188  Train Loss: 0.055, Acc: 0.980\n",
      "epoch: 137/300 batch 106/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 137/300 batch 107/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 137/300 batch 108/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 137/300 batch 109/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 137/300 batch 110/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 137/300 batch 111/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 137/300 batch 112/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 137/300 batch 113/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 137/300 batch 114/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 137/300 batch 115/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 137/300 batch 116/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 137/300 batch 117/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 137/300 batch 118/188  Train Loss: 0.066, Acc: 0.977\n",
      "epoch: 137/300 batch 119/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 137/300 batch 120/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 137/300 batch 121/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 137/300 batch 122/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 137/300 batch 123/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 137/300 batch 124/188  Train Loss: 0.032, Acc: 1.000\n",
      "epoch: 137/300 batch 125/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 137/300 batch 126/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 137/300 batch 127/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 137/300 batch 128/188  Train Loss: 0.049, Acc: 0.980\n",
      "epoch: 137/300 batch 129/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 137/300 batch 130/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 137/300 batch 131/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 137/300 batch 132/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 137/300 batch 133/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 137/300 batch 134/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 137/300 batch 135/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 137/300 batch 136/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 137/300 batch 137/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 137/300 batch 138/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 137/300 batch 139/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 137/300 batch 140/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 137/300 batch 141/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 137/300 batch 142/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 137/300 batch 143/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 137/300 batch 144/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 137/300 batch 145/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 137/300 batch 146/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 137/300 batch 147/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 137/300 batch 148/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 137/300 batch 149/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 137/300 batch 150/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 137/300 batch 151/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 137/300 batch 152/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 137/300 batch 153/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 137/300 batch 154/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 137/300 batch 155/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 137/300 batch 156/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 137/300 batch 157/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 137/300 batch 158/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 137/300 batch 159/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 137/300 batch 160/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 137/300 batch 161/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 137/300 batch 162/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 137/300 batch 163/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 137/300 batch 164/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 137/300 batch 165/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 137/300 batch 166/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 137/300 batch 167/188  Train Loss: 0.062, Acc: 0.984\n",
      "epoch: 137/300 batch 168/188  Train Loss: 0.100, Acc: 0.977\n",
      "epoch: 137/300 batch 169/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 137/300 batch 170/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 137/300 batch 171/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 137/300 batch 172/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 137/300 batch 173/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 137/300 batch 174/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 137/300 batch 175/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 137/300 batch 176/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 137/300 batch 177/188  Train Loss: 0.068, Acc: 0.984\n",
      "epoch: 137/300 batch 178/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 137/300 batch 179/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 137/300 batch 180/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 137/300 batch 181/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 137/300 batch 182/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 137/300 batch 183/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 137/300 batch 184/188  Train Loss: 0.045, Acc: 0.980\n",
      "epoch: 137/300 batch 185/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 137/300 batch 186/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 137/300 batch 187/188  Train Loss: 0.038, Acc: 0.992\n",
      "Train Loss: 0.034337, Acc: 0.992\n",
      "Val Loss: 0.057271, Acc: 0.983\n",
      "epoch: 138/300 batch   0/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 138/300 batch   1/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 138/300 batch   2/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 138/300 batch   3/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 138/300 batch   4/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 138/300 batch   5/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 138/300 batch   6/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 138/300 batch   7/188  Train Loss: 0.055, Acc: 0.980\n",
      "epoch: 138/300 batch   8/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 138/300 batch   9/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 138/300 batch  10/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 138/300 batch  11/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 138/300 batch  12/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 138/300 batch  13/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 138/300 batch  14/188  Train Loss: 0.051, Acc: 0.980\n",
      "epoch: 138/300 batch  15/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 138/300 batch  16/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 138/300 batch  17/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 138/300 batch  18/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 138/300 batch  19/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 138/300 batch  20/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 138/300 batch  21/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 138/300 batch  22/188  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 138/300 batch  23/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 138/300 batch  24/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 138/300 batch  25/188  Train Loss: 0.061, Acc: 0.977\n",
      "epoch: 138/300 batch  26/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 138/300 batch  27/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 138/300 batch  28/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 138/300 batch  29/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 138/300 batch  30/188  Train Loss: 0.043, Acc: 0.996\n",
      "epoch: 138/300 batch  31/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 138/300 batch  32/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 138/300 batch  33/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 138/300 batch  34/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 138/300 batch  35/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 138/300 batch  36/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 138/300 batch  37/188  Train Loss: 0.033, Acc: 1.000\n",
      "epoch: 138/300 batch  38/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 138/300 batch  39/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 138/300 batch  40/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 138/300 batch  41/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 138/300 batch  42/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 138/300 batch  43/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 138/300 batch  44/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 138/300 batch  45/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 138/300 batch  46/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 138/300 batch  47/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 138/300 batch  48/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 138/300 batch  49/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 138/300 batch  50/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 138/300 batch  51/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 138/300 batch  52/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 138/300 batch  53/188  Train Loss: 0.042, Acc: 0.980\n",
      "epoch: 138/300 batch  54/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 138/300 batch  55/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 138/300 batch  56/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 138/300 batch  57/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 138/300 batch  58/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 138/300 batch  59/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 138/300 batch  60/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 138/300 batch  61/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 138/300 batch  62/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 138/300 batch  63/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 138/300 batch  64/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 138/300 batch  65/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 138/300 batch  66/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 138/300 batch  67/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 138/300 batch  68/188  Train Loss: 0.053, Acc: 0.992\n",
      "epoch: 138/300 batch  69/188  Train Loss: 0.070, Acc: 0.984\n",
      "epoch: 138/300 batch  70/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 138/300 batch  71/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 138/300 batch  72/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 138/300 batch  73/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 138/300 batch  74/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 138/300 batch  75/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 138/300 batch  76/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 138/300 batch  77/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 138/300 batch  78/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 138/300 batch  79/188  Train Loss: 0.065, Acc: 0.988\n",
      "epoch: 138/300 batch  80/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 138/300 batch  81/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 138/300 batch  82/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 138/300 batch  83/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 138/300 batch  84/188  Train Loss: 0.033, Acc: 0.980\n",
      "epoch: 138/300 batch  85/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 138/300 batch  86/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 138/300 batch  87/188  Train Loss: 0.052, Acc: 0.992\n",
      "epoch: 138/300 batch  88/188  Train Loss: 0.049, Acc: 0.996\n",
      "epoch: 138/300 batch  89/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 138/300 batch  90/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 138/300 batch  91/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 138/300 batch  92/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 138/300 batch  93/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 138/300 batch  94/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 138/300 batch  95/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 138/300 batch  96/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 138/300 batch  97/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 138/300 batch  98/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 138/300 batch  99/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 138/300 batch 100/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 138/300 batch 101/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 138/300 batch 102/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 138/300 batch 103/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 138/300 batch 104/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 138/300 batch 105/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 138/300 batch 106/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 138/300 batch 107/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 138/300 batch 108/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 138/300 batch 109/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 138/300 batch 110/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 138/300 batch 111/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 138/300 batch 112/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 138/300 batch 113/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 138/300 batch 114/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 138/300 batch 115/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 138/300 batch 116/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 138/300 batch 117/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 138/300 batch 118/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 138/300 batch 119/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 138/300 batch 120/188  Train Loss: 0.066, Acc: 0.977\n",
      "epoch: 138/300 batch 121/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 138/300 batch 122/188  Train Loss: 0.069, Acc: 0.977\n",
      "epoch: 138/300 batch 123/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 138/300 batch 124/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 138/300 batch 125/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 138/300 batch 126/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 138/300 batch 127/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 138/300 batch 128/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 138/300 batch 129/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 138/300 batch 130/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 138/300 batch 131/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 138/300 batch 132/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 138/300 batch 133/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 138/300 batch 134/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 138/300 batch 135/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 138/300 batch 136/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 138/300 batch 137/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 138/300 batch 138/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 138/300 batch 139/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 138/300 batch 140/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 138/300 batch 141/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 138/300 batch 142/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 138/300 batch 143/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 138/300 batch 144/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 138/300 batch 145/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 138/300 batch 146/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 138/300 batch 147/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 138/300 batch 148/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 138/300 batch 149/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 138/300 batch 150/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 138/300 batch 151/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 138/300 batch 152/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 138/300 batch 153/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 138/300 batch 154/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 138/300 batch 155/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 138/300 batch 156/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 138/300 batch 157/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 138/300 batch 158/188  Train Loss: 0.042, Acc: 0.996\n",
      "epoch: 138/300 batch 159/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 138/300 batch 160/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 138/300 batch 161/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 138/300 batch 162/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 138/300 batch 163/188  Train Loss: 0.055, Acc: 0.992\n",
      "epoch: 138/300 batch 164/188  Train Loss: 0.067, Acc: 0.984\n",
      "epoch: 138/300 batch 165/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 138/300 batch 166/188  Train Loss: 0.059, Acc: 0.977\n",
      "epoch: 138/300 batch 167/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 138/300 batch 168/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 138/300 batch 169/188  Train Loss: 0.025, Acc: 0.988\n",
      "epoch: 138/300 batch 170/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 138/300 batch 171/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 138/300 batch 172/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 138/300 batch 173/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 138/300 batch 174/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 138/300 batch 175/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 138/300 batch 176/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 138/300 batch 177/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 138/300 batch 178/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 138/300 batch 179/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 138/300 batch 180/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 138/300 batch 181/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 138/300 batch 182/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 138/300 batch 183/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 138/300 batch 184/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 138/300 batch 185/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 138/300 batch 186/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 138/300 batch 187/188  Train Loss: 0.012, Acc: 1.000\n",
      "Train Loss: 0.034169, Acc: 0.993\n",
      "Val Loss: 0.058051, Acc: 0.982\n",
      "epoch: 139/300 batch   0/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 139/300 batch   1/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 139/300 batch   2/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 139/300 batch   3/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 139/300 batch   4/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 139/300 batch   5/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 139/300 batch   6/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 139/300 batch   7/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 139/300 batch   8/188  Train Loss: 0.070, Acc: 0.984\n",
      "epoch: 139/300 batch   9/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 139/300 batch  10/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 139/300 batch  11/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 139/300 batch  12/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 139/300 batch  13/188  Train Loss: 0.054, Acc: 0.992\n",
      "epoch: 139/300 batch  14/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 139/300 batch  15/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 139/300 batch  16/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 139/300 batch  17/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 139/300 batch  18/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 139/300 batch  19/188  Train Loss: 0.038, Acc: 0.980\n",
      "epoch: 139/300 batch  20/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 139/300 batch  21/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 139/300 batch  22/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 139/300 batch  23/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 139/300 batch  24/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 139/300 batch  25/188  Train Loss: 0.050, Acc: 0.977\n",
      "epoch: 139/300 batch  26/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 139/300 batch  27/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 139/300 batch  28/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 139/300 batch  29/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 139/300 batch  30/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 139/300 batch  31/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 139/300 batch  32/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 139/300 batch  33/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 139/300 batch  34/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 139/300 batch  35/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 139/300 batch  36/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 139/300 batch  37/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 139/300 batch  38/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 139/300 batch  39/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 139/300 batch  40/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 139/300 batch  41/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 139/300 batch  42/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 139/300 batch  43/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 139/300 batch  44/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 139/300 batch  45/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 139/300 batch  46/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 139/300 batch  47/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 139/300 batch  48/188  Train Loss: 0.050, Acc: 0.980\n",
      "epoch: 139/300 batch  49/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 139/300 batch  50/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 139/300 batch  51/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 139/300 batch  52/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 139/300 batch  53/188  Train Loss: 0.016, Acc: 0.996\n",
      "epoch: 139/300 batch  54/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 139/300 batch  55/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 139/300 batch  56/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 139/300 batch  57/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 139/300 batch  58/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 139/300 batch  59/188  Train Loss: 0.057, Acc: 0.980\n",
      "epoch: 139/300 batch  60/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 139/300 batch  61/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 139/300 batch  62/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 139/300 batch  63/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 139/300 batch  64/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 139/300 batch  65/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 139/300 batch  66/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 139/300 batch  67/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 139/300 batch  68/188  Train Loss: 0.048, Acc: 0.980\n",
      "epoch: 139/300 batch  69/188  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 139/300 batch  70/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 139/300 batch  71/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 139/300 batch  72/188  Train Loss: 0.051, Acc: 0.980\n",
      "epoch: 139/300 batch  73/188  Train Loss: 0.030, Acc: 0.984\n",
      "epoch: 139/300 batch  74/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 139/300 batch  75/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 139/300 batch  76/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 139/300 batch  77/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 139/300 batch  78/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 139/300 batch  79/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 139/300 batch  80/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 139/300 batch  81/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 139/300 batch  82/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 139/300 batch  83/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 139/300 batch  84/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 139/300 batch  85/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 139/300 batch  86/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 139/300 batch  87/188  Train Loss: 0.045, Acc: 0.980\n",
      "epoch: 139/300 batch  88/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 139/300 batch  89/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 139/300 batch  90/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 139/300 batch  91/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 139/300 batch  92/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 139/300 batch  93/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 139/300 batch  94/188  Train Loss: 0.058, Acc: 0.980\n",
      "epoch: 139/300 batch  95/188  Train Loss: 0.054, Acc: 0.980\n",
      "epoch: 139/300 batch  96/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 139/300 batch  97/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 139/300 batch  98/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 139/300 batch  99/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 139/300 batch 100/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 139/300 batch 101/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 139/300 batch 102/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 139/300 batch 103/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 139/300 batch 104/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 139/300 batch 105/188  Train Loss: 0.051, Acc: 0.992\n",
      "epoch: 139/300 batch 106/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 139/300 batch 107/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 139/300 batch 108/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 139/300 batch 109/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 139/300 batch 110/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 139/300 batch 111/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 139/300 batch 112/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 139/300 batch 113/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 139/300 batch 114/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 139/300 batch 115/188  Train Loss: 0.051, Acc: 0.980\n",
      "epoch: 139/300 batch 116/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 139/300 batch 117/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 139/300 batch 118/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 139/300 batch 119/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 139/300 batch 120/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 139/300 batch 121/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 139/300 batch 122/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 139/300 batch 123/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 139/300 batch 124/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 139/300 batch 125/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 139/300 batch 126/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 139/300 batch 127/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 139/300 batch 128/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 139/300 batch 129/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 139/300 batch 130/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 139/300 batch 131/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 139/300 batch 132/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 139/300 batch 133/188  Train Loss: 0.062, Acc: 0.984\n",
      "epoch: 139/300 batch 134/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 139/300 batch 135/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 139/300 batch 136/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 139/300 batch 137/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 139/300 batch 138/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 139/300 batch 139/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 139/300 batch 140/188  Train Loss: 0.067, Acc: 0.980\n",
      "epoch: 139/300 batch 141/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 139/300 batch 142/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 139/300 batch 143/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 139/300 batch 144/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 139/300 batch 145/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 139/300 batch 146/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 139/300 batch 147/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 139/300 batch 148/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 139/300 batch 149/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 139/300 batch 150/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 139/300 batch 151/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 139/300 batch 152/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 139/300 batch 153/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 139/300 batch 154/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 139/300 batch 155/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 139/300 batch 156/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 139/300 batch 157/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 139/300 batch 158/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 139/300 batch 159/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 139/300 batch 160/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 139/300 batch 161/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 139/300 batch 162/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 139/300 batch 163/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 139/300 batch 164/188  Train Loss: 0.068, Acc: 0.992\n",
      "epoch: 139/300 batch 165/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 139/300 batch 166/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 139/300 batch 167/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 139/300 batch 168/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 139/300 batch 169/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 139/300 batch 170/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 139/300 batch 171/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 139/300 batch 172/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 139/300 batch 173/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 139/300 batch 174/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 139/300 batch 175/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 139/300 batch 176/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 139/300 batch 177/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 139/300 batch 178/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 139/300 batch 179/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 139/300 batch 180/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 139/300 batch 181/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 139/300 batch 182/188  Train Loss: 0.058, Acc: 0.977\n",
      "epoch: 139/300 batch 183/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 139/300 batch 184/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 139/300 batch 185/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 139/300 batch 186/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 139/300 batch 187/188  Train Loss: 0.054, Acc: 0.992\n",
      "Train Loss: 0.034292, Acc: 0.992\n",
      "Val Loss: 0.057684, Acc: 0.983\n",
      "epoch: 140/300 batch   0/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 140/300 batch   1/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 140/300 batch   2/188  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 140/300 batch   3/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 140/300 batch   4/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 140/300 batch   5/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 140/300 batch   6/188  Train Loss: 0.081, Acc: 0.977\n",
      "epoch: 140/300 batch   7/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 140/300 batch   8/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 140/300 batch   9/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 140/300 batch  10/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 140/300 batch  11/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 140/300 batch  12/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 140/300 batch  13/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 140/300 batch  14/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 140/300 batch  15/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 140/300 batch  16/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 140/300 batch  17/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 140/300 batch  18/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 140/300 batch  19/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 140/300 batch  20/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 140/300 batch  21/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 140/300 batch  22/188  Train Loss: 0.062, Acc: 0.992\n",
      "epoch: 140/300 batch  23/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 140/300 batch  24/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 140/300 batch  25/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 140/300 batch  26/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 140/300 batch  27/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 140/300 batch  28/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 140/300 batch  29/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 140/300 batch  30/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 140/300 batch  31/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 140/300 batch  32/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 140/300 batch  33/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 140/300 batch  34/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 140/300 batch  35/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 140/300 batch  36/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 140/300 batch  37/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 140/300 batch  38/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 140/300 batch  39/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 140/300 batch  40/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 140/300 batch  41/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 140/300 batch  42/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 140/300 batch  43/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 140/300 batch  44/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 140/300 batch  45/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 140/300 batch  46/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 140/300 batch  47/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 140/300 batch  48/188  Train Loss: 0.049, Acc: 0.980\n",
      "epoch: 140/300 batch  49/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 140/300 batch  50/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 140/300 batch  51/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 140/300 batch  52/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 140/300 batch  53/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 140/300 batch  54/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 140/300 batch  55/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 140/300 batch  56/188  Train Loss: 0.049, Acc: 0.977\n",
      "epoch: 140/300 batch  57/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 140/300 batch  58/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 140/300 batch  59/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 140/300 batch  60/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 140/300 batch  61/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 140/300 batch  62/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 140/300 batch  63/188  Train Loss: 0.065, Acc: 0.988\n",
      "epoch: 140/300 batch  64/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 140/300 batch  65/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 140/300 batch  66/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 140/300 batch  67/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 140/300 batch  68/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 140/300 batch  69/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 140/300 batch  70/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 140/300 batch  71/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 140/300 batch  72/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 140/300 batch  73/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 140/300 batch  74/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 140/300 batch  75/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 140/300 batch  76/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 140/300 batch  77/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 140/300 batch  78/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 140/300 batch  79/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 140/300 batch  80/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 140/300 batch  81/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 140/300 batch  82/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 140/300 batch  83/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 140/300 batch  84/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 140/300 batch  85/188  Train Loss: 0.051, Acc: 0.992\n",
      "epoch: 140/300 batch  86/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 140/300 batch  87/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 140/300 batch  88/188  Train Loss: 0.048, Acc: 0.980\n",
      "epoch: 140/300 batch  89/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 140/300 batch  90/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 140/300 batch  91/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 140/300 batch  92/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 140/300 batch  93/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 140/300 batch  94/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 140/300 batch  95/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 140/300 batch  96/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 140/300 batch  97/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 140/300 batch  98/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 140/300 batch  99/188  Train Loss: 0.066, Acc: 0.980\n",
      "epoch: 140/300 batch 100/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 140/300 batch 101/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 140/300 batch 102/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 140/300 batch 103/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 140/300 batch 104/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 140/300 batch 105/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 140/300 batch 106/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 140/300 batch 107/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 140/300 batch 108/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 140/300 batch 109/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 140/300 batch 110/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 140/300 batch 111/188  Train Loss: 0.035, Acc: 0.980\n",
      "epoch: 140/300 batch 112/188  Train Loss: 0.053, Acc: 0.977\n",
      "epoch: 140/300 batch 113/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 140/300 batch 114/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 140/300 batch 115/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 140/300 batch 116/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 140/300 batch 117/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 140/300 batch 118/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 140/300 batch 119/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 140/300 batch 120/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 140/300 batch 121/188  Train Loss: 0.053, Acc: 0.992\n",
      "epoch: 140/300 batch 122/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 140/300 batch 123/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 140/300 batch 124/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 140/300 batch 125/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 140/300 batch 126/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 140/300 batch 127/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 140/300 batch 128/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 140/300 batch 129/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 140/300 batch 130/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 140/300 batch 131/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 140/300 batch 132/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 140/300 batch 133/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 140/300 batch 134/188  Train Loss: 0.065, Acc: 0.980\n",
      "epoch: 140/300 batch 135/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 140/300 batch 136/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 140/300 batch 137/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 140/300 batch 138/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 140/300 batch 139/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 140/300 batch 140/188  Train Loss: 0.058, Acc: 0.996\n",
      "epoch: 140/300 batch 141/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 140/300 batch 142/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 140/300 batch 143/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 140/300 batch 144/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 140/300 batch 145/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 140/300 batch 146/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 140/300 batch 147/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 140/300 batch 148/188  Train Loss: 0.048, Acc: 0.980\n",
      "epoch: 140/300 batch 149/188  Train Loss: 0.057, Acc: 0.988\n",
      "epoch: 140/300 batch 150/188  Train Loss: 0.072, Acc: 0.988\n",
      "epoch: 140/300 batch 151/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 140/300 batch 152/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 140/300 batch 153/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 140/300 batch 154/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 140/300 batch 155/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 140/300 batch 156/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 140/300 batch 157/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 140/300 batch 158/188  Train Loss: 0.046, Acc: 0.977\n",
      "epoch: 140/300 batch 159/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 140/300 batch 160/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 140/300 batch 161/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 140/300 batch 162/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 140/300 batch 163/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 140/300 batch 164/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 140/300 batch 165/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 140/300 batch 166/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 140/300 batch 167/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 140/300 batch 168/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 140/300 batch 169/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 140/300 batch 170/188  Train Loss: 0.044, Acc: 0.980\n",
      "epoch: 140/300 batch 171/188  Train Loss: 0.027, Acc: 0.988\n",
      "epoch: 140/300 batch 172/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 140/300 batch 173/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 140/300 batch 174/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 140/300 batch 175/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 140/300 batch 176/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 140/300 batch 177/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 140/300 batch 178/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 140/300 batch 179/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 140/300 batch 180/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 140/300 batch 181/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 140/300 batch 182/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 140/300 batch 183/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 140/300 batch 184/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 140/300 batch 185/188  Train Loss: 0.076, Acc: 0.977\n",
      "epoch: 140/300 batch 186/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 140/300 batch 187/188  Train Loss: 0.025, Acc: 1.000\n",
      "Train Loss: 0.034294, Acc: 0.992\n",
      "Val Loss: 0.057505, Acc: 0.983\n",
      "epoch: 141/300 batch   0/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 141/300 batch   1/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 141/300 batch   2/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 141/300 batch   3/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 141/300 batch   4/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 141/300 batch   5/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 141/300 batch   6/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 141/300 batch   7/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 141/300 batch   8/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 141/300 batch   9/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 141/300 batch  10/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 141/300 batch  11/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 141/300 batch  12/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 141/300 batch  13/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 141/300 batch  14/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 141/300 batch  15/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 141/300 batch  16/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 141/300 batch  17/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 141/300 batch  18/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 141/300 batch  19/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 141/300 batch  20/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 141/300 batch  21/188  Train Loss: 0.032, Acc: 1.000\n",
      "epoch: 141/300 batch  22/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 141/300 batch  23/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 141/300 batch  24/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 141/300 batch  25/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 141/300 batch  26/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 141/300 batch  27/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 141/300 batch  28/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 141/300 batch  29/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 141/300 batch  30/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 141/300 batch  31/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 141/300 batch  32/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 141/300 batch  33/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 141/300 batch  34/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 141/300 batch  35/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 141/300 batch  36/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 141/300 batch  37/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 141/300 batch  38/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 141/300 batch  39/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 141/300 batch  40/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 141/300 batch  41/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 141/300 batch  42/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 141/300 batch  43/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 141/300 batch  44/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 141/300 batch  45/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 141/300 batch  46/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 141/300 batch  47/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 141/300 batch  48/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 141/300 batch  49/188  Train Loss: 0.059, Acc: 0.977\n",
      "epoch: 141/300 batch  50/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 141/300 batch  51/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 141/300 batch  52/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 141/300 batch  53/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 141/300 batch  54/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 141/300 batch  55/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 141/300 batch  56/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 141/300 batch  57/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 141/300 batch  58/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 141/300 batch  59/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 141/300 batch  60/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 141/300 batch  61/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 141/300 batch  62/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 141/300 batch  63/188  Train Loss: 0.053, Acc: 0.992\n",
      "epoch: 141/300 batch  64/188  Train Loss: 0.016, Acc: 0.996\n",
      "epoch: 141/300 batch  65/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 141/300 batch  66/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 141/300 batch  67/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 141/300 batch  68/188  Train Loss: 0.038, Acc: 0.977\n",
      "epoch: 141/300 batch  69/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 141/300 batch  70/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 141/300 batch  71/188  Train Loss: 0.042, Acc: 0.996\n",
      "epoch: 141/300 batch  72/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 141/300 batch  73/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 141/300 batch  74/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 141/300 batch  75/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 141/300 batch  76/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 141/300 batch  77/188  Train Loss: 0.016, Acc: 0.996\n",
      "epoch: 141/300 batch  78/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 141/300 batch  79/188  Train Loss: 0.045, Acc: 0.980\n",
      "epoch: 141/300 batch  80/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 141/300 batch  81/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 141/300 batch  82/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 141/300 batch  83/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 141/300 batch  84/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 141/300 batch  85/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 141/300 batch  86/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 141/300 batch  87/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 141/300 batch  88/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 141/300 batch  89/188  Train Loss: 0.064, Acc: 0.977\n",
      "epoch: 141/300 batch  90/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 141/300 batch  91/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 141/300 batch  92/188  Train Loss: 0.024, Acc: 0.988\n",
      "epoch: 141/300 batch  93/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 141/300 batch  94/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 141/300 batch  95/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 141/300 batch  96/188  Train Loss: 0.077, Acc: 0.980\n",
      "epoch: 141/300 batch  97/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 141/300 batch  98/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 141/300 batch  99/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 141/300 batch 100/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 141/300 batch 101/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 141/300 batch 102/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 141/300 batch 103/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 141/300 batch 104/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 141/300 batch 105/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 141/300 batch 106/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 141/300 batch 107/188  Train Loss: 0.059, Acc: 0.977\n",
      "epoch: 141/300 batch 108/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 141/300 batch 109/188  Train Loss: 0.078, Acc: 0.984\n",
      "epoch: 141/300 batch 110/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 141/300 batch 111/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 141/300 batch 112/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 141/300 batch 113/188  Train Loss: 0.050, Acc: 0.980\n",
      "epoch: 141/300 batch 114/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 141/300 batch 115/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 141/300 batch 116/188  Train Loss: 0.032, Acc: 1.000\n",
      "epoch: 141/300 batch 117/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 141/300 batch 118/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 141/300 batch 119/188  Train Loss: 0.059, Acc: 0.980\n",
      "epoch: 141/300 batch 120/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 141/300 batch 121/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 141/300 batch 122/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 141/300 batch 123/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 141/300 batch 124/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 141/300 batch 125/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 141/300 batch 126/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 141/300 batch 127/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 141/300 batch 128/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 141/300 batch 129/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 141/300 batch 130/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 141/300 batch 131/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 141/300 batch 132/188  Train Loss: 0.053, Acc: 0.980\n",
      "epoch: 141/300 batch 133/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 141/300 batch 134/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 141/300 batch 135/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 141/300 batch 136/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 141/300 batch 137/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 141/300 batch 138/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 141/300 batch 139/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 141/300 batch 140/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 141/300 batch 141/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 141/300 batch 142/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 141/300 batch 143/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 141/300 batch 144/188  Train Loss: 0.060, Acc: 0.984\n",
      "epoch: 141/300 batch 145/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 141/300 batch 146/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 141/300 batch 147/188  Train Loss: 0.060, Acc: 0.992\n",
      "epoch: 141/300 batch 148/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 141/300 batch 149/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 141/300 batch 150/188  Train Loss: 0.061, Acc: 0.992\n",
      "epoch: 141/300 batch 151/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 141/300 batch 152/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 141/300 batch 153/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 141/300 batch 154/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 141/300 batch 155/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 141/300 batch 156/188  Train Loss: 0.063, Acc: 0.984\n",
      "epoch: 141/300 batch 157/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 141/300 batch 158/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 141/300 batch 159/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 141/300 batch 160/188  Train Loss: 0.047, Acc: 0.996\n",
      "epoch: 141/300 batch 161/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 141/300 batch 162/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 141/300 batch 163/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 141/300 batch 164/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 141/300 batch 165/188  Train Loss: 0.042, Acc: 0.996\n",
      "epoch: 141/300 batch 166/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 141/300 batch 167/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 141/300 batch 168/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 141/300 batch 169/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 141/300 batch 170/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 141/300 batch 171/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 141/300 batch 172/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 141/300 batch 173/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 141/300 batch 174/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 141/300 batch 175/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 141/300 batch 176/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 141/300 batch 177/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 141/300 batch 178/188  Train Loss: 0.053, Acc: 0.992\n",
      "epoch: 141/300 batch 179/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 141/300 batch 180/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 141/300 batch 181/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 141/300 batch 182/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 141/300 batch 183/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 141/300 batch 184/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 141/300 batch 185/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 141/300 batch 186/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 141/300 batch 187/188  Train Loss: 0.019, Acc: 0.992\n",
      "Train Loss: 0.034146, Acc: 0.992\n",
      "Val Loss: 0.057650, Acc: 0.982\n",
      "epoch: 142/300 batch   0/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 142/300 batch   1/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 142/300 batch   2/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 142/300 batch   3/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 142/300 batch   4/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 142/300 batch   5/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 142/300 batch   6/188  Train Loss: 0.056, Acc: 0.980\n",
      "epoch: 142/300 batch   7/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 142/300 batch   8/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 142/300 batch   9/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 142/300 batch  10/188  Train Loss: 0.041, Acc: 0.980\n",
      "epoch: 142/300 batch  11/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 142/300 batch  12/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 142/300 batch  13/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 142/300 batch  14/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 142/300 batch  15/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 142/300 batch  16/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 142/300 batch  17/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 142/300 batch  18/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 142/300 batch  19/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 142/300 batch  20/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 142/300 batch  21/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 142/300 batch  22/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 142/300 batch  23/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 142/300 batch  24/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 142/300 batch  25/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 142/300 batch  26/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 142/300 batch  27/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 142/300 batch  28/188  Train Loss: 0.061, Acc: 0.996\n",
      "epoch: 142/300 batch  29/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 142/300 batch  30/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 142/300 batch  31/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 142/300 batch  32/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 142/300 batch  33/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 142/300 batch  34/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 142/300 batch  35/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 142/300 batch  36/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 142/300 batch  37/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 142/300 batch  38/188  Train Loss: 0.055, Acc: 0.980\n",
      "epoch: 142/300 batch  39/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 142/300 batch  40/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 142/300 batch  41/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 142/300 batch  42/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 142/300 batch  43/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 142/300 batch  44/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 142/300 batch  45/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 142/300 batch  46/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 142/300 batch  47/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 142/300 batch  48/188  Train Loss: 0.067, Acc: 0.980\n",
      "epoch: 142/300 batch  49/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 142/300 batch  50/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 142/300 batch  51/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 142/300 batch  52/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 142/300 batch  53/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 142/300 batch  54/188  Train Loss: 0.044, Acc: 0.980\n",
      "epoch: 142/300 batch  55/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 142/300 batch  56/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 142/300 batch  57/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 142/300 batch  58/188  Train Loss: 0.054, Acc: 0.996\n",
      "epoch: 142/300 batch  59/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 142/300 batch  60/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 142/300 batch  61/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 142/300 batch  62/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 142/300 batch  63/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 142/300 batch  64/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 142/300 batch  65/188  Train Loss: 0.065, Acc: 0.988\n",
      "epoch: 142/300 batch  66/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 142/300 batch  67/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 142/300 batch  68/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 142/300 batch  69/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 142/300 batch  70/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 142/300 batch  71/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 142/300 batch  72/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 142/300 batch  73/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 142/300 batch  74/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 142/300 batch  75/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 142/300 batch  76/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 142/300 batch  77/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 142/300 batch  78/188  Train Loss: 0.047, Acc: 0.996\n",
      "epoch: 142/300 batch  79/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 142/300 batch  80/188  Train Loss: 0.060, Acc: 0.980\n",
      "epoch: 142/300 batch  81/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 142/300 batch  82/188  Train Loss: 0.062, Acc: 0.988\n",
      "epoch: 142/300 batch  83/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 142/300 batch  84/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 142/300 batch  85/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 142/300 batch  86/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 142/300 batch  87/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 142/300 batch  88/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 142/300 batch  89/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 142/300 batch  90/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 142/300 batch  91/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 142/300 batch  92/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 142/300 batch  93/188  Train Loss: 0.045, Acc: 0.980\n",
      "epoch: 142/300 batch  94/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 142/300 batch  95/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 142/300 batch  96/188  Train Loss: 0.061, Acc: 0.984\n",
      "epoch: 142/300 batch  97/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 142/300 batch  98/188  Train Loss: 0.048, Acc: 0.980\n",
      "epoch: 142/300 batch  99/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 142/300 batch 100/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 142/300 batch 101/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 142/300 batch 102/188  Train Loss: 0.052, Acc: 0.992\n",
      "epoch: 142/300 batch 103/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 142/300 batch 104/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 142/300 batch 105/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 142/300 batch 106/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 142/300 batch 107/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 142/300 batch 108/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 142/300 batch 109/188  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 142/300 batch 110/188  Train Loss: 0.054, Acc: 0.973\n",
      "epoch: 142/300 batch 111/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 142/300 batch 112/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 142/300 batch 113/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 142/300 batch 114/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 142/300 batch 115/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 142/300 batch 116/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 142/300 batch 117/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 142/300 batch 118/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 142/300 batch 119/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 142/300 batch 120/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 142/300 batch 121/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 142/300 batch 122/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 142/300 batch 123/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 142/300 batch 124/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 142/300 batch 125/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 142/300 batch 126/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 142/300 batch 127/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 142/300 batch 128/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 142/300 batch 129/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 142/300 batch 130/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 142/300 batch 131/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 142/300 batch 132/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 142/300 batch 133/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 142/300 batch 134/188  Train Loss: 0.034, Acc: 1.000\n",
      "epoch: 142/300 batch 135/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 142/300 batch 136/188  Train Loss: 0.055, Acc: 0.992\n",
      "epoch: 142/300 batch 137/188  Train Loss: 0.058, Acc: 0.980\n",
      "epoch: 142/300 batch 138/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 142/300 batch 139/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 142/300 batch 140/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 142/300 batch 141/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 142/300 batch 142/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 142/300 batch 143/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 142/300 batch 144/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 142/300 batch 145/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 142/300 batch 146/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 142/300 batch 147/188  Train Loss: 0.048, Acc: 0.980\n",
      "epoch: 142/300 batch 148/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 142/300 batch 149/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 142/300 batch 150/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 142/300 batch 151/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 142/300 batch 152/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 142/300 batch 153/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 142/300 batch 154/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 142/300 batch 155/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 142/300 batch 156/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 142/300 batch 157/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 142/300 batch 158/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 142/300 batch 159/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 142/300 batch 160/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 142/300 batch 161/188  Train Loss: 0.056, Acc: 0.988\n",
      "epoch: 142/300 batch 162/188  Train Loss: 0.062, Acc: 0.988\n",
      "epoch: 142/300 batch 163/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 142/300 batch 164/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 142/300 batch 165/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 142/300 batch 166/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 142/300 batch 167/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 142/300 batch 168/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 142/300 batch 169/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 142/300 batch 170/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 142/300 batch 171/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 142/300 batch 172/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 142/300 batch 173/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 142/300 batch 174/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 142/300 batch 175/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 142/300 batch 176/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 142/300 batch 177/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 142/300 batch 178/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 142/300 batch 179/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 142/300 batch 180/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 142/300 batch 181/188  Train Loss: 0.062, Acc: 0.984\n",
      "epoch: 142/300 batch 182/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 142/300 batch 183/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 142/300 batch 184/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 142/300 batch 185/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 142/300 batch 186/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 142/300 batch 187/188  Train Loss: 0.033, Acc: 0.992\n",
      "Train Loss: 0.034281, Acc: 0.992\n",
      "Val Loss: 0.057616, Acc: 0.983\n",
      "epoch: 143/300 batch   0/188  Train Loss: 0.069, Acc: 0.988\n",
      "epoch: 143/300 batch   1/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 143/300 batch   2/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 143/300 batch   3/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 143/300 batch   4/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 143/300 batch   5/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 143/300 batch   6/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 143/300 batch   7/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 143/300 batch   8/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 143/300 batch   9/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 143/300 batch  10/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 143/300 batch  11/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 143/300 batch  12/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 143/300 batch  13/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 143/300 batch  14/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 143/300 batch  15/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 143/300 batch  16/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 143/300 batch  17/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 143/300 batch  18/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 143/300 batch  19/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 143/300 batch  20/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 143/300 batch  21/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 143/300 batch  22/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 143/300 batch  23/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 143/300 batch  24/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 143/300 batch  25/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 143/300 batch  26/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 143/300 batch  27/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 143/300 batch  28/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 143/300 batch  29/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 143/300 batch  30/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 143/300 batch  31/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 143/300 batch  32/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 143/300 batch  33/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 143/300 batch  34/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 143/300 batch  35/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 143/300 batch  36/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 143/300 batch  37/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 143/300 batch  38/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 143/300 batch  39/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 143/300 batch  40/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 143/300 batch  41/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 143/300 batch  42/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 143/300 batch  43/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 143/300 batch  44/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 143/300 batch  45/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 143/300 batch  46/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 143/300 batch  47/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 143/300 batch  48/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 143/300 batch  49/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 143/300 batch  50/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 143/300 batch  51/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 143/300 batch  52/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 143/300 batch  53/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 143/300 batch  54/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 143/300 batch  55/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 143/300 batch  56/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 143/300 batch  57/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 143/300 batch  58/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 143/300 batch  59/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 143/300 batch  60/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 143/300 batch  61/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 143/300 batch  62/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 143/300 batch  63/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 143/300 batch  64/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 143/300 batch  65/188  Train Loss: 0.056, Acc: 0.992\n",
      "epoch: 143/300 batch  66/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 143/300 batch  67/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 143/300 batch  68/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 143/300 batch  69/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 143/300 batch  70/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 143/300 batch  71/188  Train Loss: 0.062, Acc: 0.969\n",
      "epoch: 143/300 batch  72/188  Train Loss: 0.031, Acc: 1.000\n",
      "epoch: 143/300 batch  73/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 143/300 batch  74/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 143/300 batch  75/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 143/300 batch  76/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 143/300 batch  77/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 143/300 batch  78/188  Train Loss: 0.062, Acc: 0.977\n",
      "epoch: 143/300 batch  79/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 143/300 batch  80/188  Train Loss: 0.051, Acc: 0.992\n",
      "epoch: 143/300 batch  81/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 143/300 batch  82/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 143/300 batch  83/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 143/300 batch  84/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 143/300 batch  85/188  Train Loss: 0.060, Acc: 0.980\n",
      "epoch: 143/300 batch  86/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 143/300 batch  87/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 143/300 batch  88/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 143/300 batch  89/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 143/300 batch  90/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 143/300 batch  91/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 143/300 batch  92/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 143/300 batch  93/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 143/300 batch  94/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 143/300 batch  95/188  Train Loss: 0.059, Acc: 0.984\n",
      "epoch: 143/300 batch  96/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 143/300 batch  97/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 143/300 batch  98/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 143/300 batch  99/188  Train Loss: 0.051, Acc: 0.980\n",
      "epoch: 143/300 batch 100/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 143/300 batch 101/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 143/300 batch 102/188  Train Loss: 0.039, Acc: 0.980\n",
      "epoch: 143/300 batch 103/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 143/300 batch 104/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 143/300 batch 105/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 143/300 batch 106/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 143/300 batch 107/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 143/300 batch 108/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 143/300 batch 109/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 143/300 batch 110/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 143/300 batch 111/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 143/300 batch 112/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 143/300 batch 113/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 143/300 batch 114/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 143/300 batch 115/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 143/300 batch 116/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 143/300 batch 117/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 143/300 batch 118/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 143/300 batch 119/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 143/300 batch 120/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 143/300 batch 121/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 143/300 batch 122/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 143/300 batch 123/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 143/300 batch 124/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 143/300 batch 125/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 143/300 batch 126/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 143/300 batch 127/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 143/300 batch 128/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 143/300 batch 129/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 143/300 batch 130/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 143/300 batch 131/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 143/300 batch 132/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 143/300 batch 133/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 143/300 batch 134/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 143/300 batch 135/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 143/300 batch 136/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 143/300 batch 137/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 143/300 batch 138/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 143/300 batch 139/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 143/300 batch 140/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 143/300 batch 141/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 143/300 batch 142/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 143/300 batch 143/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 143/300 batch 144/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 143/300 batch 145/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 143/300 batch 146/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 143/300 batch 147/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 143/300 batch 148/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 143/300 batch 149/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 143/300 batch 150/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 143/300 batch 151/188  Train Loss: 0.055, Acc: 0.980\n",
      "epoch: 143/300 batch 152/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 143/300 batch 153/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 143/300 batch 154/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 143/300 batch 155/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 143/300 batch 156/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 143/300 batch 157/188  Train Loss: 0.069, Acc: 0.988\n",
      "epoch: 143/300 batch 158/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 143/300 batch 159/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 143/300 batch 160/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 143/300 batch 161/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 143/300 batch 162/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 143/300 batch 163/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 143/300 batch 164/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 143/300 batch 165/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 143/300 batch 166/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 143/300 batch 167/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 143/300 batch 168/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 143/300 batch 169/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 143/300 batch 170/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 143/300 batch 171/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 143/300 batch 172/188  Train Loss: 0.046, Acc: 0.977\n",
      "epoch: 143/300 batch 173/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 143/300 batch 174/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 143/300 batch 175/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 143/300 batch 176/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 143/300 batch 177/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 143/300 batch 178/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 143/300 batch 179/188  Train Loss: 0.059, Acc: 0.988\n",
      "epoch: 143/300 batch 180/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 143/300 batch 181/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 143/300 batch 182/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 143/300 batch 183/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 143/300 batch 184/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 143/300 batch 185/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 143/300 batch 186/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 143/300 batch 187/188  Train Loss: 0.019, Acc: 1.000\n",
      "Train Loss: 0.034134, Acc: 0.992\n",
      "Val Loss: 0.057233, Acc: 0.982\n",
      "epoch: 144/300 batch   0/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 144/300 batch   1/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 144/300 batch   2/188  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 144/300 batch   3/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 144/300 batch   4/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 144/300 batch   5/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 144/300 batch   6/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 144/300 batch   7/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 144/300 batch   8/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 144/300 batch   9/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 144/300 batch  10/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 144/300 batch  11/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 144/300 batch  12/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 144/300 batch  13/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 144/300 batch  14/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 144/300 batch  15/188  Train Loss: 0.068, Acc: 0.996\n",
      "epoch: 144/300 batch  16/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 144/300 batch  17/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 144/300 batch  18/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 144/300 batch  19/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 144/300 batch  20/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 144/300 batch  21/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 144/300 batch  22/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 144/300 batch  23/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 144/300 batch  24/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 144/300 batch  25/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 144/300 batch  26/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 144/300 batch  27/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 144/300 batch  28/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 144/300 batch  29/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 144/300 batch  30/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 144/300 batch  31/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 144/300 batch  32/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 144/300 batch  33/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 144/300 batch  34/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 144/300 batch  35/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 144/300 batch  36/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 144/300 batch  37/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 144/300 batch  38/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 144/300 batch  39/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 144/300 batch  40/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 144/300 batch  41/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 144/300 batch  42/188  Train Loss: 0.058, Acc: 0.988\n",
      "epoch: 144/300 batch  43/188  Train Loss: 0.052, Acc: 0.977\n",
      "epoch: 144/300 batch  44/188  Train Loss: 0.076, Acc: 0.977\n",
      "epoch: 144/300 batch  45/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 144/300 batch  46/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 144/300 batch  47/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 144/300 batch  48/188  Train Loss: 0.047, Acc: 0.996\n",
      "epoch: 144/300 batch  49/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 144/300 batch  50/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 144/300 batch  51/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 144/300 batch  52/188  Train Loss: 0.077, Acc: 0.980\n",
      "epoch: 144/300 batch  53/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 144/300 batch  54/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 144/300 batch  55/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 144/300 batch  56/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 144/300 batch  57/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 144/300 batch  58/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 144/300 batch  59/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 144/300 batch  60/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 144/300 batch  61/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 144/300 batch  62/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 144/300 batch  63/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 144/300 batch  64/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 144/300 batch  65/188  Train Loss: 0.059, Acc: 0.980\n",
      "epoch: 144/300 batch  66/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 144/300 batch  67/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 144/300 batch  68/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 144/300 batch  69/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 144/300 batch  70/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 144/300 batch  71/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 144/300 batch  72/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 144/300 batch  73/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 144/300 batch  74/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 144/300 batch  75/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 144/300 batch  76/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 144/300 batch  77/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 144/300 batch  78/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 144/300 batch  79/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 144/300 batch  80/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 144/300 batch  81/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 144/300 batch  82/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 144/300 batch  83/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 144/300 batch  84/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 144/300 batch  85/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 144/300 batch  86/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 144/300 batch  87/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 144/300 batch  88/188  Train Loss: 0.036, Acc: 0.980\n",
      "epoch: 144/300 batch  89/188  Train Loss: 0.057, Acc: 0.977\n",
      "epoch: 144/300 batch  90/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 144/300 batch  91/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 144/300 batch  92/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 144/300 batch  93/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 144/300 batch  94/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 144/300 batch  95/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 144/300 batch  96/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 144/300 batch  97/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 144/300 batch  98/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 144/300 batch  99/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 144/300 batch 100/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 144/300 batch 101/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 144/300 batch 102/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 144/300 batch 103/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 144/300 batch 104/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 144/300 batch 105/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 144/300 batch 106/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 144/300 batch 107/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 144/300 batch 108/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 144/300 batch 109/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 144/300 batch 110/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 144/300 batch 111/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 144/300 batch 112/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 144/300 batch 113/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 144/300 batch 114/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 144/300 batch 115/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 144/300 batch 116/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 144/300 batch 117/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 144/300 batch 118/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 144/300 batch 119/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 144/300 batch 120/188  Train Loss: 0.058, Acc: 0.992\n",
      "epoch: 144/300 batch 121/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 144/300 batch 122/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 144/300 batch 123/188  Train Loss: 0.025, Acc: 0.988\n",
      "epoch: 144/300 batch 124/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 144/300 batch 125/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 144/300 batch 126/188  Train Loss: 0.060, Acc: 0.988\n",
      "epoch: 144/300 batch 127/188  Train Loss: 0.052, Acc: 0.980\n",
      "epoch: 144/300 batch 128/188  Train Loss: 0.056, Acc: 0.988\n",
      "epoch: 144/300 batch 129/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 144/300 batch 130/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 144/300 batch 131/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 144/300 batch 132/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 144/300 batch 133/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 144/300 batch 134/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 144/300 batch 135/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 144/300 batch 136/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 144/300 batch 137/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 144/300 batch 138/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 144/300 batch 139/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 144/300 batch 140/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 144/300 batch 141/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 144/300 batch 142/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 144/300 batch 143/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 144/300 batch 144/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 144/300 batch 145/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 144/300 batch 146/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 144/300 batch 147/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 144/300 batch 148/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 144/300 batch 149/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 144/300 batch 150/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 144/300 batch 151/188  Train Loss: 0.061, Acc: 0.988\n",
      "epoch: 144/300 batch 152/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 144/300 batch 153/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 144/300 batch 154/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 144/300 batch 155/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 144/300 batch 156/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 144/300 batch 157/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 144/300 batch 158/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 144/300 batch 159/188  Train Loss: 0.045, Acc: 0.996\n",
      "epoch: 144/300 batch 160/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 144/300 batch 161/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 144/300 batch 162/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 144/300 batch 163/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 144/300 batch 164/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 144/300 batch 165/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 144/300 batch 166/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 144/300 batch 167/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 144/300 batch 168/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 144/300 batch 169/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 144/300 batch 170/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 144/300 batch 171/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 144/300 batch 172/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 144/300 batch 173/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 144/300 batch 174/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 144/300 batch 175/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 144/300 batch 176/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 144/300 batch 177/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 144/300 batch 178/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 144/300 batch 179/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 144/300 batch 180/188  Train Loss: 0.077, Acc: 0.977\n",
      "epoch: 144/300 batch 181/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 144/300 batch 182/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 144/300 batch 183/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 144/300 batch 184/188  Train Loss: 0.048, Acc: 0.980\n",
      "epoch: 144/300 batch 185/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 144/300 batch 186/188  Train Loss: 0.045, Acc: 0.980\n",
      "epoch: 144/300 batch 187/188  Train Loss: 0.033, Acc: 0.992\n",
      "Train Loss: 0.034222, Acc: 0.992\n",
      "Val Loss: 0.057567, Acc: 0.983\n",
      "epoch: 145/300 batch   0/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 145/300 batch   1/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 145/300 batch   2/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 145/300 batch   3/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 145/300 batch   4/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 145/300 batch   5/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 145/300 batch   6/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 145/300 batch   7/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 145/300 batch   8/188  Train Loss: 0.025, Acc: 0.988\n",
      "epoch: 145/300 batch   9/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 145/300 batch  10/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 145/300 batch  11/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 145/300 batch  12/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 145/300 batch  13/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 145/300 batch  14/188  Train Loss: 0.053, Acc: 0.980\n",
      "epoch: 145/300 batch  15/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 145/300 batch  16/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 145/300 batch  17/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 145/300 batch  18/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 145/300 batch  19/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 145/300 batch  20/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 145/300 batch  21/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 145/300 batch  22/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 145/300 batch  23/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 145/300 batch  24/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 145/300 batch  25/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 145/300 batch  26/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 145/300 batch  27/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 145/300 batch  28/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 145/300 batch  29/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 145/300 batch  30/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 145/300 batch  31/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 145/300 batch  32/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 145/300 batch  33/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 145/300 batch  34/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 145/300 batch  35/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 145/300 batch  36/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 145/300 batch  37/188  Train Loss: 0.030, Acc: 0.984\n",
      "epoch: 145/300 batch  38/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 145/300 batch  39/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 145/300 batch  40/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 145/300 batch  41/188  Train Loss: 0.073, Acc: 0.988\n",
      "epoch: 145/300 batch  42/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 145/300 batch  43/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 145/300 batch  44/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 145/300 batch  45/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 145/300 batch  46/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 145/300 batch  47/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 145/300 batch  48/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 145/300 batch  49/188  Train Loss: 0.047, Acc: 0.980\n",
      "epoch: 145/300 batch  50/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 145/300 batch  51/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 145/300 batch  52/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 145/300 batch  53/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 145/300 batch  54/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 145/300 batch  55/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 145/300 batch  56/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 145/300 batch  57/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 145/300 batch  58/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 145/300 batch  59/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 145/300 batch  60/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 145/300 batch  61/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 145/300 batch  62/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 145/300 batch  63/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 145/300 batch  64/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 145/300 batch  65/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 145/300 batch  66/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 145/300 batch  67/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 145/300 batch  68/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 145/300 batch  69/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 145/300 batch  70/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 145/300 batch  71/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 145/300 batch  72/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 145/300 batch  73/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 145/300 batch  74/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 145/300 batch  75/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 145/300 batch  76/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 145/300 batch  77/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 145/300 batch  78/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 145/300 batch  79/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 145/300 batch  80/188  Train Loss: 0.067, Acc: 0.984\n",
      "epoch: 145/300 batch  81/188  Train Loss: 0.058, Acc: 0.988\n",
      "epoch: 145/300 batch  82/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 145/300 batch  83/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 145/300 batch  84/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 145/300 batch  85/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 145/300 batch  86/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 145/300 batch  87/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 145/300 batch  88/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 145/300 batch  89/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 145/300 batch  90/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 145/300 batch  91/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 145/300 batch  92/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 145/300 batch  93/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 145/300 batch  94/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 145/300 batch  95/188  Train Loss: 0.059, Acc: 0.977\n",
      "epoch: 145/300 batch  96/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 145/300 batch  97/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 145/300 batch  98/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 145/300 batch  99/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 145/300 batch 100/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 145/300 batch 101/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 145/300 batch 102/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 145/300 batch 103/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 145/300 batch 104/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 145/300 batch 105/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 145/300 batch 106/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 145/300 batch 107/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 145/300 batch 108/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 145/300 batch 109/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 145/300 batch 110/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 145/300 batch 111/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 145/300 batch 112/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 145/300 batch 113/188  Train Loss: 0.048, Acc: 0.980\n",
      "epoch: 145/300 batch 114/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 145/300 batch 115/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 145/300 batch 116/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 145/300 batch 117/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 145/300 batch 118/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 145/300 batch 119/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 145/300 batch 120/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 145/300 batch 121/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 145/300 batch 122/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 145/300 batch 123/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 145/300 batch 124/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 145/300 batch 125/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 145/300 batch 126/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 145/300 batch 127/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 145/300 batch 128/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 145/300 batch 129/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 145/300 batch 130/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 145/300 batch 131/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 145/300 batch 132/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 145/300 batch 133/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 145/300 batch 134/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 145/300 batch 135/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 145/300 batch 136/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 145/300 batch 137/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 145/300 batch 138/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 145/300 batch 139/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 145/300 batch 140/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 145/300 batch 141/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 145/300 batch 142/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 145/300 batch 143/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 145/300 batch 144/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 145/300 batch 145/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 145/300 batch 146/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 145/300 batch 147/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 145/300 batch 148/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 145/300 batch 149/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 145/300 batch 150/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 145/300 batch 151/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 145/300 batch 152/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 145/300 batch 153/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 145/300 batch 154/188  Train Loss: 0.070, Acc: 0.988\n",
      "epoch: 145/300 batch 155/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 145/300 batch 156/188  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 145/300 batch 157/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 145/300 batch 158/188  Train Loss: 0.081, Acc: 0.988\n",
      "epoch: 145/300 batch 159/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 145/300 batch 160/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 145/300 batch 161/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 145/300 batch 162/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 145/300 batch 163/188  Train Loss: 0.047, Acc: 0.980\n",
      "epoch: 145/300 batch 164/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 145/300 batch 165/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 145/300 batch 166/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 145/300 batch 167/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 145/300 batch 168/188  Train Loss: 0.051, Acc: 0.992\n",
      "epoch: 145/300 batch 169/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 145/300 batch 170/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 145/300 batch 171/188  Train Loss: 0.059, Acc: 0.984\n",
      "epoch: 145/300 batch 172/188  Train Loss: 0.064, Acc: 0.984\n",
      "epoch: 145/300 batch 173/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 145/300 batch 174/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 145/300 batch 175/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 145/300 batch 176/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 145/300 batch 177/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 145/300 batch 178/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 145/300 batch 179/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 145/300 batch 180/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 145/300 batch 181/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 145/300 batch 182/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 145/300 batch 183/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 145/300 batch 184/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 145/300 batch 185/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 145/300 batch 186/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 145/300 batch 187/188  Train Loss: 0.035, Acc: 0.984\n",
      "Train Loss: 0.034216, Acc: 0.992\n",
      "Val Loss: 0.057412, Acc: 0.983\n",
      "epoch: 146/300 batch   0/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 146/300 batch   1/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 146/300 batch   2/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 146/300 batch   3/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 146/300 batch   4/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 146/300 batch   5/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 146/300 batch   6/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 146/300 batch   7/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 146/300 batch   8/188  Train Loss: 0.057, Acc: 0.980\n",
      "epoch: 146/300 batch   9/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 146/300 batch  10/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 146/300 batch  11/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 146/300 batch  12/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 146/300 batch  13/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 146/300 batch  14/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 146/300 batch  15/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 146/300 batch  16/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 146/300 batch  17/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 146/300 batch  18/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 146/300 batch  19/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 146/300 batch  20/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 146/300 batch  21/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 146/300 batch  22/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 146/300 batch  23/188  Train Loss: 0.062, Acc: 0.988\n",
      "epoch: 146/300 batch  24/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 146/300 batch  25/188  Train Loss: 0.060, Acc: 0.977\n",
      "epoch: 146/300 batch  26/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 146/300 batch  27/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 146/300 batch  28/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 146/300 batch  29/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 146/300 batch  30/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 146/300 batch  31/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 146/300 batch  32/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 146/300 batch  33/188  Train Loss: 0.059, Acc: 0.988\n",
      "epoch: 146/300 batch  34/188  Train Loss: 0.042, Acc: 0.996\n",
      "epoch: 146/300 batch  35/188  Train Loss: 0.046, Acc: 0.996\n",
      "epoch: 146/300 batch  36/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 146/300 batch  37/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 146/300 batch  38/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 146/300 batch  39/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 146/300 batch  40/188  Train Loss: 0.044, Acc: 0.980\n",
      "epoch: 146/300 batch  41/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 146/300 batch  42/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 146/300 batch  43/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 146/300 batch  44/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 146/300 batch  45/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 146/300 batch  46/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 146/300 batch  47/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 146/300 batch  48/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 146/300 batch  49/188  Train Loss: 0.052, Acc: 0.977\n",
      "epoch: 146/300 batch  50/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 146/300 batch  51/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 146/300 batch  52/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 146/300 batch  53/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 146/300 batch  54/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 146/300 batch  55/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 146/300 batch  56/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 146/300 batch  57/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 146/300 batch  58/188  Train Loss: 0.050, Acc: 0.977\n",
      "epoch: 146/300 batch  59/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 146/300 batch  60/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 146/300 batch  61/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 146/300 batch  62/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 146/300 batch  63/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 146/300 batch  64/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 146/300 batch  65/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 146/300 batch  66/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 146/300 batch  67/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 146/300 batch  68/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 146/300 batch  69/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 146/300 batch  70/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 146/300 batch  71/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 146/300 batch  72/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 146/300 batch  73/188  Train Loss: 0.067, Acc: 0.992\n",
      "epoch: 146/300 batch  74/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 146/300 batch  75/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 146/300 batch  76/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 146/300 batch  77/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 146/300 batch  78/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 146/300 batch  79/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 146/300 batch  80/188  Train Loss: 0.038, Acc: 1.000\n",
      "epoch: 146/300 batch  81/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 146/300 batch  82/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 146/300 batch  83/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 146/300 batch  84/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 146/300 batch  85/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 146/300 batch  86/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 146/300 batch  87/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 146/300 batch  88/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 146/300 batch  89/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 146/300 batch  90/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 146/300 batch  91/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 146/300 batch  92/188  Train Loss: 0.051, Acc: 0.980\n",
      "epoch: 146/300 batch  93/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 146/300 batch  94/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 146/300 batch  95/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 146/300 batch  96/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 146/300 batch  97/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 146/300 batch  98/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 146/300 batch  99/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 146/300 batch 100/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 146/300 batch 101/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 146/300 batch 102/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 146/300 batch 103/188  Train Loss: 0.055, Acc: 0.973\n",
      "epoch: 146/300 batch 104/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 146/300 batch 105/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 146/300 batch 106/188  Train Loss: 0.014, Acc: 0.996\n",
      "epoch: 146/300 batch 107/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 146/300 batch 108/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 146/300 batch 109/188  Train Loss: 0.044, Acc: 0.980\n",
      "epoch: 146/300 batch 110/188  Train Loss: 0.047, Acc: 0.980\n",
      "epoch: 146/300 batch 111/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 146/300 batch 112/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 146/300 batch 113/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 146/300 batch 114/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 146/300 batch 115/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 146/300 batch 116/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 146/300 batch 117/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 146/300 batch 118/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 146/300 batch 119/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 146/300 batch 120/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 146/300 batch 121/188  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 146/300 batch 122/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 146/300 batch 123/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 146/300 batch 124/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 146/300 batch 125/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 146/300 batch 126/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 146/300 batch 127/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 146/300 batch 128/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 146/300 batch 129/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 146/300 batch 130/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 146/300 batch 131/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 146/300 batch 132/188  Train Loss: 0.060, Acc: 0.984\n",
      "epoch: 146/300 batch 133/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 146/300 batch 134/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 146/300 batch 135/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 146/300 batch 136/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 146/300 batch 137/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 146/300 batch 138/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 146/300 batch 139/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 146/300 batch 140/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 146/300 batch 141/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 146/300 batch 142/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 146/300 batch 143/188  Train Loss: 0.043, Acc: 0.980\n",
      "epoch: 146/300 batch 144/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 146/300 batch 145/188  Train Loss: 0.044, Acc: 0.980\n",
      "epoch: 146/300 batch 146/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 146/300 batch 147/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 146/300 batch 148/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 146/300 batch 149/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 146/300 batch 150/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 146/300 batch 151/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 146/300 batch 152/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 146/300 batch 153/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 146/300 batch 154/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 146/300 batch 155/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 146/300 batch 156/188  Train Loss: 0.042, Acc: 0.996\n",
      "epoch: 146/300 batch 157/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 146/300 batch 158/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 146/300 batch 159/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 146/300 batch 160/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 146/300 batch 161/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 146/300 batch 162/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 146/300 batch 163/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 146/300 batch 164/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 146/300 batch 165/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 146/300 batch 166/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 146/300 batch 167/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 146/300 batch 168/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 146/300 batch 169/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 146/300 batch 170/188  Train Loss: 0.042, Acc: 0.980\n",
      "epoch: 146/300 batch 171/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 146/300 batch 172/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 146/300 batch 173/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 146/300 batch 174/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 146/300 batch 175/188  Train Loss: 0.047, Acc: 0.980\n",
      "epoch: 146/300 batch 176/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 146/300 batch 177/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 146/300 batch 178/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 146/300 batch 179/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 146/300 batch 180/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 146/300 batch 181/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 146/300 batch 182/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 146/300 batch 183/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 146/300 batch 184/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 146/300 batch 185/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 146/300 batch 186/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 146/300 batch 187/188  Train Loss: 0.041, Acc: 0.984\n",
      "Train Loss: 0.034089, Acc: 0.992\n",
      "Val Loss: 0.057344, Acc: 0.982\n",
      "epoch: 147/300 batch   0/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 147/300 batch   1/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 147/300 batch   2/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 147/300 batch   3/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 147/300 batch   4/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 147/300 batch   5/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 147/300 batch   6/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 147/300 batch   7/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 147/300 batch   8/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 147/300 batch   9/188  Train Loss: 0.059, Acc: 0.984\n",
      "epoch: 147/300 batch  10/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 147/300 batch  11/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 147/300 batch  12/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 147/300 batch  13/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 147/300 batch  14/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 147/300 batch  15/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 147/300 batch  16/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 147/300 batch  17/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 147/300 batch  18/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 147/300 batch  19/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 147/300 batch  20/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 147/300 batch  21/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 147/300 batch  22/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 147/300 batch  23/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 147/300 batch  24/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 147/300 batch  25/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 147/300 batch  26/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 147/300 batch  27/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 147/300 batch  28/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 147/300 batch  29/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 147/300 batch  30/188  Train Loss: 0.044, Acc: 0.980\n",
      "epoch: 147/300 batch  31/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 147/300 batch  32/188  Train Loss: 0.077, Acc: 0.980\n",
      "epoch: 147/300 batch  33/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 147/300 batch  34/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 147/300 batch  35/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 147/300 batch  36/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 147/300 batch  37/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 147/300 batch  38/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 147/300 batch  39/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 147/300 batch  40/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 147/300 batch  41/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 147/300 batch  42/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 147/300 batch  43/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 147/300 batch  44/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 147/300 batch  45/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 147/300 batch  46/188  Train Loss: 0.058, Acc: 0.977\n",
      "epoch: 147/300 batch  47/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 147/300 batch  48/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 147/300 batch  49/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 147/300 batch  50/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 147/300 batch  51/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 147/300 batch  52/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 147/300 batch  53/188  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 147/300 batch  54/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 147/300 batch  55/188  Train Loss: 0.048, Acc: 0.996\n",
      "epoch: 147/300 batch  56/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 147/300 batch  57/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 147/300 batch  58/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 147/300 batch  59/188  Train Loss: 0.033, Acc: 0.984\n",
      "epoch: 147/300 batch  60/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 147/300 batch  61/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 147/300 batch  62/188  Train Loss: 0.063, Acc: 0.984\n",
      "epoch: 147/300 batch  63/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 147/300 batch  64/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 147/300 batch  65/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 147/300 batch  66/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 147/300 batch  67/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 147/300 batch  68/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 147/300 batch  69/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 147/300 batch  70/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 147/300 batch  71/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 147/300 batch  72/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 147/300 batch  73/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 147/300 batch  74/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 147/300 batch  75/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 147/300 batch  76/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 147/300 batch  77/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 147/300 batch  78/188  Train Loss: 0.053, Acc: 0.977\n",
      "epoch: 147/300 batch  79/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 147/300 batch  80/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 147/300 batch  81/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 147/300 batch  82/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 147/300 batch  83/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 147/300 batch  84/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 147/300 batch  85/188  Train Loss: 0.042, Acc: 0.996\n",
      "epoch: 147/300 batch  86/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 147/300 batch  87/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 147/300 batch  88/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 147/300 batch  89/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 147/300 batch  90/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 147/300 batch  91/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 147/300 batch  92/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 147/300 batch  93/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 147/300 batch  94/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 147/300 batch  95/188  Train Loss: 0.025, Acc: 0.988\n",
      "epoch: 147/300 batch  96/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 147/300 batch  97/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 147/300 batch  98/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 147/300 batch  99/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 147/300 batch 100/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 147/300 batch 101/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 147/300 batch 102/188  Train Loss: 0.054, Acc: 0.980\n",
      "epoch: 147/300 batch 103/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 147/300 batch 104/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 147/300 batch 105/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 147/300 batch 106/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 147/300 batch 107/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 147/300 batch 108/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 147/300 batch 109/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 147/300 batch 110/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 147/300 batch 111/188  Train Loss: 0.064, Acc: 0.988\n",
      "epoch: 147/300 batch 112/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 147/300 batch 113/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 147/300 batch 114/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 147/300 batch 115/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 147/300 batch 116/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 147/300 batch 117/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 147/300 batch 118/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 147/300 batch 119/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 147/300 batch 120/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 147/300 batch 121/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 147/300 batch 122/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 147/300 batch 123/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 147/300 batch 124/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 147/300 batch 125/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 147/300 batch 126/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 147/300 batch 127/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 147/300 batch 128/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 147/300 batch 129/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 147/300 batch 130/188  Train Loss: 0.081, Acc: 0.984\n",
      "epoch: 147/300 batch 131/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 147/300 batch 132/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 147/300 batch 133/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 147/300 batch 134/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 147/300 batch 135/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 147/300 batch 136/188  Train Loss: 0.061, Acc: 0.984\n",
      "epoch: 147/300 batch 137/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 147/300 batch 138/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 147/300 batch 139/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 147/300 batch 140/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 147/300 batch 141/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 147/300 batch 142/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 147/300 batch 143/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 147/300 batch 144/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 147/300 batch 145/188  Train Loss: 0.058, Acc: 0.988\n",
      "epoch: 147/300 batch 146/188  Train Loss: 0.048, Acc: 0.980\n",
      "epoch: 147/300 batch 147/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 147/300 batch 148/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 147/300 batch 149/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 147/300 batch 150/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 147/300 batch 151/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 147/300 batch 152/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 147/300 batch 153/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 147/300 batch 154/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 147/300 batch 155/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 147/300 batch 156/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 147/300 batch 157/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 147/300 batch 158/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 147/300 batch 159/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 147/300 batch 160/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 147/300 batch 161/188  Train Loss: 0.031, Acc: 0.984\n",
      "epoch: 147/300 batch 162/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 147/300 batch 163/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 147/300 batch 164/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 147/300 batch 165/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 147/300 batch 166/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 147/300 batch 167/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 147/300 batch 168/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 147/300 batch 169/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 147/300 batch 170/188  Train Loss: 0.028, Acc: 0.984\n",
      "epoch: 147/300 batch 171/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 147/300 batch 172/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 147/300 batch 173/188  Train Loss: 0.044, Acc: 0.996\n",
      "epoch: 147/300 batch 174/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 147/300 batch 175/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 147/300 batch 176/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 147/300 batch 177/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 147/300 batch 178/188  Train Loss: 0.069, Acc: 0.980\n",
      "epoch: 147/300 batch 179/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 147/300 batch 180/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 147/300 batch 181/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 147/300 batch 182/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 147/300 batch 183/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 147/300 batch 184/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 147/300 batch 185/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 147/300 batch 186/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 147/300 batch 187/188  Train Loss: 0.070, Acc: 0.969\n",
      "Train Loss: 0.034222, Acc: 0.992\n",
      "Val Loss: 0.057404, Acc: 0.983\n",
      "epoch: 148/300 batch   0/188  Train Loss: 0.059, Acc: 0.984\n",
      "epoch: 148/300 batch   1/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 148/300 batch   2/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 148/300 batch   3/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 148/300 batch   4/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 148/300 batch   5/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 148/300 batch   6/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 148/300 batch   7/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 148/300 batch   8/188  Train Loss: 0.050, Acc: 0.980\n",
      "epoch: 148/300 batch   9/188  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 148/300 batch  10/188  Train Loss: 0.060, Acc: 0.992\n",
      "epoch: 148/300 batch  11/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 148/300 batch  12/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 148/300 batch  13/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 148/300 batch  14/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 148/300 batch  15/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 148/300 batch  16/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 148/300 batch  17/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 148/300 batch  18/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 148/300 batch  19/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 148/300 batch  20/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 148/300 batch  21/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 148/300 batch  22/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 148/300 batch  23/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 148/300 batch  24/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 148/300 batch  25/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 148/300 batch  26/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 148/300 batch  27/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 148/300 batch  28/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 148/300 batch  29/188  Train Loss: 0.042, Acc: 0.996\n",
      "epoch: 148/300 batch  30/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 148/300 batch  31/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 148/300 batch  32/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 148/300 batch  33/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 148/300 batch  34/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 148/300 batch  35/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 148/300 batch  36/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 148/300 batch  37/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 148/300 batch  38/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 148/300 batch  39/188  Train Loss: 0.067, Acc: 0.988\n",
      "epoch: 148/300 batch  40/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 148/300 batch  41/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 148/300 batch  42/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 148/300 batch  43/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 148/300 batch  44/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 148/300 batch  45/188  Train Loss: 0.047, Acc: 0.980\n",
      "epoch: 148/300 batch  46/188  Train Loss: 0.016, Acc: 0.996\n",
      "epoch: 148/300 batch  47/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 148/300 batch  48/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 148/300 batch  49/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 148/300 batch  50/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 148/300 batch  51/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 148/300 batch  52/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 148/300 batch  53/188  Train Loss: 0.066, Acc: 0.984\n",
      "epoch: 148/300 batch  54/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 148/300 batch  55/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 148/300 batch  56/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 148/300 batch  57/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 148/300 batch  58/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 148/300 batch  59/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 148/300 batch  60/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 148/300 batch  61/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 148/300 batch  62/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 148/300 batch  63/188  Train Loss: 0.063, Acc: 0.992\n",
      "epoch: 148/300 batch  64/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 148/300 batch  65/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 148/300 batch  66/188  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 148/300 batch  67/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 148/300 batch  68/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 148/300 batch  69/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 148/300 batch  70/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 148/300 batch  71/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 148/300 batch  72/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 148/300 batch  73/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 148/300 batch  74/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 148/300 batch  75/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 148/300 batch  76/188  Train Loss: 0.057, Acc: 0.980\n",
      "epoch: 148/300 batch  77/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 148/300 batch  78/188  Train Loss: 0.057, Acc: 0.988\n",
      "epoch: 148/300 batch  79/188  Train Loss: 0.055, Acc: 0.980\n",
      "epoch: 148/300 batch  80/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 148/300 batch  81/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 148/300 batch  82/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 148/300 batch  83/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 148/300 batch  84/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 148/300 batch  85/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 148/300 batch  86/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 148/300 batch  87/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 148/300 batch  88/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 148/300 batch  89/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 148/300 batch  90/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 148/300 batch  91/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 148/300 batch  92/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 148/300 batch  93/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 148/300 batch  94/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 148/300 batch  95/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 148/300 batch  96/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 148/300 batch  97/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 148/300 batch  98/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 148/300 batch  99/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 148/300 batch 100/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 148/300 batch 101/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 148/300 batch 102/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 148/300 batch 103/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 148/300 batch 104/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 148/300 batch 105/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 148/300 batch 106/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 148/300 batch 107/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 148/300 batch 108/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 148/300 batch 109/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 148/300 batch 110/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 148/300 batch 111/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 148/300 batch 112/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 148/300 batch 113/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 148/300 batch 114/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 148/300 batch 115/188  Train Loss: 0.051, Acc: 0.980\n",
      "epoch: 148/300 batch 116/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 148/300 batch 117/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 148/300 batch 118/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 148/300 batch 119/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 148/300 batch 120/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 148/300 batch 121/188  Train Loss: 0.052, Acc: 0.980\n",
      "epoch: 148/300 batch 122/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 148/300 batch 123/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 148/300 batch 124/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 148/300 batch 125/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 148/300 batch 126/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 148/300 batch 127/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 148/300 batch 128/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 148/300 batch 129/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 148/300 batch 130/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 148/300 batch 131/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 148/300 batch 132/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 148/300 batch 133/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 148/300 batch 134/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 148/300 batch 135/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 148/300 batch 136/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 148/300 batch 137/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 148/300 batch 138/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 148/300 batch 139/188  Train Loss: 0.034, Acc: 0.984\n",
      "epoch: 148/300 batch 140/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 148/300 batch 141/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 148/300 batch 142/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 148/300 batch 143/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 148/300 batch 144/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 148/300 batch 145/188  Train Loss: 0.058, Acc: 0.988\n",
      "epoch: 148/300 batch 146/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 148/300 batch 147/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 148/300 batch 148/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 148/300 batch 149/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 148/300 batch 150/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 148/300 batch 151/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 148/300 batch 152/188  Train Loss: 0.034, Acc: 0.984\n",
      "epoch: 148/300 batch 153/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 148/300 batch 154/188  Train Loss: 0.050, Acc: 0.980\n",
      "epoch: 148/300 batch 155/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 148/300 batch 156/188  Train Loss: 0.053, Acc: 0.992\n",
      "epoch: 148/300 batch 157/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 148/300 batch 158/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 148/300 batch 159/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 148/300 batch 160/188  Train Loss: 0.060, Acc: 0.988\n",
      "epoch: 148/300 batch 161/188  Train Loss: 0.058, Acc: 0.980\n",
      "epoch: 148/300 batch 162/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 148/300 batch 163/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 148/300 batch 164/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 148/300 batch 165/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 148/300 batch 166/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 148/300 batch 167/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 148/300 batch 168/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 148/300 batch 169/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 148/300 batch 170/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 148/300 batch 171/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 148/300 batch 172/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 148/300 batch 173/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 148/300 batch 174/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 148/300 batch 175/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 148/300 batch 176/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 148/300 batch 177/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 148/300 batch 178/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 148/300 batch 179/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 148/300 batch 180/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 148/300 batch 181/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 148/300 batch 182/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 148/300 batch 183/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 148/300 batch 184/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 148/300 batch 185/188  Train Loss: 0.076, Acc: 0.977\n",
      "epoch: 148/300 batch 186/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 148/300 batch 187/188  Train Loss: 0.035, Acc: 1.000\n",
      "Train Loss: 0.034066, Acc: 0.992\n",
      "Val Loss: 0.057576, Acc: 0.982\n",
      "epoch: 149/300 batch   0/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 149/300 batch   1/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 149/300 batch   2/188  Train Loss: 0.059, Acc: 0.988\n",
      "epoch: 149/300 batch   3/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 149/300 batch   4/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 149/300 batch   5/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 149/300 batch   6/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 149/300 batch   7/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 149/300 batch   8/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 149/300 batch   9/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 149/300 batch  10/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 149/300 batch  11/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 149/300 batch  12/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 149/300 batch  13/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 149/300 batch  14/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 149/300 batch  15/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 149/300 batch  16/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 149/300 batch  17/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 149/300 batch  18/188  Train Loss: 0.053, Acc: 0.977\n",
      "epoch: 149/300 batch  19/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 149/300 batch  20/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 149/300 batch  21/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 149/300 batch  22/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 149/300 batch  23/188  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 149/300 batch  24/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 149/300 batch  25/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 149/300 batch  26/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 149/300 batch  27/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 149/300 batch  28/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 149/300 batch  29/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 149/300 batch  30/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 149/300 batch  31/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 149/300 batch  32/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 149/300 batch  33/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 149/300 batch  34/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 149/300 batch  35/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 149/300 batch  36/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 149/300 batch  37/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 149/300 batch  38/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 149/300 batch  39/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 149/300 batch  40/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 149/300 batch  41/188  Train Loss: 0.095, Acc: 0.984\n",
      "epoch: 149/300 batch  42/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 149/300 batch  43/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 149/300 batch  44/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 149/300 batch  45/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 149/300 batch  46/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 149/300 batch  47/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 149/300 batch  48/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 149/300 batch  49/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 149/300 batch  50/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 149/300 batch  51/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 149/300 batch  52/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 149/300 batch  53/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 149/300 batch  54/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 149/300 batch  55/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 149/300 batch  56/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 149/300 batch  57/188  Train Loss: 0.057, Acc: 0.980\n",
      "epoch: 149/300 batch  58/188  Train Loss: 0.025, Acc: 0.988\n",
      "epoch: 149/300 batch  59/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 149/300 batch  60/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 149/300 batch  61/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 149/300 batch  62/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 149/300 batch  63/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 149/300 batch  64/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 149/300 batch  65/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 149/300 batch  66/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 149/300 batch  67/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 149/300 batch  68/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 149/300 batch  69/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 149/300 batch  70/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 149/300 batch  71/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 149/300 batch  72/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 149/300 batch  73/188  Train Loss: 0.037, Acc: 1.000\n",
      "epoch: 149/300 batch  74/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 149/300 batch  75/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 149/300 batch  76/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 149/300 batch  77/188  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 149/300 batch  78/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 149/300 batch  79/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 149/300 batch  80/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 149/300 batch  81/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 149/300 batch  82/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 149/300 batch  83/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 149/300 batch  84/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 149/300 batch  85/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 149/300 batch  86/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 149/300 batch  87/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 149/300 batch  88/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 149/300 batch  89/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 149/300 batch  90/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 149/300 batch  91/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 149/300 batch  92/188  Train Loss: 0.054, Acc: 0.980\n",
      "epoch: 149/300 batch  93/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 149/300 batch  94/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 149/300 batch  95/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 149/300 batch  96/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 149/300 batch  97/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 149/300 batch  98/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 149/300 batch  99/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 149/300 batch 100/188  Train Loss: 0.025, Acc: 0.988\n",
      "epoch: 149/300 batch 101/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 149/300 batch 102/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 149/300 batch 103/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 149/300 batch 104/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 149/300 batch 105/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 149/300 batch 106/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 149/300 batch 107/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 149/300 batch 108/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 149/300 batch 109/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 149/300 batch 110/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 149/300 batch 111/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 149/300 batch 112/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 149/300 batch 113/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 149/300 batch 114/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 149/300 batch 115/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 149/300 batch 116/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 149/300 batch 117/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 149/300 batch 118/188  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 149/300 batch 119/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 149/300 batch 120/188  Train Loss: 0.046, Acc: 0.996\n",
      "epoch: 149/300 batch 121/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 149/300 batch 122/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 149/300 batch 123/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 149/300 batch 124/188  Train Loss: 0.056, Acc: 0.988\n",
      "epoch: 149/300 batch 125/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 149/300 batch 126/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 149/300 batch 127/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 149/300 batch 128/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 149/300 batch 129/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 149/300 batch 130/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 149/300 batch 131/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 149/300 batch 132/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 149/300 batch 133/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 149/300 batch 134/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 149/300 batch 135/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 149/300 batch 136/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 149/300 batch 137/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 149/300 batch 138/188  Train Loss: 0.031, Acc: 1.000\n",
      "epoch: 149/300 batch 139/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 149/300 batch 140/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 149/300 batch 141/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 149/300 batch 142/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 149/300 batch 143/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 149/300 batch 144/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 149/300 batch 145/188  Train Loss: 0.068, Acc: 0.992\n",
      "epoch: 149/300 batch 146/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 149/300 batch 147/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 149/300 batch 148/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 149/300 batch 149/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 149/300 batch 150/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 149/300 batch 151/188  Train Loss: 0.067, Acc: 0.988\n",
      "epoch: 149/300 batch 152/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 149/300 batch 153/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 149/300 batch 154/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 149/300 batch 155/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 149/300 batch 156/188  Train Loss: 0.048, Acc: 0.980\n",
      "epoch: 149/300 batch 157/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 149/300 batch 158/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 149/300 batch 159/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 149/300 batch 160/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 149/300 batch 161/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 149/300 batch 162/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 149/300 batch 163/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 149/300 batch 164/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 149/300 batch 165/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 149/300 batch 166/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 149/300 batch 167/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 149/300 batch 168/188  Train Loss: 0.051, Acc: 0.980\n",
      "epoch: 149/300 batch 169/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 149/300 batch 170/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 149/300 batch 171/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 149/300 batch 172/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 149/300 batch 173/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 149/300 batch 174/188  Train Loss: 0.067, Acc: 0.977\n",
      "epoch: 149/300 batch 175/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 149/300 batch 176/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 149/300 batch 177/188  Train Loss: 0.050, Acc: 0.977\n",
      "epoch: 149/300 batch 178/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 149/300 batch 179/188  Train Loss: 0.052, Acc: 0.980\n",
      "epoch: 149/300 batch 180/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 149/300 batch 181/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 149/300 batch 182/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 149/300 batch 183/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 149/300 batch 184/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 149/300 batch 185/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 149/300 batch 186/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 149/300 batch 187/188  Train Loss: 0.019, Acc: 0.992\n",
      "Train Loss: 0.034065, Acc: 0.992\n",
      "Val Loss: 0.057611, Acc: 0.983\n",
      "epoch: 150/300 batch   0/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 150/300 batch   1/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 150/300 batch   2/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 150/300 batch   3/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 150/300 batch   4/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 150/300 batch   5/188  Train Loss: 0.045, Acc: 0.996\n",
      "epoch: 150/300 batch   6/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 150/300 batch   7/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 150/300 batch   8/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 150/300 batch   9/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 150/300 batch  10/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 150/300 batch  11/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 150/300 batch  12/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 150/300 batch  13/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 150/300 batch  14/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 150/300 batch  15/188  Train Loss: 0.060, Acc: 0.984\n",
      "epoch: 150/300 batch  16/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 150/300 batch  17/188  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 150/300 batch  18/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 150/300 batch  19/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 150/300 batch  20/188  Train Loss: 0.031, Acc: 1.000\n",
      "epoch: 150/300 batch  21/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 150/300 batch  22/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 150/300 batch  23/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 150/300 batch  24/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 150/300 batch  25/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 150/300 batch  26/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 150/300 batch  27/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 150/300 batch  28/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 150/300 batch  29/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 150/300 batch  30/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 150/300 batch  31/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 150/300 batch  32/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 150/300 batch  33/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 150/300 batch  34/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 150/300 batch  35/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 150/300 batch  36/188  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 150/300 batch  37/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 150/300 batch  38/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 150/300 batch  39/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 150/300 batch  40/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 150/300 batch  41/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 150/300 batch  42/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 150/300 batch  43/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 150/300 batch  44/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 150/300 batch  45/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 150/300 batch  46/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 150/300 batch  47/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 150/300 batch  48/188  Train Loss: 0.060, Acc: 0.984\n",
      "epoch: 150/300 batch  49/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 150/300 batch  50/188  Train Loss: 0.070, Acc: 0.992\n",
      "epoch: 150/300 batch  51/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 150/300 batch  52/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 150/300 batch  53/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 150/300 batch  54/188  Train Loss: 0.034, Acc: 0.984\n",
      "epoch: 150/300 batch  55/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 150/300 batch  56/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 150/300 batch  57/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 150/300 batch  58/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 150/300 batch  59/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 150/300 batch  60/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 150/300 batch  61/188  Train Loss: 0.027, Acc: 0.988\n",
      "epoch: 150/300 batch  62/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 150/300 batch  63/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 150/300 batch  64/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 150/300 batch  65/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 150/300 batch  66/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 150/300 batch  67/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 150/300 batch  68/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 150/300 batch  69/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 150/300 batch  70/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 150/300 batch  71/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 150/300 batch  72/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 150/300 batch  73/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 150/300 batch  74/188  Train Loss: 0.081, Acc: 0.980\n",
      "epoch: 150/300 batch  75/188  Train Loss: 0.070, Acc: 0.984\n",
      "epoch: 150/300 batch  76/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 150/300 batch  77/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 150/300 batch  78/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 150/300 batch  79/188  Train Loss: 0.052, Acc: 0.977\n",
      "epoch: 150/300 batch  80/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 150/300 batch  81/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 150/300 batch  82/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 150/300 batch  83/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 150/300 batch  84/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 150/300 batch  85/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 150/300 batch  86/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 150/300 batch  87/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 150/300 batch  88/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 150/300 batch  89/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 150/300 batch  90/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 150/300 batch  91/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 150/300 batch  92/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 150/300 batch  93/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 150/300 batch  94/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 150/300 batch  95/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 150/300 batch  96/188  Train Loss: 0.055, Acc: 0.980\n",
      "epoch: 150/300 batch  97/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 150/300 batch  98/188  Train Loss: 0.057, Acc: 0.980\n",
      "epoch: 150/300 batch  99/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 150/300 batch 100/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 150/300 batch 101/188  Train Loss: 0.027, Acc: 0.988\n",
      "epoch: 150/300 batch 102/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 150/300 batch 103/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 150/300 batch 104/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 150/300 batch 105/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 150/300 batch 106/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 150/300 batch 107/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 150/300 batch 108/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 150/300 batch 109/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 150/300 batch 110/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 150/300 batch 111/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 150/300 batch 112/188  Train Loss: 0.015, Acc: 0.996\n",
      "epoch: 150/300 batch 113/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 150/300 batch 114/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 150/300 batch 115/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 150/300 batch 116/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 150/300 batch 117/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 150/300 batch 118/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 150/300 batch 119/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 150/300 batch 120/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 150/300 batch 121/188  Train Loss: 0.055, Acc: 0.977\n",
      "epoch: 150/300 batch 122/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 150/300 batch 123/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 150/300 batch 124/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 150/300 batch 125/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 150/300 batch 126/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 150/300 batch 127/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 150/300 batch 128/188  Train Loss: 0.065, Acc: 0.984\n",
      "epoch: 150/300 batch 129/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 150/300 batch 130/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 150/300 batch 131/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 150/300 batch 132/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 150/300 batch 133/188  Train Loss: 0.055, Acc: 0.980\n",
      "epoch: 150/300 batch 134/188  Train Loss: 0.052, Acc: 0.980\n",
      "epoch: 150/300 batch 135/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 150/300 batch 136/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 150/300 batch 137/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 150/300 batch 138/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 150/300 batch 139/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 150/300 batch 140/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 150/300 batch 141/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 150/300 batch 142/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 150/300 batch 143/188  Train Loss: 0.048, Acc: 0.980\n",
      "epoch: 150/300 batch 144/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 150/300 batch 145/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 150/300 batch 146/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 150/300 batch 147/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 150/300 batch 148/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 150/300 batch 149/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 150/300 batch 150/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 150/300 batch 151/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 150/300 batch 152/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 150/300 batch 153/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 150/300 batch 154/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 150/300 batch 155/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 150/300 batch 156/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 150/300 batch 157/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 150/300 batch 158/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 150/300 batch 159/188  Train Loss: 0.074, Acc: 0.984\n",
      "epoch: 150/300 batch 160/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 150/300 batch 161/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 150/300 batch 162/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 150/300 batch 163/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 150/300 batch 164/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 150/300 batch 165/188  Train Loss: 0.026, Acc: 0.988\n",
      "epoch: 150/300 batch 166/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 150/300 batch 167/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 150/300 batch 168/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 150/300 batch 169/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 150/300 batch 170/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 150/300 batch 171/188  Train Loss: 0.033, Acc: 0.984\n",
      "epoch: 150/300 batch 172/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 150/300 batch 173/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 150/300 batch 174/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 150/300 batch 175/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 150/300 batch 176/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 150/300 batch 177/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 150/300 batch 178/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 150/300 batch 179/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 150/300 batch 180/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 150/300 batch 181/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 150/300 batch 182/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 150/300 batch 183/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 150/300 batch 184/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 150/300 batch 185/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 150/300 batch 186/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 150/300 batch 187/188  Train Loss: 0.014, Acc: 1.000\n",
      "Train Loss: 0.034022, Acc: 0.992\n",
      "Val Loss: 0.057705, Acc: 0.983\n",
      "epoch: 151/300 batch   0/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 151/300 batch   1/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 151/300 batch   2/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 151/300 batch   3/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 151/300 batch   4/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 151/300 batch   5/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 151/300 batch   6/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 151/300 batch   7/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 151/300 batch   8/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 151/300 batch   9/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 151/300 batch  10/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 151/300 batch  11/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 151/300 batch  12/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 151/300 batch  13/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 151/300 batch  14/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 151/300 batch  15/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 151/300 batch  16/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 151/300 batch  17/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 151/300 batch  18/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 151/300 batch  19/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 151/300 batch  20/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 151/300 batch  21/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 151/300 batch  22/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 151/300 batch  23/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 151/300 batch  24/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 151/300 batch  25/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 151/300 batch  26/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 151/300 batch  27/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 151/300 batch  28/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 151/300 batch  29/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 151/300 batch  30/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 151/300 batch  31/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 151/300 batch  32/188  Train Loss: 0.063, Acc: 0.988\n",
      "epoch: 151/300 batch  33/188  Train Loss: 0.037, Acc: 0.980\n",
      "epoch: 151/300 batch  34/188  Train Loss: 0.049, Acc: 0.980\n",
      "epoch: 151/300 batch  35/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 151/300 batch  36/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 151/300 batch  37/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 151/300 batch  38/188  Train Loss: 0.057, Acc: 0.988\n",
      "epoch: 151/300 batch  39/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 151/300 batch  40/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 151/300 batch  41/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 151/300 batch  42/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 151/300 batch  43/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 151/300 batch  44/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 151/300 batch  45/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 151/300 batch  46/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 151/300 batch  47/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 151/300 batch  48/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 151/300 batch  49/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 151/300 batch  50/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 151/300 batch  51/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 151/300 batch  52/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 151/300 batch  53/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 151/300 batch  54/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 151/300 batch  55/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 151/300 batch  56/188  Train Loss: 0.044, Acc: 0.980\n",
      "epoch: 151/300 batch  57/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 151/300 batch  58/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 151/300 batch  59/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 151/300 batch  60/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 151/300 batch  61/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 151/300 batch  62/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 151/300 batch  63/188  Train Loss: 0.031, Acc: 1.000\n",
      "epoch: 151/300 batch  64/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 151/300 batch  65/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 151/300 batch  66/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 151/300 batch  67/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 151/300 batch  68/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 151/300 batch  69/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 151/300 batch  70/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 151/300 batch  71/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 151/300 batch  72/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 151/300 batch  73/188  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 151/300 batch  74/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 151/300 batch  75/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 151/300 batch  76/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 151/300 batch  77/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 151/300 batch  78/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 151/300 batch  79/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 151/300 batch  80/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 151/300 batch  81/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 151/300 batch  82/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 151/300 batch  83/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 151/300 batch  84/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 151/300 batch  85/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 151/300 batch  86/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 151/300 batch  87/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 151/300 batch  88/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 151/300 batch  89/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 151/300 batch  90/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 151/300 batch  91/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 151/300 batch  92/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 151/300 batch  93/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 151/300 batch  94/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 151/300 batch  95/188  Train Loss: 0.067, Acc: 0.973\n",
      "epoch: 151/300 batch  96/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 151/300 batch  97/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 151/300 batch  98/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 151/300 batch  99/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 151/300 batch 100/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 151/300 batch 101/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 151/300 batch 102/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 151/300 batch 103/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 151/300 batch 104/188  Train Loss: 0.046, Acc: 0.996\n",
      "epoch: 151/300 batch 105/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 151/300 batch 106/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 151/300 batch 107/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 151/300 batch 108/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 151/300 batch 109/188  Train Loss: 0.054, Acc: 0.992\n",
      "epoch: 151/300 batch 110/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 151/300 batch 111/188  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 151/300 batch 112/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 151/300 batch 113/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 151/300 batch 114/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 151/300 batch 115/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 151/300 batch 116/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 151/300 batch 117/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 151/300 batch 118/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 151/300 batch 119/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 151/300 batch 120/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 151/300 batch 121/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 151/300 batch 122/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 151/300 batch 123/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 151/300 batch 124/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 151/300 batch 125/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 151/300 batch 126/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 151/300 batch 127/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 151/300 batch 128/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 151/300 batch 129/188  Train Loss: 0.044, Acc: 0.980\n",
      "epoch: 151/300 batch 130/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 151/300 batch 131/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 151/300 batch 132/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 151/300 batch 133/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 151/300 batch 134/188  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 151/300 batch 135/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 151/300 batch 136/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 151/300 batch 137/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 151/300 batch 138/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 151/300 batch 139/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 151/300 batch 140/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 151/300 batch 141/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 151/300 batch 142/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 151/300 batch 143/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 151/300 batch 144/188  Train Loss: 0.080, Acc: 0.988\n",
      "epoch: 151/300 batch 145/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 151/300 batch 146/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 151/300 batch 147/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 151/300 batch 148/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 151/300 batch 149/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 151/300 batch 150/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 151/300 batch 151/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 151/300 batch 152/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 151/300 batch 153/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 151/300 batch 154/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 151/300 batch 155/188  Train Loss: 0.065, Acc: 0.988\n",
      "epoch: 151/300 batch 156/188  Train Loss: 0.015, Acc: 0.996\n",
      "epoch: 151/300 batch 157/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 151/300 batch 158/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 151/300 batch 159/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 151/300 batch 160/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 151/300 batch 161/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 151/300 batch 162/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 151/300 batch 163/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 151/300 batch 164/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 151/300 batch 165/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 151/300 batch 166/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 151/300 batch 167/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 151/300 batch 168/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 151/300 batch 169/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 151/300 batch 170/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 151/300 batch 171/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 151/300 batch 172/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 151/300 batch 173/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 151/300 batch 174/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 151/300 batch 175/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 151/300 batch 176/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 151/300 batch 177/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 151/300 batch 178/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 151/300 batch 179/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 151/300 batch 180/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 151/300 batch 181/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 151/300 batch 182/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 151/300 batch 183/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 151/300 batch 184/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 151/300 batch 185/188  Train Loss: 0.051, Acc: 0.980\n",
      "epoch: 151/300 batch 186/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 151/300 batch 187/188  Train Loss: 0.037, Acc: 0.984\n",
      "Train Loss: 0.034050, Acc: 0.992\n",
      "Val Loss: 0.057449, Acc: 0.983\n",
      "epoch: 152/300 batch   0/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 152/300 batch   1/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 152/300 batch   2/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 152/300 batch   3/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 152/300 batch   4/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 152/300 batch   5/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 152/300 batch   6/188  Train Loss: 0.051, Acc: 0.992\n",
      "epoch: 152/300 batch   7/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 152/300 batch   8/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 152/300 batch   9/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 152/300 batch  10/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 152/300 batch  11/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 152/300 batch  12/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 152/300 batch  13/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 152/300 batch  14/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 152/300 batch  15/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 152/300 batch  16/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 152/300 batch  17/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 152/300 batch  18/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 152/300 batch  19/188  Train Loss: 0.061, Acc: 0.988\n",
      "epoch: 152/300 batch  20/188  Train Loss: 0.054, Acc: 0.980\n",
      "epoch: 152/300 batch  21/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 152/300 batch  22/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 152/300 batch  23/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 152/300 batch  24/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 152/300 batch  25/188  Train Loss: 0.062, Acc: 0.988\n",
      "epoch: 152/300 batch  26/188  Train Loss: 0.061, Acc: 0.980\n",
      "epoch: 152/300 batch  27/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 152/300 batch  28/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 152/300 batch  29/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 152/300 batch  30/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 152/300 batch  31/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 152/300 batch  32/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 152/300 batch  33/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 152/300 batch  34/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 152/300 batch  35/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 152/300 batch  36/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 152/300 batch  37/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 152/300 batch  38/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 152/300 batch  39/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 152/300 batch  40/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 152/300 batch  41/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 152/300 batch  42/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 152/300 batch  43/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 152/300 batch  44/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 152/300 batch  45/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 152/300 batch  46/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 152/300 batch  47/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 152/300 batch  48/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 152/300 batch  49/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 152/300 batch  50/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 152/300 batch  51/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 152/300 batch  52/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 152/300 batch  53/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 152/300 batch  54/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 152/300 batch  55/188  Train Loss: 0.061, Acc: 0.992\n",
      "epoch: 152/300 batch  56/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 152/300 batch  57/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 152/300 batch  58/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 152/300 batch  59/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 152/300 batch  60/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 152/300 batch  61/188  Train Loss: 0.041, Acc: 0.980\n",
      "epoch: 152/300 batch  62/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 152/300 batch  63/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 152/300 batch  64/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 152/300 batch  65/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 152/300 batch  66/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 152/300 batch  67/188  Train Loss: 0.056, Acc: 0.988\n",
      "epoch: 152/300 batch  68/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 152/300 batch  69/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 152/300 batch  70/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 152/300 batch  71/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 152/300 batch  72/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 152/300 batch  73/188  Train Loss: 0.032, Acc: 1.000\n",
      "epoch: 152/300 batch  74/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 152/300 batch  75/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 152/300 batch  76/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 152/300 batch  77/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 152/300 batch  78/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 152/300 batch  79/188  Train Loss: 0.058, Acc: 0.988\n",
      "epoch: 152/300 batch  80/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 152/300 batch  81/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 152/300 batch  82/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 152/300 batch  83/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 152/300 batch  84/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 152/300 batch  85/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 152/300 batch  86/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 152/300 batch  87/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 152/300 batch  88/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 152/300 batch  89/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 152/300 batch  90/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 152/300 batch  91/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 152/300 batch  92/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 152/300 batch  93/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 152/300 batch  94/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 152/300 batch  95/188  Train Loss: 0.033, Acc: 1.000\n",
      "epoch: 152/300 batch  96/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 152/300 batch  97/188  Train Loss: 0.067, Acc: 0.992\n",
      "epoch: 152/300 batch  98/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 152/300 batch  99/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 152/300 batch 100/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 152/300 batch 101/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 152/300 batch 102/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 152/300 batch 103/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 152/300 batch 104/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 152/300 batch 105/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 152/300 batch 106/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 152/300 batch 107/188  Train Loss: 0.016, Acc: 0.996\n",
      "epoch: 152/300 batch 108/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 152/300 batch 109/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 152/300 batch 110/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 152/300 batch 111/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 152/300 batch 112/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 152/300 batch 113/188  Train Loss: 0.065, Acc: 0.980\n",
      "epoch: 152/300 batch 114/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 152/300 batch 115/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 152/300 batch 116/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 152/300 batch 117/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 152/300 batch 118/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 152/300 batch 119/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 152/300 batch 120/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 152/300 batch 121/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 152/300 batch 122/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 152/300 batch 123/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 152/300 batch 124/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 152/300 batch 125/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 152/300 batch 126/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 152/300 batch 127/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 152/300 batch 128/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 152/300 batch 129/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 152/300 batch 130/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 152/300 batch 131/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 152/300 batch 132/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 152/300 batch 133/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 152/300 batch 134/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 152/300 batch 135/188  Train Loss: 0.039, Acc: 0.980\n",
      "epoch: 152/300 batch 136/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 152/300 batch 137/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 152/300 batch 138/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 152/300 batch 139/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 152/300 batch 140/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 152/300 batch 141/188  Train Loss: 0.066, Acc: 0.984\n",
      "epoch: 152/300 batch 142/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 152/300 batch 143/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 152/300 batch 144/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 152/300 batch 145/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 152/300 batch 146/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 152/300 batch 147/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 152/300 batch 148/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 152/300 batch 149/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 152/300 batch 150/188  Train Loss: 0.031, Acc: 0.984\n",
      "epoch: 152/300 batch 151/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 152/300 batch 152/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 152/300 batch 153/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 152/300 batch 154/188  Train Loss: 0.064, Acc: 0.988\n",
      "epoch: 152/300 batch 155/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 152/300 batch 156/188  Train Loss: 0.061, Acc: 0.969\n",
      "epoch: 152/300 batch 157/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 152/300 batch 158/188  Train Loss: 0.053, Acc: 0.980\n",
      "epoch: 152/300 batch 159/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 152/300 batch 160/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 152/300 batch 161/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 152/300 batch 162/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 152/300 batch 163/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 152/300 batch 164/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 152/300 batch 165/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 152/300 batch 166/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 152/300 batch 167/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 152/300 batch 168/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 152/300 batch 169/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 152/300 batch 170/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 152/300 batch 171/188  Train Loss: 0.046, Acc: 0.980\n",
      "epoch: 152/300 batch 172/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 152/300 batch 173/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 152/300 batch 174/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 152/300 batch 175/188  Train Loss: 0.062, Acc: 0.988\n",
      "epoch: 152/300 batch 176/188  Train Loss: 0.070, Acc: 0.973\n",
      "epoch: 152/300 batch 177/188  Train Loss: 0.035, Acc: 1.000\n",
      "epoch: 152/300 batch 178/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 152/300 batch 179/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 152/300 batch 180/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 152/300 batch 181/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 152/300 batch 182/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 152/300 batch 183/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 152/300 batch 184/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 152/300 batch 185/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 152/300 batch 186/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 152/300 batch 187/188  Train Loss: 0.051, Acc: 0.977\n",
      "Train Loss: 0.034069, Acc: 0.992\n",
      "Val Loss: 0.057750, Acc: 0.983\n",
      "epoch: 153/300 batch   0/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 153/300 batch   1/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 153/300 batch   2/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 153/300 batch   3/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 153/300 batch   4/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 153/300 batch   5/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 153/300 batch   6/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 153/300 batch   7/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 153/300 batch   8/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 153/300 batch   9/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 153/300 batch  10/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 153/300 batch  11/188  Train Loss: 0.033, Acc: 1.000\n",
      "epoch: 153/300 batch  12/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 153/300 batch  13/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 153/300 batch  14/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 153/300 batch  15/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 153/300 batch  16/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 153/300 batch  17/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 153/300 batch  18/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 153/300 batch  19/188  Train Loss: 0.047, Acc: 0.980\n",
      "epoch: 153/300 batch  20/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 153/300 batch  21/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 153/300 batch  22/188  Train Loss: 0.075, Acc: 0.984\n",
      "epoch: 153/300 batch  23/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 153/300 batch  24/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 153/300 batch  25/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 153/300 batch  26/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 153/300 batch  27/188  Train Loss: 0.052, Acc: 0.977\n",
      "epoch: 153/300 batch  28/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 153/300 batch  29/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 153/300 batch  30/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 153/300 batch  31/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 153/300 batch  32/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 153/300 batch  33/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 153/300 batch  34/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 153/300 batch  35/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 153/300 batch  36/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 153/300 batch  37/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 153/300 batch  38/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 153/300 batch  39/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 153/300 batch  40/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 153/300 batch  41/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 153/300 batch  42/188  Train Loss: 0.045, Acc: 0.977\n",
      "epoch: 153/300 batch  43/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 153/300 batch  44/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 153/300 batch  45/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 153/300 batch  46/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 153/300 batch  47/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 153/300 batch  48/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 153/300 batch  49/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 153/300 batch  50/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 153/300 batch  51/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 153/300 batch  52/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 153/300 batch  53/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 153/300 batch  54/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 153/300 batch  55/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 153/300 batch  56/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 153/300 batch  57/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 153/300 batch  58/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 153/300 batch  59/188  Train Loss: 0.052, Acc: 0.980\n",
      "epoch: 153/300 batch  60/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 153/300 batch  61/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 153/300 batch  62/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 153/300 batch  63/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 153/300 batch  64/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 153/300 batch  65/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 153/300 batch  66/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 153/300 batch  67/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 153/300 batch  68/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 153/300 batch  69/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 153/300 batch  70/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 153/300 batch  71/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 153/300 batch  72/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 153/300 batch  73/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 153/300 batch  74/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 153/300 batch  75/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 153/300 batch  76/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 153/300 batch  77/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 153/300 batch  78/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 153/300 batch  79/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 153/300 batch  80/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 153/300 batch  81/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 153/300 batch  82/188  Train Loss: 0.032, Acc: 1.000\n",
      "epoch: 153/300 batch  83/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 153/300 batch  84/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 153/300 batch  85/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 153/300 batch  86/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 153/300 batch  87/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 153/300 batch  88/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 153/300 batch  89/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 153/300 batch  90/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 153/300 batch  91/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 153/300 batch  92/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 153/300 batch  93/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 153/300 batch  94/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 153/300 batch  95/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 153/300 batch  96/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 153/300 batch  97/188  Train Loss: 0.064, Acc: 0.984\n",
      "epoch: 153/300 batch  98/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 153/300 batch  99/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 153/300 batch 100/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 153/300 batch 101/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 153/300 batch 102/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 153/300 batch 103/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 153/300 batch 104/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 153/300 batch 105/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 153/300 batch 106/188  Train Loss: 0.052, Acc: 0.977\n",
      "epoch: 153/300 batch 107/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 153/300 batch 108/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 153/300 batch 109/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 153/300 batch 110/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 153/300 batch 111/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 153/300 batch 112/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 153/300 batch 113/188  Train Loss: 0.079, Acc: 0.980\n",
      "epoch: 153/300 batch 114/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 153/300 batch 115/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 153/300 batch 116/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 153/300 batch 117/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 153/300 batch 118/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 153/300 batch 119/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 153/300 batch 120/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 153/300 batch 121/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 153/300 batch 122/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 153/300 batch 123/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 153/300 batch 124/188  Train Loss: 0.059, Acc: 0.980\n",
      "epoch: 153/300 batch 125/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 153/300 batch 126/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 153/300 batch 127/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 153/300 batch 128/188  Train Loss: 0.043, Acc: 0.980\n",
      "epoch: 153/300 batch 129/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 153/300 batch 130/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 153/300 batch 131/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 153/300 batch 132/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 153/300 batch 133/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 153/300 batch 134/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 153/300 batch 135/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 153/300 batch 136/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 153/300 batch 137/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 153/300 batch 138/188  Train Loss: 0.024, Acc: 0.988\n",
      "epoch: 153/300 batch 139/188  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 153/300 batch 140/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 153/300 batch 141/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 153/300 batch 142/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 153/300 batch 143/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 153/300 batch 144/188  Train Loss: 0.033, Acc: 0.984\n",
      "epoch: 153/300 batch 145/188  Train Loss: 0.047, Acc: 0.996\n",
      "epoch: 153/300 batch 146/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 153/300 batch 147/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 153/300 batch 148/188  Train Loss: 0.072, Acc: 0.980\n",
      "epoch: 153/300 batch 149/188  Train Loss: 0.060, Acc: 0.980\n",
      "epoch: 153/300 batch 150/188  Train Loss: 0.063, Acc: 0.980\n",
      "epoch: 153/300 batch 151/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 153/300 batch 152/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 153/300 batch 153/188  Train Loss: 0.051, Acc: 0.992\n",
      "epoch: 153/300 batch 154/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 153/300 batch 155/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 153/300 batch 156/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 153/300 batch 157/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 153/300 batch 158/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 153/300 batch 159/188  Train Loss: 0.036, Acc: 0.980\n",
      "epoch: 153/300 batch 160/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 153/300 batch 161/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 153/300 batch 162/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 153/300 batch 163/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 153/300 batch 164/188  Train Loss: 0.057, Acc: 0.992\n",
      "epoch: 153/300 batch 165/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 153/300 batch 166/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 153/300 batch 167/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 153/300 batch 168/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 153/300 batch 169/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 153/300 batch 170/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 153/300 batch 171/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 153/300 batch 172/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 153/300 batch 173/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 153/300 batch 174/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 153/300 batch 175/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 153/300 batch 176/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 153/300 batch 177/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 153/300 batch 178/188  Train Loss: 0.063, Acc: 0.992\n",
      "epoch: 153/300 batch 179/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 153/300 batch 180/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 153/300 batch 181/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 153/300 batch 182/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 153/300 batch 183/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 153/300 batch 184/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 153/300 batch 185/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 153/300 batch 186/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 153/300 batch 187/188  Train Loss: 0.026, Acc: 0.992\n",
      "Train Loss: 0.033999, Acc: 0.993\n",
      "Val Loss: 0.057427, Acc: 0.982\n",
      "epoch: 154/300 batch   0/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 154/300 batch   1/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 154/300 batch   2/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 154/300 batch   3/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 154/300 batch   4/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 154/300 batch   5/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 154/300 batch   6/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 154/300 batch   7/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 154/300 batch   8/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 154/300 batch   9/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 154/300 batch  10/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 154/300 batch  11/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 154/300 batch  12/188  Train Loss: 0.043, Acc: 0.980\n",
      "epoch: 154/300 batch  13/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 154/300 batch  14/188  Train Loss: 0.065, Acc: 0.984\n",
      "epoch: 154/300 batch  15/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 154/300 batch  16/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 154/300 batch  17/188  Train Loss: 0.025, Acc: 0.988\n",
      "epoch: 154/300 batch  18/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 154/300 batch  19/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 154/300 batch  20/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 154/300 batch  21/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 154/300 batch  22/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 154/300 batch  23/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 154/300 batch  24/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 154/300 batch  25/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 154/300 batch  26/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 154/300 batch  27/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 154/300 batch  28/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 154/300 batch  29/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 154/300 batch  30/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 154/300 batch  31/188  Train Loss: 0.044, Acc: 0.980\n",
      "epoch: 154/300 batch  32/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 154/300 batch  33/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 154/300 batch  34/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 154/300 batch  35/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 154/300 batch  36/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 154/300 batch  37/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 154/300 batch  38/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 154/300 batch  39/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 154/300 batch  40/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 154/300 batch  41/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 154/300 batch  42/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 154/300 batch  43/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 154/300 batch  44/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 154/300 batch  45/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 154/300 batch  46/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 154/300 batch  47/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 154/300 batch  48/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 154/300 batch  49/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 154/300 batch  50/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 154/300 batch  51/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 154/300 batch  52/188  Train Loss: 0.047, Acc: 0.980\n",
      "epoch: 154/300 batch  53/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 154/300 batch  54/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 154/300 batch  55/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 154/300 batch  56/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 154/300 batch  57/188  Train Loss: 0.063, Acc: 0.984\n",
      "epoch: 154/300 batch  58/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 154/300 batch  59/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 154/300 batch  60/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 154/300 batch  61/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 154/300 batch  62/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 154/300 batch  63/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 154/300 batch  64/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 154/300 batch  65/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 154/300 batch  66/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 154/300 batch  67/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 154/300 batch  68/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 154/300 batch  69/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 154/300 batch  70/188  Train Loss: 0.042, Acc: 0.996\n",
      "epoch: 154/300 batch  71/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 154/300 batch  72/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 154/300 batch  73/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 154/300 batch  74/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 154/300 batch  75/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 154/300 batch  76/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 154/300 batch  77/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 154/300 batch  78/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 154/300 batch  79/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 154/300 batch  80/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 154/300 batch  81/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 154/300 batch  82/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 154/300 batch  83/188  Train Loss: 0.072, Acc: 0.984\n",
      "epoch: 154/300 batch  84/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 154/300 batch  85/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 154/300 batch  86/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 154/300 batch  87/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 154/300 batch  88/188  Train Loss: 0.049, Acc: 0.980\n",
      "epoch: 154/300 batch  89/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 154/300 batch  90/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 154/300 batch  91/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 154/300 batch  92/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 154/300 batch  93/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 154/300 batch  94/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 154/300 batch  95/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 154/300 batch  96/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 154/300 batch  97/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 154/300 batch  98/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 154/300 batch  99/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 154/300 batch 100/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 154/300 batch 101/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 154/300 batch 102/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 154/300 batch 103/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 154/300 batch 104/188  Train Loss: 0.042, Acc: 0.980\n",
      "epoch: 154/300 batch 105/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 154/300 batch 106/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 154/300 batch 107/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 154/300 batch 108/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 154/300 batch 109/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 154/300 batch 110/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 154/300 batch 111/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 154/300 batch 112/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 154/300 batch 113/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 154/300 batch 114/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 154/300 batch 115/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 154/300 batch 116/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 154/300 batch 117/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 154/300 batch 118/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 154/300 batch 119/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 154/300 batch 120/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 154/300 batch 121/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 154/300 batch 122/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 154/300 batch 123/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 154/300 batch 124/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 154/300 batch 125/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 154/300 batch 126/188  Train Loss: 0.059, Acc: 0.984\n",
      "epoch: 154/300 batch 127/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 154/300 batch 128/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 154/300 batch 129/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 154/300 batch 130/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 154/300 batch 131/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 154/300 batch 132/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 154/300 batch 133/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 154/300 batch 134/188  Train Loss: 0.044, Acc: 0.980\n",
      "epoch: 154/300 batch 135/188  Train Loss: 0.071, Acc: 0.977\n",
      "epoch: 154/300 batch 136/188  Train Loss: 0.056, Acc: 0.988\n",
      "epoch: 154/300 batch 137/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 154/300 batch 138/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 154/300 batch 139/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 154/300 batch 140/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 154/300 batch 141/188  Train Loss: 0.057, Acc: 0.988\n",
      "epoch: 154/300 batch 142/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 154/300 batch 143/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 154/300 batch 144/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 154/300 batch 145/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 154/300 batch 146/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 154/300 batch 147/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 154/300 batch 148/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 154/300 batch 149/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 154/300 batch 150/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 154/300 batch 151/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 154/300 batch 152/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 154/300 batch 153/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 154/300 batch 154/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 154/300 batch 155/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 154/300 batch 156/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 154/300 batch 157/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 154/300 batch 158/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 154/300 batch 159/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 154/300 batch 160/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 154/300 batch 161/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 154/300 batch 162/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 154/300 batch 163/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 154/300 batch 164/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 154/300 batch 165/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 154/300 batch 166/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 154/300 batch 167/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 154/300 batch 168/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 154/300 batch 169/188  Train Loss: 0.042, Acc: 0.996\n",
      "epoch: 154/300 batch 170/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 154/300 batch 171/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 154/300 batch 172/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 154/300 batch 173/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 154/300 batch 174/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 154/300 batch 175/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 154/300 batch 176/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 154/300 batch 177/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 154/300 batch 178/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 154/300 batch 179/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 154/300 batch 180/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 154/300 batch 181/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 154/300 batch 182/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 154/300 batch 183/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 154/300 batch 184/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 154/300 batch 185/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 154/300 batch 186/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 154/300 batch 187/188  Train Loss: 0.080, Acc: 0.984\n",
      "Train Loss: 0.034085, Acc: 0.992\n",
      "Val Loss: 0.057636, Acc: 0.983\n",
      "epoch: 155/300 batch   0/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 155/300 batch   1/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 155/300 batch   2/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 155/300 batch   3/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 155/300 batch   4/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 155/300 batch   5/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 155/300 batch   6/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 155/300 batch   7/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 155/300 batch   8/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 155/300 batch   9/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 155/300 batch  10/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 155/300 batch  11/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 155/300 batch  12/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 155/300 batch  13/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 155/300 batch  14/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 155/300 batch  15/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 155/300 batch  16/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 155/300 batch  17/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 155/300 batch  18/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 155/300 batch  19/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 155/300 batch  20/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 155/300 batch  21/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 155/300 batch  22/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 155/300 batch  23/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 155/300 batch  24/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 155/300 batch  25/188  Train Loss: 0.053, Acc: 0.992\n",
      "epoch: 155/300 batch  26/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 155/300 batch  27/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 155/300 batch  28/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 155/300 batch  29/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 155/300 batch  30/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 155/300 batch  31/188  Train Loss: 0.062, Acc: 0.984\n",
      "epoch: 155/300 batch  32/188  Train Loss: 0.065, Acc: 0.980\n",
      "epoch: 155/300 batch  33/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 155/300 batch  34/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 155/300 batch  35/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 155/300 batch  36/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 155/300 batch  37/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 155/300 batch  38/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 155/300 batch  39/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 155/300 batch  40/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 155/300 batch  41/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 155/300 batch  42/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 155/300 batch  43/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 155/300 batch  44/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 155/300 batch  45/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 155/300 batch  46/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 155/300 batch  47/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 155/300 batch  48/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 155/300 batch  49/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 155/300 batch  50/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 155/300 batch  51/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 155/300 batch  52/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 155/300 batch  53/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 155/300 batch  54/188  Train Loss: 0.042, Acc: 0.996\n",
      "epoch: 155/300 batch  55/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 155/300 batch  56/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 155/300 batch  57/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 155/300 batch  58/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 155/300 batch  59/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 155/300 batch  60/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 155/300 batch  61/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 155/300 batch  62/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 155/300 batch  63/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 155/300 batch  64/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 155/300 batch  65/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 155/300 batch  66/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 155/300 batch  67/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 155/300 batch  68/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 155/300 batch  69/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 155/300 batch  70/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 155/300 batch  71/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 155/300 batch  72/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 155/300 batch  73/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 155/300 batch  74/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 155/300 batch  75/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 155/300 batch  76/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 155/300 batch  77/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 155/300 batch  78/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 155/300 batch  79/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 155/300 batch  80/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 155/300 batch  81/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 155/300 batch  82/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 155/300 batch  83/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 155/300 batch  84/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 155/300 batch  85/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 155/300 batch  86/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 155/300 batch  87/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 155/300 batch  88/188  Train Loss: 0.046, Acc: 0.980\n",
      "epoch: 155/300 batch  89/188  Train Loss: 0.060, Acc: 0.984\n",
      "epoch: 155/300 batch  90/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 155/300 batch  91/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 155/300 batch  92/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 155/300 batch  93/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 155/300 batch  94/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 155/300 batch  95/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 155/300 batch  96/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 155/300 batch  97/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 155/300 batch  98/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 155/300 batch  99/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 155/300 batch 100/188  Train Loss: 0.060, Acc: 0.984\n",
      "epoch: 155/300 batch 101/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 155/300 batch 102/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 155/300 batch 103/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 155/300 batch 104/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 155/300 batch 105/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 155/300 batch 106/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 155/300 batch 107/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 155/300 batch 108/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 155/300 batch 109/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 155/300 batch 110/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 155/300 batch 111/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 155/300 batch 112/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 155/300 batch 113/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 155/300 batch 114/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 155/300 batch 115/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 155/300 batch 116/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 155/300 batch 117/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 155/300 batch 118/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 155/300 batch 119/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 155/300 batch 120/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 155/300 batch 121/188  Train Loss: 0.046, Acc: 0.996\n",
      "epoch: 155/300 batch 122/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 155/300 batch 123/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 155/300 batch 124/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 155/300 batch 125/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 155/300 batch 126/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 155/300 batch 127/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 155/300 batch 128/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 155/300 batch 129/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 155/300 batch 130/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 155/300 batch 131/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 155/300 batch 132/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 155/300 batch 133/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 155/300 batch 134/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 155/300 batch 135/188  Train Loss: 0.048, Acc: 0.973\n",
      "epoch: 155/300 batch 136/188  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 155/300 batch 137/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 155/300 batch 138/188  Train Loss: 0.094, Acc: 0.977\n",
      "epoch: 155/300 batch 139/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 155/300 batch 140/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 155/300 batch 141/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 155/300 batch 142/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 155/300 batch 143/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 155/300 batch 144/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 155/300 batch 145/188  Train Loss: 0.034, Acc: 0.984\n",
      "epoch: 155/300 batch 146/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 155/300 batch 147/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 155/300 batch 148/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 155/300 batch 149/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 155/300 batch 150/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 155/300 batch 151/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 155/300 batch 152/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 155/300 batch 153/188  Train Loss: 0.057, Acc: 0.980\n",
      "epoch: 155/300 batch 154/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 155/300 batch 155/188  Train Loss: 0.043, Acc: 0.980\n",
      "epoch: 155/300 batch 156/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 155/300 batch 157/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 155/300 batch 158/188  Train Loss: 0.065, Acc: 0.980\n",
      "epoch: 155/300 batch 159/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 155/300 batch 160/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 155/300 batch 161/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 155/300 batch 162/188  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 155/300 batch 163/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 155/300 batch 164/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 155/300 batch 165/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 155/300 batch 166/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 155/300 batch 167/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 155/300 batch 168/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 155/300 batch 169/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 155/300 batch 170/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 155/300 batch 171/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 155/300 batch 172/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 155/300 batch 173/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 155/300 batch 174/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 155/300 batch 175/188  Train Loss: 0.074, Acc: 0.980\n",
      "epoch: 155/300 batch 176/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 155/300 batch 177/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 155/300 batch 178/188  Train Loss: 0.043, Acc: 0.980\n",
      "epoch: 155/300 batch 179/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 155/300 batch 180/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 155/300 batch 181/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 155/300 batch 182/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 155/300 batch 183/188  Train Loss: 0.031, Acc: 0.984\n",
      "epoch: 155/300 batch 184/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 155/300 batch 185/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 155/300 batch 186/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 155/300 batch 187/188  Train Loss: 0.033, Acc: 1.000\n",
      "Train Loss: 0.033949, Acc: 0.992\n",
      "Val Loss: 0.057687, Acc: 0.983\n",
      "epoch: 156/300 batch   0/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 156/300 batch   1/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 156/300 batch   2/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 156/300 batch   3/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 156/300 batch   4/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 156/300 batch   5/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 156/300 batch   6/188  Train Loss: 0.029, Acc: 0.984\n",
      "epoch: 156/300 batch   7/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 156/300 batch   8/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 156/300 batch   9/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 156/300 batch  10/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 156/300 batch  11/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 156/300 batch  12/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 156/300 batch  13/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 156/300 batch  14/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 156/300 batch  15/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 156/300 batch  16/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 156/300 batch  17/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 156/300 batch  18/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 156/300 batch  19/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 156/300 batch  20/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 156/300 batch  21/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 156/300 batch  22/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 156/300 batch  23/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 156/300 batch  24/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 156/300 batch  25/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 156/300 batch  26/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 156/300 batch  27/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 156/300 batch  28/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 156/300 batch  29/188  Train Loss: 0.051, Acc: 0.992\n",
      "epoch: 156/300 batch  30/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 156/300 batch  31/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 156/300 batch  32/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 156/300 batch  33/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 156/300 batch  34/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 156/300 batch  35/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 156/300 batch  36/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 156/300 batch  37/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 156/300 batch  38/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 156/300 batch  39/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 156/300 batch  40/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 156/300 batch  41/188  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 156/300 batch  42/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 156/300 batch  43/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 156/300 batch  44/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 156/300 batch  45/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 156/300 batch  46/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 156/300 batch  47/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 156/300 batch  48/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 156/300 batch  49/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 156/300 batch  50/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 156/300 batch  51/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 156/300 batch  52/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 156/300 batch  53/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 156/300 batch  54/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 156/300 batch  55/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 156/300 batch  56/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 156/300 batch  57/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 156/300 batch  58/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 156/300 batch  59/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 156/300 batch  60/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 156/300 batch  61/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 156/300 batch  62/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 156/300 batch  63/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 156/300 batch  64/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 156/300 batch  65/188  Train Loss: 0.031, Acc: 1.000\n",
      "epoch: 156/300 batch  66/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 156/300 batch  67/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 156/300 batch  68/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 156/300 batch  69/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 156/300 batch  70/188  Train Loss: 0.061, Acc: 0.984\n",
      "epoch: 156/300 batch  71/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 156/300 batch  72/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 156/300 batch  73/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 156/300 batch  74/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 156/300 batch  75/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 156/300 batch  76/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 156/300 batch  77/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 156/300 batch  78/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 156/300 batch  79/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 156/300 batch  80/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 156/300 batch  81/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 156/300 batch  82/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 156/300 batch  83/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 156/300 batch  84/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 156/300 batch  85/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 156/300 batch  86/188  Train Loss: 0.059, Acc: 0.988\n",
      "epoch: 156/300 batch  87/188  Train Loss: 0.035, Acc: 1.000\n",
      "epoch: 156/300 batch  88/188  Train Loss: 0.047, Acc: 0.977\n",
      "epoch: 156/300 batch  89/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 156/300 batch  90/188  Train Loss: 0.042, Acc: 0.996\n",
      "epoch: 156/300 batch  91/188  Train Loss: 0.039, Acc: 0.980\n",
      "epoch: 156/300 batch  92/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 156/300 batch  93/188  Train Loss: 0.049, Acc: 0.996\n",
      "epoch: 156/300 batch  94/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 156/300 batch  95/188  Train Loss: 0.069, Acc: 0.992\n",
      "epoch: 156/300 batch  96/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 156/300 batch  97/188  Train Loss: 0.042, Acc: 0.996\n",
      "epoch: 156/300 batch  98/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 156/300 batch  99/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 156/300 batch 100/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 156/300 batch 101/188  Train Loss: 0.058, Acc: 0.988\n",
      "epoch: 156/300 batch 102/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 156/300 batch 103/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 156/300 batch 104/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 156/300 batch 105/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 156/300 batch 106/188  Train Loss: 0.045, Acc: 0.980\n",
      "epoch: 156/300 batch 107/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 156/300 batch 108/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 156/300 batch 109/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 156/300 batch 110/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 156/300 batch 111/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 156/300 batch 112/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 156/300 batch 113/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 156/300 batch 114/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 156/300 batch 115/188  Train Loss: 0.031, Acc: 1.000\n",
      "epoch: 156/300 batch 116/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 156/300 batch 117/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 156/300 batch 118/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 156/300 batch 119/188  Train Loss: 0.050, Acc: 0.980\n",
      "epoch: 156/300 batch 120/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 156/300 batch 121/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 156/300 batch 122/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 156/300 batch 123/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 156/300 batch 124/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 156/300 batch 125/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 156/300 batch 126/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 156/300 batch 127/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 156/300 batch 128/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 156/300 batch 129/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 156/300 batch 130/188  Train Loss: 0.044, Acc: 0.980\n",
      "epoch: 156/300 batch 131/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 156/300 batch 132/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 156/300 batch 133/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 156/300 batch 134/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 156/300 batch 135/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 156/300 batch 136/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 156/300 batch 137/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 156/300 batch 138/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 156/300 batch 139/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 156/300 batch 140/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 156/300 batch 141/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 156/300 batch 142/188  Train Loss: 0.062, Acc: 0.980\n",
      "epoch: 156/300 batch 143/188  Train Loss: 0.060, Acc: 0.977\n",
      "epoch: 156/300 batch 144/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 156/300 batch 145/188  Train Loss: 0.051, Acc: 0.980\n",
      "epoch: 156/300 batch 146/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 156/300 batch 147/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 156/300 batch 148/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 156/300 batch 149/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 156/300 batch 150/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 156/300 batch 151/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 156/300 batch 152/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 156/300 batch 153/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 156/300 batch 154/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 156/300 batch 155/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 156/300 batch 156/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 156/300 batch 157/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 156/300 batch 158/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 156/300 batch 159/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 156/300 batch 160/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 156/300 batch 161/188  Train Loss: 0.044, Acc: 0.996\n",
      "epoch: 156/300 batch 162/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 156/300 batch 163/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 156/300 batch 164/188  Train Loss: 0.060, Acc: 0.984\n",
      "epoch: 156/300 batch 165/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 156/300 batch 166/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 156/300 batch 167/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 156/300 batch 168/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 156/300 batch 169/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 156/300 batch 170/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 156/300 batch 171/188  Train Loss: 0.056, Acc: 0.988\n",
      "epoch: 156/300 batch 172/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 156/300 batch 173/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 156/300 batch 174/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 156/300 batch 175/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 156/300 batch 176/188  Train Loss: 0.071, Acc: 0.980\n",
      "epoch: 156/300 batch 177/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 156/300 batch 178/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 156/300 batch 179/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 156/300 batch 180/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 156/300 batch 181/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 156/300 batch 182/188  Train Loss: 0.070, Acc: 0.984\n",
      "epoch: 156/300 batch 183/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 156/300 batch 184/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 156/300 batch 185/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 156/300 batch 186/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 156/300 batch 187/188  Train Loss: 0.053, Acc: 0.992\n",
      "Train Loss: 0.033999, Acc: 0.992\n",
      "Val Loss: 0.057383, Acc: 0.982\n",
      "epoch: 157/300 batch   0/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 157/300 batch   1/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 157/300 batch   2/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 157/300 batch   3/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 157/300 batch   4/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 157/300 batch   5/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 157/300 batch   6/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 157/300 batch   7/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 157/300 batch   8/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 157/300 batch   9/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 157/300 batch  10/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 157/300 batch  11/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 157/300 batch  12/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 157/300 batch  13/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 157/300 batch  14/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 157/300 batch  15/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 157/300 batch  16/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 157/300 batch  17/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 157/300 batch  18/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 157/300 batch  19/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 157/300 batch  20/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 157/300 batch  21/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 157/300 batch  22/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 157/300 batch  23/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 157/300 batch  24/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 157/300 batch  25/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 157/300 batch  26/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 157/300 batch  27/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 157/300 batch  28/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 157/300 batch  29/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 157/300 batch  30/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 157/300 batch  31/188  Train Loss: 0.036, Acc: 0.980\n",
      "epoch: 157/300 batch  32/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 157/300 batch  33/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 157/300 batch  34/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 157/300 batch  35/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 157/300 batch  36/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 157/300 batch  37/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 157/300 batch  38/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 157/300 batch  39/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 157/300 batch  40/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 157/300 batch  41/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 157/300 batch  42/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 157/300 batch  43/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 157/300 batch  44/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 157/300 batch  45/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 157/300 batch  46/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 157/300 batch  47/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 157/300 batch  48/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 157/300 batch  49/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 157/300 batch  50/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 157/300 batch  51/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 157/300 batch  52/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 157/300 batch  53/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 157/300 batch  54/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 157/300 batch  55/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 157/300 batch  56/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 157/300 batch  57/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 157/300 batch  58/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 157/300 batch  59/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 157/300 batch  60/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 157/300 batch  61/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 157/300 batch  62/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 157/300 batch  63/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 157/300 batch  64/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 157/300 batch  65/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 157/300 batch  66/188  Train Loss: 0.074, Acc: 0.977\n",
      "epoch: 157/300 batch  67/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 157/300 batch  68/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 157/300 batch  69/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 157/300 batch  70/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 157/300 batch  71/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 157/300 batch  72/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 157/300 batch  73/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 157/300 batch  74/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 157/300 batch  75/188  Train Loss: 0.068, Acc: 0.977\n",
      "epoch: 157/300 batch  76/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 157/300 batch  77/188  Train Loss: 0.093, Acc: 0.977\n",
      "epoch: 157/300 batch  78/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 157/300 batch  79/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 157/300 batch  80/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 157/300 batch  81/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 157/300 batch  82/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 157/300 batch  83/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 157/300 batch  84/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 157/300 batch  85/188  Train Loss: 0.051, Acc: 0.992\n",
      "epoch: 157/300 batch  86/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 157/300 batch  87/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 157/300 batch  88/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 157/300 batch  89/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 157/300 batch  90/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 157/300 batch  91/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 157/300 batch  92/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 157/300 batch  93/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 157/300 batch  94/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 157/300 batch  95/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 157/300 batch  96/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 157/300 batch  97/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 157/300 batch  98/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 157/300 batch  99/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 157/300 batch 100/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 157/300 batch 101/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 157/300 batch 102/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 157/300 batch 103/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 157/300 batch 104/188  Train Loss: 0.056, Acc: 0.980\n",
      "epoch: 157/300 batch 105/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 157/300 batch 106/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 157/300 batch 107/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 157/300 batch 108/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 157/300 batch 109/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 157/300 batch 110/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 157/300 batch 111/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 157/300 batch 112/188  Train Loss: 0.051, Acc: 0.980\n",
      "epoch: 157/300 batch 113/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 157/300 batch 114/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 157/300 batch 115/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 157/300 batch 116/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 157/300 batch 117/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 157/300 batch 118/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 157/300 batch 119/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 157/300 batch 120/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 157/300 batch 121/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 157/300 batch 122/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 157/300 batch 123/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 157/300 batch 124/188  Train Loss: 0.055, Acc: 0.980\n",
      "epoch: 157/300 batch 125/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 157/300 batch 126/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 157/300 batch 127/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 157/300 batch 128/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 157/300 batch 129/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 157/300 batch 130/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 157/300 batch 131/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 157/300 batch 132/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 157/300 batch 133/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 157/300 batch 134/188  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 157/300 batch 135/188  Train Loss: 0.024, Acc: 0.988\n",
      "epoch: 157/300 batch 136/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 157/300 batch 137/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 157/300 batch 138/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 157/300 batch 139/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 157/300 batch 140/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 157/300 batch 141/188  Train Loss: 0.087, Acc: 0.984\n",
      "epoch: 157/300 batch 142/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 157/300 batch 143/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 157/300 batch 144/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 157/300 batch 145/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 157/300 batch 146/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 157/300 batch 147/188  Train Loss: 0.016, Acc: 0.996\n",
      "epoch: 157/300 batch 148/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 157/300 batch 149/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 157/300 batch 150/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 157/300 batch 151/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 157/300 batch 152/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 157/300 batch 153/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 157/300 batch 154/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 157/300 batch 155/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 157/300 batch 156/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 157/300 batch 157/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 157/300 batch 158/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 157/300 batch 159/188  Train Loss: 0.066, Acc: 0.984\n",
      "epoch: 157/300 batch 160/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 157/300 batch 161/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 157/300 batch 162/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 157/300 batch 163/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 157/300 batch 164/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 157/300 batch 165/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 157/300 batch 166/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 157/300 batch 167/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 157/300 batch 168/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 157/300 batch 169/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 157/300 batch 170/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 157/300 batch 171/188  Train Loss: 0.065, Acc: 0.977\n",
      "epoch: 157/300 batch 172/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 157/300 batch 173/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 157/300 batch 174/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 157/300 batch 175/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 157/300 batch 176/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 157/300 batch 177/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 157/300 batch 178/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 157/300 batch 179/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 157/300 batch 180/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 157/300 batch 181/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 157/300 batch 182/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 157/300 batch 183/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 157/300 batch 184/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 157/300 batch 185/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 157/300 batch 186/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 157/300 batch 187/188  Train Loss: 0.026, Acc: 0.992\n",
      "Train Loss: 0.033910, Acc: 0.992\n",
      "Val Loss: 0.057651, Acc: 0.982\n",
      "epoch: 158/300 batch   0/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 158/300 batch   1/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 158/300 batch   2/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 158/300 batch   3/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 158/300 batch   4/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 158/300 batch   5/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 158/300 batch   6/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 158/300 batch   7/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 158/300 batch   8/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 158/300 batch   9/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 158/300 batch  10/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 158/300 batch  11/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 158/300 batch  12/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 158/300 batch  13/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 158/300 batch  14/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 158/300 batch  15/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 158/300 batch  16/188  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 158/300 batch  17/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 158/300 batch  18/188  Train Loss: 0.042, Acc: 0.996\n",
      "epoch: 158/300 batch  19/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 158/300 batch  20/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 158/300 batch  21/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 158/300 batch  22/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 158/300 batch  23/188  Train Loss: 0.045, Acc: 0.996\n",
      "epoch: 158/300 batch  24/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 158/300 batch  25/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 158/300 batch  26/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 158/300 batch  27/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 158/300 batch  28/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 158/300 batch  29/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 158/300 batch  30/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 158/300 batch  31/188  Train Loss: 0.056, Acc: 0.977\n",
      "epoch: 158/300 batch  32/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 158/300 batch  33/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 158/300 batch  34/188  Train Loss: 0.052, Acc: 0.980\n",
      "epoch: 158/300 batch  35/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 158/300 batch  36/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 158/300 batch  37/188  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 158/300 batch  38/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 158/300 batch  39/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 158/300 batch  40/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 158/300 batch  41/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 158/300 batch  42/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 158/300 batch  43/188  Train Loss: 0.055, Acc: 0.980\n",
      "epoch: 158/300 batch  44/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 158/300 batch  45/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 158/300 batch  46/188  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 158/300 batch  47/188  Train Loss: 0.063, Acc: 0.973\n",
      "epoch: 158/300 batch  48/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 158/300 batch  49/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 158/300 batch  50/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 158/300 batch  51/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 158/300 batch  52/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 158/300 batch  53/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 158/300 batch  54/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 158/300 batch  55/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 158/300 batch  56/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 158/300 batch  57/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 158/300 batch  58/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 158/300 batch  59/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 158/300 batch  60/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 158/300 batch  61/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 158/300 batch  62/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 158/300 batch  63/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 158/300 batch  64/188  Train Loss: 0.069, Acc: 0.977\n",
      "epoch: 158/300 batch  65/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 158/300 batch  66/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 158/300 batch  67/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 158/300 batch  68/188  Train Loss: 0.033, Acc: 0.980\n",
      "epoch: 158/300 batch  69/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 158/300 batch  70/188  Train Loss: 0.030, Acc: 0.984\n",
      "epoch: 158/300 batch  71/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 158/300 batch  72/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 158/300 batch  73/188  Train Loss: 0.051, Acc: 0.980\n",
      "epoch: 158/300 batch  74/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 158/300 batch  75/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 158/300 batch  76/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 158/300 batch  77/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 158/300 batch  78/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 158/300 batch  79/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 158/300 batch  80/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 158/300 batch  81/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 158/300 batch  82/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 158/300 batch  83/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 158/300 batch  84/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 158/300 batch  85/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 158/300 batch  86/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 158/300 batch  87/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 158/300 batch  88/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 158/300 batch  89/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 158/300 batch  90/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 158/300 batch  91/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 158/300 batch  92/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 158/300 batch  93/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 158/300 batch  94/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 158/300 batch  95/188  Train Loss: 0.013, Acc: 0.996\n",
      "epoch: 158/300 batch  96/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 158/300 batch  97/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 158/300 batch  98/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 158/300 batch  99/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 158/300 batch 100/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 158/300 batch 101/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 158/300 batch 102/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 158/300 batch 103/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 158/300 batch 104/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 158/300 batch 105/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 158/300 batch 106/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 158/300 batch 107/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 158/300 batch 108/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 158/300 batch 109/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 158/300 batch 110/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 158/300 batch 111/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 158/300 batch 112/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 158/300 batch 113/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 158/300 batch 114/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 158/300 batch 115/188  Train Loss: 0.061, Acc: 0.980\n",
      "epoch: 158/300 batch 116/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 158/300 batch 117/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 158/300 batch 118/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 158/300 batch 119/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 158/300 batch 120/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 158/300 batch 121/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 158/300 batch 122/188  Train Loss: 0.064, Acc: 0.988\n",
      "epoch: 158/300 batch 123/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 158/300 batch 124/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 158/300 batch 125/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 158/300 batch 126/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 158/300 batch 127/188  Train Loss: 0.052, Acc: 0.980\n",
      "epoch: 158/300 batch 128/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 158/300 batch 129/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 158/300 batch 130/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 158/300 batch 131/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 158/300 batch 132/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 158/300 batch 133/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 158/300 batch 134/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 158/300 batch 135/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 158/300 batch 136/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 158/300 batch 137/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 158/300 batch 138/188  Train Loss: 0.067, Acc: 0.980\n",
      "epoch: 158/300 batch 139/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 158/300 batch 140/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 158/300 batch 141/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 158/300 batch 142/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 158/300 batch 143/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 158/300 batch 144/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 158/300 batch 145/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 158/300 batch 146/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 158/300 batch 147/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 158/300 batch 148/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 158/300 batch 149/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 158/300 batch 150/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 158/300 batch 151/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 158/300 batch 152/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 158/300 batch 153/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 158/300 batch 154/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 158/300 batch 155/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 158/300 batch 156/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 158/300 batch 157/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 158/300 batch 158/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 158/300 batch 159/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 158/300 batch 160/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 158/300 batch 161/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 158/300 batch 162/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 158/300 batch 163/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 158/300 batch 164/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 158/300 batch 165/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 158/300 batch 166/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 158/300 batch 167/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 158/300 batch 168/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 158/300 batch 169/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 158/300 batch 170/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 158/300 batch 171/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 158/300 batch 172/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 158/300 batch 173/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 158/300 batch 174/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 158/300 batch 175/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 158/300 batch 176/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 158/300 batch 177/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 158/300 batch 178/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 158/300 batch 179/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 158/300 batch 180/188  Train Loss: 0.082, Acc: 0.984\n",
      "epoch: 158/300 batch 181/188  Train Loss: 0.046, Acc: 0.980\n",
      "epoch: 158/300 batch 182/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 158/300 batch 183/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 158/300 batch 184/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 158/300 batch 185/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 158/300 batch 186/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 158/300 batch 187/188  Train Loss: 0.031, Acc: 0.992\n",
      "Train Loss: 0.033935, Acc: 0.992\n",
      "Val Loss: 0.057503, Acc: 0.982\n",
      "epoch: 159/300 batch   0/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 159/300 batch   1/188  Train Loss: 0.040, Acc: 0.980\n",
      "epoch: 159/300 batch   2/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 159/300 batch   3/188  Train Loss: 0.062, Acc: 0.984\n",
      "epoch: 159/300 batch   4/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 159/300 batch   5/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 159/300 batch   6/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 159/300 batch   7/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 159/300 batch   8/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 159/300 batch   9/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 159/300 batch  10/188  Train Loss: 0.034, Acc: 0.984\n",
      "epoch: 159/300 batch  11/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 159/300 batch  12/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 159/300 batch  13/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 159/300 batch  14/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 159/300 batch  15/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 159/300 batch  16/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 159/300 batch  17/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 159/300 batch  18/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 159/300 batch  19/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 159/300 batch  20/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 159/300 batch  21/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 159/300 batch  22/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 159/300 batch  23/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 159/300 batch  24/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 159/300 batch  25/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 159/300 batch  26/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 159/300 batch  27/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 159/300 batch  28/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 159/300 batch  29/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 159/300 batch  30/188  Train Loss: 0.040, Acc: 0.980\n",
      "epoch: 159/300 batch  31/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 159/300 batch  32/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 159/300 batch  33/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 159/300 batch  34/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 159/300 batch  35/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 159/300 batch  36/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 159/300 batch  37/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 159/300 batch  38/188  Train Loss: 0.065, Acc: 0.977\n",
      "epoch: 159/300 batch  39/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 159/300 batch  40/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 159/300 batch  41/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 159/300 batch  42/188  Train Loss: 0.064, Acc: 0.984\n",
      "epoch: 159/300 batch  43/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 159/300 batch  44/188  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 159/300 batch  45/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 159/300 batch  46/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 159/300 batch  47/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 159/300 batch  48/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 159/300 batch  49/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 159/300 batch  50/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 159/300 batch  51/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 159/300 batch  52/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 159/300 batch  53/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 159/300 batch  54/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 159/300 batch  55/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 159/300 batch  56/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 159/300 batch  57/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 159/300 batch  58/188  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 159/300 batch  59/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 159/300 batch  60/188  Train Loss: 0.056, Acc: 0.980\n",
      "epoch: 159/300 batch  61/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 159/300 batch  62/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 159/300 batch  63/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 159/300 batch  64/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 159/300 batch  65/188  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 159/300 batch  66/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 159/300 batch  67/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 159/300 batch  68/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 159/300 batch  69/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 159/300 batch  70/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 159/300 batch  71/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 159/300 batch  72/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 159/300 batch  73/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 159/300 batch  74/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 159/300 batch  75/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 159/300 batch  76/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 159/300 batch  77/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 159/300 batch  78/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 159/300 batch  79/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 159/300 batch  80/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 159/300 batch  81/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 159/300 batch  82/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 159/300 batch  83/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 159/300 batch  84/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 159/300 batch  85/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 159/300 batch  86/188  Train Loss: 0.069, Acc: 0.988\n",
      "epoch: 159/300 batch  87/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 159/300 batch  88/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 159/300 batch  89/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 159/300 batch  90/188  Train Loss: 0.044, Acc: 0.996\n",
      "epoch: 159/300 batch  91/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 159/300 batch  92/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 159/300 batch  93/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 159/300 batch  94/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 159/300 batch  95/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 159/300 batch  96/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 159/300 batch  97/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 159/300 batch  98/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 159/300 batch  99/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 159/300 batch 100/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 159/300 batch 101/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 159/300 batch 102/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 159/300 batch 103/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 159/300 batch 104/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 159/300 batch 105/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 159/300 batch 106/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 159/300 batch 107/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 159/300 batch 108/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 159/300 batch 109/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 159/300 batch 110/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 159/300 batch 111/188  Train Loss: 0.060, Acc: 0.988\n",
      "epoch: 159/300 batch 112/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 159/300 batch 113/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 159/300 batch 114/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 159/300 batch 115/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 159/300 batch 116/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 159/300 batch 117/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 159/300 batch 118/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 159/300 batch 119/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 159/300 batch 120/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 159/300 batch 121/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 159/300 batch 122/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 159/300 batch 123/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 159/300 batch 124/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 159/300 batch 125/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 159/300 batch 126/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 159/300 batch 127/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 159/300 batch 128/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 159/300 batch 129/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 159/300 batch 130/188  Train Loss: 0.074, Acc: 0.980\n",
      "epoch: 159/300 batch 131/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 159/300 batch 132/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 159/300 batch 133/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 159/300 batch 134/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 159/300 batch 135/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 159/300 batch 136/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 159/300 batch 137/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 159/300 batch 138/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 159/300 batch 139/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 159/300 batch 140/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 159/300 batch 141/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 159/300 batch 142/188  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 159/300 batch 143/188  Train Loss: 0.015, Acc: 0.996\n",
      "epoch: 159/300 batch 144/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 159/300 batch 145/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 159/300 batch 146/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 159/300 batch 147/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 159/300 batch 148/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 159/300 batch 149/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 159/300 batch 150/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 159/300 batch 151/188  Train Loss: 0.082, Acc: 0.992\n",
      "epoch: 159/300 batch 152/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 159/300 batch 153/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 159/300 batch 154/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 159/300 batch 155/188  Train Loss: 0.054, Acc: 0.980\n",
      "epoch: 159/300 batch 156/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 159/300 batch 157/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 159/300 batch 158/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 159/300 batch 159/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 159/300 batch 160/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 159/300 batch 161/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 159/300 batch 162/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 159/300 batch 163/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 159/300 batch 164/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 159/300 batch 165/188  Train Loss: 0.025, Acc: 0.988\n",
      "epoch: 159/300 batch 166/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 159/300 batch 167/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 159/300 batch 168/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 159/300 batch 169/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 159/300 batch 170/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 159/300 batch 171/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 159/300 batch 172/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 159/300 batch 173/188  Train Loss: 0.067, Acc: 0.988\n",
      "epoch: 159/300 batch 174/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 159/300 batch 175/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 159/300 batch 176/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 159/300 batch 177/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 159/300 batch 178/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 159/300 batch 179/188  Train Loss: 0.031, Acc: 1.000\n",
      "epoch: 159/300 batch 180/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 159/300 batch 181/188  Train Loss: 0.044, Acc: 0.980\n",
      "epoch: 159/300 batch 182/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 159/300 batch 183/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 159/300 batch 184/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 159/300 batch 185/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 159/300 batch 186/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 159/300 batch 187/188  Train Loss: 0.050, Acc: 0.977\n",
      "Train Loss: 0.033876, Acc: 0.993\n",
      "Val Loss: 0.057581, Acc: 0.983\n",
      "epoch: 160/300 batch   0/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 160/300 batch   1/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 160/300 batch   2/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 160/300 batch   3/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 160/300 batch   4/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 160/300 batch   5/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 160/300 batch   6/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 160/300 batch   7/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 160/300 batch   8/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 160/300 batch   9/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 160/300 batch  10/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 160/300 batch  11/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 160/300 batch  12/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 160/300 batch  13/188  Train Loss: 0.029, Acc: 0.984\n",
      "epoch: 160/300 batch  14/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 160/300 batch  15/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 160/300 batch  16/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 160/300 batch  17/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 160/300 batch  18/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 160/300 batch  19/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 160/300 batch  20/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 160/300 batch  21/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 160/300 batch  22/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 160/300 batch  23/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 160/300 batch  24/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 160/300 batch  25/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 160/300 batch  26/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 160/300 batch  27/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 160/300 batch  28/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 160/300 batch  29/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 160/300 batch  30/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 160/300 batch  31/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 160/300 batch  32/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 160/300 batch  33/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 160/300 batch  34/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 160/300 batch  35/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 160/300 batch  36/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 160/300 batch  37/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 160/300 batch  38/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 160/300 batch  39/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 160/300 batch  40/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 160/300 batch  41/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 160/300 batch  42/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 160/300 batch  43/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 160/300 batch  44/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 160/300 batch  45/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 160/300 batch  46/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 160/300 batch  47/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 160/300 batch  48/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 160/300 batch  49/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 160/300 batch  50/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 160/300 batch  51/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 160/300 batch  52/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 160/300 batch  53/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 160/300 batch  54/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 160/300 batch  55/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 160/300 batch  56/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 160/300 batch  57/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 160/300 batch  58/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 160/300 batch  59/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 160/300 batch  60/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 160/300 batch  61/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 160/300 batch  62/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 160/300 batch  63/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 160/300 batch  64/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 160/300 batch  65/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 160/300 batch  66/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 160/300 batch  67/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 160/300 batch  68/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 160/300 batch  69/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 160/300 batch  70/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 160/300 batch  71/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 160/300 batch  72/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 160/300 batch  73/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 160/300 batch  74/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 160/300 batch  75/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 160/300 batch  76/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 160/300 batch  77/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 160/300 batch  78/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 160/300 batch  79/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 160/300 batch  80/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 160/300 batch  81/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 160/300 batch  82/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 160/300 batch  83/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 160/300 batch  84/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 160/300 batch  85/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 160/300 batch  86/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 160/300 batch  87/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 160/300 batch  88/188  Train Loss: 0.082, Acc: 0.988\n",
      "epoch: 160/300 batch  89/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 160/300 batch  90/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 160/300 batch  91/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 160/300 batch  92/188  Train Loss: 0.038, Acc: 0.980\n",
      "epoch: 160/300 batch  93/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 160/300 batch  94/188  Train Loss: 0.016, Acc: 0.996\n",
      "epoch: 160/300 batch  95/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 160/300 batch  96/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 160/300 batch  97/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 160/300 batch  98/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 160/300 batch  99/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 160/300 batch 100/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 160/300 batch 101/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 160/300 batch 102/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 160/300 batch 103/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 160/300 batch 104/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 160/300 batch 105/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 160/300 batch 106/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 160/300 batch 107/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 160/300 batch 108/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 160/300 batch 109/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 160/300 batch 110/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 160/300 batch 111/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 160/300 batch 112/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 160/300 batch 113/188  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 160/300 batch 114/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 160/300 batch 115/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 160/300 batch 116/188  Train Loss: 0.034, Acc: 0.984\n",
      "epoch: 160/300 batch 117/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 160/300 batch 118/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 160/300 batch 119/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 160/300 batch 120/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 160/300 batch 121/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 160/300 batch 122/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 160/300 batch 123/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 160/300 batch 124/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 160/300 batch 125/188  Train Loss: 0.057, Acc: 0.988\n",
      "epoch: 160/300 batch 126/188  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 160/300 batch 127/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 160/300 batch 128/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 160/300 batch 129/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 160/300 batch 130/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 160/300 batch 131/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 160/300 batch 132/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 160/300 batch 133/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 160/300 batch 134/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 160/300 batch 135/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 160/300 batch 136/188  Train Loss: 0.070, Acc: 0.980\n",
      "epoch: 160/300 batch 137/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 160/300 batch 138/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 160/300 batch 139/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 160/300 batch 140/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 160/300 batch 141/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 160/300 batch 142/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 160/300 batch 143/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 160/300 batch 144/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 160/300 batch 145/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 160/300 batch 146/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 160/300 batch 147/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 160/300 batch 148/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 160/300 batch 149/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 160/300 batch 150/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 160/300 batch 151/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 160/300 batch 152/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 160/300 batch 153/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 160/300 batch 154/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 160/300 batch 155/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 160/300 batch 156/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 160/300 batch 157/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 160/300 batch 158/188  Train Loss: 0.062, Acc: 0.984\n",
      "epoch: 160/300 batch 159/188  Train Loss: 0.066, Acc: 0.980\n",
      "epoch: 160/300 batch 160/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 160/300 batch 161/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 160/300 batch 162/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 160/300 batch 163/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 160/300 batch 164/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 160/300 batch 165/188  Train Loss: 0.033, Acc: 0.984\n",
      "epoch: 160/300 batch 166/188  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 160/300 batch 167/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 160/300 batch 168/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 160/300 batch 169/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 160/300 batch 170/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 160/300 batch 171/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 160/300 batch 172/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 160/300 batch 173/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 160/300 batch 174/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 160/300 batch 175/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 160/300 batch 176/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 160/300 batch 177/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 160/300 batch 178/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 160/300 batch 179/188  Train Loss: 0.072, Acc: 0.980\n",
      "epoch: 160/300 batch 180/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 160/300 batch 181/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 160/300 batch 182/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 160/300 batch 183/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 160/300 batch 184/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 160/300 batch 185/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 160/300 batch 186/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 160/300 batch 187/188  Train Loss: 0.038, Acc: 0.984\n",
      "Train Loss: 0.033916, Acc: 0.993\n",
      "Val Loss: 0.057413, Acc: 0.982\n",
      "epoch: 161/300 batch   0/188  Train Loss: 0.045, Acc: 0.980\n",
      "epoch: 161/300 batch   1/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 161/300 batch   2/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 161/300 batch   3/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 161/300 batch   4/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 161/300 batch   5/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 161/300 batch   6/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 161/300 batch   7/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 161/300 batch   8/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 161/300 batch   9/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 161/300 batch  10/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 161/300 batch  11/188  Train Loss: 0.065, Acc: 0.977\n",
      "epoch: 161/300 batch  12/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 161/300 batch  13/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 161/300 batch  14/188  Train Loss: 0.027, Acc: 0.988\n",
      "epoch: 161/300 batch  15/188  Train Loss: 0.051, Acc: 0.992\n",
      "epoch: 161/300 batch  16/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 161/300 batch  17/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 161/300 batch  18/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 161/300 batch  19/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 161/300 batch  20/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 161/300 batch  21/188  Train Loss: 0.053, Acc: 0.992\n",
      "epoch: 161/300 batch  22/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 161/300 batch  23/188  Train Loss: 0.067, Acc: 0.980\n",
      "epoch: 161/300 batch  24/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 161/300 batch  25/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 161/300 batch  26/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 161/300 batch  27/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 161/300 batch  28/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 161/300 batch  29/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 161/300 batch  30/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 161/300 batch  31/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 161/300 batch  32/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 161/300 batch  33/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 161/300 batch  34/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 161/300 batch  35/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 161/300 batch  36/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 161/300 batch  37/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 161/300 batch  38/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 161/300 batch  39/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 161/300 batch  40/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 161/300 batch  41/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 161/300 batch  42/188  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 161/300 batch  43/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 161/300 batch  44/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 161/300 batch  45/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 161/300 batch  46/188  Train Loss: 0.072, Acc: 0.977\n",
      "epoch: 161/300 batch  47/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 161/300 batch  48/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 161/300 batch  49/188  Train Loss: 0.048, Acc: 0.996\n",
      "epoch: 161/300 batch  50/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 161/300 batch  51/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 161/300 batch  52/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 161/300 batch  53/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 161/300 batch  54/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 161/300 batch  55/188  Train Loss: 0.095, Acc: 0.980\n",
      "epoch: 161/300 batch  56/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 161/300 batch  57/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 161/300 batch  58/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 161/300 batch  59/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 161/300 batch  60/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 161/300 batch  61/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 161/300 batch  62/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 161/300 batch  63/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 161/300 batch  64/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 161/300 batch  65/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 161/300 batch  66/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 161/300 batch  67/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 161/300 batch  68/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 161/300 batch  69/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 161/300 batch  70/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 161/300 batch  71/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 161/300 batch  72/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 161/300 batch  73/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 161/300 batch  74/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 161/300 batch  75/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 161/300 batch  76/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 161/300 batch  77/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 161/300 batch  78/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 161/300 batch  79/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 161/300 batch  80/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 161/300 batch  81/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 161/300 batch  82/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 161/300 batch  83/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 161/300 batch  84/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 161/300 batch  85/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 161/300 batch  86/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 161/300 batch  87/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 161/300 batch  88/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 161/300 batch  89/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 161/300 batch  90/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 161/300 batch  91/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 161/300 batch  92/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 161/300 batch  93/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 161/300 batch  94/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 161/300 batch  95/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 161/300 batch  96/188  Train Loss: 0.068, Acc: 0.988\n",
      "epoch: 161/300 batch  97/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 161/300 batch  98/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 161/300 batch  99/188  Train Loss: 0.035, Acc: 1.000\n",
      "epoch: 161/300 batch 100/188  Train Loss: 0.023, Acc: 0.988\n",
      "epoch: 161/300 batch 101/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 161/300 batch 102/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 161/300 batch 103/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 161/300 batch 104/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 161/300 batch 105/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 161/300 batch 106/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 161/300 batch 107/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 161/300 batch 108/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 161/300 batch 109/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 161/300 batch 110/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 161/300 batch 111/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 161/300 batch 112/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 161/300 batch 113/188  Train Loss: 0.047, Acc: 0.980\n",
      "epoch: 161/300 batch 114/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 161/300 batch 115/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 161/300 batch 116/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 161/300 batch 117/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 161/300 batch 118/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 161/300 batch 119/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 161/300 batch 120/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 161/300 batch 121/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 161/300 batch 122/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 161/300 batch 123/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 161/300 batch 124/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 161/300 batch 125/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 161/300 batch 126/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 161/300 batch 127/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 161/300 batch 128/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 161/300 batch 129/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 161/300 batch 130/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 161/300 batch 131/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 161/300 batch 132/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 161/300 batch 133/188  Train Loss: 0.073, Acc: 0.984\n",
      "epoch: 161/300 batch 134/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 161/300 batch 135/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 161/300 batch 136/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 161/300 batch 137/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 161/300 batch 138/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 161/300 batch 139/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 161/300 batch 140/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 161/300 batch 141/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 161/300 batch 142/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 161/300 batch 143/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 161/300 batch 144/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 161/300 batch 145/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 161/300 batch 146/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 161/300 batch 147/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 161/300 batch 148/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 161/300 batch 149/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 161/300 batch 150/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 161/300 batch 151/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 161/300 batch 152/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 161/300 batch 153/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 161/300 batch 154/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 161/300 batch 155/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 161/300 batch 156/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 161/300 batch 157/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 161/300 batch 158/188  Train Loss: 0.033, Acc: 1.000\n",
      "epoch: 161/300 batch 159/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 161/300 batch 160/188  Train Loss: 0.055, Acc: 0.980\n",
      "epoch: 161/300 batch 161/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 161/300 batch 162/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 161/300 batch 163/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 161/300 batch 164/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 161/300 batch 165/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 161/300 batch 166/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 161/300 batch 167/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 161/300 batch 168/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 161/300 batch 169/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 161/300 batch 170/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 161/300 batch 171/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 161/300 batch 172/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 161/300 batch 173/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 161/300 batch 174/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 161/300 batch 175/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 161/300 batch 176/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 161/300 batch 177/188  Train Loss: 0.053, Acc: 0.977\n",
      "epoch: 161/300 batch 178/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 161/300 batch 179/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 161/300 batch 180/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 161/300 batch 181/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 161/300 batch 182/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 161/300 batch 183/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 161/300 batch 184/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 161/300 batch 185/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 161/300 batch 186/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 161/300 batch 187/188  Train Loss: 0.058, Acc: 0.984\n",
      "Train Loss: 0.033991, Acc: 0.993\n",
      "Val Loss: 0.057213, Acc: 0.983\n",
      "epoch: 162/300 batch   0/188  Train Loss: 0.059, Acc: 0.984\n",
      "epoch: 162/300 batch   1/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 162/300 batch   2/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 162/300 batch   3/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 162/300 batch   4/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 162/300 batch   5/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 162/300 batch   6/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 162/300 batch   7/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 162/300 batch   8/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 162/300 batch   9/188  Train Loss: 0.033, Acc: 1.000\n",
      "epoch: 162/300 batch  10/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 162/300 batch  11/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 162/300 batch  12/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 162/300 batch  13/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 162/300 batch  14/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 162/300 batch  15/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 162/300 batch  16/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 162/300 batch  17/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 162/300 batch  18/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 162/300 batch  19/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 162/300 batch  20/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 162/300 batch  21/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 162/300 batch  22/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 162/300 batch  23/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 162/300 batch  24/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 162/300 batch  25/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 162/300 batch  26/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 162/300 batch  27/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 162/300 batch  28/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 162/300 batch  29/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 162/300 batch  30/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 162/300 batch  31/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 162/300 batch  32/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 162/300 batch  33/188  Train Loss: 0.042, Acc: 0.980\n",
      "epoch: 162/300 batch  34/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 162/300 batch  35/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 162/300 batch  36/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 162/300 batch  37/188  Train Loss: 0.054, Acc: 0.980\n",
      "epoch: 162/300 batch  38/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 162/300 batch  39/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 162/300 batch  40/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 162/300 batch  41/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 162/300 batch  42/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 162/300 batch  43/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 162/300 batch  44/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 162/300 batch  45/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 162/300 batch  46/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 162/300 batch  47/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 162/300 batch  48/188  Train Loss: 0.053, Acc: 0.992\n",
      "epoch: 162/300 batch  49/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 162/300 batch  50/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 162/300 batch  51/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 162/300 batch  52/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 162/300 batch  53/188  Train Loss: 0.063, Acc: 0.984\n",
      "epoch: 162/300 batch  54/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 162/300 batch  55/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 162/300 batch  56/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 162/300 batch  57/188  Train Loss: 0.052, Acc: 0.980\n",
      "epoch: 162/300 batch  58/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 162/300 batch  59/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 162/300 batch  60/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 162/300 batch  61/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 162/300 batch  62/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 162/300 batch  63/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 162/300 batch  64/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 162/300 batch  65/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 162/300 batch  66/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 162/300 batch  67/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 162/300 batch  68/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 162/300 batch  69/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 162/300 batch  70/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 162/300 batch  71/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 162/300 batch  72/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 162/300 batch  73/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 162/300 batch  74/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 162/300 batch  75/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 162/300 batch  76/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 162/300 batch  77/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 162/300 batch  78/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 162/300 batch  79/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 162/300 batch  80/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 162/300 batch  81/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 162/300 batch  82/188  Train Loss: 0.091, Acc: 0.980\n",
      "epoch: 162/300 batch  83/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 162/300 batch  84/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 162/300 batch  85/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 162/300 batch  86/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 162/300 batch  87/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 162/300 batch  88/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 162/300 batch  89/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 162/300 batch  90/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 162/300 batch  91/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 162/300 batch  92/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 162/300 batch  93/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 162/300 batch  94/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 162/300 batch  95/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 162/300 batch  96/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 162/300 batch  97/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 162/300 batch  98/188  Train Loss: 0.061, Acc: 0.980\n",
      "epoch: 162/300 batch  99/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 162/300 batch 100/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 162/300 batch 101/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 162/300 batch 102/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 162/300 batch 103/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 162/300 batch 104/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 162/300 batch 105/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 162/300 batch 106/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 162/300 batch 107/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 162/300 batch 108/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 162/300 batch 109/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 162/300 batch 110/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 162/300 batch 111/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 162/300 batch 112/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 162/300 batch 113/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 162/300 batch 114/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 162/300 batch 115/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 162/300 batch 116/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 162/300 batch 117/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 162/300 batch 118/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 162/300 batch 119/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 162/300 batch 120/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 162/300 batch 121/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 162/300 batch 122/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 162/300 batch 123/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 162/300 batch 124/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 162/300 batch 125/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 162/300 batch 126/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 162/300 batch 127/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 162/300 batch 128/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 162/300 batch 129/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 162/300 batch 130/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 162/300 batch 131/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 162/300 batch 132/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 162/300 batch 133/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 162/300 batch 134/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 162/300 batch 135/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 162/300 batch 136/188  Train Loss: 0.051, Acc: 0.980\n",
      "epoch: 162/300 batch 137/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 162/300 batch 138/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 162/300 batch 139/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 162/300 batch 140/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 162/300 batch 141/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 162/300 batch 142/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 162/300 batch 143/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 162/300 batch 144/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 162/300 batch 145/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 162/300 batch 146/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 162/300 batch 147/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 162/300 batch 148/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 162/300 batch 149/188  Train Loss: 0.062, Acc: 0.980\n",
      "epoch: 162/300 batch 150/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 162/300 batch 151/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 162/300 batch 152/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 162/300 batch 153/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 162/300 batch 154/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 162/300 batch 155/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 162/300 batch 156/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 162/300 batch 157/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 162/300 batch 158/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 162/300 batch 159/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 162/300 batch 160/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 162/300 batch 161/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 162/300 batch 162/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 162/300 batch 163/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 162/300 batch 164/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 162/300 batch 165/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 162/300 batch 166/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 162/300 batch 167/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 162/300 batch 168/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 162/300 batch 169/188  Train Loss: 0.060, Acc: 0.984\n",
      "epoch: 162/300 batch 170/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 162/300 batch 171/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 162/300 batch 172/188  Train Loss: 0.051, Acc: 0.992\n",
      "epoch: 162/300 batch 173/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 162/300 batch 174/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 162/300 batch 175/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 162/300 batch 176/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 162/300 batch 177/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 162/300 batch 178/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 162/300 batch 179/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 162/300 batch 180/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 162/300 batch 181/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 162/300 batch 182/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 162/300 batch 183/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 162/300 batch 184/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 162/300 batch 185/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 162/300 batch 186/188  Train Loss: 0.052, Acc: 0.980\n",
      "epoch: 162/300 batch 187/188  Train Loss: 0.019, Acc: 1.000\n",
      "Train Loss: 0.033804, Acc: 0.993\n",
      "Val Loss: 0.057641, Acc: 0.982\n",
      "epoch: 163/300 batch   0/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 163/300 batch   1/188  Train Loss: 0.052, Acc: 0.980\n",
      "epoch: 163/300 batch   2/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 163/300 batch   3/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 163/300 batch   4/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 163/300 batch   5/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 163/300 batch   6/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 163/300 batch   7/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 163/300 batch   8/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 163/300 batch   9/188  Train Loss: 0.046, Acc: 0.980\n",
      "epoch: 163/300 batch  10/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 163/300 batch  11/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 163/300 batch  12/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 163/300 batch  13/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 163/300 batch  14/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 163/300 batch  15/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 163/300 batch  16/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 163/300 batch  17/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 163/300 batch  18/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 163/300 batch  19/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 163/300 batch  20/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 163/300 batch  21/188  Train Loss: 0.074, Acc: 0.984\n",
      "epoch: 163/300 batch  22/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 163/300 batch  23/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 163/300 batch  24/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 163/300 batch  25/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 163/300 batch  26/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 163/300 batch  27/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 163/300 batch  28/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 163/300 batch  29/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 163/300 batch  30/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 163/300 batch  31/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 163/300 batch  32/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 163/300 batch  33/188  Train Loss: 0.057, Acc: 0.988\n",
      "epoch: 163/300 batch  34/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 163/300 batch  35/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 163/300 batch  36/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 163/300 batch  37/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 163/300 batch  38/188  Train Loss: 0.053, Acc: 0.977\n",
      "epoch: 163/300 batch  39/188  Train Loss: 0.050, Acc: 0.977\n",
      "epoch: 163/300 batch  40/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 163/300 batch  41/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 163/300 batch  42/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 163/300 batch  43/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 163/300 batch  44/188  Train Loss: 0.044, Acc: 1.000\n",
      "epoch: 163/300 batch  45/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 163/300 batch  46/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 163/300 batch  47/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 163/300 batch  48/188  Train Loss: 0.056, Acc: 0.992\n",
      "epoch: 163/300 batch  49/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 163/300 batch  50/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 163/300 batch  51/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 163/300 batch  52/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 163/300 batch  53/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 163/300 batch  54/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 163/300 batch  55/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 163/300 batch  56/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 163/300 batch  57/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 163/300 batch  58/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 163/300 batch  59/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 163/300 batch  60/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 163/300 batch  61/188  Train Loss: 0.045, Acc: 0.996\n",
      "epoch: 163/300 batch  62/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 163/300 batch  63/188  Train Loss: 0.046, Acc: 0.996\n",
      "epoch: 163/300 batch  64/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 163/300 batch  65/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 163/300 batch  66/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 163/300 batch  67/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 163/300 batch  68/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 163/300 batch  69/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 163/300 batch  70/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 163/300 batch  71/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 163/300 batch  72/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 163/300 batch  73/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 163/300 batch  74/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 163/300 batch  75/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 163/300 batch  76/188  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 163/300 batch  77/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 163/300 batch  78/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 163/300 batch  79/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 163/300 batch  80/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 163/300 batch  81/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 163/300 batch  82/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 163/300 batch  83/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 163/300 batch  84/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 163/300 batch  85/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 163/300 batch  86/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 163/300 batch  87/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 163/300 batch  88/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 163/300 batch  89/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 163/300 batch  90/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 163/300 batch  91/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 163/300 batch  92/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 163/300 batch  93/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 163/300 batch  94/188  Train Loss: 0.034, Acc: 0.984\n",
      "epoch: 163/300 batch  95/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 163/300 batch  96/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 163/300 batch  97/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 163/300 batch  98/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 163/300 batch  99/188  Train Loss: 0.056, Acc: 0.988\n",
      "epoch: 163/300 batch 100/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 163/300 batch 101/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 163/300 batch 102/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 163/300 batch 103/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 163/300 batch 104/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 163/300 batch 105/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 163/300 batch 106/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 163/300 batch 107/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 163/300 batch 108/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 163/300 batch 109/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 163/300 batch 110/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 163/300 batch 111/188  Train Loss: 0.057, Acc: 0.988\n",
      "epoch: 163/300 batch 112/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 163/300 batch 113/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 163/300 batch 114/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 163/300 batch 115/188  Train Loss: 0.051, Acc: 0.980\n",
      "epoch: 163/300 batch 116/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 163/300 batch 117/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 163/300 batch 118/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 163/300 batch 119/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 163/300 batch 120/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 163/300 batch 121/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 163/300 batch 122/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 163/300 batch 123/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 163/300 batch 124/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 163/300 batch 125/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 163/300 batch 126/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 163/300 batch 127/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 163/300 batch 128/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 163/300 batch 129/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 163/300 batch 130/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 163/300 batch 131/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 163/300 batch 132/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 163/300 batch 133/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 163/300 batch 134/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 163/300 batch 135/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 163/300 batch 136/188  Train Loss: 0.075, Acc: 0.984\n",
      "epoch: 163/300 batch 137/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 163/300 batch 138/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 163/300 batch 139/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 163/300 batch 140/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 163/300 batch 141/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 163/300 batch 142/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 163/300 batch 143/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 163/300 batch 144/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 163/300 batch 145/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 163/300 batch 146/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 163/300 batch 147/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 163/300 batch 148/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 163/300 batch 149/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 163/300 batch 150/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 163/300 batch 151/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 163/300 batch 152/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 163/300 batch 153/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 163/300 batch 154/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 163/300 batch 155/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 163/300 batch 156/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 163/300 batch 157/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 163/300 batch 158/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 163/300 batch 159/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 163/300 batch 160/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 163/300 batch 161/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 163/300 batch 162/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 163/300 batch 163/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 163/300 batch 164/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 163/300 batch 165/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 163/300 batch 166/188  Train Loss: 0.049, Acc: 0.980\n",
      "epoch: 163/300 batch 167/188  Train Loss: 0.032, Acc: 0.984\n",
      "epoch: 163/300 batch 168/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 163/300 batch 169/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 163/300 batch 170/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 163/300 batch 171/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 163/300 batch 172/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 163/300 batch 173/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 163/300 batch 174/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 163/300 batch 175/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 163/300 batch 176/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 163/300 batch 177/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 163/300 batch 178/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 163/300 batch 179/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 163/300 batch 180/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 163/300 batch 181/188  Train Loss: 0.057, Acc: 0.977\n",
      "epoch: 163/300 batch 182/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 163/300 batch 183/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 163/300 batch 184/188  Train Loss: 0.059, Acc: 0.984\n",
      "epoch: 163/300 batch 185/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 163/300 batch 186/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 163/300 batch 187/188  Train Loss: 0.028, Acc: 0.992\n",
      "Train Loss: 0.033845, Acc: 0.993\n",
      "Val Loss: 0.057414, Acc: 0.983\n",
      "epoch: 164/300 batch   0/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 164/300 batch   1/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 164/300 batch   2/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 164/300 batch   3/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 164/300 batch   4/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 164/300 batch   5/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 164/300 batch   6/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 164/300 batch   7/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 164/300 batch   8/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 164/300 batch   9/188  Train Loss: 0.067, Acc: 0.984\n",
      "epoch: 164/300 batch  10/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 164/300 batch  11/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 164/300 batch  12/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 164/300 batch  13/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 164/300 batch  14/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 164/300 batch  15/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 164/300 batch  16/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 164/300 batch  17/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 164/300 batch  18/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 164/300 batch  19/188  Train Loss: 0.053, Acc: 0.992\n",
      "epoch: 164/300 batch  20/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 164/300 batch  21/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 164/300 batch  22/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 164/300 batch  23/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 164/300 batch  24/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 164/300 batch  25/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 164/300 batch  26/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 164/300 batch  27/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 164/300 batch  28/188  Train Loss: 0.045, Acc: 0.980\n",
      "epoch: 164/300 batch  29/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 164/300 batch  30/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 164/300 batch  31/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 164/300 batch  32/188  Train Loss: 0.050, Acc: 0.980\n",
      "epoch: 164/300 batch  33/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 164/300 batch  34/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 164/300 batch  35/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 164/300 batch  36/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 164/300 batch  37/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 164/300 batch  38/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 164/300 batch  39/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 164/300 batch  40/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 164/300 batch  41/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 164/300 batch  42/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 164/300 batch  43/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 164/300 batch  44/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 164/300 batch  45/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 164/300 batch  46/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 164/300 batch  47/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 164/300 batch  48/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 164/300 batch  49/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 164/300 batch  50/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 164/300 batch  51/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 164/300 batch  52/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 164/300 batch  53/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 164/300 batch  54/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 164/300 batch  55/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 164/300 batch  56/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 164/300 batch  57/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 164/300 batch  58/188  Train Loss: 0.079, Acc: 0.980\n",
      "epoch: 164/300 batch  59/188  Train Loss: 0.054, Acc: 0.977\n",
      "epoch: 164/300 batch  60/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 164/300 batch  61/188  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 164/300 batch  62/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 164/300 batch  63/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 164/300 batch  64/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 164/300 batch  65/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 164/300 batch  66/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 164/300 batch  67/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 164/300 batch  68/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 164/300 batch  69/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 164/300 batch  70/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 164/300 batch  71/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 164/300 batch  72/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 164/300 batch  73/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 164/300 batch  74/188  Train Loss: 0.052, Acc: 0.980\n",
      "epoch: 164/300 batch  75/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 164/300 batch  76/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 164/300 batch  77/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 164/300 batch  78/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 164/300 batch  79/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 164/300 batch  80/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 164/300 batch  81/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 164/300 batch  82/188  Train Loss: 0.066, Acc: 0.980\n",
      "epoch: 164/300 batch  83/188  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 164/300 batch  84/188  Train Loss: 0.052, Acc: 0.977\n",
      "epoch: 164/300 batch  85/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 164/300 batch  86/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 164/300 batch  87/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 164/300 batch  88/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 164/300 batch  89/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 164/300 batch  90/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 164/300 batch  91/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 164/300 batch  92/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 164/300 batch  93/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 164/300 batch  94/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 164/300 batch  95/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 164/300 batch  96/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 164/300 batch  97/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 164/300 batch  98/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 164/300 batch  99/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 164/300 batch 100/188  Train Loss: 0.069, Acc: 0.984\n",
      "epoch: 164/300 batch 101/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 164/300 batch 102/188  Train Loss: 0.042, Acc: 0.996\n",
      "epoch: 164/300 batch 103/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 164/300 batch 104/188  Train Loss: 0.057, Acc: 0.980\n",
      "epoch: 164/300 batch 105/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 164/300 batch 106/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 164/300 batch 107/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 164/300 batch 108/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 164/300 batch 109/188  Train Loss: 0.074, Acc: 0.980\n",
      "epoch: 164/300 batch 110/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 164/300 batch 111/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 164/300 batch 112/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 164/300 batch 113/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 164/300 batch 114/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 164/300 batch 115/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 164/300 batch 116/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 164/300 batch 117/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 164/300 batch 118/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 164/300 batch 119/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 164/300 batch 120/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 164/300 batch 121/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 164/300 batch 122/188  Train Loss: 0.055, Acc: 0.977\n",
      "epoch: 164/300 batch 123/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 164/300 batch 124/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 164/300 batch 125/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 164/300 batch 126/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 164/300 batch 127/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 164/300 batch 128/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 164/300 batch 129/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 164/300 batch 130/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 164/300 batch 131/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 164/300 batch 132/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 164/300 batch 133/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 164/300 batch 134/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 164/300 batch 135/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 164/300 batch 136/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 164/300 batch 137/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 164/300 batch 138/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 164/300 batch 139/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 164/300 batch 140/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 164/300 batch 141/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 164/300 batch 142/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 164/300 batch 143/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 164/300 batch 144/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 164/300 batch 145/188  Train Loss: 0.058, Acc: 0.988\n",
      "epoch: 164/300 batch 146/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 164/300 batch 147/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 164/300 batch 148/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 164/300 batch 149/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 164/300 batch 150/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 164/300 batch 151/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 164/300 batch 152/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 164/300 batch 153/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 164/300 batch 154/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 164/300 batch 155/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 164/300 batch 156/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 164/300 batch 157/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 164/300 batch 158/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 164/300 batch 159/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 164/300 batch 160/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 164/300 batch 161/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 164/300 batch 162/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 164/300 batch 163/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 164/300 batch 164/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 164/300 batch 165/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 164/300 batch 166/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 164/300 batch 167/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 164/300 batch 168/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 164/300 batch 169/188  Train Loss: 0.069, Acc: 0.992\n",
      "epoch: 164/300 batch 170/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 164/300 batch 171/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 164/300 batch 172/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 164/300 batch 173/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 164/300 batch 174/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 164/300 batch 175/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 164/300 batch 176/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 164/300 batch 177/188  Train Loss: 0.061, Acc: 0.980\n",
      "epoch: 164/300 batch 178/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 164/300 batch 179/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 164/300 batch 180/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 164/300 batch 181/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 164/300 batch 182/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 164/300 batch 183/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 164/300 batch 184/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 164/300 batch 185/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 164/300 batch 186/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 164/300 batch 187/188  Train Loss: 0.023, Acc: 0.992\n",
      "Train Loss: 0.033766, Acc: 0.993\n",
      "Val Loss: 0.057546, Acc: 0.982\n",
      "epoch: 165/300 batch   0/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 165/300 batch   1/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 165/300 batch   2/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 165/300 batch   3/188  Train Loss: 0.054, Acc: 0.992\n",
      "epoch: 165/300 batch   4/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 165/300 batch   5/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 165/300 batch   6/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 165/300 batch   7/188  Train Loss: 0.040, Acc: 0.980\n",
      "epoch: 165/300 batch   8/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 165/300 batch   9/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 165/300 batch  10/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 165/300 batch  11/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 165/300 batch  12/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 165/300 batch  13/188  Train Loss: 0.052, Acc: 0.980\n",
      "epoch: 165/300 batch  14/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 165/300 batch  15/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 165/300 batch  16/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 165/300 batch  17/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 165/300 batch  18/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 165/300 batch  19/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 165/300 batch  20/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 165/300 batch  21/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 165/300 batch  22/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 165/300 batch  23/188  Train Loss: 0.056, Acc: 0.977\n",
      "epoch: 165/300 batch  24/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 165/300 batch  25/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 165/300 batch  26/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 165/300 batch  27/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 165/300 batch  28/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 165/300 batch  29/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 165/300 batch  30/188  Train Loss: 0.058, Acc: 0.980\n",
      "epoch: 165/300 batch  31/188  Train Loss: 0.047, Acc: 0.980\n",
      "epoch: 165/300 batch  32/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 165/300 batch  33/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 165/300 batch  34/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 165/300 batch  35/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 165/300 batch  36/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 165/300 batch  37/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 165/300 batch  38/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 165/300 batch  39/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 165/300 batch  40/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 165/300 batch  41/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 165/300 batch  42/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 165/300 batch  43/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 165/300 batch  44/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 165/300 batch  45/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 165/300 batch  46/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 165/300 batch  47/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 165/300 batch  48/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 165/300 batch  49/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 165/300 batch  50/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 165/300 batch  51/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 165/300 batch  52/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 165/300 batch  53/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 165/300 batch  54/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 165/300 batch  55/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 165/300 batch  56/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 165/300 batch  57/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 165/300 batch  58/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 165/300 batch  59/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 165/300 batch  60/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 165/300 batch  61/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 165/300 batch  62/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 165/300 batch  63/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 165/300 batch  64/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 165/300 batch  65/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 165/300 batch  66/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 165/300 batch  67/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 165/300 batch  68/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 165/300 batch  69/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 165/300 batch  70/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 165/300 batch  71/188  Train Loss: 0.032, Acc: 0.984\n",
      "epoch: 165/300 batch  72/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 165/300 batch  73/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 165/300 batch  74/188  Train Loss: 0.050, Acc: 0.980\n",
      "epoch: 165/300 batch  75/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 165/300 batch  76/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 165/300 batch  77/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 165/300 batch  78/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 165/300 batch  79/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 165/300 batch  80/188  Train Loss: 0.049, Acc: 0.977\n",
      "epoch: 165/300 batch  81/188  Train Loss: 0.061, Acc: 0.984\n",
      "epoch: 165/300 batch  82/188  Train Loss: 0.056, Acc: 0.988\n",
      "epoch: 165/300 batch  83/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 165/300 batch  84/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 165/300 batch  85/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 165/300 batch  86/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 165/300 batch  87/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 165/300 batch  88/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 165/300 batch  89/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 165/300 batch  90/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 165/300 batch  91/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 165/300 batch  92/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 165/300 batch  93/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 165/300 batch  94/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 165/300 batch  95/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 165/300 batch  96/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 165/300 batch  97/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 165/300 batch  98/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 165/300 batch  99/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 165/300 batch 100/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 165/300 batch 101/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 165/300 batch 102/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 165/300 batch 103/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 165/300 batch 104/188  Train Loss: 0.062, Acc: 0.980\n",
      "epoch: 165/300 batch 105/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 165/300 batch 106/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 165/300 batch 107/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 165/300 batch 108/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 165/300 batch 109/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 165/300 batch 110/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 165/300 batch 111/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 165/300 batch 112/188  Train Loss: 0.056, Acc: 0.988\n",
      "epoch: 165/300 batch 113/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 165/300 batch 114/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 165/300 batch 115/188  Train Loss: 0.071, Acc: 0.988\n",
      "epoch: 165/300 batch 116/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 165/300 batch 117/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 165/300 batch 118/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 165/300 batch 119/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 165/300 batch 120/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 165/300 batch 121/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 165/300 batch 122/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 165/300 batch 123/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 165/300 batch 124/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 165/300 batch 125/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 165/300 batch 126/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 165/300 batch 127/188  Train Loss: 0.056, Acc: 0.992\n",
      "epoch: 165/300 batch 128/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 165/300 batch 129/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 165/300 batch 130/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 165/300 batch 131/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 165/300 batch 132/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 165/300 batch 133/188  Train Loss: 0.066, Acc: 0.992\n",
      "epoch: 165/300 batch 134/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 165/300 batch 135/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 165/300 batch 136/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 165/300 batch 137/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 165/300 batch 138/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 165/300 batch 139/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 165/300 batch 140/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 165/300 batch 141/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 165/300 batch 142/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 165/300 batch 143/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 165/300 batch 144/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 165/300 batch 145/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 165/300 batch 146/188  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 165/300 batch 147/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 165/300 batch 148/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 165/300 batch 149/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 165/300 batch 150/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 165/300 batch 151/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 165/300 batch 152/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 165/300 batch 153/188  Train Loss: 0.047, Acc: 0.996\n",
      "epoch: 165/300 batch 154/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 165/300 batch 155/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 165/300 batch 156/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 165/300 batch 157/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 165/300 batch 158/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 165/300 batch 159/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 165/300 batch 160/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 165/300 batch 161/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 165/300 batch 162/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 165/300 batch 163/188  Train Loss: 0.062, Acc: 0.984\n",
      "epoch: 165/300 batch 164/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 165/300 batch 165/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 165/300 batch 166/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 165/300 batch 167/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 165/300 batch 168/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 165/300 batch 169/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 165/300 batch 170/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 165/300 batch 171/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 165/300 batch 172/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 165/300 batch 173/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 165/300 batch 174/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 165/300 batch 175/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 165/300 batch 176/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 165/300 batch 177/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 165/300 batch 178/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 165/300 batch 179/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 165/300 batch 180/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 165/300 batch 181/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 165/300 batch 182/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 165/300 batch 183/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 165/300 batch 184/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 165/300 batch 185/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 165/300 batch 186/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 165/300 batch 187/188  Train Loss: 0.050, Acc: 0.984\n",
      "Train Loss: 0.033823, Acc: 0.993\n",
      "Val Loss: 0.057281, Acc: 0.983\n",
      "epoch: 166/300 batch   0/188  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 166/300 batch   1/188  Train Loss: 0.044, Acc: 0.980\n",
      "epoch: 166/300 batch   2/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 166/300 batch   3/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 166/300 batch   4/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 166/300 batch   5/188  Train Loss: 0.045, Acc: 0.996\n",
      "epoch: 166/300 batch   6/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 166/300 batch   7/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 166/300 batch   8/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 166/300 batch   9/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 166/300 batch  10/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 166/300 batch  11/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 166/300 batch  12/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 166/300 batch  13/188  Train Loss: 0.035, Acc: 1.000\n",
      "epoch: 166/300 batch  14/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 166/300 batch  15/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 166/300 batch  16/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 166/300 batch  17/188  Train Loss: 0.054, Acc: 0.992\n",
      "epoch: 166/300 batch  18/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 166/300 batch  19/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 166/300 batch  20/188  Train Loss: 0.049, Acc: 0.980\n",
      "epoch: 166/300 batch  21/188  Train Loss: 0.032, Acc: 0.984\n",
      "epoch: 166/300 batch  22/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 166/300 batch  23/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 166/300 batch  24/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 166/300 batch  25/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 166/300 batch  26/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 166/300 batch  27/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 166/300 batch  28/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 166/300 batch  29/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 166/300 batch  30/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 166/300 batch  31/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 166/300 batch  32/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 166/300 batch  33/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 166/300 batch  34/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 166/300 batch  35/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 166/300 batch  36/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 166/300 batch  37/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 166/300 batch  38/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 166/300 batch  39/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 166/300 batch  40/188  Train Loss: 0.047, Acc: 0.980\n",
      "epoch: 166/300 batch  41/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 166/300 batch  42/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 166/300 batch  43/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 166/300 batch  44/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 166/300 batch  45/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 166/300 batch  46/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 166/300 batch  47/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 166/300 batch  48/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 166/300 batch  49/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 166/300 batch  50/188  Train Loss: 0.043, Acc: 0.996\n",
      "epoch: 166/300 batch  51/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 166/300 batch  52/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 166/300 batch  53/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 166/300 batch  54/188  Train Loss: 0.059, Acc: 0.984\n",
      "epoch: 166/300 batch  55/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 166/300 batch  56/188  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 166/300 batch  57/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 166/300 batch  58/188  Train Loss: 0.039, Acc: 0.980\n",
      "epoch: 166/300 batch  59/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 166/300 batch  60/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 166/300 batch  61/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 166/300 batch  62/188  Train Loss: 0.067, Acc: 0.996\n",
      "epoch: 166/300 batch  63/188  Train Loss: 0.044, Acc: 0.996\n",
      "epoch: 166/300 batch  64/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 166/300 batch  65/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 166/300 batch  66/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 166/300 batch  67/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 166/300 batch  68/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 166/300 batch  69/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 166/300 batch  70/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 166/300 batch  71/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 166/300 batch  72/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 166/300 batch  73/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 166/300 batch  74/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 166/300 batch  75/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 166/300 batch  76/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 166/300 batch  77/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 166/300 batch  78/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 166/300 batch  79/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 166/300 batch  80/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 166/300 batch  81/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 166/300 batch  82/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 166/300 batch  83/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 166/300 batch  84/188  Train Loss: 0.051, Acc: 0.992\n",
      "epoch: 166/300 batch  85/188  Train Loss: 0.048, Acc: 0.980\n",
      "epoch: 166/300 batch  86/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 166/300 batch  87/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 166/300 batch  88/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 166/300 batch  89/188  Train Loss: 0.026, Acc: 0.988\n",
      "epoch: 166/300 batch  90/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 166/300 batch  91/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 166/300 batch  92/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 166/300 batch  93/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 166/300 batch  94/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 166/300 batch  95/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 166/300 batch  96/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 166/300 batch  97/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 166/300 batch  98/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 166/300 batch  99/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 166/300 batch 100/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 166/300 batch 101/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 166/300 batch 102/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 166/300 batch 103/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 166/300 batch 104/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 166/300 batch 105/188  Train Loss: 0.044, Acc: 0.980\n",
      "epoch: 166/300 batch 106/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 166/300 batch 107/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 166/300 batch 108/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 166/300 batch 109/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 166/300 batch 110/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 166/300 batch 111/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 166/300 batch 112/188  Train Loss: 0.063, Acc: 0.984\n",
      "epoch: 166/300 batch 113/188  Train Loss: 0.016, Acc: 0.996\n",
      "epoch: 166/300 batch 114/188  Train Loss: 0.064, Acc: 0.984\n",
      "epoch: 166/300 batch 115/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 166/300 batch 116/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 166/300 batch 117/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 166/300 batch 118/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 166/300 batch 119/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 166/300 batch 120/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 166/300 batch 121/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 166/300 batch 122/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 166/300 batch 123/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 166/300 batch 124/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 166/300 batch 125/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 166/300 batch 126/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 166/300 batch 127/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 166/300 batch 128/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 166/300 batch 129/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 166/300 batch 130/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 166/300 batch 131/188  Train Loss: 0.048, Acc: 0.980\n",
      "epoch: 166/300 batch 132/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 166/300 batch 133/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 166/300 batch 134/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 166/300 batch 135/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 166/300 batch 136/188  Train Loss: 0.055, Acc: 0.980\n",
      "epoch: 166/300 batch 137/188  Train Loss: 0.026, Acc: 0.988\n",
      "epoch: 166/300 batch 138/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 166/300 batch 139/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 166/300 batch 140/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 166/300 batch 141/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 166/300 batch 142/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 166/300 batch 143/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 166/300 batch 144/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 166/300 batch 145/188  Train Loss: 0.065, Acc: 0.973\n",
      "epoch: 166/300 batch 146/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 166/300 batch 147/188  Train Loss: 0.032, Acc: 1.000\n",
      "epoch: 166/300 batch 148/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 166/300 batch 149/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 166/300 batch 150/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 166/300 batch 151/188  Train Loss: 0.016, Acc: 0.996\n",
      "epoch: 166/300 batch 152/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 166/300 batch 153/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 166/300 batch 154/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 166/300 batch 155/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 166/300 batch 156/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 166/300 batch 157/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 166/300 batch 158/188  Train Loss: 0.045, Acc: 0.980\n",
      "epoch: 166/300 batch 159/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 166/300 batch 160/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 166/300 batch 161/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 166/300 batch 162/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 166/300 batch 163/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 166/300 batch 164/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 166/300 batch 165/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 166/300 batch 166/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 166/300 batch 167/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 166/300 batch 168/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 166/300 batch 169/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 166/300 batch 170/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 166/300 batch 171/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 166/300 batch 172/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 166/300 batch 173/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 166/300 batch 174/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 166/300 batch 175/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 166/300 batch 176/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 166/300 batch 177/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 166/300 batch 178/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 166/300 batch 179/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 166/300 batch 180/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 166/300 batch 181/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 166/300 batch 182/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 166/300 batch 183/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 166/300 batch 184/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 166/300 batch 185/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 166/300 batch 186/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 166/300 batch 187/188  Train Loss: 0.027, Acc: 1.000\n",
      "Train Loss: 0.033791, Acc: 0.992\n",
      "Val Loss: 0.057581, Acc: 0.983\n",
      "epoch: 167/300 batch   0/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 167/300 batch   1/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 167/300 batch   2/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 167/300 batch   3/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 167/300 batch   4/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 167/300 batch   5/188  Train Loss: 0.043, Acc: 0.980\n",
      "epoch: 167/300 batch   6/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 167/300 batch   7/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 167/300 batch   8/188  Train Loss: 0.047, Acc: 0.977\n",
      "epoch: 167/300 batch   9/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 167/300 batch  10/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 167/300 batch  11/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 167/300 batch  12/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 167/300 batch  13/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 167/300 batch  14/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 167/300 batch  15/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 167/300 batch  16/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 167/300 batch  17/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 167/300 batch  18/188  Train Loss: 0.064, Acc: 0.980\n",
      "epoch: 167/300 batch  19/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 167/300 batch  20/188  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 167/300 batch  21/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 167/300 batch  22/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 167/300 batch  23/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 167/300 batch  24/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 167/300 batch  25/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 167/300 batch  26/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 167/300 batch  27/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 167/300 batch  28/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 167/300 batch  29/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 167/300 batch  30/188  Train Loss: 0.052, Acc: 0.980\n",
      "epoch: 167/300 batch  31/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 167/300 batch  32/188  Train Loss: 0.042, Acc: 0.996\n",
      "epoch: 167/300 batch  33/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 167/300 batch  34/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 167/300 batch  35/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 167/300 batch  36/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 167/300 batch  37/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 167/300 batch  38/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 167/300 batch  39/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 167/300 batch  40/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 167/300 batch  41/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 167/300 batch  42/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 167/300 batch  43/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 167/300 batch  44/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 167/300 batch  45/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 167/300 batch  46/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 167/300 batch  47/188  Train Loss: 0.053, Acc: 0.980\n",
      "epoch: 167/300 batch  48/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 167/300 batch  49/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 167/300 batch  50/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 167/300 batch  51/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 167/300 batch  52/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 167/300 batch  53/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 167/300 batch  54/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 167/300 batch  55/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 167/300 batch  56/188  Train Loss: 0.047, Acc: 0.977\n",
      "epoch: 167/300 batch  57/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 167/300 batch  58/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 167/300 batch  59/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 167/300 batch  60/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 167/300 batch  61/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 167/300 batch  62/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 167/300 batch  63/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 167/300 batch  64/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 167/300 batch  65/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 167/300 batch  66/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 167/300 batch  67/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 167/300 batch  68/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 167/300 batch  69/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 167/300 batch  70/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 167/300 batch  71/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 167/300 batch  72/188  Train Loss: 0.055, Acc: 0.980\n",
      "epoch: 167/300 batch  73/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 167/300 batch  74/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 167/300 batch  75/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 167/300 batch  76/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 167/300 batch  77/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 167/300 batch  78/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 167/300 batch  79/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 167/300 batch  80/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 167/300 batch  81/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 167/300 batch  82/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 167/300 batch  83/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 167/300 batch  84/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 167/300 batch  85/188  Train Loss: 0.034, Acc: 0.984\n",
      "epoch: 167/300 batch  86/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 167/300 batch  87/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 167/300 batch  88/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 167/300 batch  89/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 167/300 batch  90/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 167/300 batch  91/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 167/300 batch  92/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 167/300 batch  93/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 167/300 batch  94/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 167/300 batch  95/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 167/300 batch  96/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 167/300 batch  97/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 167/300 batch  98/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 167/300 batch  99/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 167/300 batch 100/188  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 167/300 batch 101/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 167/300 batch 102/188  Train Loss: 0.073, Acc: 0.980\n",
      "epoch: 167/300 batch 103/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 167/300 batch 104/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 167/300 batch 105/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 167/300 batch 106/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 167/300 batch 107/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 167/300 batch 108/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 167/300 batch 109/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 167/300 batch 110/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 167/300 batch 111/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 167/300 batch 112/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 167/300 batch 113/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 167/300 batch 114/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 167/300 batch 115/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 167/300 batch 116/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 167/300 batch 117/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 167/300 batch 118/188  Train Loss: 0.040, Acc: 0.980\n",
      "epoch: 167/300 batch 119/188  Train Loss: 0.042, Acc: 0.980\n",
      "epoch: 167/300 batch 120/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 167/300 batch 121/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 167/300 batch 122/188  Train Loss: 0.093, Acc: 0.980\n",
      "epoch: 167/300 batch 123/188  Train Loss: 0.026, Acc: 0.988\n",
      "epoch: 167/300 batch 124/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 167/300 batch 125/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 167/300 batch 126/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 167/300 batch 127/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 167/300 batch 128/188  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 167/300 batch 129/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 167/300 batch 130/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 167/300 batch 131/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 167/300 batch 132/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 167/300 batch 133/188  Train Loss: 0.054, Acc: 0.980\n",
      "epoch: 167/300 batch 134/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 167/300 batch 135/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 167/300 batch 136/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 167/300 batch 137/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 167/300 batch 138/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 167/300 batch 139/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 167/300 batch 140/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 167/300 batch 141/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 167/300 batch 142/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 167/300 batch 143/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 167/300 batch 144/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 167/300 batch 145/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 167/300 batch 146/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 167/300 batch 147/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 167/300 batch 148/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 167/300 batch 149/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 167/300 batch 150/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 167/300 batch 151/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 167/300 batch 152/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 167/300 batch 153/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 167/300 batch 154/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 167/300 batch 155/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 167/300 batch 156/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 167/300 batch 157/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 167/300 batch 158/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 167/300 batch 159/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 167/300 batch 160/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 167/300 batch 161/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 167/300 batch 162/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 167/300 batch 163/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 167/300 batch 164/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 167/300 batch 165/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 167/300 batch 166/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 167/300 batch 167/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 167/300 batch 168/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 167/300 batch 169/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 167/300 batch 170/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 167/300 batch 171/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 167/300 batch 172/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 167/300 batch 173/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 167/300 batch 174/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 167/300 batch 175/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 167/300 batch 176/188  Train Loss: 0.069, Acc: 0.973\n",
      "epoch: 167/300 batch 177/188  Train Loss: 0.042, Acc: 0.996\n",
      "epoch: 167/300 batch 178/188  Train Loss: 0.027, Acc: 0.988\n",
      "epoch: 167/300 batch 179/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 167/300 batch 180/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 167/300 batch 181/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 167/300 batch 182/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 167/300 batch 183/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 167/300 batch 184/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 167/300 batch 185/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 167/300 batch 186/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 167/300 batch 187/188  Train Loss: 0.021, Acc: 1.000\n",
      "Train Loss: 0.033762, Acc: 0.992\n",
      "Val Loss: 0.057306, Acc: 0.983\n",
      "epoch: 168/300 batch   0/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 168/300 batch   1/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 168/300 batch   2/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 168/300 batch   3/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 168/300 batch   4/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 168/300 batch   5/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 168/300 batch   6/188  Train Loss: 0.060, Acc: 0.984\n",
      "epoch: 168/300 batch   7/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 168/300 batch   8/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 168/300 batch   9/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 168/300 batch  10/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 168/300 batch  11/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 168/300 batch  12/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 168/300 batch  13/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 168/300 batch  14/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 168/300 batch  15/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 168/300 batch  16/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 168/300 batch  17/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 168/300 batch  18/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 168/300 batch  19/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 168/300 batch  20/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 168/300 batch  21/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 168/300 batch  22/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 168/300 batch  23/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 168/300 batch  24/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 168/300 batch  25/188  Train Loss: 0.063, Acc: 0.980\n",
      "epoch: 168/300 batch  26/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 168/300 batch  27/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 168/300 batch  28/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 168/300 batch  29/188  Train Loss: 0.052, Acc: 0.992\n",
      "epoch: 168/300 batch  30/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 168/300 batch  31/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 168/300 batch  32/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 168/300 batch  33/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 168/300 batch  34/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 168/300 batch  35/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 168/300 batch  36/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 168/300 batch  37/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 168/300 batch  38/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 168/300 batch  39/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 168/300 batch  40/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 168/300 batch  41/188  Train Loss: 0.057, Acc: 0.988\n",
      "epoch: 168/300 batch  42/188  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 168/300 batch  43/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 168/300 batch  44/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 168/300 batch  45/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 168/300 batch  46/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 168/300 batch  47/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 168/300 batch  48/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 168/300 batch  49/188  Train Loss: 0.061, Acc: 0.973\n",
      "epoch: 168/300 batch  50/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 168/300 batch  51/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 168/300 batch  52/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 168/300 batch  53/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 168/300 batch  54/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 168/300 batch  55/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 168/300 batch  56/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 168/300 batch  57/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 168/300 batch  58/188  Train Loss: 0.042, Acc: 0.996\n",
      "epoch: 168/300 batch  59/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 168/300 batch  60/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 168/300 batch  61/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 168/300 batch  62/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 168/300 batch  63/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 168/300 batch  64/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 168/300 batch  65/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 168/300 batch  66/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 168/300 batch  67/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 168/300 batch  68/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 168/300 batch  69/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 168/300 batch  70/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 168/300 batch  71/188  Train Loss: 0.062, Acc: 0.984\n",
      "epoch: 168/300 batch  72/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 168/300 batch  73/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 168/300 batch  74/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 168/300 batch  75/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 168/300 batch  76/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 168/300 batch  77/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 168/300 batch  78/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 168/300 batch  79/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 168/300 batch  80/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 168/300 batch  81/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 168/300 batch  82/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 168/300 batch  83/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 168/300 batch  84/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 168/300 batch  85/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 168/300 batch  86/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 168/300 batch  87/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 168/300 batch  88/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 168/300 batch  89/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 168/300 batch  90/188  Train Loss: 0.062, Acc: 0.984\n",
      "epoch: 168/300 batch  91/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 168/300 batch  92/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 168/300 batch  93/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 168/300 batch  94/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 168/300 batch  95/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 168/300 batch  96/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 168/300 batch  97/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 168/300 batch  98/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 168/300 batch  99/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 168/300 batch 100/188  Train Loss: 0.045, Acc: 0.996\n",
      "epoch: 168/300 batch 101/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 168/300 batch 102/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 168/300 batch 103/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 168/300 batch 104/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 168/300 batch 105/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 168/300 batch 106/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 168/300 batch 107/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 168/300 batch 108/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 168/300 batch 109/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 168/300 batch 110/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 168/300 batch 111/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 168/300 batch 112/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 168/300 batch 113/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 168/300 batch 114/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 168/300 batch 115/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 168/300 batch 116/188  Train Loss: 0.044, Acc: 0.996\n",
      "epoch: 168/300 batch 117/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 168/300 batch 118/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 168/300 batch 119/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 168/300 batch 120/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 168/300 batch 121/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 168/300 batch 122/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 168/300 batch 123/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 168/300 batch 124/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 168/300 batch 125/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 168/300 batch 126/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 168/300 batch 127/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 168/300 batch 128/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 168/300 batch 129/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 168/300 batch 130/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 168/300 batch 131/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 168/300 batch 132/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 168/300 batch 133/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 168/300 batch 134/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 168/300 batch 135/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 168/300 batch 136/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 168/300 batch 137/188  Train Loss: 0.063, Acc: 0.980\n",
      "epoch: 168/300 batch 138/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 168/300 batch 139/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 168/300 batch 140/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 168/300 batch 141/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 168/300 batch 142/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 168/300 batch 143/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 168/300 batch 144/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 168/300 batch 145/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 168/300 batch 146/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 168/300 batch 147/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 168/300 batch 148/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 168/300 batch 149/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 168/300 batch 150/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 168/300 batch 151/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 168/300 batch 152/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 168/300 batch 153/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 168/300 batch 154/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 168/300 batch 155/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 168/300 batch 156/188  Train Loss: 0.054, Acc: 0.992\n",
      "epoch: 168/300 batch 157/188  Train Loss: 0.101, Acc: 0.984\n",
      "epoch: 168/300 batch 158/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 168/300 batch 159/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 168/300 batch 160/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 168/300 batch 161/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 168/300 batch 162/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 168/300 batch 163/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 168/300 batch 164/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 168/300 batch 165/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 168/300 batch 166/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 168/300 batch 167/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 168/300 batch 168/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 168/300 batch 169/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 168/300 batch 170/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 168/300 batch 171/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 168/300 batch 172/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 168/300 batch 173/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 168/300 batch 174/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 168/300 batch 175/188  Train Loss: 0.060, Acc: 0.977\n",
      "epoch: 168/300 batch 176/188  Train Loss: 0.033, Acc: 0.984\n",
      "epoch: 168/300 batch 177/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 168/300 batch 178/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 168/300 batch 179/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 168/300 batch 180/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 168/300 batch 181/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 168/300 batch 182/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 168/300 batch 183/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 168/300 batch 184/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 168/300 batch 185/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 168/300 batch 186/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 168/300 batch 187/188  Train Loss: 0.029, Acc: 1.000\n",
      "Train Loss: 0.033736, Acc: 0.993\n",
      "Val Loss: 0.057313, Acc: 0.983\n",
      "epoch: 169/300 batch   0/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 169/300 batch   1/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 169/300 batch   2/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 169/300 batch   3/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 169/300 batch   4/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 169/300 batch   5/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 169/300 batch   6/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 169/300 batch   7/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 169/300 batch   8/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 169/300 batch   9/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 169/300 batch  10/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 169/300 batch  11/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 169/300 batch  12/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 169/300 batch  13/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 169/300 batch  14/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 169/300 batch  15/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 169/300 batch  16/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 169/300 batch  17/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 169/300 batch  18/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 169/300 batch  19/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 169/300 batch  20/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 169/300 batch  21/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 169/300 batch  22/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 169/300 batch  23/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 169/300 batch  24/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 169/300 batch  25/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 169/300 batch  26/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 169/300 batch  27/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 169/300 batch  28/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 169/300 batch  29/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 169/300 batch  30/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 169/300 batch  31/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 169/300 batch  32/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 169/300 batch  33/188  Train Loss: 0.049, Acc: 0.996\n",
      "epoch: 169/300 batch  34/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 169/300 batch  35/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 169/300 batch  36/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 169/300 batch  37/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 169/300 batch  38/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 169/300 batch  39/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 169/300 batch  40/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 169/300 batch  41/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 169/300 batch  42/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 169/300 batch  43/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 169/300 batch  44/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 169/300 batch  45/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 169/300 batch  46/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 169/300 batch  47/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 169/300 batch  48/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 169/300 batch  49/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 169/300 batch  50/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 169/300 batch  51/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 169/300 batch  52/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 169/300 batch  53/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 169/300 batch  54/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 169/300 batch  55/188  Train Loss: 0.051, Acc: 0.992\n",
      "epoch: 169/300 batch  56/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 169/300 batch  57/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 169/300 batch  58/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 169/300 batch  59/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 169/300 batch  60/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 169/300 batch  61/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 169/300 batch  62/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 169/300 batch  63/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 169/300 batch  64/188  Train Loss: 0.051, Acc: 0.980\n",
      "epoch: 169/300 batch  65/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 169/300 batch  66/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 169/300 batch  67/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 169/300 batch  68/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 169/300 batch  69/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 169/300 batch  70/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 169/300 batch  71/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 169/300 batch  72/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 169/300 batch  73/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 169/300 batch  74/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 169/300 batch  75/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 169/300 batch  76/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 169/300 batch  77/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 169/300 batch  78/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 169/300 batch  79/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 169/300 batch  80/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 169/300 batch  81/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 169/300 batch  82/188  Train Loss: 0.038, Acc: 0.977\n",
      "epoch: 169/300 batch  83/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 169/300 batch  84/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 169/300 batch  85/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 169/300 batch  86/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 169/300 batch  87/188  Train Loss: 0.054, Acc: 0.996\n",
      "epoch: 169/300 batch  88/188  Train Loss: 0.050, Acc: 0.980\n",
      "epoch: 169/300 batch  89/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 169/300 batch  90/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 169/300 batch  91/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 169/300 batch  92/188  Train Loss: 0.048, Acc: 0.980\n",
      "epoch: 169/300 batch  93/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 169/300 batch  94/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 169/300 batch  95/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 169/300 batch  96/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 169/300 batch  97/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 169/300 batch  98/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 169/300 batch  99/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 169/300 batch 100/188  Train Loss: 0.044, Acc: 0.980\n",
      "epoch: 169/300 batch 101/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 169/300 batch 102/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 169/300 batch 103/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 169/300 batch 104/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 169/300 batch 105/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 169/300 batch 106/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 169/300 batch 107/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 169/300 batch 108/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 169/300 batch 109/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 169/300 batch 110/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 169/300 batch 111/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 169/300 batch 112/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 169/300 batch 113/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 169/300 batch 114/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 169/300 batch 115/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 169/300 batch 116/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 169/300 batch 117/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 169/300 batch 118/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 169/300 batch 119/188  Train Loss: 0.046, Acc: 0.980\n",
      "epoch: 169/300 batch 120/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 169/300 batch 121/188  Train Loss: 0.024, Acc: 0.988\n",
      "epoch: 169/300 batch 122/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 169/300 batch 123/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 169/300 batch 124/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 169/300 batch 125/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 169/300 batch 126/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 169/300 batch 127/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 169/300 batch 128/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 169/300 batch 129/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 169/300 batch 130/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 169/300 batch 131/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 169/300 batch 132/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 169/300 batch 133/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 169/300 batch 134/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 169/300 batch 135/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 169/300 batch 136/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 169/300 batch 137/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 169/300 batch 138/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 169/300 batch 139/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 169/300 batch 140/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 169/300 batch 141/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 169/300 batch 142/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 169/300 batch 143/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 169/300 batch 144/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 169/300 batch 145/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 169/300 batch 146/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 169/300 batch 147/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 169/300 batch 148/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 169/300 batch 149/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 169/300 batch 150/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 169/300 batch 151/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 169/300 batch 152/188  Train Loss: 0.053, Acc: 0.980\n",
      "epoch: 169/300 batch 153/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 169/300 batch 154/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 169/300 batch 155/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 169/300 batch 156/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 169/300 batch 157/188  Train Loss: 0.058, Acc: 0.988\n",
      "epoch: 169/300 batch 158/188  Train Loss: 0.064, Acc: 0.969\n",
      "epoch: 169/300 batch 159/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 169/300 batch 160/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 169/300 batch 161/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 169/300 batch 162/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 169/300 batch 163/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 169/300 batch 164/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 169/300 batch 165/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 169/300 batch 166/188  Train Loss: 0.074, Acc: 0.980\n",
      "epoch: 169/300 batch 167/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 169/300 batch 168/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 169/300 batch 169/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 169/300 batch 170/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 169/300 batch 171/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 169/300 batch 172/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 169/300 batch 173/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 169/300 batch 174/188  Train Loss: 0.027, Acc: 0.988\n",
      "epoch: 169/300 batch 175/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 169/300 batch 176/188  Train Loss: 0.065, Acc: 0.980\n",
      "epoch: 169/300 batch 177/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 169/300 batch 178/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 169/300 batch 179/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 169/300 batch 180/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 169/300 batch 181/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 169/300 batch 182/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 169/300 batch 183/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 169/300 batch 184/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 169/300 batch 185/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 169/300 batch 186/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 169/300 batch 187/188  Train Loss: 0.025, Acc: 0.992\n",
      "Train Loss: 0.033724, Acc: 0.992\n",
      "Val Loss: 0.057489, Acc: 0.983\n",
      "epoch: 170/300 batch   0/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 170/300 batch   1/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 170/300 batch   2/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 170/300 batch   3/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 170/300 batch   4/188  Train Loss: 0.052, Acc: 0.980\n",
      "epoch: 170/300 batch   5/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 170/300 batch   6/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 170/300 batch   7/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 170/300 batch   8/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 170/300 batch   9/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 170/300 batch  10/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 170/300 batch  11/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 170/300 batch  12/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 170/300 batch  13/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 170/300 batch  14/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 170/300 batch  15/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 170/300 batch  16/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 170/300 batch  17/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 170/300 batch  18/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 170/300 batch  19/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 170/300 batch  20/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 170/300 batch  21/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 170/300 batch  22/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 170/300 batch  23/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 170/300 batch  24/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 170/300 batch  25/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 170/300 batch  26/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 170/300 batch  27/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 170/300 batch  28/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 170/300 batch  29/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 170/300 batch  30/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 170/300 batch  31/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 170/300 batch  32/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 170/300 batch  33/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 170/300 batch  34/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 170/300 batch  35/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 170/300 batch  36/188  Train Loss: 0.063, Acc: 0.977\n",
      "epoch: 170/300 batch  37/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 170/300 batch  38/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 170/300 batch  39/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 170/300 batch  40/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 170/300 batch  41/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 170/300 batch  42/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 170/300 batch  43/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 170/300 batch  44/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 170/300 batch  45/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 170/300 batch  46/188  Train Loss: 0.073, Acc: 0.980\n",
      "epoch: 170/300 batch  47/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 170/300 batch  48/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 170/300 batch  49/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 170/300 batch  50/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 170/300 batch  51/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 170/300 batch  52/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 170/300 batch  53/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 170/300 batch  54/188  Train Loss: 0.080, Acc: 0.984\n",
      "epoch: 170/300 batch  55/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 170/300 batch  56/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 170/300 batch  57/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 170/300 batch  58/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 170/300 batch  59/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 170/300 batch  60/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 170/300 batch  61/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 170/300 batch  62/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 170/300 batch  63/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 170/300 batch  64/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 170/300 batch  65/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 170/300 batch  66/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 170/300 batch  67/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 170/300 batch  68/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 170/300 batch  69/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 170/300 batch  70/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 170/300 batch  71/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 170/300 batch  72/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 170/300 batch  73/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 170/300 batch  74/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 170/300 batch  75/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 170/300 batch  76/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 170/300 batch  77/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 170/300 batch  78/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 170/300 batch  79/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 170/300 batch  80/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 170/300 batch  81/188  Train Loss: 0.051, Acc: 0.980\n",
      "epoch: 170/300 batch  82/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 170/300 batch  83/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 170/300 batch  84/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 170/300 batch  85/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 170/300 batch  86/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 170/300 batch  87/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 170/300 batch  88/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 170/300 batch  89/188  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 170/300 batch  90/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 170/300 batch  91/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 170/300 batch  92/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 170/300 batch  93/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 170/300 batch  94/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 170/300 batch  95/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 170/300 batch  96/188  Train Loss: 0.051, Acc: 0.992\n",
      "epoch: 170/300 batch  97/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 170/300 batch  98/188  Train Loss: 0.027, Acc: 0.988\n",
      "epoch: 170/300 batch  99/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 170/300 batch 100/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 170/300 batch 101/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 170/300 batch 102/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 170/300 batch 103/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 170/300 batch 104/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 170/300 batch 105/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 170/300 batch 106/188  Train Loss: 0.051, Acc: 0.992\n",
      "epoch: 170/300 batch 107/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 170/300 batch 108/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 170/300 batch 109/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 170/300 batch 110/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 170/300 batch 111/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 170/300 batch 112/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 170/300 batch 113/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 170/300 batch 114/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 170/300 batch 115/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 170/300 batch 116/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 170/300 batch 117/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 170/300 batch 118/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 170/300 batch 119/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 170/300 batch 120/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 170/300 batch 121/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 170/300 batch 122/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 170/300 batch 123/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 170/300 batch 124/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 170/300 batch 125/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 170/300 batch 126/188  Train Loss: 0.050, Acc: 0.977\n",
      "epoch: 170/300 batch 127/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 170/300 batch 128/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 170/300 batch 129/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 170/300 batch 130/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 170/300 batch 131/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 170/300 batch 132/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 170/300 batch 133/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 170/300 batch 134/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 170/300 batch 135/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 170/300 batch 136/188  Train Loss: 0.026, Acc: 0.988\n",
      "epoch: 170/300 batch 137/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 170/300 batch 138/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 170/300 batch 139/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 170/300 batch 140/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 170/300 batch 141/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 170/300 batch 142/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 170/300 batch 143/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 170/300 batch 144/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 170/300 batch 145/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 170/300 batch 146/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 170/300 batch 147/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 170/300 batch 148/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 170/300 batch 149/188  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 170/300 batch 150/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 170/300 batch 151/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 170/300 batch 152/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 170/300 batch 153/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 170/300 batch 154/188  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 170/300 batch 155/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 170/300 batch 156/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 170/300 batch 157/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 170/300 batch 158/188  Train Loss: 0.044, Acc: 0.977\n",
      "epoch: 170/300 batch 159/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 170/300 batch 160/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 170/300 batch 161/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 170/300 batch 162/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 170/300 batch 163/188  Train Loss: 0.042, Acc: 0.980\n",
      "epoch: 170/300 batch 164/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 170/300 batch 165/188  Train Loss: 0.031, Acc: 0.980\n",
      "epoch: 170/300 batch 166/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 170/300 batch 167/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 170/300 batch 168/188  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 170/300 batch 169/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 170/300 batch 170/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 170/300 batch 171/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 170/300 batch 172/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 170/300 batch 173/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 170/300 batch 174/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 170/300 batch 175/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 170/300 batch 176/188  Train Loss: 0.059, Acc: 0.984\n",
      "epoch: 170/300 batch 177/188  Train Loss: 0.051, Acc: 0.992\n",
      "epoch: 170/300 batch 178/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 170/300 batch 179/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 170/300 batch 180/188  Train Loss: 0.046, Acc: 0.980\n",
      "epoch: 170/300 batch 181/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 170/300 batch 182/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 170/300 batch 183/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 170/300 batch 184/188  Train Loss: 0.073, Acc: 0.980\n",
      "epoch: 170/300 batch 185/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 170/300 batch 186/188  Train Loss: 0.051, Acc: 0.992\n",
      "epoch: 170/300 batch 187/188  Train Loss: 0.028, Acc: 1.000\n",
      "Train Loss: 0.033696, Acc: 0.992\n",
      "Val Loss: 0.057527, Acc: 0.983\n",
      "epoch: 171/300 batch   0/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 171/300 batch   1/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 171/300 batch   2/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 171/300 batch   3/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 171/300 batch   4/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 171/300 batch   5/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 171/300 batch   6/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 171/300 batch   7/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 171/300 batch   8/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 171/300 batch   9/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 171/300 batch  10/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 171/300 batch  11/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 171/300 batch  12/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 171/300 batch  13/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 171/300 batch  14/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 171/300 batch  15/188  Train Loss: 0.045, Acc: 0.980\n",
      "epoch: 171/300 batch  16/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 171/300 batch  17/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 171/300 batch  18/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 171/300 batch  19/188  Train Loss: 0.055, Acc: 0.977\n",
      "epoch: 171/300 batch  20/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 171/300 batch  21/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 171/300 batch  22/188  Train Loss: 0.065, Acc: 0.984\n",
      "epoch: 171/300 batch  23/188  Train Loss: 0.054, Acc: 0.992\n",
      "epoch: 171/300 batch  24/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 171/300 batch  25/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 171/300 batch  26/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 171/300 batch  27/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 171/300 batch  28/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 171/300 batch  29/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 171/300 batch  30/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 171/300 batch  31/188  Train Loss: 0.063, Acc: 0.980\n",
      "epoch: 171/300 batch  32/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 171/300 batch  33/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 171/300 batch  34/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 171/300 batch  35/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 171/300 batch  36/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 171/300 batch  37/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 171/300 batch  38/188  Train Loss: 0.044, Acc: 0.996\n",
      "epoch: 171/300 batch  39/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 171/300 batch  40/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 171/300 batch  41/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 171/300 batch  42/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 171/300 batch  43/188  Train Loss: 0.066, Acc: 0.992\n",
      "epoch: 171/300 batch  44/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 171/300 batch  45/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 171/300 batch  46/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 171/300 batch  47/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 171/300 batch  48/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 171/300 batch  49/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 171/300 batch  50/188  Train Loss: 0.045, Acc: 0.996\n",
      "epoch: 171/300 batch  51/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 171/300 batch  52/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 171/300 batch  53/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 171/300 batch  54/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 171/300 batch  55/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 171/300 batch  56/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 171/300 batch  57/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 171/300 batch  58/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 171/300 batch  59/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 171/300 batch  60/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 171/300 batch  61/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 171/300 batch  62/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 171/300 batch  63/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 171/300 batch  64/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 171/300 batch  65/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 171/300 batch  66/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 171/300 batch  67/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 171/300 batch  68/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 171/300 batch  69/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 171/300 batch  70/188  Train Loss: 0.044, Acc: 0.980\n",
      "epoch: 171/300 batch  71/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 171/300 batch  72/188  Train Loss: 0.048, Acc: 0.977\n",
      "epoch: 171/300 batch  73/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 171/300 batch  74/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 171/300 batch  75/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 171/300 batch  76/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 171/300 batch  77/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 171/300 batch  78/188  Train Loss: 0.068, Acc: 0.977\n",
      "epoch: 171/300 batch  79/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 171/300 batch  80/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 171/300 batch  81/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 171/300 batch  82/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 171/300 batch  83/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 171/300 batch  84/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 171/300 batch  85/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 171/300 batch  86/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 171/300 batch  87/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 171/300 batch  88/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 171/300 batch  89/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 171/300 batch  90/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 171/300 batch  91/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 171/300 batch  92/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 171/300 batch  93/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 171/300 batch  94/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 171/300 batch  95/188  Train Loss: 0.062, Acc: 0.980\n",
      "epoch: 171/300 batch  96/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 171/300 batch  97/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 171/300 batch  98/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 171/300 batch  99/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 171/300 batch 100/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 171/300 batch 101/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 171/300 batch 102/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 171/300 batch 103/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 171/300 batch 104/188  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 171/300 batch 105/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 171/300 batch 106/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 171/300 batch 107/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 171/300 batch 108/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 171/300 batch 109/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 171/300 batch 110/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 171/300 batch 111/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 171/300 batch 112/188  Train Loss: 0.053, Acc: 0.980\n",
      "epoch: 171/300 batch 113/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 171/300 batch 114/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 171/300 batch 115/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 171/300 batch 116/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 171/300 batch 117/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 171/300 batch 118/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 171/300 batch 119/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 171/300 batch 120/188  Train Loss: 0.043, Acc: 0.996\n",
      "epoch: 171/300 batch 121/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 171/300 batch 122/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 171/300 batch 123/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 171/300 batch 124/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 171/300 batch 125/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 171/300 batch 126/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 171/300 batch 127/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 171/300 batch 128/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 171/300 batch 129/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 171/300 batch 130/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 171/300 batch 131/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 171/300 batch 132/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 171/300 batch 133/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 171/300 batch 134/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 171/300 batch 135/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 171/300 batch 136/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 171/300 batch 137/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 171/300 batch 138/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 171/300 batch 139/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 171/300 batch 140/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 171/300 batch 141/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 171/300 batch 142/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 171/300 batch 143/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 171/300 batch 144/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 171/300 batch 145/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 171/300 batch 146/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 171/300 batch 147/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 171/300 batch 148/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 171/300 batch 149/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 171/300 batch 150/188  Train Loss: 0.044, Acc: 0.980\n",
      "epoch: 171/300 batch 151/188  Train Loss: 0.063, Acc: 0.980\n",
      "epoch: 171/300 batch 152/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 171/300 batch 153/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 171/300 batch 154/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 171/300 batch 155/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 171/300 batch 156/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 171/300 batch 157/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 171/300 batch 158/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 171/300 batch 159/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 171/300 batch 160/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 171/300 batch 161/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 171/300 batch 162/188  Train Loss: 0.067, Acc: 0.977\n",
      "epoch: 171/300 batch 163/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 171/300 batch 164/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 171/300 batch 165/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 171/300 batch 166/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 171/300 batch 167/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 171/300 batch 168/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 171/300 batch 169/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 171/300 batch 170/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 171/300 batch 171/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 171/300 batch 172/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 171/300 batch 173/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 171/300 batch 174/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 171/300 batch 175/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 171/300 batch 176/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 171/300 batch 177/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 171/300 batch 178/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 171/300 batch 179/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 171/300 batch 180/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 171/300 batch 181/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 171/300 batch 182/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 171/300 batch 183/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 171/300 batch 184/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 171/300 batch 185/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 171/300 batch 186/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 171/300 batch 187/188  Train Loss: 0.050, Acc: 0.992\n",
      "Train Loss: 0.033788, Acc: 0.992\n",
      "Val Loss: 0.057151, Acc: 0.983\n",
      "epoch: 172/300 batch   0/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 172/300 batch   1/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 172/300 batch   2/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 172/300 batch   3/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 172/300 batch   4/188  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 172/300 batch   5/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 172/300 batch   6/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 172/300 batch   7/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 172/300 batch   8/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 172/300 batch   9/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 172/300 batch  10/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 172/300 batch  11/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 172/300 batch  12/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 172/300 batch  13/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 172/300 batch  14/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 172/300 batch  15/188  Train Loss: 0.059, Acc: 0.980\n",
      "epoch: 172/300 batch  16/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 172/300 batch  17/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 172/300 batch  18/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 172/300 batch  19/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 172/300 batch  20/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 172/300 batch  21/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 172/300 batch  22/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 172/300 batch  23/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 172/300 batch  24/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 172/300 batch  25/188  Train Loss: 0.057, Acc: 0.992\n",
      "epoch: 172/300 batch  26/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 172/300 batch  27/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 172/300 batch  28/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 172/300 batch  29/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 172/300 batch  30/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 172/300 batch  31/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 172/300 batch  32/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 172/300 batch  33/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 172/300 batch  34/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 172/300 batch  35/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 172/300 batch  36/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 172/300 batch  37/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 172/300 batch  38/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 172/300 batch  39/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 172/300 batch  40/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 172/300 batch  41/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 172/300 batch  42/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 172/300 batch  43/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 172/300 batch  44/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 172/300 batch  45/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 172/300 batch  46/188  Train Loss: 0.052, Acc: 0.992\n",
      "epoch: 172/300 batch  47/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 172/300 batch  48/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 172/300 batch  49/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 172/300 batch  50/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 172/300 batch  51/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 172/300 batch  52/188  Train Loss: 0.047, Acc: 0.980\n",
      "epoch: 172/300 batch  53/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 172/300 batch  54/188  Train Loss: 0.048, Acc: 0.980\n",
      "epoch: 172/300 batch  55/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 172/300 batch  56/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 172/300 batch  57/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 172/300 batch  58/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 172/300 batch  59/188  Train Loss: 0.063, Acc: 0.984\n",
      "epoch: 172/300 batch  60/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 172/300 batch  61/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 172/300 batch  62/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 172/300 batch  63/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 172/300 batch  64/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 172/300 batch  65/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 172/300 batch  66/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 172/300 batch  67/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 172/300 batch  68/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 172/300 batch  69/188  Train Loss: 0.049, Acc: 0.977\n",
      "epoch: 172/300 batch  70/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 172/300 batch  71/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 172/300 batch  72/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 172/300 batch  73/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 172/300 batch  74/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 172/300 batch  75/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 172/300 batch  76/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 172/300 batch  77/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 172/300 batch  78/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 172/300 batch  79/188  Train Loss: 0.048, Acc: 0.980\n",
      "epoch: 172/300 batch  80/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 172/300 batch  81/188  Train Loss: 0.045, Acc: 0.996\n",
      "epoch: 172/300 batch  82/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 172/300 batch  83/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 172/300 batch  84/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 172/300 batch  85/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 172/300 batch  86/188  Train Loss: 0.067, Acc: 0.980\n",
      "epoch: 172/300 batch  87/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 172/300 batch  88/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 172/300 batch  89/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 172/300 batch  90/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 172/300 batch  91/188  Train Loss: 0.027, Acc: 0.988\n",
      "epoch: 172/300 batch  92/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 172/300 batch  93/188  Train Loss: 0.058, Acc: 0.988\n",
      "epoch: 172/300 batch  94/188  Train Loss: 0.044, Acc: 0.980\n",
      "epoch: 172/300 batch  95/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 172/300 batch  96/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 172/300 batch  97/188  Train Loss: 0.068, Acc: 0.980\n",
      "epoch: 172/300 batch  98/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 172/300 batch  99/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 172/300 batch 100/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 172/300 batch 101/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 172/300 batch 102/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 172/300 batch 103/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 172/300 batch 104/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 172/300 batch 105/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 172/300 batch 106/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 172/300 batch 107/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 172/300 batch 108/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 172/300 batch 109/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 172/300 batch 110/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 172/300 batch 111/188  Train Loss: 0.031, Acc: 0.984\n",
      "epoch: 172/300 batch 112/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 172/300 batch 113/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 172/300 batch 114/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 172/300 batch 115/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 172/300 batch 116/188  Train Loss: 0.043, Acc: 0.980\n",
      "epoch: 172/300 batch 117/188  Train Loss: 0.027, Acc: 0.988\n",
      "epoch: 172/300 batch 118/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 172/300 batch 119/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 172/300 batch 120/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 172/300 batch 121/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 172/300 batch 122/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 172/300 batch 123/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 172/300 batch 124/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 172/300 batch 125/188  Train Loss: 0.083, Acc: 0.988\n",
      "epoch: 172/300 batch 126/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 172/300 batch 127/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 172/300 batch 128/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 172/300 batch 129/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 172/300 batch 130/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 172/300 batch 131/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 172/300 batch 132/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 172/300 batch 133/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 172/300 batch 134/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 172/300 batch 135/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 172/300 batch 136/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 172/300 batch 137/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 172/300 batch 138/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 172/300 batch 139/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 172/300 batch 140/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 172/300 batch 141/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 172/300 batch 142/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 172/300 batch 143/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 172/300 batch 144/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 172/300 batch 145/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 172/300 batch 146/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 172/300 batch 147/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 172/300 batch 148/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 172/300 batch 149/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 172/300 batch 150/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 172/300 batch 151/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 172/300 batch 152/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 172/300 batch 153/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 172/300 batch 154/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 172/300 batch 155/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 172/300 batch 156/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 172/300 batch 157/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 172/300 batch 158/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 172/300 batch 159/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 172/300 batch 160/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 172/300 batch 161/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 172/300 batch 162/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 172/300 batch 163/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 172/300 batch 164/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 172/300 batch 165/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 172/300 batch 166/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 172/300 batch 167/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 172/300 batch 168/188  Train Loss: 0.048, Acc: 0.980\n",
      "epoch: 172/300 batch 169/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 172/300 batch 170/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 172/300 batch 171/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 172/300 batch 172/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 172/300 batch 173/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 172/300 batch 174/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 172/300 batch 175/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 172/300 batch 176/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 172/300 batch 177/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 172/300 batch 178/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 172/300 batch 179/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 172/300 batch 180/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 172/300 batch 181/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 172/300 batch 182/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 172/300 batch 183/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 172/300 batch 184/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 172/300 batch 185/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 172/300 batch 186/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 172/300 batch 187/188  Train Loss: 0.007, Acc: 1.000\n",
      "Train Loss: 0.033626, Acc: 0.992\n",
      "Val Loss: 0.057434, Acc: 0.983\n",
      "epoch: 173/300 batch   0/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 173/300 batch   1/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 173/300 batch   2/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 173/300 batch   3/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 173/300 batch   4/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 173/300 batch   5/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 173/300 batch   6/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 173/300 batch   7/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 173/300 batch   8/188  Train Loss: 0.044, Acc: 0.980\n",
      "epoch: 173/300 batch   9/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 173/300 batch  10/188  Train Loss: 0.061, Acc: 0.980\n",
      "epoch: 173/300 batch  11/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 173/300 batch  12/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 173/300 batch  13/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 173/300 batch  14/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 173/300 batch  15/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 173/300 batch  16/188  Train Loss: 0.033, Acc: 0.984\n",
      "epoch: 173/300 batch  17/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 173/300 batch  18/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 173/300 batch  19/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 173/300 batch  20/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 173/300 batch  21/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 173/300 batch  22/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 173/300 batch  23/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 173/300 batch  24/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 173/300 batch  25/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 173/300 batch  26/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 173/300 batch  27/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 173/300 batch  28/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 173/300 batch  29/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 173/300 batch  30/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 173/300 batch  31/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 173/300 batch  32/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 173/300 batch  33/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 173/300 batch  34/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 173/300 batch  35/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 173/300 batch  36/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 173/300 batch  37/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 173/300 batch  38/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 173/300 batch  39/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 173/300 batch  40/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 173/300 batch  41/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 173/300 batch  42/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 173/300 batch  43/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 173/300 batch  44/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 173/300 batch  45/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 173/300 batch  46/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 173/300 batch  47/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 173/300 batch  48/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 173/300 batch  49/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 173/300 batch  50/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 173/300 batch  51/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 173/300 batch  52/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 173/300 batch  53/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 173/300 batch  54/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 173/300 batch  55/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 173/300 batch  56/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 173/300 batch  57/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 173/300 batch  58/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 173/300 batch  59/188  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 173/300 batch  60/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 173/300 batch  61/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 173/300 batch  62/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 173/300 batch  63/188  Train Loss: 0.031, Acc: 1.000\n",
      "epoch: 173/300 batch  64/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 173/300 batch  65/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 173/300 batch  66/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 173/300 batch  67/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 173/300 batch  68/188  Train Loss: 0.060, Acc: 0.984\n",
      "epoch: 173/300 batch  69/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 173/300 batch  70/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 173/300 batch  71/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 173/300 batch  72/188  Train Loss: 0.044, Acc: 0.996\n",
      "epoch: 173/300 batch  73/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 173/300 batch  74/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 173/300 batch  75/188  Train Loss: 0.073, Acc: 0.969\n",
      "epoch: 173/300 batch  76/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 173/300 batch  77/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 173/300 batch  78/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 173/300 batch  79/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 173/300 batch  80/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 173/300 batch  81/188  Train Loss: 0.055, Acc: 0.992\n",
      "epoch: 173/300 batch  82/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 173/300 batch  83/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 173/300 batch  84/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 173/300 batch  85/188  Train Loss: 0.073, Acc: 0.980\n",
      "epoch: 173/300 batch  86/188  Train Loss: 0.048, Acc: 0.980\n",
      "epoch: 173/300 batch  87/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 173/300 batch  88/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 173/300 batch  89/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 173/300 batch  90/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 173/300 batch  91/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 173/300 batch  92/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 173/300 batch  93/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 173/300 batch  94/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 173/300 batch  95/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 173/300 batch  96/188  Train Loss: 0.046, Acc: 0.980\n",
      "epoch: 173/300 batch  97/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 173/300 batch  98/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 173/300 batch  99/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 173/300 batch 100/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 173/300 batch 101/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 173/300 batch 102/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 173/300 batch 103/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 173/300 batch 104/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 173/300 batch 105/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 173/300 batch 106/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 173/300 batch 107/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 173/300 batch 108/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 173/300 batch 109/188  Train Loss: 0.043, Acc: 0.996\n",
      "epoch: 173/300 batch 110/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 173/300 batch 111/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 173/300 batch 112/188  Train Loss: 0.059, Acc: 0.984\n",
      "epoch: 173/300 batch 113/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 173/300 batch 114/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 173/300 batch 115/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 173/300 batch 116/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 173/300 batch 117/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 173/300 batch 118/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 173/300 batch 119/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 173/300 batch 120/188  Train Loss: 0.063, Acc: 0.980\n",
      "epoch: 173/300 batch 121/188  Train Loss: 0.042, Acc: 0.980\n",
      "epoch: 173/300 batch 122/188  Train Loss: 0.088, Acc: 0.984\n",
      "epoch: 173/300 batch 123/188  Train Loss: 0.053, Acc: 0.980\n",
      "epoch: 173/300 batch 124/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 173/300 batch 125/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 173/300 batch 126/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 173/300 batch 127/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 173/300 batch 128/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 173/300 batch 129/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 173/300 batch 130/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 173/300 batch 131/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 173/300 batch 132/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 173/300 batch 133/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 173/300 batch 134/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 173/300 batch 135/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 173/300 batch 136/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 173/300 batch 137/188  Train Loss: 0.074, Acc: 0.980\n",
      "epoch: 173/300 batch 138/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 173/300 batch 139/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 173/300 batch 140/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 173/300 batch 141/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 173/300 batch 142/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 173/300 batch 143/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 173/300 batch 144/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 173/300 batch 145/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 173/300 batch 146/188  Train Loss: 0.025, Acc: 0.988\n",
      "epoch: 173/300 batch 147/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 173/300 batch 148/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 173/300 batch 149/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 173/300 batch 150/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 173/300 batch 151/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 173/300 batch 152/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 173/300 batch 153/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 173/300 batch 154/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 173/300 batch 155/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 173/300 batch 156/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 173/300 batch 157/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 173/300 batch 158/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 173/300 batch 159/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 173/300 batch 160/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 173/300 batch 161/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 173/300 batch 162/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 173/300 batch 163/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 173/300 batch 164/188  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 173/300 batch 165/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 173/300 batch 166/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 173/300 batch 167/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 173/300 batch 168/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 173/300 batch 169/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 173/300 batch 170/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 173/300 batch 171/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 173/300 batch 172/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 173/300 batch 173/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 173/300 batch 174/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 173/300 batch 175/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 173/300 batch 176/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 173/300 batch 177/188  Train Loss: 0.064, Acc: 0.984\n",
      "epoch: 173/300 batch 178/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 173/300 batch 179/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 173/300 batch 180/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 173/300 batch 181/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 173/300 batch 182/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 173/300 batch 183/188  Train Loss: 0.059, Acc: 0.984\n",
      "epoch: 173/300 batch 184/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 173/300 batch 185/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 173/300 batch 186/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 173/300 batch 187/188  Train Loss: 0.044, Acc: 0.992\n",
      "Train Loss: 0.033736, Acc: 0.992\n",
      "Val Loss: 0.057998, Acc: 0.982\n",
      "epoch: 174/300 batch   0/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 174/300 batch   1/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 174/300 batch   2/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 174/300 batch   3/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 174/300 batch   4/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 174/300 batch   5/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 174/300 batch   6/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 174/300 batch   7/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 174/300 batch   8/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 174/300 batch   9/188  Train Loss: 0.051, Acc: 0.996\n",
      "epoch: 174/300 batch  10/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 174/300 batch  11/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 174/300 batch  12/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 174/300 batch  13/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 174/300 batch  14/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 174/300 batch  15/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 174/300 batch  16/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 174/300 batch  17/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 174/300 batch  18/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 174/300 batch  19/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 174/300 batch  20/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 174/300 batch  21/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 174/300 batch  22/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 174/300 batch  23/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 174/300 batch  24/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 174/300 batch  25/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 174/300 batch  26/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 174/300 batch  27/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 174/300 batch  28/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 174/300 batch  29/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 174/300 batch  30/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 174/300 batch  31/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 174/300 batch  32/188  Train Loss: 0.057, Acc: 0.988\n",
      "epoch: 174/300 batch  33/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 174/300 batch  34/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 174/300 batch  35/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 174/300 batch  36/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 174/300 batch  37/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 174/300 batch  38/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 174/300 batch  39/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 174/300 batch  40/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 174/300 batch  41/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 174/300 batch  42/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 174/300 batch  43/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 174/300 batch  44/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 174/300 batch  45/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 174/300 batch  46/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 174/300 batch  47/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 174/300 batch  48/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 174/300 batch  49/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 174/300 batch  50/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 174/300 batch  51/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 174/300 batch  52/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 174/300 batch  53/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 174/300 batch  54/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 174/300 batch  55/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 174/300 batch  56/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 174/300 batch  57/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 174/300 batch  58/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 174/300 batch  59/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 174/300 batch  60/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 174/300 batch  61/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 174/300 batch  62/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 174/300 batch  63/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 174/300 batch  64/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 174/300 batch  65/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 174/300 batch  66/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 174/300 batch  67/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 174/300 batch  68/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 174/300 batch  69/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 174/300 batch  70/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 174/300 batch  71/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 174/300 batch  72/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 174/300 batch  73/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 174/300 batch  74/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 174/300 batch  75/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 174/300 batch  76/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 174/300 batch  77/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 174/300 batch  78/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 174/300 batch  79/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 174/300 batch  80/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 174/300 batch  81/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 174/300 batch  82/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 174/300 batch  83/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 174/300 batch  84/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 174/300 batch  85/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 174/300 batch  86/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 174/300 batch  87/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 174/300 batch  88/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 174/300 batch  89/188  Train Loss: 0.045, Acc: 0.980\n",
      "epoch: 174/300 batch  90/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 174/300 batch  91/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 174/300 batch  92/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 174/300 batch  93/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 174/300 batch  94/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 174/300 batch  95/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 174/300 batch  96/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 174/300 batch  97/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 174/300 batch  98/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 174/300 batch  99/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 174/300 batch 100/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 174/300 batch 101/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 174/300 batch 102/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 174/300 batch 103/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 174/300 batch 104/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 174/300 batch 105/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 174/300 batch 106/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 174/300 batch 107/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 174/300 batch 108/188  Train Loss: 0.064, Acc: 0.980\n",
      "epoch: 174/300 batch 109/188  Train Loss: 0.075, Acc: 0.984\n",
      "epoch: 174/300 batch 110/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 174/300 batch 111/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 174/300 batch 112/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 174/300 batch 113/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 174/300 batch 114/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 174/300 batch 115/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 174/300 batch 116/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 174/300 batch 117/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 174/300 batch 118/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 174/300 batch 119/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 174/300 batch 120/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 174/300 batch 121/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 174/300 batch 122/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 174/300 batch 123/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 174/300 batch 124/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 174/300 batch 125/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 174/300 batch 126/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 174/300 batch 127/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 174/300 batch 128/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 174/300 batch 129/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 174/300 batch 130/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 174/300 batch 131/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 174/300 batch 132/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 174/300 batch 133/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 174/300 batch 134/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 174/300 batch 135/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 174/300 batch 136/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 174/300 batch 137/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 174/300 batch 138/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 174/300 batch 139/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 174/300 batch 140/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 174/300 batch 141/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 174/300 batch 142/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 174/300 batch 143/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 174/300 batch 144/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 174/300 batch 145/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 174/300 batch 146/188  Train Loss: 0.052, Acc: 0.992\n",
      "epoch: 174/300 batch 147/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 174/300 batch 148/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 174/300 batch 149/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 174/300 batch 150/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 174/300 batch 151/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 174/300 batch 152/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 174/300 batch 153/188  Train Loss: 0.082, Acc: 0.988\n",
      "epoch: 174/300 batch 154/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 174/300 batch 155/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 174/300 batch 156/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 174/300 batch 157/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 174/300 batch 158/188  Train Loss: 0.050, Acc: 0.980\n",
      "epoch: 174/300 batch 159/188  Train Loss: 0.045, Acc: 0.980\n",
      "epoch: 174/300 batch 160/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 174/300 batch 161/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 174/300 batch 162/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 174/300 batch 163/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 174/300 batch 164/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 174/300 batch 165/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 174/300 batch 166/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 174/300 batch 167/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 174/300 batch 168/188  Train Loss: 0.043, Acc: 0.980\n",
      "epoch: 174/300 batch 169/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 174/300 batch 170/188  Train Loss: 0.048, Acc: 0.980\n",
      "epoch: 174/300 batch 171/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 174/300 batch 172/188  Train Loss: 0.054, Acc: 0.980\n",
      "epoch: 174/300 batch 173/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 174/300 batch 174/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 174/300 batch 175/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 174/300 batch 176/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 174/300 batch 177/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 174/300 batch 178/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 174/300 batch 179/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 174/300 batch 180/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 174/300 batch 181/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 174/300 batch 182/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 174/300 batch 183/188  Train Loss: 0.039, Acc: 0.980\n",
      "epoch: 174/300 batch 184/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 174/300 batch 185/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 174/300 batch 186/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 174/300 batch 187/188  Train Loss: 0.045, Acc: 0.984\n",
      "Train Loss: 0.033676, Acc: 0.992\n",
      "Val Loss: 0.057412, Acc: 0.983\n",
      "epoch: 175/300 batch   0/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 175/300 batch   1/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 175/300 batch   2/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 175/300 batch   3/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 175/300 batch   4/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 175/300 batch   5/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 175/300 batch   6/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 175/300 batch   7/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 175/300 batch   8/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 175/300 batch   9/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 175/300 batch  10/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 175/300 batch  11/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 175/300 batch  12/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 175/300 batch  13/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 175/300 batch  14/188  Train Loss: 0.059, Acc: 0.984\n",
      "epoch: 175/300 batch  15/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 175/300 batch  16/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 175/300 batch  17/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 175/300 batch  18/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 175/300 batch  19/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 175/300 batch  20/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 175/300 batch  21/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 175/300 batch  22/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 175/300 batch  23/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 175/300 batch  24/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 175/300 batch  25/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 175/300 batch  26/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 175/300 batch  27/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 175/300 batch  28/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 175/300 batch  29/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 175/300 batch  30/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 175/300 batch  31/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 175/300 batch  32/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 175/300 batch  33/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 175/300 batch  34/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 175/300 batch  35/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 175/300 batch  36/188  Train Loss: 0.035, Acc: 1.000\n",
      "epoch: 175/300 batch  37/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 175/300 batch  38/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 175/300 batch  39/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 175/300 batch  40/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 175/300 batch  41/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 175/300 batch  42/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 175/300 batch  43/188  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 175/300 batch  44/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 175/300 batch  45/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 175/300 batch  46/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 175/300 batch  47/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 175/300 batch  48/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 175/300 batch  49/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 175/300 batch  50/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 175/300 batch  51/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 175/300 batch  52/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 175/300 batch  53/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 175/300 batch  54/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 175/300 batch  55/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 175/300 batch  56/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 175/300 batch  57/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 175/300 batch  58/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 175/300 batch  59/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 175/300 batch  60/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 175/300 batch  61/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 175/300 batch  62/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 175/300 batch  63/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 175/300 batch  64/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 175/300 batch  65/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 175/300 batch  66/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 175/300 batch  67/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 175/300 batch  68/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 175/300 batch  69/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 175/300 batch  70/188  Train Loss: 0.034, Acc: 0.984\n",
      "epoch: 175/300 batch  71/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 175/300 batch  72/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 175/300 batch  73/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 175/300 batch  74/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 175/300 batch  75/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 175/300 batch  76/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 175/300 batch  77/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 175/300 batch  78/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 175/300 batch  79/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 175/300 batch  80/188  Train Loss: 0.051, Acc: 0.992\n",
      "epoch: 175/300 batch  81/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 175/300 batch  82/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 175/300 batch  83/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 175/300 batch  84/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 175/300 batch  85/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 175/300 batch  86/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 175/300 batch  87/188  Train Loss: 0.034, Acc: 1.000\n",
      "epoch: 175/300 batch  88/188  Train Loss: 0.079, Acc: 0.984\n",
      "epoch: 175/300 batch  89/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 175/300 batch  90/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 175/300 batch  91/188  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 175/300 batch  92/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 175/300 batch  93/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 175/300 batch  94/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 175/300 batch  95/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 175/300 batch  96/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 175/300 batch  97/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 175/300 batch  98/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 175/300 batch  99/188  Train Loss: 0.048, Acc: 0.977\n",
      "epoch: 175/300 batch 100/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 175/300 batch 101/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 175/300 batch 102/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 175/300 batch 103/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 175/300 batch 104/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 175/300 batch 105/188  Train Loss: 0.062, Acc: 0.984\n",
      "epoch: 175/300 batch 106/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 175/300 batch 107/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 175/300 batch 108/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 175/300 batch 109/188  Train Loss: 0.060, Acc: 0.988\n",
      "epoch: 175/300 batch 110/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 175/300 batch 111/188  Train Loss: 0.060, Acc: 0.977\n",
      "epoch: 175/300 batch 112/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 175/300 batch 113/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 175/300 batch 114/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 175/300 batch 115/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 175/300 batch 116/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 175/300 batch 117/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 175/300 batch 118/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 175/300 batch 119/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 175/300 batch 120/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 175/300 batch 121/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 175/300 batch 122/188  Train Loss: 0.062, Acc: 0.980\n",
      "epoch: 175/300 batch 123/188  Train Loss: 0.043, Acc: 0.996\n",
      "epoch: 175/300 batch 124/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 175/300 batch 125/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 175/300 batch 126/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 175/300 batch 127/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 175/300 batch 128/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 175/300 batch 129/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 175/300 batch 130/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 175/300 batch 131/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 175/300 batch 132/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 175/300 batch 133/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 175/300 batch 134/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 175/300 batch 135/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 175/300 batch 136/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 175/300 batch 137/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 175/300 batch 138/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 175/300 batch 139/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 175/300 batch 140/188  Train Loss: 0.046, Acc: 0.996\n",
      "epoch: 175/300 batch 141/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 175/300 batch 142/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 175/300 batch 143/188  Train Loss: 0.049, Acc: 0.980\n",
      "epoch: 175/300 batch 144/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 175/300 batch 145/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 175/300 batch 146/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 175/300 batch 147/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 175/300 batch 148/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 175/300 batch 149/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 175/300 batch 150/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 175/300 batch 151/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 175/300 batch 152/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 175/300 batch 153/188  Train Loss: 0.045, Acc: 0.980\n",
      "epoch: 175/300 batch 154/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 175/300 batch 155/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 175/300 batch 156/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 175/300 batch 157/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 175/300 batch 158/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 175/300 batch 159/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 175/300 batch 160/188  Train Loss: 0.043, Acc: 0.996\n",
      "epoch: 175/300 batch 161/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 175/300 batch 162/188  Train Loss: 0.026, Acc: 0.988\n",
      "epoch: 175/300 batch 163/188  Train Loss: 0.066, Acc: 0.980\n",
      "epoch: 175/300 batch 164/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 175/300 batch 165/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 175/300 batch 166/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 175/300 batch 167/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 175/300 batch 168/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 175/300 batch 169/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 175/300 batch 170/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 175/300 batch 171/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 175/300 batch 172/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 175/300 batch 173/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 175/300 batch 174/188  Train Loss: 0.052, Acc: 0.992\n",
      "epoch: 175/300 batch 175/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 175/300 batch 176/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 175/300 batch 177/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 175/300 batch 178/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 175/300 batch 179/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 175/300 batch 180/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 175/300 batch 181/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 175/300 batch 182/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 175/300 batch 183/188  Train Loss: 0.042, Acc: 0.996\n",
      "epoch: 175/300 batch 184/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 175/300 batch 185/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 175/300 batch 186/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 175/300 batch 187/188  Train Loss: 0.018, Acc: 0.992\n",
      "Train Loss: 0.033558, Acc: 0.993\n",
      "Val Loss: 0.057166, Acc: 0.983\n",
      "epoch: 176/300 batch   0/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 176/300 batch   1/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 176/300 batch   2/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 176/300 batch   3/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 176/300 batch   4/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 176/300 batch   5/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 176/300 batch   6/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 176/300 batch   7/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 176/300 batch   8/188  Train Loss: 0.032, Acc: 1.000\n",
      "epoch: 176/300 batch   9/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 176/300 batch  10/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 176/300 batch  11/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 176/300 batch  12/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 176/300 batch  13/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 176/300 batch  14/188  Train Loss: 0.063, Acc: 0.988\n",
      "epoch: 176/300 batch  15/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 176/300 batch  16/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 176/300 batch  17/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 176/300 batch  18/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 176/300 batch  19/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 176/300 batch  20/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 176/300 batch  21/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 176/300 batch  22/188  Train Loss: 0.062, Acc: 0.980\n",
      "epoch: 176/300 batch  23/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 176/300 batch  24/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 176/300 batch  25/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 176/300 batch  26/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 176/300 batch  27/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 176/300 batch  28/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 176/300 batch  29/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 176/300 batch  30/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 176/300 batch  31/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 176/300 batch  32/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 176/300 batch  33/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 176/300 batch  34/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 176/300 batch  35/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 176/300 batch  36/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 176/300 batch  37/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 176/300 batch  38/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 176/300 batch  39/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 176/300 batch  40/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 176/300 batch  41/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 176/300 batch  42/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 176/300 batch  43/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 176/300 batch  44/188  Train Loss: 0.042, Acc: 0.996\n",
      "epoch: 176/300 batch  45/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 176/300 batch  46/188  Train Loss: 0.049, Acc: 0.980\n",
      "epoch: 176/300 batch  47/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 176/300 batch  48/188  Train Loss: 0.061, Acc: 0.984\n",
      "epoch: 176/300 batch  49/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 176/300 batch  50/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 176/300 batch  51/188  Train Loss: 0.058, Acc: 0.992\n",
      "epoch: 176/300 batch  52/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 176/300 batch  53/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 176/300 batch  54/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 176/300 batch  55/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 176/300 batch  56/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 176/300 batch  57/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 176/300 batch  58/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 176/300 batch  59/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 176/300 batch  60/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 176/300 batch  61/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 176/300 batch  62/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 176/300 batch  63/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 176/300 batch  64/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 176/300 batch  65/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 176/300 batch  66/188  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 176/300 batch  67/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 176/300 batch  68/188  Train Loss: 0.061, Acc: 0.988\n",
      "epoch: 176/300 batch  69/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 176/300 batch  70/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 176/300 batch  71/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 176/300 batch  72/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 176/300 batch  73/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 176/300 batch  74/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 176/300 batch  75/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 176/300 batch  76/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 176/300 batch  77/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 176/300 batch  78/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 176/300 batch  79/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 176/300 batch  80/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 176/300 batch  81/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 176/300 batch  82/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 176/300 batch  83/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 176/300 batch  84/188  Train Loss: 0.074, Acc: 0.980\n",
      "epoch: 176/300 batch  85/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 176/300 batch  86/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 176/300 batch  87/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 176/300 batch  88/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 176/300 batch  89/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 176/300 batch  90/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 176/300 batch  91/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 176/300 batch  92/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 176/300 batch  93/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 176/300 batch  94/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 176/300 batch  95/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 176/300 batch  96/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 176/300 batch  97/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 176/300 batch  98/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 176/300 batch  99/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 176/300 batch 100/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 176/300 batch 101/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 176/300 batch 102/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 176/300 batch 103/188  Train Loss: 0.052, Acc: 0.996\n",
      "epoch: 176/300 batch 104/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 176/300 batch 105/188  Train Loss: 0.050, Acc: 0.980\n",
      "epoch: 176/300 batch 106/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 176/300 batch 107/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 176/300 batch 108/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 176/300 batch 109/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 176/300 batch 110/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 176/300 batch 111/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 176/300 batch 112/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 176/300 batch 113/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 176/300 batch 114/188  Train Loss: 0.080, Acc: 0.977\n",
      "epoch: 176/300 batch 115/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 176/300 batch 116/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 176/300 batch 117/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 176/300 batch 118/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 176/300 batch 119/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 176/300 batch 120/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 176/300 batch 121/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 176/300 batch 122/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 176/300 batch 123/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 176/300 batch 124/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 176/300 batch 125/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 176/300 batch 126/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 176/300 batch 127/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 176/300 batch 128/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 176/300 batch 129/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 176/300 batch 130/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 176/300 batch 131/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 176/300 batch 132/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 176/300 batch 133/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 176/300 batch 134/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 176/300 batch 135/188  Train Loss: 0.065, Acc: 0.988\n",
      "epoch: 176/300 batch 136/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 176/300 batch 137/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 176/300 batch 138/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 176/300 batch 139/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 176/300 batch 140/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 176/300 batch 141/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 176/300 batch 142/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 176/300 batch 143/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 176/300 batch 144/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 176/300 batch 145/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 176/300 batch 146/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 176/300 batch 147/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 176/300 batch 148/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 176/300 batch 149/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 176/300 batch 150/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 176/300 batch 151/188  Train Loss: 0.041, Acc: 0.980\n",
      "epoch: 176/300 batch 152/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 176/300 batch 153/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 176/300 batch 154/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 176/300 batch 155/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 176/300 batch 156/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 176/300 batch 157/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 176/300 batch 158/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 176/300 batch 159/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 176/300 batch 160/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 176/300 batch 161/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 176/300 batch 162/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 176/300 batch 163/188  Train Loss: 0.027, Acc: 0.988\n",
      "epoch: 176/300 batch 164/188  Train Loss: 0.025, Acc: 0.988\n",
      "epoch: 176/300 batch 165/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 176/300 batch 166/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 176/300 batch 167/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 176/300 batch 168/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 176/300 batch 169/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 176/300 batch 170/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 176/300 batch 171/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 176/300 batch 172/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 176/300 batch 173/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 176/300 batch 174/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 176/300 batch 175/188  Train Loss: 0.068, Acc: 0.984\n",
      "epoch: 176/300 batch 176/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 176/300 batch 177/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 176/300 batch 178/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 176/300 batch 179/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 176/300 batch 180/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 176/300 batch 181/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 176/300 batch 182/188  Train Loss: 0.032, Acc: 0.984\n",
      "epoch: 176/300 batch 183/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 176/300 batch 184/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 176/300 batch 185/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 176/300 batch 186/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 176/300 batch 187/188  Train Loss: 0.013, Acc: 1.000\n",
      "Train Loss: 0.033647, Acc: 0.993\n",
      "Val Loss: 0.057295, Acc: 0.983\n",
      "epoch: 177/300 batch   0/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 177/300 batch   1/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 177/300 batch   2/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 177/300 batch   3/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 177/300 batch   4/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 177/300 batch   5/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 177/300 batch   6/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 177/300 batch   7/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 177/300 batch   8/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 177/300 batch   9/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 177/300 batch  10/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 177/300 batch  11/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 177/300 batch  12/188  Train Loss: 0.060, Acc: 0.992\n",
      "epoch: 177/300 batch  13/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 177/300 batch  14/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 177/300 batch  15/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 177/300 batch  16/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 177/300 batch  17/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 177/300 batch  18/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 177/300 batch  19/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 177/300 batch  20/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 177/300 batch  21/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 177/300 batch  22/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 177/300 batch  23/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 177/300 batch  24/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 177/300 batch  25/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 177/300 batch  26/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 177/300 batch  27/188  Train Loss: 0.061, Acc: 0.988\n",
      "epoch: 177/300 batch  28/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 177/300 batch  29/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 177/300 batch  30/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 177/300 batch  31/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 177/300 batch  32/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 177/300 batch  33/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 177/300 batch  34/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 177/300 batch  35/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 177/300 batch  36/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 177/300 batch  37/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 177/300 batch  38/188  Train Loss: 0.055, Acc: 0.980\n",
      "epoch: 177/300 batch  39/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 177/300 batch  40/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 177/300 batch  41/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 177/300 batch  42/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 177/300 batch  43/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 177/300 batch  44/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 177/300 batch  45/188  Train Loss: 0.043, Acc: 0.980\n",
      "epoch: 177/300 batch  46/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 177/300 batch  47/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 177/300 batch  48/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 177/300 batch  49/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 177/300 batch  50/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 177/300 batch  51/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 177/300 batch  52/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 177/300 batch  53/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 177/300 batch  54/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 177/300 batch  55/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 177/300 batch  56/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 177/300 batch  57/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 177/300 batch  58/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 177/300 batch  59/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 177/300 batch  60/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 177/300 batch  61/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 177/300 batch  62/188  Train Loss: 0.054, Acc: 0.992\n",
      "epoch: 177/300 batch  63/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 177/300 batch  64/188  Train Loss: 0.052, Acc: 0.977\n",
      "epoch: 177/300 batch  65/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 177/300 batch  66/188  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 177/300 batch  67/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 177/300 batch  68/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 177/300 batch  69/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 177/300 batch  70/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 177/300 batch  71/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 177/300 batch  72/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 177/300 batch  73/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 177/300 batch  74/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 177/300 batch  75/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 177/300 batch  76/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 177/300 batch  77/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 177/300 batch  78/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 177/300 batch  79/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 177/300 batch  80/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 177/300 batch  81/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 177/300 batch  82/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 177/300 batch  83/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 177/300 batch  84/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 177/300 batch  85/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 177/300 batch  86/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 177/300 batch  87/188  Train Loss: 0.054, Acc: 0.977\n",
      "epoch: 177/300 batch  88/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 177/300 batch  89/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 177/300 batch  90/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 177/300 batch  91/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 177/300 batch  92/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 177/300 batch  93/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 177/300 batch  94/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 177/300 batch  95/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 177/300 batch  96/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 177/300 batch  97/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 177/300 batch  98/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 177/300 batch  99/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 177/300 batch 100/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 177/300 batch 101/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 177/300 batch 102/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 177/300 batch 103/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 177/300 batch 104/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 177/300 batch 105/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 177/300 batch 106/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 177/300 batch 107/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 177/300 batch 108/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 177/300 batch 109/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 177/300 batch 110/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 177/300 batch 111/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 177/300 batch 112/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 177/300 batch 113/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 177/300 batch 114/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 177/300 batch 115/188  Train Loss: 0.048, Acc: 0.980\n",
      "epoch: 177/300 batch 116/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 177/300 batch 117/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 177/300 batch 118/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 177/300 batch 119/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 177/300 batch 120/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 177/300 batch 121/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 177/300 batch 122/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 177/300 batch 123/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 177/300 batch 124/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 177/300 batch 125/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 177/300 batch 126/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 177/300 batch 127/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 177/300 batch 128/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 177/300 batch 129/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 177/300 batch 130/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 177/300 batch 131/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 177/300 batch 132/188  Train Loss: 0.027, Acc: 0.988\n",
      "epoch: 177/300 batch 133/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 177/300 batch 134/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 177/300 batch 135/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 177/300 batch 136/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 177/300 batch 137/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 177/300 batch 138/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 177/300 batch 139/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 177/300 batch 140/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 177/300 batch 141/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 177/300 batch 142/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 177/300 batch 143/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 177/300 batch 144/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 177/300 batch 145/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 177/300 batch 146/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 177/300 batch 147/188  Train Loss: 0.026, Acc: 0.988\n",
      "epoch: 177/300 batch 148/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 177/300 batch 149/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 177/300 batch 150/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 177/300 batch 151/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 177/300 batch 152/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 177/300 batch 153/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 177/300 batch 154/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 177/300 batch 155/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 177/300 batch 156/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 177/300 batch 157/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 177/300 batch 158/188  Train Loss: 0.056, Acc: 0.992\n",
      "epoch: 177/300 batch 159/188  Train Loss: 0.075, Acc: 0.973\n",
      "epoch: 177/300 batch 160/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 177/300 batch 161/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 177/300 batch 162/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 177/300 batch 163/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 177/300 batch 164/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 177/300 batch 165/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 177/300 batch 166/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 177/300 batch 167/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 177/300 batch 168/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 177/300 batch 169/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 177/300 batch 170/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 177/300 batch 171/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 177/300 batch 172/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 177/300 batch 173/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 177/300 batch 174/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 177/300 batch 175/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 177/300 batch 176/188  Train Loss: 0.061, Acc: 0.984\n",
      "epoch: 177/300 batch 177/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 177/300 batch 178/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 177/300 batch 179/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 177/300 batch 180/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 177/300 batch 181/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 177/300 batch 182/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 177/300 batch 183/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 177/300 batch 184/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 177/300 batch 185/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 177/300 batch 186/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 177/300 batch 187/188  Train Loss: 0.090, Acc: 0.969\n",
      "Train Loss: 0.033760, Acc: 0.993\n",
      "Val Loss: 0.057324, Acc: 0.982\n",
      "epoch: 178/300 batch   0/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 178/300 batch   1/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 178/300 batch   2/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 178/300 batch   3/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 178/300 batch   4/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 178/300 batch   5/188  Train Loss: 0.016, Acc: 0.996\n",
      "epoch: 178/300 batch   6/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 178/300 batch   7/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 178/300 batch   8/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 178/300 batch   9/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 178/300 batch  10/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 178/300 batch  11/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 178/300 batch  12/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 178/300 batch  13/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 178/300 batch  14/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 178/300 batch  15/188  Train Loss: 0.044, Acc: 0.996\n",
      "epoch: 178/300 batch  16/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 178/300 batch  17/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 178/300 batch  18/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 178/300 batch  19/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 178/300 batch  20/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 178/300 batch  21/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 178/300 batch  22/188  Train Loss: 0.062, Acc: 0.984\n",
      "epoch: 178/300 batch  23/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 178/300 batch  24/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 178/300 batch  25/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 178/300 batch  26/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 178/300 batch  27/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 178/300 batch  28/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 178/300 batch  29/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 178/300 batch  30/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 178/300 batch  31/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 178/300 batch  32/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 178/300 batch  33/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 178/300 batch  34/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 178/300 batch  35/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 178/300 batch  36/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 178/300 batch  37/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 178/300 batch  38/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 178/300 batch  39/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 178/300 batch  40/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 178/300 batch  41/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 178/300 batch  42/188  Train Loss: 0.042, Acc: 0.980\n",
      "epoch: 178/300 batch  43/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 178/300 batch  44/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 178/300 batch  45/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 178/300 batch  46/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 178/300 batch  47/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 178/300 batch  48/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 178/300 batch  49/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 178/300 batch  50/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 178/300 batch  51/188  Train Loss: 0.043, Acc: 0.980\n",
      "epoch: 178/300 batch  52/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 178/300 batch  53/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 178/300 batch  54/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 178/300 batch  55/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 178/300 batch  56/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 178/300 batch  57/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 178/300 batch  58/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 178/300 batch  59/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 178/300 batch  60/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 178/300 batch  61/188  Train Loss: 0.054, Acc: 0.980\n",
      "epoch: 178/300 batch  62/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 178/300 batch  63/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 178/300 batch  64/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 178/300 batch  65/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 178/300 batch  66/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 178/300 batch  67/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 178/300 batch  68/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 178/300 batch  69/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 178/300 batch  70/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 178/300 batch  71/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 178/300 batch  72/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 178/300 batch  73/188  Train Loss: 0.051, Acc: 0.992\n",
      "epoch: 178/300 batch  74/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 178/300 batch  75/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 178/300 batch  76/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 178/300 batch  77/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 178/300 batch  78/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 178/300 batch  79/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 178/300 batch  80/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 178/300 batch  81/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 178/300 batch  82/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 178/300 batch  83/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 178/300 batch  84/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 178/300 batch  85/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 178/300 batch  86/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 178/300 batch  87/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 178/300 batch  88/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 178/300 batch  89/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 178/300 batch  90/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 178/300 batch  91/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 178/300 batch  92/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 178/300 batch  93/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 178/300 batch  94/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 178/300 batch  95/188  Train Loss: 0.067, Acc: 0.988\n",
      "epoch: 178/300 batch  96/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 178/300 batch  97/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 178/300 batch  98/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 178/300 batch  99/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 178/300 batch 100/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 178/300 batch 101/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 178/300 batch 102/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 178/300 batch 103/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 178/300 batch 104/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 178/300 batch 105/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 178/300 batch 106/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 178/300 batch 107/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 178/300 batch 108/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 178/300 batch 109/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 178/300 batch 110/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 178/300 batch 111/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 178/300 batch 112/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 178/300 batch 113/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 178/300 batch 114/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 178/300 batch 115/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 178/300 batch 116/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 178/300 batch 117/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 178/300 batch 118/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 178/300 batch 119/188  Train Loss: 0.054, Acc: 0.992\n",
      "epoch: 178/300 batch 120/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 178/300 batch 121/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 178/300 batch 122/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 178/300 batch 123/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 178/300 batch 124/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 178/300 batch 125/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 178/300 batch 126/188  Train Loss: 0.059, Acc: 0.980\n",
      "epoch: 178/300 batch 127/188  Train Loss: 0.015, Acc: 0.996\n",
      "epoch: 178/300 batch 128/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 178/300 batch 129/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 178/300 batch 130/188  Train Loss: 0.054, Acc: 0.992\n",
      "epoch: 178/300 batch 131/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 178/300 batch 132/188  Train Loss: 0.061, Acc: 0.977\n",
      "epoch: 178/300 batch 133/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 178/300 batch 134/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 178/300 batch 135/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 178/300 batch 136/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 178/300 batch 137/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 178/300 batch 138/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 178/300 batch 139/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 178/300 batch 140/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 178/300 batch 141/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 178/300 batch 142/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 178/300 batch 143/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 178/300 batch 144/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 178/300 batch 145/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 178/300 batch 146/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 178/300 batch 147/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 178/300 batch 148/188  Train Loss: 0.031, Acc: 1.000\n",
      "epoch: 178/300 batch 149/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 178/300 batch 150/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 178/300 batch 151/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 178/300 batch 152/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 178/300 batch 153/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 178/300 batch 154/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 178/300 batch 155/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 178/300 batch 156/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 178/300 batch 157/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 178/300 batch 158/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 178/300 batch 159/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 178/300 batch 160/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 178/300 batch 161/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 178/300 batch 162/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 178/300 batch 163/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 178/300 batch 164/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 178/300 batch 165/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 178/300 batch 166/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 178/300 batch 167/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 178/300 batch 168/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 178/300 batch 169/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 178/300 batch 170/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 178/300 batch 171/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 178/300 batch 172/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 178/300 batch 173/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 178/300 batch 174/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 178/300 batch 175/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 178/300 batch 176/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 178/300 batch 177/188  Train Loss: 0.050, Acc: 0.980\n",
      "epoch: 178/300 batch 178/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 178/300 batch 179/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 178/300 batch 180/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 178/300 batch 181/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 178/300 batch 182/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 178/300 batch 183/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 178/300 batch 184/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 178/300 batch 185/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 178/300 batch 186/188  Train Loss: 0.060, Acc: 0.984\n",
      "epoch: 178/300 batch 187/188  Train Loss: 0.011, Acc: 1.000\n",
      "Train Loss: 0.033543, Acc: 0.993\n",
      "Val Loss: 0.057543, Acc: 0.983\n",
      "epoch: 179/300 batch   0/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 179/300 batch   1/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 179/300 batch   2/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 179/300 batch   3/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 179/300 batch   4/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 179/300 batch   5/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 179/300 batch   6/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 179/300 batch   7/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 179/300 batch   8/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 179/300 batch   9/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 179/300 batch  10/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 179/300 batch  11/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 179/300 batch  12/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 179/300 batch  13/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 179/300 batch  14/188  Train Loss: 0.048, Acc: 0.996\n",
      "epoch: 179/300 batch  15/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 179/300 batch  16/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 179/300 batch  17/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 179/300 batch  18/188  Train Loss: 0.080, Acc: 0.969\n",
      "epoch: 179/300 batch  19/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 179/300 batch  20/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 179/300 batch  21/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 179/300 batch  22/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 179/300 batch  23/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 179/300 batch  24/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 179/300 batch  25/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 179/300 batch  26/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 179/300 batch  27/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 179/300 batch  28/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 179/300 batch  29/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 179/300 batch  30/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 179/300 batch  31/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 179/300 batch  32/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 179/300 batch  33/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 179/300 batch  34/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 179/300 batch  35/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 179/300 batch  36/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 179/300 batch  37/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 179/300 batch  38/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 179/300 batch  39/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 179/300 batch  40/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 179/300 batch  41/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 179/300 batch  42/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 179/300 batch  43/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 179/300 batch  44/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 179/300 batch  45/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 179/300 batch  46/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 179/300 batch  47/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 179/300 batch  48/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 179/300 batch  49/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 179/300 batch  50/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 179/300 batch  51/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 179/300 batch  52/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 179/300 batch  53/188  Train Loss: 0.023, Acc: 0.988\n",
      "epoch: 179/300 batch  54/188  Train Loss: 0.066, Acc: 0.980\n",
      "epoch: 179/300 batch  55/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 179/300 batch  56/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 179/300 batch  57/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 179/300 batch  58/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 179/300 batch  59/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 179/300 batch  60/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 179/300 batch  61/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 179/300 batch  62/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 179/300 batch  63/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 179/300 batch  64/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 179/300 batch  65/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 179/300 batch  66/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 179/300 batch  67/188  Train Loss: 0.016, Acc: 0.996\n",
      "epoch: 179/300 batch  68/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 179/300 batch  69/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 179/300 batch  70/188  Train Loss: 0.048, Acc: 0.980\n",
      "epoch: 179/300 batch  71/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 179/300 batch  72/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 179/300 batch  73/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 179/300 batch  74/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 179/300 batch  75/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 179/300 batch  76/188  Train Loss: 0.034, Acc: 1.000\n",
      "epoch: 179/300 batch  77/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 179/300 batch  78/188  Train Loss: 0.032, Acc: 1.000\n",
      "epoch: 179/300 batch  79/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 179/300 batch  80/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 179/300 batch  81/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 179/300 batch  82/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 179/300 batch  83/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 179/300 batch  84/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 179/300 batch  85/188  Train Loss: 0.081, Acc: 0.988\n",
      "epoch: 179/300 batch  86/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 179/300 batch  87/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 179/300 batch  88/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 179/300 batch  89/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 179/300 batch  90/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 179/300 batch  91/188  Train Loss: 0.057, Acc: 0.980\n",
      "epoch: 179/300 batch  92/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 179/300 batch  93/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 179/300 batch  94/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 179/300 batch  95/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 179/300 batch  96/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 179/300 batch  97/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 179/300 batch  98/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 179/300 batch  99/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 179/300 batch 100/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 179/300 batch 101/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 179/300 batch 102/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 179/300 batch 103/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 179/300 batch 104/188  Train Loss: 0.045, Acc: 0.977\n",
      "epoch: 179/300 batch 105/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 179/300 batch 106/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 179/300 batch 107/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 179/300 batch 108/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 179/300 batch 109/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 179/300 batch 110/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 179/300 batch 111/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 179/300 batch 112/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 179/300 batch 113/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 179/300 batch 114/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 179/300 batch 115/188  Train Loss: 0.060, Acc: 0.984\n",
      "epoch: 179/300 batch 116/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 179/300 batch 117/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 179/300 batch 118/188  Train Loss: 0.033, Acc: 0.984\n",
      "epoch: 179/300 batch 119/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 179/300 batch 120/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 179/300 batch 121/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 179/300 batch 122/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 179/300 batch 123/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 179/300 batch 124/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 179/300 batch 125/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 179/300 batch 126/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 179/300 batch 127/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 179/300 batch 128/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 179/300 batch 129/188  Train Loss: 0.024, Acc: 0.988\n",
      "epoch: 179/300 batch 130/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 179/300 batch 131/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 179/300 batch 132/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 179/300 batch 133/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 179/300 batch 134/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 179/300 batch 135/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 179/300 batch 136/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 179/300 batch 137/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 179/300 batch 138/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 179/300 batch 139/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 179/300 batch 140/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 179/300 batch 141/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 179/300 batch 142/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 179/300 batch 143/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 179/300 batch 144/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 179/300 batch 145/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 179/300 batch 146/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 179/300 batch 147/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 179/300 batch 148/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 179/300 batch 149/188  Train Loss: 0.055, Acc: 0.977\n",
      "epoch: 179/300 batch 150/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 179/300 batch 151/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 179/300 batch 152/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 179/300 batch 153/188  Train Loss: 0.060, Acc: 0.984\n",
      "epoch: 179/300 batch 154/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 179/300 batch 155/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 179/300 batch 156/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 179/300 batch 157/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 179/300 batch 158/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 179/300 batch 159/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 179/300 batch 160/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 179/300 batch 161/188  Train Loss: 0.070, Acc: 0.969\n",
      "epoch: 179/300 batch 162/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 179/300 batch 163/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 179/300 batch 164/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 179/300 batch 165/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 179/300 batch 166/188  Train Loss: 0.051, Acc: 0.996\n",
      "epoch: 179/300 batch 167/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 179/300 batch 168/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 179/300 batch 169/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 179/300 batch 170/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 179/300 batch 171/188  Train Loss: 0.064, Acc: 0.988\n",
      "epoch: 179/300 batch 172/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 179/300 batch 173/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 179/300 batch 174/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 179/300 batch 175/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 179/300 batch 176/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 179/300 batch 177/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 179/300 batch 178/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 179/300 batch 179/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 179/300 batch 180/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 179/300 batch 181/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 179/300 batch 182/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 179/300 batch 183/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 179/300 batch 184/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 179/300 batch 185/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 179/300 batch 186/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 179/300 batch 187/188  Train Loss: 0.027, Acc: 0.992\n",
      "Train Loss: 0.033512, Acc: 0.993\n",
      "Val Loss: 0.057320, Acc: 0.982\n",
      "epoch: 180/300 batch   0/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 180/300 batch   1/188  Train Loss: 0.055, Acc: 0.977\n",
      "epoch: 180/300 batch   2/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 180/300 batch   3/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 180/300 batch   4/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 180/300 batch   5/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 180/300 batch   6/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 180/300 batch   7/188  Train Loss: 0.057, Acc: 0.988\n",
      "epoch: 180/300 batch   8/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 180/300 batch   9/188  Train Loss: 0.062, Acc: 0.980\n",
      "epoch: 180/300 batch  10/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 180/300 batch  11/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 180/300 batch  12/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 180/300 batch  13/188  Train Loss: 0.034, Acc: 1.000\n",
      "epoch: 180/300 batch  14/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 180/300 batch  15/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 180/300 batch  16/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 180/300 batch  17/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 180/300 batch  18/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 180/300 batch  19/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 180/300 batch  20/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 180/300 batch  21/188  Train Loss: 0.054, Acc: 0.980\n",
      "epoch: 180/300 batch  22/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 180/300 batch  23/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 180/300 batch  24/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 180/300 batch  25/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 180/300 batch  26/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 180/300 batch  27/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 180/300 batch  28/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 180/300 batch  29/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 180/300 batch  30/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 180/300 batch  31/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 180/300 batch  32/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 180/300 batch  33/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 180/300 batch  34/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 180/300 batch  35/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 180/300 batch  36/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 180/300 batch  37/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 180/300 batch  38/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 180/300 batch  39/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 180/300 batch  40/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 180/300 batch  41/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 180/300 batch  42/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 180/300 batch  43/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 180/300 batch  44/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 180/300 batch  45/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 180/300 batch  46/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 180/300 batch  47/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 180/300 batch  48/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 180/300 batch  49/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 180/300 batch  50/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 180/300 batch  51/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 180/300 batch  52/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 180/300 batch  53/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 180/300 batch  54/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 180/300 batch  55/188  Train Loss: 0.062, Acc: 0.980\n",
      "epoch: 180/300 batch  56/188  Train Loss: 0.056, Acc: 0.977\n",
      "epoch: 180/300 batch  57/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 180/300 batch  58/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 180/300 batch  59/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 180/300 batch  60/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 180/300 batch  61/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 180/300 batch  62/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 180/300 batch  63/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 180/300 batch  64/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 180/300 batch  65/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 180/300 batch  66/188  Train Loss: 0.052, Acc: 0.980\n",
      "epoch: 180/300 batch  67/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 180/300 batch  68/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 180/300 batch  69/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 180/300 batch  70/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 180/300 batch  71/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 180/300 batch  72/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 180/300 batch  73/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 180/300 batch  74/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 180/300 batch  75/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 180/300 batch  76/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 180/300 batch  77/188  Train Loss: 0.042, Acc: 0.996\n",
      "epoch: 180/300 batch  78/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 180/300 batch  79/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 180/300 batch  80/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 180/300 batch  81/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 180/300 batch  82/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 180/300 batch  83/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 180/300 batch  84/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 180/300 batch  85/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 180/300 batch  86/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 180/300 batch  87/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 180/300 batch  88/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 180/300 batch  89/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 180/300 batch  90/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 180/300 batch  91/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 180/300 batch  92/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 180/300 batch  93/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 180/300 batch  94/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 180/300 batch  95/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 180/300 batch  96/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 180/300 batch  97/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 180/300 batch  98/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 180/300 batch  99/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 180/300 batch 100/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 180/300 batch 101/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 180/300 batch 102/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 180/300 batch 103/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 180/300 batch 104/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 180/300 batch 105/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 180/300 batch 106/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 180/300 batch 107/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 180/300 batch 108/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 180/300 batch 109/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 180/300 batch 110/188  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 180/300 batch 111/188  Train Loss: 0.068, Acc: 0.984\n",
      "epoch: 180/300 batch 112/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 180/300 batch 113/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 180/300 batch 114/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 180/300 batch 115/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 180/300 batch 116/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 180/300 batch 117/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 180/300 batch 118/188  Train Loss: 0.047, Acc: 0.980\n",
      "epoch: 180/300 batch 119/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 180/300 batch 120/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 180/300 batch 121/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 180/300 batch 122/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 180/300 batch 123/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 180/300 batch 124/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 180/300 batch 125/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 180/300 batch 126/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 180/300 batch 127/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 180/300 batch 128/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 180/300 batch 129/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 180/300 batch 130/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 180/300 batch 131/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 180/300 batch 132/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 180/300 batch 133/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 180/300 batch 134/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 180/300 batch 135/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 180/300 batch 136/188  Train Loss: 0.060, Acc: 0.973\n",
      "epoch: 180/300 batch 137/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 180/300 batch 138/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 180/300 batch 139/188  Train Loss: 0.051, Acc: 0.992\n",
      "epoch: 180/300 batch 140/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 180/300 batch 141/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 180/300 batch 142/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 180/300 batch 143/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 180/300 batch 144/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 180/300 batch 145/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 180/300 batch 146/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 180/300 batch 147/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 180/300 batch 148/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 180/300 batch 149/188  Train Loss: 0.080, Acc: 0.977\n",
      "epoch: 180/300 batch 150/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 180/300 batch 151/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 180/300 batch 152/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 180/300 batch 153/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 180/300 batch 154/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 180/300 batch 155/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 180/300 batch 156/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 180/300 batch 157/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 180/300 batch 158/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 180/300 batch 159/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 180/300 batch 160/188  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 180/300 batch 161/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 180/300 batch 162/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 180/300 batch 163/188  Train Loss: 0.065, Acc: 0.984\n",
      "epoch: 180/300 batch 164/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 180/300 batch 165/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 180/300 batch 166/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 180/300 batch 167/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 180/300 batch 168/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 180/300 batch 169/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 180/300 batch 170/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 180/300 batch 171/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 180/300 batch 172/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 180/300 batch 173/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 180/300 batch 174/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 180/300 batch 175/188  Train Loss: 0.057, Acc: 0.980\n",
      "epoch: 180/300 batch 176/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 180/300 batch 177/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 180/300 batch 178/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 180/300 batch 179/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 180/300 batch 180/188  Train Loss: 0.077, Acc: 0.992\n",
      "epoch: 180/300 batch 181/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 180/300 batch 182/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 180/300 batch 183/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 180/300 batch 184/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 180/300 batch 185/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 180/300 batch 186/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 180/300 batch 187/188  Train Loss: 0.029, Acc: 0.984\n",
      "Train Loss: 0.033587, Acc: 0.992\n",
      "Val Loss: 0.057636, Acc: 0.982\n",
      "epoch: 181/300 batch   0/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 181/300 batch   1/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 181/300 batch   2/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 181/300 batch   3/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 181/300 batch   4/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 181/300 batch   5/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 181/300 batch   6/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 181/300 batch   7/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 181/300 batch   8/188  Train Loss: 0.072, Acc: 0.977\n",
      "epoch: 181/300 batch   9/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 181/300 batch  10/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 181/300 batch  11/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 181/300 batch  12/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 181/300 batch  13/188  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 181/300 batch  14/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 181/300 batch  15/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 181/300 batch  16/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 181/300 batch  17/188  Train Loss: 0.067, Acc: 0.984\n",
      "epoch: 181/300 batch  18/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 181/300 batch  19/188  Train Loss: 0.061, Acc: 0.973\n",
      "epoch: 181/300 batch  20/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 181/300 batch  21/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 181/300 batch  22/188  Train Loss: 0.059, Acc: 0.973\n",
      "epoch: 181/300 batch  23/188  Train Loss: 0.022, Acc: 0.988\n",
      "epoch: 181/300 batch  24/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 181/300 batch  25/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 181/300 batch  26/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 181/300 batch  27/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 181/300 batch  28/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 181/300 batch  29/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 181/300 batch  30/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 181/300 batch  31/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 181/300 batch  32/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 181/300 batch  33/188  Train Loss: 0.063, Acc: 0.980\n",
      "epoch: 181/300 batch  34/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 181/300 batch  35/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 181/300 batch  36/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 181/300 batch  37/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 181/300 batch  38/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 181/300 batch  39/188  Train Loss: 0.054, Acc: 0.980\n",
      "epoch: 181/300 batch  40/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 181/300 batch  41/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 181/300 batch  42/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 181/300 batch  43/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 181/300 batch  44/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 181/300 batch  45/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 181/300 batch  46/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 181/300 batch  47/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 181/300 batch  48/188  Train Loss: 0.057, Acc: 0.977\n",
      "epoch: 181/300 batch  49/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 181/300 batch  50/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 181/300 batch  51/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 181/300 batch  52/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 181/300 batch  53/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 181/300 batch  54/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 181/300 batch  55/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 181/300 batch  56/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 181/300 batch  57/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 181/300 batch  58/188  Train Loss: 0.027, Acc: 0.988\n",
      "epoch: 181/300 batch  59/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 181/300 batch  60/188  Train Loss: 0.039, Acc: 0.980\n",
      "epoch: 181/300 batch  61/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 181/300 batch  62/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 181/300 batch  63/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 181/300 batch  64/188  Train Loss: 0.074, Acc: 0.973\n",
      "epoch: 181/300 batch  65/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 181/300 batch  66/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 181/300 batch  67/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 181/300 batch  68/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 181/300 batch  69/188  Train Loss: 0.031, Acc: 1.000\n",
      "epoch: 181/300 batch  70/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 181/300 batch  71/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 181/300 batch  72/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 181/300 batch  73/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 181/300 batch  74/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 181/300 batch  75/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 181/300 batch  76/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 181/300 batch  77/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 181/300 batch  78/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 181/300 batch  79/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 181/300 batch  80/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 181/300 batch  81/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 181/300 batch  82/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 181/300 batch  83/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 181/300 batch  84/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 181/300 batch  85/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 181/300 batch  86/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 181/300 batch  87/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 181/300 batch  88/188  Train Loss: 0.055, Acc: 0.996\n",
      "epoch: 181/300 batch  89/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 181/300 batch  90/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 181/300 batch  91/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 181/300 batch  92/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 181/300 batch  93/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 181/300 batch  94/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 181/300 batch  95/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 181/300 batch  96/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 181/300 batch  97/188  Train Loss: 0.023, Acc: 0.984\n",
      "epoch: 181/300 batch  98/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 181/300 batch  99/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 181/300 batch 100/188  Train Loss: 0.054, Acc: 0.992\n",
      "epoch: 181/300 batch 101/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 181/300 batch 102/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 181/300 batch 103/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 181/300 batch 104/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 181/300 batch 105/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 181/300 batch 106/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 181/300 batch 107/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 181/300 batch 108/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 181/300 batch 109/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 181/300 batch 110/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 181/300 batch 111/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 181/300 batch 112/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 181/300 batch 113/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 181/300 batch 114/188  Train Loss: 0.027, Acc: 0.988\n",
      "epoch: 181/300 batch 115/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 181/300 batch 116/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 181/300 batch 117/188  Train Loss: 0.052, Acc: 0.980\n",
      "epoch: 181/300 batch 118/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 181/300 batch 119/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 181/300 batch 120/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 181/300 batch 121/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 181/300 batch 122/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 181/300 batch 123/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 181/300 batch 124/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 181/300 batch 125/188  Train Loss: 0.052, Acc: 0.992\n",
      "epoch: 181/300 batch 126/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 181/300 batch 127/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 181/300 batch 128/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 181/300 batch 129/188  Train Loss: 0.065, Acc: 0.973\n",
      "epoch: 181/300 batch 130/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 181/300 batch 131/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 181/300 batch 132/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 181/300 batch 133/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 181/300 batch 134/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 181/300 batch 135/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 181/300 batch 136/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 181/300 batch 137/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 181/300 batch 138/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 181/300 batch 139/188  Train Loss: 0.059, Acc: 0.977\n",
      "epoch: 181/300 batch 140/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 181/300 batch 141/188  Train Loss: 0.060, Acc: 0.977\n",
      "epoch: 181/300 batch 142/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 181/300 batch 143/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 181/300 batch 144/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 181/300 batch 145/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 181/300 batch 146/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 181/300 batch 147/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 181/300 batch 148/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 181/300 batch 149/188  Train Loss: 0.032, Acc: 0.984\n",
      "epoch: 181/300 batch 150/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 181/300 batch 151/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 181/300 batch 152/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 181/300 batch 153/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 181/300 batch 154/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 181/300 batch 155/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 181/300 batch 156/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 181/300 batch 157/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 181/300 batch 158/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 181/300 batch 159/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 181/300 batch 160/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 181/300 batch 161/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 181/300 batch 162/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 181/300 batch 163/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 181/300 batch 164/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 181/300 batch 165/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 181/300 batch 166/188  Train Loss: 0.062, Acc: 0.977\n",
      "epoch: 181/300 batch 167/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 181/300 batch 168/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 181/300 batch 169/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 181/300 batch 170/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 181/300 batch 171/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 181/300 batch 172/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 181/300 batch 173/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 181/300 batch 174/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 181/300 batch 175/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 181/300 batch 176/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 181/300 batch 177/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 181/300 batch 178/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 181/300 batch 179/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 181/300 batch 180/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 181/300 batch 181/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 181/300 batch 182/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 181/300 batch 183/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 181/300 batch 184/188  Train Loss: 0.056, Acc: 0.988\n",
      "epoch: 181/300 batch 185/188  Train Loss: 0.033, Acc: 0.984\n",
      "epoch: 181/300 batch 186/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 181/300 batch 187/188  Train Loss: 0.035, Acc: 0.992\n",
      "Train Loss: 0.033586, Acc: 0.992\n",
      "Val Loss: 0.057243, Acc: 0.982\n",
      "epoch: 182/300 batch   0/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 182/300 batch   1/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 182/300 batch   2/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 182/300 batch   3/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 182/300 batch   4/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 182/300 batch   5/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 182/300 batch   6/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 182/300 batch   7/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 182/300 batch   8/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 182/300 batch   9/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 182/300 batch  10/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 182/300 batch  11/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 182/300 batch  12/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 182/300 batch  13/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 182/300 batch  14/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 182/300 batch  15/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 182/300 batch  16/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 182/300 batch  17/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 182/300 batch  18/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 182/300 batch  19/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 182/300 batch  20/188  Train Loss: 0.032, Acc: 1.000\n",
      "epoch: 182/300 batch  21/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 182/300 batch  22/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 182/300 batch  23/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 182/300 batch  24/188  Train Loss: 0.064, Acc: 0.973\n",
      "epoch: 182/300 batch  25/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 182/300 batch  26/188  Train Loss: 0.044, Acc: 0.996\n",
      "epoch: 182/300 batch  27/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 182/300 batch  28/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 182/300 batch  29/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 182/300 batch  30/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 182/300 batch  31/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 182/300 batch  32/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 182/300 batch  33/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 182/300 batch  34/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 182/300 batch  35/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 182/300 batch  36/188  Train Loss: 0.076, Acc: 0.980\n",
      "epoch: 182/300 batch  37/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 182/300 batch  38/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 182/300 batch  39/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 182/300 batch  40/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 182/300 batch  41/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 182/300 batch  42/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 182/300 batch  43/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 182/300 batch  44/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 182/300 batch  45/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 182/300 batch  46/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 182/300 batch  47/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 182/300 batch  48/188  Train Loss: 0.073, Acc: 0.980\n",
      "epoch: 182/300 batch  49/188  Train Loss: 0.042, Acc: 0.980\n",
      "epoch: 182/300 batch  50/188  Train Loss: 0.068, Acc: 0.973\n",
      "epoch: 182/300 batch  51/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 182/300 batch  52/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 182/300 batch  53/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 182/300 batch  54/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 182/300 batch  55/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 182/300 batch  56/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 182/300 batch  57/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 182/300 batch  58/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 182/300 batch  59/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 182/300 batch  60/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 182/300 batch  61/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 182/300 batch  62/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 182/300 batch  63/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 182/300 batch  64/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 182/300 batch  65/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 182/300 batch  66/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 182/300 batch  67/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 182/300 batch  68/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 182/300 batch  69/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 182/300 batch  70/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 182/300 batch  71/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 182/300 batch  72/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 182/300 batch  73/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 182/300 batch  74/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 182/300 batch  75/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 182/300 batch  76/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 182/300 batch  77/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 182/300 batch  78/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 182/300 batch  79/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 182/300 batch  80/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 182/300 batch  81/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 182/300 batch  82/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 182/300 batch  83/188  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 182/300 batch  84/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 182/300 batch  85/188  Train Loss: 0.063, Acc: 0.988\n",
      "epoch: 182/300 batch  86/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 182/300 batch  87/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 182/300 batch  88/188  Train Loss: 0.055, Acc: 0.980\n",
      "epoch: 182/300 batch  89/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 182/300 batch  90/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 182/300 batch  91/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 182/300 batch  92/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 182/300 batch  93/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 182/300 batch  94/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 182/300 batch  95/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 182/300 batch  96/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 182/300 batch  97/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 182/300 batch  98/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 182/300 batch  99/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 182/300 batch 100/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 182/300 batch 101/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 182/300 batch 102/188  Train Loss: 0.055, Acc: 0.977\n",
      "epoch: 182/300 batch 103/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 182/300 batch 104/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 182/300 batch 105/188  Train Loss: 0.054, Acc: 0.992\n",
      "epoch: 182/300 batch 106/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 182/300 batch 107/188  Train Loss: 0.033, Acc: 0.984\n",
      "epoch: 182/300 batch 108/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 182/300 batch 109/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 182/300 batch 110/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 182/300 batch 111/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 182/300 batch 112/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 182/300 batch 113/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 182/300 batch 114/188  Train Loss: 0.052, Acc: 0.992\n",
      "epoch: 182/300 batch 115/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 182/300 batch 116/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 182/300 batch 117/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 182/300 batch 118/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 182/300 batch 119/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 182/300 batch 120/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 182/300 batch 121/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 182/300 batch 122/188  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 182/300 batch 123/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 182/300 batch 124/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 182/300 batch 125/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 182/300 batch 126/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 182/300 batch 127/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 182/300 batch 128/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 182/300 batch 129/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 182/300 batch 130/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 182/300 batch 131/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 182/300 batch 132/188  Train Loss: 0.034, Acc: 0.984\n",
      "epoch: 182/300 batch 133/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 182/300 batch 134/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 182/300 batch 135/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 182/300 batch 136/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 182/300 batch 137/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 182/300 batch 138/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 182/300 batch 139/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 182/300 batch 140/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 182/300 batch 141/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 182/300 batch 142/188  Train Loss: 0.062, Acc: 0.980\n",
      "epoch: 182/300 batch 143/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 182/300 batch 144/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 182/300 batch 145/188  Train Loss: 0.040, Acc: 0.980\n",
      "epoch: 182/300 batch 146/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 182/300 batch 147/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 182/300 batch 148/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 182/300 batch 149/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 182/300 batch 150/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 182/300 batch 151/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 182/300 batch 152/188  Train Loss: 0.065, Acc: 0.996\n",
      "epoch: 182/300 batch 153/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 182/300 batch 154/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 182/300 batch 155/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 182/300 batch 156/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 182/300 batch 157/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 182/300 batch 158/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 182/300 batch 159/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 182/300 batch 160/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 182/300 batch 161/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 182/300 batch 162/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 182/300 batch 163/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 182/300 batch 164/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 182/300 batch 165/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 182/300 batch 166/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 182/300 batch 167/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 182/300 batch 168/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 182/300 batch 169/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 182/300 batch 170/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 182/300 batch 171/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 182/300 batch 172/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 182/300 batch 173/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 182/300 batch 174/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 182/300 batch 175/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 182/300 batch 176/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 182/300 batch 177/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 182/300 batch 178/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 182/300 batch 179/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 182/300 batch 180/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 182/300 batch 181/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 182/300 batch 182/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 182/300 batch 183/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 182/300 batch 184/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 182/300 batch 185/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 182/300 batch 186/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 182/300 batch 187/188  Train Loss: 0.015, Acc: 1.000\n",
      "Train Loss: 0.033487, Acc: 0.993\n",
      "Val Loss: 0.057481, Acc: 0.983\n",
      "epoch: 183/300 batch   0/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 183/300 batch   1/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 183/300 batch   2/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 183/300 batch   3/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 183/300 batch   4/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 183/300 batch   5/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 183/300 batch   6/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 183/300 batch   7/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 183/300 batch   8/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 183/300 batch   9/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 183/300 batch  10/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 183/300 batch  11/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 183/300 batch  12/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 183/300 batch  13/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 183/300 batch  14/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 183/300 batch  15/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 183/300 batch  16/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 183/300 batch  17/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 183/300 batch  18/188  Train Loss: 0.053, Acc: 0.980\n",
      "epoch: 183/300 batch  19/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 183/300 batch  20/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 183/300 batch  21/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 183/300 batch  22/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 183/300 batch  23/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 183/300 batch  24/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 183/300 batch  25/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 183/300 batch  26/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 183/300 batch  27/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 183/300 batch  28/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 183/300 batch  29/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 183/300 batch  30/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 183/300 batch  31/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 183/300 batch  32/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 183/300 batch  33/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 183/300 batch  34/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 183/300 batch  35/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 183/300 batch  36/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 183/300 batch  37/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 183/300 batch  38/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 183/300 batch  39/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 183/300 batch  40/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 183/300 batch  41/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 183/300 batch  42/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 183/300 batch  43/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 183/300 batch  44/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 183/300 batch  45/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 183/300 batch  46/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 183/300 batch  47/188  Train Loss: 0.070, Acc: 0.980\n",
      "epoch: 183/300 batch  48/188  Train Loss: 0.052, Acc: 0.992\n",
      "epoch: 183/300 batch  49/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 183/300 batch  50/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 183/300 batch  51/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 183/300 batch  52/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 183/300 batch  53/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 183/300 batch  54/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 183/300 batch  55/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 183/300 batch  56/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 183/300 batch  57/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 183/300 batch  58/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 183/300 batch  59/188  Train Loss: 0.053, Acc: 0.980\n",
      "epoch: 183/300 batch  60/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 183/300 batch  61/188  Train Loss: 0.038, Acc: 0.980\n",
      "epoch: 183/300 batch  62/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 183/300 batch  63/188  Train Loss: 0.074, Acc: 0.992\n",
      "epoch: 183/300 batch  64/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 183/300 batch  65/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 183/300 batch  66/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 183/300 batch  67/188  Train Loss: 0.044, Acc: 0.980\n",
      "epoch: 183/300 batch  68/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 183/300 batch  69/188  Train Loss: 0.057, Acc: 0.988\n",
      "epoch: 183/300 batch  70/188  Train Loss: 0.063, Acc: 0.980\n",
      "epoch: 183/300 batch  71/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 183/300 batch  72/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 183/300 batch  73/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 183/300 batch  74/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 183/300 batch  75/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 183/300 batch  76/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 183/300 batch  77/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 183/300 batch  78/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 183/300 batch  79/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 183/300 batch  80/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 183/300 batch  81/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 183/300 batch  82/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 183/300 batch  83/188  Train Loss: 0.059, Acc: 0.984\n",
      "epoch: 183/300 batch  84/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 183/300 batch  85/188  Train Loss: 0.054, Acc: 0.977\n",
      "epoch: 183/300 batch  86/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 183/300 batch  87/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 183/300 batch  88/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 183/300 batch  89/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 183/300 batch  90/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 183/300 batch  91/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 183/300 batch  92/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 183/300 batch  93/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 183/300 batch  94/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 183/300 batch  95/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 183/300 batch  96/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 183/300 batch  97/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 183/300 batch  98/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 183/300 batch  99/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 183/300 batch 100/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 183/300 batch 101/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 183/300 batch 102/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 183/300 batch 103/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 183/300 batch 104/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 183/300 batch 105/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 183/300 batch 106/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 183/300 batch 107/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 183/300 batch 108/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 183/300 batch 109/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 183/300 batch 110/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 183/300 batch 111/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 183/300 batch 112/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 183/300 batch 113/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 183/300 batch 114/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 183/300 batch 115/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 183/300 batch 116/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 183/300 batch 117/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 183/300 batch 118/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 183/300 batch 119/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 183/300 batch 120/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 183/300 batch 121/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 183/300 batch 122/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 183/300 batch 123/188  Train Loss: 0.062, Acc: 0.988\n",
      "epoch: 183/300 batch 124/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 183/300 batch 125/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 183/300 batch 126/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 183/300 batch 127/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 183/300 batch 128/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 183/300 batch 129/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 183/300 batch 130/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 183/300 batch 131/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 183/300 batch 132/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 183/300 batch 133/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 183/300 batch 134/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 183/300 batch 135/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 183/300 batch 136/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 183/300 batch 137/188  Train Loss: 0.015, Acc: 0.996\n",
      "epoch: 183/300 batch 138/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 183/300 batch 139/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 183/300 batch 140/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 183/300 batch 141/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 183/300 batch 142/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 183/300 batch 143/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 183/300 batch 144/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 183/300 batch 145/188  Train Loss: 0.053, Acc: 0.980\n",
      "epoch: 183/300 batch 146/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 183/300 batch 147/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 183/300 batch 148/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 183/300 batch 149/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 183/300 batch 150/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 183/300 batch 151/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 183/300 batch 152/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 183/300 batch 153/188  Train Loss: 0.064, Acc: 0.988\n",
      "epoch: 183/300 batch 154/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 183/300 batch 155/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 183/300 batch 156/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 183/300 batch 157/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 183/300 batch 158/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 183/300 batch 159/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 183/300 batch 160/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 183/300 batch 161/188  Train Loss: 0.054, Acc: 0.992\n",
      "epoch: 183/300 batch 162/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 183/300 batch 163/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 183/300 batch 164/188  Train Loss: 0.055, Acc: 0.980\n",
      "epoch: 183/300 batch 165/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 183/300 batch 166/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 183/300 batch 167/188  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 183/300 batch 168/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 183/300 batch 169/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 183/300 batch 170/188  Train Loss: 0.031, Acc: 1.000\n",
      "epoch: 183/300 batch 171/188  Train Loss: 0.016, Acc: 0.996\n",
      "epoch: 183/300 batch 172/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 183/300 batch 173/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 183/300 batch 174/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 183/300 batch 175/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 183/300 batch 176/188  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 183/300 batch 177/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 183/300 batch 178/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 183/300 batch 179/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 183/300 batch 180/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 183/300 batch 181/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 183/300 batch 182/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 183/300 batch 183/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 183/300 batch 184/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 183/300 batch 185/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 183/300 batch 186/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 183/300 batch 187/188  Train Loss: 0.062, Acc: 0.984\n",
      "Train Loss: 0.033682, Acc: 0.992\n",
      "Val Loss: 0.057574, Acc: 0.983\n",
      "epoch: 184/300 batch   0/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 184/300 batch   1/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 184/300 batch   2/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 184/300 batch   3/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 184/300 batch   4/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 184/300 batch   5/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 184/300 batch   6/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 184/300 batch   7/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 184/300 batch   8/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 184/300 batch   9/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 184/300 batch  10/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 184/300 batch  11/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 184/300 batch  12/188  Train Loss: 0.053, Acc: 0.980\n",
      "epoch: 184/300 batch  13/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 184/300 batch  14/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 184/300 batch  15/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 184/300 batch  16/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 184/300 batch  17/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 184/300 batch  18/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 184/300 batch  19/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 184/300 batch  20/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 184/300 batch  21/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 184/300 batch  22/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 184/300 batch  23/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 184/300 batch  24/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 184/300 batch  25/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 184/300 batch  26/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 184/300 batch  27/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 184/300 batch  28/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 184/300 batch  29/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 184/300 batch  30/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 184/300 batch  31/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 184/300 batch  32/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 184/300 batch  33/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 184/300 batch  34/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 184/300 batch  35/188  Train Loss: 0.050, Acc: 0.980\n",
      "epoch: 184/300 batch  36/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 184/300 batch  37/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 184/300 batch  38/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 184/300 batch  39/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 184/300 batch  40/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 184/300 batch  41/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 184/300 batch  42/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 184/300 batch  43/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 184/300 batch  44/188  Train Loss: 0.053, Acc: 0.980\n",
      "epoch: 184/300 batch  45/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 184/300 batch  46/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 184/300 batch  47/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 184/300 batch  48/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 184/300 batch  49/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 184/300 batch  50/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 184/300 batch  51/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 184/300 batch  52/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 184/300 batch  53/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 184/300 batch  54/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 184/300 batch  55/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 184/300 batch  56/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 184/300 batch  57/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 184/300 batch  58/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 184/300 batch  59/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 184/300 batch  60/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 184/300 batch  61/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 184/300 batch  62/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 184/300 batch  63/188  Train Loss: 0.063, Acc: 0.996\n",
      "epoch: 184/300 batch  64/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 184/300 batch  65/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 184/300 batch  66/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 184/300 batch  67/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 184/300 batch  68/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 184/300 batch  69/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 184/300 batch  70/188  Train Loss: 0.069, Acc: 0.984\n",
      "epoch: 184/300 batch  71/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 184/300 batch  72/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 184/300 batch  73/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 184/300 batch  74/188  Train Loss: 0.056, Acc: 0.988\n",
      "epoch: 184/300 batch  75/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 184/300 batch  76/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 184/300 batch  77/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 184/300 batch  78/188  Train Loss: 0.057, Acc: 0.988\n",
      "epoch: 184/300 batch  79/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 184/300 batch  80/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 184/300 batch  81/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 184/300 batch  82/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 184/300 batch  83/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 184/300 batch  84/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 184/300 batch  85/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 184/300 batch  86/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 184/300 batch  87/188  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 184/300 batch  88/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 184/300 batch  89/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 184/300 batch  90/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 184/300 batch  91/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 184/300 batch  92/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 184/300 batch  93/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 184/300 batch  94/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 184/300 batch  95/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 184/300 batch  96/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 184/300 batch  97/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 184/300 batch  98/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 184/300 batch  99/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 184/300 batch 100/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 184/300 batch 101/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 184/300 batch 102/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 184/300 batch 103/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 184/300 batch 104/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 184/300 batch 105/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 184/300 batch 106/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 184/300 batch 107/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 184/300 batch 108/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 184/300 batch 109/188  Train Loss: 0.044, Acc: 0.980\n",
      "epoch: 184/300 batch 110/188  Train Loss: 0.072, Acc: 0.980\n",
      "epoch: 184/300 batch 111/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 184/300 batch 112/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 184/300 batch 113/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 184/300 batch 114/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 184/300 batch 115/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 184/300 batch 116/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 184/300 batch 117/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 184/300 batch 118/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 184/300 batch 119/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 184/300 batch 120/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 184/300 batch 121/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 184/300 batch 122/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 184/300 batch 123/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 184/300 batch 124/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 184/300 batch 125/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 184/300 batch 126/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 184/300 batch 127/188  Train Loss: 0.059, Acc: 0.984\n",
      "epoch: 184/300 batch 128/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 184/300 batch 129/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 184/300 batch 130/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 184/300 batch 131/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 184/300 batch 132/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 184/300 batch 133/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 184/300 batch 134/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 184/300 batch 135/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 184/300 batch 136/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 184/300 batch 137/188  Train Loss: 0.059, Acc: 0.980\n",
      "epoch: 184/300 batch 138/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 184/300 batch 139/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 184/300 batch 140/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 184/300 batch 141/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 184/300 batch 142/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 184/300 batch 143/188  Train Loss: 0.070, Acc: 0.980\n",
      "epoch: 184/300 batch 144/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 184/300 batch 145/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 184/300 batch 146/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 184/300 batch 147/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 184/300 batch 148/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 184/300 batch 149/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 184/300 batch 150/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 184/300 batch 151/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 184/300 batch 152/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 184/300 batch 153/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 184/300 batch 154/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 184/300 batch 155/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 184/300 batch 156/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 184/300 batch 157/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 184/300 batch 158/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 184/300 batch 159/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 184/300 batch 160/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 184/300 batch 161/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 184/300 batch 162/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 184/300 batch 163/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 184/300 batch 164/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 184/300 batch 165/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 184/300 batch 166/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 184/300 batch 167/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 184/300 batch 168/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 184/300 batch 169/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 184/300 batch 170/188  Train Loss: 0.051, Acc: 0.977\n",
      "epoch: 184/300 batch 171/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 184/300 batch 172/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 184/300 batch 173/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 184/300 batch 174/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 184/300 batch 175/188  Train Loss: 0.054, Acc: 0.992\n",
      "epoch: 184/300 batch 176/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 184/300 batch 177/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 184/300 batch 178/188  Train Loss: 0.062, Acc: 0.977\n",
      "epoch: 184/300 batch 179/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 184/300 batch 180/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 184/300 batch 181/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 184/300 batch 182/188  Train Loss: 0.046, Acc: 0.996\n",
      "epoch: 184/300 batch 183/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 184/300 batch 184/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 184/300 batch 185/188  Train Loss: 0.022, Acc: 0.988\n",
      "epoch: 184/300 batch 186/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 184/300 batch 187/188  Train Loss: 0.027, Acc: 0.984\n",
      "Train Loss: 0.033513, Acc: 0.993\n",
      "Val Loss: 0.057761, Acc: 0.982\n",
      "epoch: 185/300 batch   0/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 185/300 batch   1/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 185/300 batch   2/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 185/300 batch   3/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 185/300 batch   4/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 185/300 batch   5/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 185/300 batch   6/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 185/300 batch   7/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 185/300 batch   8/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 185/300 batch   9/188  Train Loss: 0.052, Acc: 0.980\n",
      "epoch: 185/300 batch  10/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 185/300 batch  11/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 185/300 batch  12/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 185/300 batch  13/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 185/300 batch  14/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 185/300 batch  15/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 185/300 batch  16/188  Train Loss: 0.054, Acc: 0.992\n",
      "epoch: 185/300 batch  17/188  Train Loss: 0.045, Acc: 0.980\n",
      "epoch: 185/300 batch  18/188  Train Loss: 0.040, Acc: 0.980\n",
      "epoch: 185/300 batch  19/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 185/300 batch  20/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 185/300 batch  21/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 185/300 batch  22/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 185/300 batch  23/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 185/300 batch  24/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 185/300 batch  25/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 185/300 batch  26/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 185/300 batch  27/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 185/300 batch  28/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 185/300 batch  29/188  Train Loss: 0.064, Acc: 0.980\n",
      "epoch: 185/300 batch  30/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 185/300 batch  31/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 185/300 batch  32/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 185/300 batch  33/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 185/300 batch  34/188  Train Loss: 0.063, Acc: 0.988\n",
      "epoch: 185/300 batch  35/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 185/300 batch  36/188  Train Loss: 0.056, Acc: 0.988\n",
      "epoch: 185/300 batch  37/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 185/300 batch  38/188  Train Loss: 0.058, Acc: 0.980\n",
      "epoch: 185/300 batch  39/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 185/300 batch  40/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 185/300 batch  41/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 185/300 batch  42/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 185/300 batch  43/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 185/300 batch  44/188  Train Loss: 0.054, Acc: 0.980\n",
      "epoch: 185/300 batch  45/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 185/300 batch  46/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 185/300 batch  47/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 185/300 batch  48/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 185/300 batch  49/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 185/300 batch  50/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 185/300 batch  51/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 185/300 batch  52/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 185/300 batch  53/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 185/300 batch  54/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 185/300 batch  55/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 185/300 batch  56/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 185/300 batch  57/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 185/300 batch  58/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 185/300 batch  59/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 185/300 batch  60/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 185/300 batch  61/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 185/300 batch  62/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 185/300 batch  63/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 185/300 batch  64/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 185/300 batch  65/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 185/300 batch  66/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 185/300 batch  67/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 185/300 batch  68/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 185/300 batch  69/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 185/300 batch  70/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 185/300 batch  71/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 185/300 batch  72/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 185/300 batch  73/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 185/300 batch  74/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 185/300 batch  75/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 185/300 batch  76/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 185/300 batch  77/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 185/300 batch  78/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 185/300 batch  79/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 185/300 batch  80/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 185/300 batch  81/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 185/300 batch  82/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 185/300 batch  83/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 185/300 batch  84/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 185/300 batch  85/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 185/300 batch  86/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 185/300 batch  87/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 185/300 batch  88/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 185/300 batch  89/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 185/300 batch  90/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 185/300 batch  91/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 185/300 batch  92/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 185/300 batch  93/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 185/300 batch  94/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 185/300 batch  95/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 185/300 batch  96/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 185/300 batch  97/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 185/300 batch  98/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 185/300 batch  99/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 185/300 batch 100/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 185/300 batch 101/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 185/300 batch 102/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 185/300 batch 103/188  Train Loss: 0.062, Acc: 0.980\n",
      "epoch: 185/300 batch 104/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 185/300 batch 105/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 185/300 batch 106/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 185/300 batch 107/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 185/300 batch 108/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 185/300 batch 109/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 185/300 batch 110/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 185/300 batch 111/188  Train Loss: 0.049, Acc: 0.980\n",
      "epoch: 185/300 batch 112/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 185/300 batch 113/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 185/300 batch 114/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 185/300 batch 115/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 185/300 batch 116/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 185/300 batch 117/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 185/300 batch 118/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 185/300 batch 119/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 185/300 batch 120/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 185/300 batch 121/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 185/300 batch 122/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 185/300 batch 123/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 185/300 batch 124/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 185/300 batch 125/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 185/300 batch 126/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 185/300 batch 127/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 185/300 batch 128/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 185/300 batch 129/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 185/300 batch 130/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 185/300 batch 131/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 185/300 batch 132/188  Train Loss: 0.045, Acc: 0.996\n",
      "epoch: 185/300 batch 133/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 185/300 batch 134/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 185/300 batch 135/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 185/300 batch 136/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 185/300 batch 137/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 185/300 batch 138/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 185/300 batch 139/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 185/300 batch 140/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 185/300 batch 141/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 185/300 batch 142/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 185/300 batch 143/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 185/300 batch 144/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 185/300 batch 145/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 185/300 batch 146/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 185/300 batch 147/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 185/300 batch 148/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 185/300 batch 149/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 185/300 batch 150/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 185/300 batch 151/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 185/300 batch 152/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 185/300 batch 153/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 185/300 batch 154/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 185/300 batch 155/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 185/300 batch 156/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 185/300 batch 157/188  Train Loss: 0.054, Acc: 0.969\n",
      "epoch: 185/300 batch 158/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 185/300 batch 159/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 185/300 batch 160/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 185/300 batch 161/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 185/300 batch 162/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 185/300 batch 163/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 185/300 batch 164/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 185/300 batch 165/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 185/300 batch 166/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 185/300 batch 167/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 185/300 batch 168/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 185/300 batch 169/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 185/300 batch 170/188  Train Loss: 0.061, Acc: 0.980\n",
      "epoch: 185/300 batch 171/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 185/300 batch 172/188  Train Loss: 0.062, Acc: 0.980\n",
      "epoch: 185/300 batch 173/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 185/300 batch 174/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 185/300 batch 175/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 185/300 batch 176/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 185/300 batch 177/188  Train Loss: 0.044, Acc: 0.996\n",
      "epoch: 185/300 batch 178/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 185/300 batch 179/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 185/300 batch 180/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 185/300 batch 181/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 185/300 batch 182/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 185/300 batch 183/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 185/300 batch 184/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 185/300 batch 185/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 185/300 batch 186/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 185/300 batch 187/188  Train Loss: 0.038, Acc: 0.992\n",
      "Train Loss: 0.033517, Acc: 0.993\n",
      "Val Loss: 0.057542, Acc: 0.983\n",
      "epoch: 186/300 batch   0/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 186/300 batch   1/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 186/300 batch   2/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 186/300 batch   3/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 186/300 batch   4/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 186/300 batch   5/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 186/300 batch   6/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 186/300 batch   7/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 186/300 batch   8/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 186/300 batch   9/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 186/300 batch  10/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 186/300 batch  11/188  Train Loss: 0.052, Acc: 0.992\n",
      "epoch: 186/300 batch  12/188  Train Loss: 0.034, Acc: 1.000\n",
      "epoch: 186/300 batch  13/188  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 186/300 batch  14/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 186/300 batch  15/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 186/300 batch  16/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 186/300 batch  17/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 186/300 batch  18/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 186/300 batch  19/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 186/300 batch  20/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 186/300 batch  21/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 186/300 batch  22/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 186/300 batch  23/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 186/300 batch  24/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 186/300 batch  25/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 186/300 batch  26/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 186/300 batch  27/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 186/300 batch  28/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 186/300 batch  29/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 186/300 batch  30/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 186/300 batch  31/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 186/300 batch  32/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 186/300 batch  33/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 186/300 batch  34/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 186/300 batch  35/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 186/300 batch  36/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 186/300 batch  37/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 186/300 batch  38/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 186/300 batch  39/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 186/300 batch  40/188  Train Loss: 0.066, Acc: 0.992\n",
      "epoch: 186/300 batch  41/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 186/300 batch  42/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 186/300 batch  43/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 186/300 batch  44/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 186/300 batch  45/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 186/300 batch  46/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 186/300 batch  47/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 186/300 batch  48/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 186/300 batch  49/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 186/300 batch  50/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 186/300 batch  51/188  Train Loss: 0.071, Acc: 0.973\n",
      "epoch: 186/300 batch  52/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 186/300 batch  53/188  Train Loss: 0.069, Acc: 0.973\n",
      "epoch: 186/300 batch  54/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 186/300 batch  55/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 186/300 batch  56/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 186/300 batch  57/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 186/300 batch  58/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 186/300 batch  59/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 186/300 batch  60/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 186/300 batch  61/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 186/300 batch  62/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 186/300 batch  63/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 186/300 batch  64/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 186/300 batch  65/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 186/300 batch  66/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 186/300 batch  67/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 186/300 batch  68/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 186/300 batch  69/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 186/300 batch  70/188  Train Loss: 0.016, Acc: 0.996\n",
      "epoch: 186/300 batch  71/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 186/300 batch  72/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 186/300 batch  73/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 186/300 batch  74/188  Train Loss: 0.050, Acc: 0.980\n",
      "epoch: 186/300 batch  75/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 186/300 batch  76/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 186/300 batch  77/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 186/300 batch  78/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 186/300 batch  79/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 186/300 batch  80/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 186/300 batch  81/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 186/300 batch  82/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 186/300 batch  83/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 186/300 batch  84/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 186/300 batch  85/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 186/300 batch  86/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 186/300 batch  87/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 186/300 batch  88/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 186/300 batch  89/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 186/300 batch  90/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 186/300 batch  91/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 186/300 batch  92/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 186/300 batch  93/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 186/300 batch  94/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 186/300 batch  95/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 186/300 batch  96/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 186/300 batch  97/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 186/300 batch  98/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 186/300 batch  99/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 186/300 batch 100/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 186/300 batch 101/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 186/300 batch 102/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 186/300 batch 103/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 186/300 batch 104/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 186/300 batch 105/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 186/300 batch 106/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 186/300 batch 107/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 186/300 batch 108/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 186/300 batch 109/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 186/300 batch 110/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 186/300 batch 111/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 186/300 batch 112/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 186/300 batch 113/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 186/300 batch 114/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 186/300 batch 115/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 186/300 batch 116/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 186/300 batch 117/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 186/300 batch 118/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 186/300 batch 119/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 186/300 batch 120/188  Train Loss: 0.062, Acc: 0.977\n",
      "epoch: 186/300 batch 121/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 186/300 batch 122/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 186/300 batch 123/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 186/300 batch 124/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 186/300 batch 125/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 186/300 batch 126/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 186/300 batch 127/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 186/300 batch 128/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 186/300 batch 129/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 186/300 batch 130/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 186/300 batch 131/188  Train Loss: 0.048, Acc: 0.980\n",
      "epoch: 186/300 batch 132/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 186/300 batch 133/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 186/300 batch 134/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 186/300 batch 135/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 186/300 batch 136/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 186/300 batch 137/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 186/300 batch 138/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 186/300 batch 139/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 186/300 batch 140/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 186/300 batch 141/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 186/300 batch 142/188  Train Loss: 0.055, Acc: 0.992\n",
      "epoch: 186/300 batch 143/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 186/300 batch 144/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 186/300 batch 145/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 186/300 batch 146/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 186/300 batch 147/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 186/300 batch 148/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 186/300 batch 149/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 186/300 batch 150/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 186/300 batch 151/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 186/300 batch 152/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 186/300 batch 153/188  Train Loss: 0.048, Acc: 0.980\n",
      "epoch: 186/300 batch 154/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 186/300 batch 155/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 186/300 batch 156/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 186/300 batch 157/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 186/300 batch 158/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 186/300 batch 159/188  Train Loss: 0.056, Acc: 0.988\n",
      "epoch: 186/300 batch 160/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 186/300 batch 161/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 186/300 batch 162/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 186/300 batch 163/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 186/300 batch 164/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 186/300 batch 165/188  Train Loss: 0.050, Acc: 0.980\n",
      "epoch: 186/300 batch 166/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 186/300 batch 167/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 186/300 batch 168/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 186/300 batch 169/188  Train Loss: 0.050, Acc: 0.980\n",
      "epoch: 186/300 batch 170/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 186/300 batch 171/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 186/300 batch 172/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 186/300 batch 173/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 186/300 batch 174/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 186/300 batch 175/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 186/300 batch 176/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 186/300 batch 177/188  Train Loss: 0.054, Acc: 0.992\n",
      "epoch: 186/300 batch 178/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 186/300 batch 179/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 186/300 batch 180/188  Train Loss: 0.059, Acc: 0.984\n",
      "epoch: 186/300 batch 181/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 186/300 batch 182/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 186/300 batch 183/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 186/300 batch 184/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 186/300 batch 185/188  Train Loss: 0.025, Acc: 0.988\n",
      "epoch: 186/300 batch 186/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 186/300 batch 187/188  Train Loss: 0.050, Acc: 0.984\n",
      "Train Loss: 0.033551, Acc: 0.992\n",
      "Val Loss: 0.057330, Acc: 0.983\n",
      "epoch: 187/300 batch   0/188  Train Loss: 0.065, Acc: 0.992\n",
      "epoch: 187/300 batch   1/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 187/300 batch   2/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 187/300 batch   3/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 187/300 batch   4/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 187/300 batch   5/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 187/300 batch   6/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 187/300 batch   7/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 187/300 batch   8/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 187/300 batch   9/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 187/300 batch  10/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 187/300 batch  11/188  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 187/300 batch  12/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 187/300 batch  13/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 187/300 batch  14/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 187/300 batch  15/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 187/300 batch  16/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 187/300 batch  17/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 187/300 batch  18/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 187/300 batch  19/188  Train Loss: 0.040, Acc: 0.980\n",
      "epoch: 187/300 batch  20/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 187/300 batch  21/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 187/300 batch  22/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 187/300 batch  23/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 187/300 batch  24/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 187/300 batch  25/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 187/300 batch  26/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 187/300 batch  27/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 187/300 batch  28/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 187/300 batch  29/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 187/300 batch  30/188  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 187/300 batch  31/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 187/300 batch  32/188  Train Loss: 0.055, Acc: 0.992\n",
      "epoch: 187/300 batch  33/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 187/300 batch  34/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 187/300 batch  35/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 187/300 batch  36/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 187/300 batch  37/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 187/300 batch  38/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 187/300 batch  39/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 187/300 batch  40/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 187/300 batch  41/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 187/300 batch  42/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 187/300 batch  43/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 187/300 batch  44/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 187/300 batch  45/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 187/300 batch  46/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 187/300 batch  47/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 187/300 batch  48/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 187/300 batch  49/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 187/300 batch  50/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 187/300 batch  51/188  Train Loss: 0.067, Acc: 0.980\n",
      "epoch: 187/300 batch  52/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 187/300 batch  53/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 187/300 batch  54/188  Train Loss: 0.074, Acc: 0.980\n",
      "epoch: 187/300 batch  55/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 187/300 batch  56/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 187/300 batch  57/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 187/300 batch  58/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 187/300 batch  59/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 187/300 batch  60/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 187/300 batch  61/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 187/300 batch  62/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 187/300 batch  63/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 187/300 batch  64/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 187/300 batch  65/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 187/300 batch  66/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 187/300 batch  67/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 187/300 batch  68/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 187/300 batch  69/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 187/300 batch  70/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 187/300 batch  71/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 187/300 batch  72/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 187/300 batch  73/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 187/300 batch  74/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 187/300 batch  75/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 187/300 batch  76/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 187/300 batch  77/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 187/300 batch  78/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 187/300 batch  79/188  Train Loss: 0.047, Acc: 0.996\n",
      "epoch: 187/300 batch  80/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 187/300 batch  81/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 187/300 batch  82/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 187/300 batch  83/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 187/300 batch  84/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 187/300 batch  85/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 187/300 batch  86/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 187/300 batch  87/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 187/300 batch  88/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 187/300 batch  89/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 187/300 batch  90/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 187/300 batch  91/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 187/300 batch  92/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 187/300 batch  93/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 187/300 batch  94/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 187/300 batch  95/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 187/300 batch  96/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 187/300 batch  97/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 187/300 batch  98/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 187/300 batch  99/188  Train Loss: 0.067, Acc: 0.988\n",
      "epoch: 187/300 batch 100/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 187/300 batch 101/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 187/300 batch 102/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 187/300 batch 103/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 187/300 batch 104/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 187/300 batch 105/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 187/300 batch 106/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 187/300 batch 107/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 187/300 batch 108/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 187/300 batch 109/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 187/300 batch 110/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 187/300 batch 111/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 187/300 batch 112/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 187/300 batch 113/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 187/300 batch 114/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 187/300 batch 115/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 187/300 batch 116/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 187/300 batch 117/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 187/300 batch 118/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 187/300 batch 119/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 187/300 batch 120/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 187/300 batch 121/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 187/300 batch 122/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 187/300 batch 123/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 187/300 batch 124/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 187/300 batch 125/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 187/300 batch 126/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 187/300 batch 127/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 187/300 batch 128/188  Train Loss: 0.045, Acc: 0.980\n",
      "epoch: 187/300 batch 129/188  Train Loss: 0.047, Acc: 0.980\n",
      "epoch: 187/300 batch 130/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 187/300 batch 131/188  Train Loss: 0.034, Acc: 0.984\n",
      "epoch: 187/300 batch 132/188  Train Loss: 0.056, Acc: 0.988\n",
      "epoch: 187/300 batch 133/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 187/300 batch 134/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 187/300 batch 135/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 187/300 batch 136/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 187/300 batch 137/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 187/300 batch 138/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 187/300 batch 139/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 187/300 batch 140/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 187/300 batch 141/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 187/300 batch 142/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 187/300 batch 143/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 187/300 batch 144/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 187/300 batch 145/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 187/300 batch 146/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 187/300 batch 147/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 187/300 batch 148/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 187/300 batch 149/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 187/300 batch 150/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 187/300 batch 151/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 187/300 batch 152/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 187/300 batch 153/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 187/300 batch 154/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 187/300 batch 155/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 187/300 batch 156/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 187/300 batch 157/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 187/300 batch 158/188  Train Loss: 0.026, Acc: 0.984\n",
      "epoch: 187/300 batch 159/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 187/300 batch 160/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 187/300 batch 161/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 187/300 batch 162/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 187/300 batch 163/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 187/300 batch 164/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 187/300 batch 165/188  Train Loss: 0.027, Acc: 0.988\n",
      "epoch: 187/300 batch 166/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 187/300 batch 167/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 187/300 batch 168/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 187/300 batch 169/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 187/300 batch 170/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 187/300 batch 171/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 187/300 batch 172/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 187/300 batch 173/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 187/300 batch 174/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 187/300 batch 175/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 187/300 batch 176/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 187/300 batch 177/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 187/300 batch 178/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 187/300 batch 179/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 187/300 batch 180/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 187/300 batch 181/188  Train Loss: 0.056, Acc: 0.988\n",
      "epoch: 187/300 batch 182/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 187/300 batch 183/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 187/300 batch 184/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 187/300 batch 185/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 187/300 batch 186/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 187/300 batch 187/188  Train Loss: 0.017, Acc: 1.000\n",
      "Train Loss: 0.033447, Acc: 0.993\n",
      "Val Loss: 0.057505, Acc: 0.983\n",
      "epoch: 188/300 batch   0/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 188/300 batch   1/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 188/300 batch   2/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 188/300 batch   3/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 188/300 batch   4/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 188/300 batch   5/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 188/300 batch   6/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 188/300 batch   7/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 188/300 batch   8/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 188/300 batch   9/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 188/300 batch  10/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 188/300 batch  11/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 188/300 batch  12/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 188/300 batch  13/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 188/300 batch  14/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 188/300 batch  15/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 188/300 batch  16/188  Train Loss: 0.059, Acc: 0.988\n",
      "epoch: 188/300 batch  17/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 188/300 batch  18/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 188/300 batch  19/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 188/300 batch  20/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 188/300 batch  21/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 188/300 batch  22/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 188/300 batch  23/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 188/300 batch  24/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 188/300 batch  25/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 188/300 batch  26/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 188/300 batch  27/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 188/300 batch  28/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 188/300 batch  29/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 188/300 batch  30/188  Train Loss: 0.063, Acc: 0.980\n",
      "epoch: 188/300 batch  31/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 188/300 batch  32/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 188/300 batch  33/188  Train Loss: 0.027, Acc: 0.988\n",
      "epoch: 188/300 batch  34/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 188/300 batch  35/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 188/300 batch  36/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 188/300 batch  37/188  Train Loss: 0.045, Acc: 0.996\n",
      "epoch: 188/300 batch  38/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 188/300 batch  39/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 188/300 batch  40/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 188/300 batch  41/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 188/300 batch  42/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 188/300 batch  43/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 188/300 batch  44/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 188/300 batch  45/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 188/300 batch  46/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 188/300 batch  47/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 188/300 batch  48/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 188/300 batch  49/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 188/300 batch  50/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 188/300 batch  51/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 188/300 batch  52/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 188/300 batch  53/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 188/300 batch  54/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 188/300 batch  55/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 188/300 batch  56/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 188/300 batch  57/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 188/300 batch  58/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 188/300 batch  59/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 188/300 batch  60/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 188/300 batch  61/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 188/300 batch  62/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 188/300 batch  63/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 188/300 batch  64/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 188/300 batch  65/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 188/300 batch  66/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 188/300 batch  67/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 188/300 batch  68/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 188/300 batch  69/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 188/300 batch  70/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 188/300 batch  71/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 188/300 batch  72/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 188/300 batch  73/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 188/300 batch  74/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 188/300 batch  75/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 188/300 batch  76/188  Train Loss: 0.058, Acc: 0.980\n",
      "epoch: 188/300 batch  77/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 188/300 batch  78/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 188/300 batch  79/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 188/300 batch  80/188  Train Loss: 0.055, Acc: 0.973\n",
      "epoch: 188/300 batch  81/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 188/300 batch  82/188  Train Loss: 0.053, Acc: 0.977\n",
      "epoch: 188/300 batch  83/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 188/300 batch  84/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 188/300 batch  85/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 188/300 batch  86/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 188/300 batch  87/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 188/300 batch  88/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 188/300 batch  89/188  Train Loss: 0.054, Acc: 0.977\n",
      "epoch: 188/300 batch  90/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 188/300 batch  91/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 188/300 batch  92/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 188/300 batch  93/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 188/300 batch  94/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 188/300 batch  95/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 188/300 batch  96/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 188/300 batch  97/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 188/300 batch  98/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 188/300 batch  99/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 188/300 batch 100/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 188/300 batch 101/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 188/300 batch 102/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 188/300 batch 103/188  Train Loss: 0.048, Acc: 0.980\n",
      "epoch: 188/300 batch 104/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 188/300 batch 105/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 188/300 batch 106/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 188/300 batch 107/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 188/300 batch 108/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 188/300 batch 109/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 188/300 batch 110/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 188/300 batch 111/188  Train Loss: 0.060, Acc: 0.980\n",
      "epoch: 188/300 batch 112/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 188/300 batch 113/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 188/300 batch 114/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 188/300 batch 115/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 188/300 batch 116/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 188/300 batch 117/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 188/300 batch 118/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 188/300 batch 119/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 188/300 batch 120/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 188/300 batch 121/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 188/300 batch 122/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 188/300 batch 123/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 188/300 batch 124/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 188/300 batch 125/188  Train Loss: 0.053, Acc: 0.980\n",
      "epoch: 188/300 batch 126/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 188/300 batch 127/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 188/300 batch 128/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 188/300 batch 129/188  Train Loss: 0.031, Acc: 1.000\n",
      "epoch: 188/300 batch 130/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 188/300 batch 131/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 188/300 batch 132/188  Train Loss: 0.095, Acc: 0.984\n",
      "epoch: 188/300 batch 133/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 188/300 batch 134/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 188/300 batch 135/188  Train Loss: 0.031, Acc: 1.000\n",
      "epoch: 188/300 batch 136/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 188/300 batch 137/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 188/300 batch 138/188  Train Loss: 0.063, Acc: 0.988\n",
      "epoch: 188/300 batch 139/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 188/300 batch 140/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 188/300 batch 141/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 188/300 batch 142/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 188/300 batch 143/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 188/300 batch 144/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 188/300 batch 145/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 188/300 batch 146/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 188/300 batch 147/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 188/300 batch 148/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 188/300 batch 149/188  Train Loss: 0.062, Acc: 0.984\n",
      "epoch: 188/300 batch 150/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 188/300 batch 151/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 188/300 batch 152/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 188/300 batch 153/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 188/300 batch 154/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 188/300 batch 155/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 188/300 batch 156/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 188/300 batch 157/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 188/300 batch 158/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 188/300 batch 159/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 188/300 batch 160/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 188/300 batch 161/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 188/300 batch 162/188  Train Loss: 0.025, Acc: 0.988\n",
      "epoch: 188/300 batch 163/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 188/300 batch 164/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 188/300 batch 165/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 188/300 batch 166/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 188/300 batch 167/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 188/300 batch 168/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 188/300 batch 169/188  Train Loss: 0.049, Acc: 0.980\n",
      "epoch: 188/300 batch 170/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 188/300 batch 171/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 188/300 batch 172/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 188/300 batch 173/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 188/300 batch 174/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 188/300 batch 175/188  Train Loss: 0.088, Acc: 0.980\n",
      "epoch: 188/300 batch 176/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 188/300 batch 177/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 188/300 batch 178/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 188/300 batch 179/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 188/300 batch 180/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 188/300 batch 181/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 188/300 batch 182/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 188/300 batch 183/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 188/300 batch 184/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 188/300 batch 185/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 188/300 batch 186/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 188/300 batch 187/188  Train Loss: 0.040, Acc: 0.992\n",
      "Train Loss: 0.033554, Acc: 0.992\n",
      "Val Loss: 0.057646, Acc: 0.983\n",
      "epoch: 189/300 batch   0/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 189/300 batch   1/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 189/300 batch   2/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 189/300 batch   3/188  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 189/300 batch   4/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 189/300 batch   5/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 189/300 batch   6/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 189/300 batch   7/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 189/300 batch   8/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 189/300 batch   9/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 189/300 batch  10/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 189/300 batch  11/188  Train Loss: 0.058, Acc: 0.988\n",
      "epoch: 189/300 batch  12/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 189/300 batch  13/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 189/300 batch  14/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 189/300 batch  15/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 189/300 batch  16/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 189/300 batch  17/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 189/300 batch  18/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 189/300 batch  19/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 189/300 batch  20/188  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 189/300 batch  21/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 189/300 batch  22/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 189/300 batch  23/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 189/300 batch  24/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 189/300 batch  25/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 189/300 batch  26/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 189/300 batch  27/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 189/300 batch  28/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 189/300 batch  29/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 189/300 batch  30/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 189/300 batch  31/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 189/300 batch  32/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 189/300 batch  33/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 189/300 batch  34/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 189/300 batch  35/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 189/300 batch  36/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 189/300 batch  37/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 189/300 batch  38/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 189/300 batch  39/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 189/300 batch  40/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 189/300 batch  41/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 189/300 batch  42/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 189/300 batch  43/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 189/300 batch  44/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 189/300 batch  45/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 189/300 batch  46/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 189/300 batch  47/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 189/300 batch  48/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 189/300 batch  49/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 189/300 batch  50/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 189/300 batch  51/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 189/300 batch  52/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 189/300 batch  53/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 189/300 batch  54/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 189/300 batch  55/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 189/300 batch  56/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 189/300 batch  57/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 189/300 batch  58/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 189/300 batch  59/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 189/300 batch  60/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 189/300 batch  61/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 189/300 batch  62/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 189/300 batch  63/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 189/300 batch  64/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 189/300 batch  65/188  Train Loss: 0.063, Acc: 0.980\n",
      "epoch: 189/300 batch  66/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 189/300 batch  67/188  Train Loss: 0.062, Acc: 0.992\n",
      "epoch: 189/300 batch  68/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 189/300 batch  69/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 189/300 batch  70/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 189/300 batch  71/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 189/300 batch  72/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 189/300 batch  73/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 189/300 batch  74/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 189/300 batch  75/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 189/300 batch  76/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 189/300 batch  77/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 189/300 batch  78/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 189/300 batch  79/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 189/300 batch  80/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 189/300 batch  81/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 189/300 batch  82/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 189/300 batch  83/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 189/300 batch  84/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 189/300 batch  85/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 189/300 batch  86/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 189/300 batch  87/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 189/300 batch  88/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 189/300 batch  89/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 189/300 batch  90/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 189/300 batch  91/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 189/300 batch  92/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 189/300 batch  93/188  Train Loss: 0.061, Acc: 0.992\n",
      "epoch: 189/300 batch  94/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 189/300 batch  95/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 189/300 batch  96/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 189/300 batch  97/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 189/300 batch  98/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 189/300 batch  99/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 189/300 batch 100/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 189/300 batch 101/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 189/300 batch 102/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 189/300 batch 103/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 189/300 batch 104/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 189/300 batch 105/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 189/300 batch 106/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 189/300 batch 107/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 189/300 batch 108/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 189/300 batch 109/188  Train Loss: 0.051, Acc: 0.992\n",
      "epoch: 189/300 batch 110/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 189/300 batch 111/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 189/300 batch 112/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 189/300 batch 113/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 189/300 batch 114/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 189/300 batch 115/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 189/300 batch 116/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 189/300 batch 117/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 189/300 batch 118/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 189/300 batch 119/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 189/300 batch 120/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 189/300 batch 121/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 189/300 batch 122/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 189/300 batch 123/188  Train Loss: 0.049, Acc: 0.980\n",
      "epoch: 189/300 batch 124/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 189/300 batch 125/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 189/300 batch 126/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 189/300 batch 127/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 189/300 batch 128/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 189/300 batch 129/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 189/300 batch 130/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 189/300 batch 131/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 189/300 batch 132/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 189/300 batch 133/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 189/300 batch 134/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 189/300 batch 135/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 189/300 batch 136/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 189/300 batch 137/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 189/300 batch 138/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 189/300 batch 139/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 189/300 batch 140/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 189/300 batch 141/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 189/300 batch 142/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 189/300 batch 143/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 189/300 batch 144/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 189/300 batch 145/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 189/300 batch 146/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 189/300 batch 147/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 189/300 batch 148/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 189/300 batch 149/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 189/300 batch 150/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 189/300 batch 151/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 189/300 batch 152/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 189/300 batch 153/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 189/300 batch 154/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 189/300 batch 155/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 189/300 batch 156/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 189/300 batch 157/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 189/300 batch 158/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 189/300 batch 159/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 189/300 batch 160/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 189/300 batch 161/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 189/300 batch 162/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 189/300 batch 163/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 189/300 batch 164/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 189/300 batch 165/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 189/300 batch 166/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 189/300 batch 167/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 189/300 batch 168/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 189/300 batch 169/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 189/300 batch 170/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 189/300 batch 171/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 189/300 batch 172/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 189/300 batch 173/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 189/300 batch 174/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 189/300 batch 175/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 189/300 batch 176/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 189/300 batch 177/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 189/300 batch 178/188  Train Loss: 0.056, Acc: 0.988\n",
      "epoch: 189/300 batch 179/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 189/300 batch 180/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 189/300 batch 181/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 189/300 batch 182/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 189/300 batch 183/188  Train Loss: 0.076, Acc: 0.984\n",
      "epoch: 189/300 batch 184/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 189/300 batch 185/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 189/300 batch 186/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 189/300 batch 187/188  Train Loss: 0.028, Acc: 1.000\n",
      "Train Loss: 0.033473, Acc: 0.993\n",
      "Val Loss: 0.057278, Acc: 0.983\n",
      "epoch: 190/300 batch   0/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 190/300 batch   1/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 190/300 batch   2/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 190/300 batch   3/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 190/300 batch   4/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 190/300 batch   5/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 190/300 batch   6/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 190/300 batch   7/188  Train Loss: 0.061, Acc: 0.984\n",
      "epoch: 190/300 batch   8/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 190/300 batch   9/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 190/300 batch  10/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 190/300 batch  11/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 190/300 batch  12/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 190/300 batch  13/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 190/300 batch  14/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 190/300 batch  15/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 190/300 batch  16/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 190/300 batch  17/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 190/300 batch  18/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 190/300 batch  19/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 190/300 batch  20/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 190/300 batch  21/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 190/300 batch  22/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 190/300 batch  23/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 190/300 batch  24/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 190/300 batch  25/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 190/300 batch  26/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 190/300 batch  27/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 190/300 batch  28/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 190/300 batch  29/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 190/300 batch  30/188  Train Loss: 0.056, Acc: 0.980\n",
      "epoch: 190/300 batch  31/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 190/300 batch  32/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 190/300 batch  33/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 190/300 batch  34/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 190/300 batch  35/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 190/300 batch  36/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 190/300 batch  37/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 190/300 batch  38/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 190/300 batch  39/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 190/300 batch  40/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 190/300 batch  41/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 190/300 batch  42/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 190/300 batch  43/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 190/300 batch  44/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 190/300 batch  45/188  Train Loss: 0.053, Acc: 0.992\n",
      "epoch: 190/300 batch  46/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 190/300 batch  47/188  Train Loss: 0.027, Acc: 0.988\n",
      "epoch: 190/300 batch  48/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 190/300 batch  49/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 190/300 batch  50/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 190/300 batch  51/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 190/300 batch  52/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 190/300 batch  53/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 190/300 batch  54/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 190/300 batch  55/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 190/300 batch  56/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 190/300 batch  57/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 190/300 batch  58/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 190/300 batch  59/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 190/300 batch  60/188  Train Loss: 0.054, Acc: 0.973\n",
      "epoch: 190/300 batch  61/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 190/300 batch  62/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 190/300 batch  63/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 190/300 batch  64/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 190/300 batch  65/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 190/300 batch  66/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 190/300 batch  67/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 190/300 batch  68/188  Train Loss: 0.044, Acc: 0.996\n",
      "epoch: 190/300 batch  69/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 190/300 batch  70/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 190/300 batch  71/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 190/300 batch  72/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 190/300 batch  73/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 190/300 batch  74/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 190/300 batch  75/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 190/300 batch  76/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 190/300 batch  77/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 190/300 batch  78/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 190/300 batch  79/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 190/300 batch  80/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 190/300 batch  81/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 190/300 batch  82/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 190/300 batch  83/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 190/300 batch  84/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 190/300 batch  85/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 190/300 batch  86/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 190/300 batch  87/188  Train Loss: 0.063, Acc: 0.973\n",
      "epoch: 190/300 batch  88/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 190/300 batch  89/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 190/300 batch  90/188  Train Loss: 0.031, Acc: 1.000\n",
      "epoch: 190/300 batch  91/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 190/300 batch  92/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 190/300 batch  93/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 190/300 batch  94/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 190/300 batch  95/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 190/300 batch  96/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 190/300 batch  97/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 190/300 batch  98/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 190/300 batch  99/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 190/300 batch 100/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 190/300 batch 101/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 190/300 batch 102/188  Train Loss: 0.033, Acc: 1.000\n",
      "epoch: 190/300 batch 103/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 190/300 batch 104/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 190/300 batch 105/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 190/300 batch 106/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 190/300 batch 107/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 190/300 batch 108/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 190/300 batch 109/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 190/300 batch 110/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 190/300 batch 111/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 190/300 batch 112/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 190/300 batch 113/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 190/300 batch 114/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 190/300 batch 115/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 190/300 batch 116/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 190/300 batch 117/188  Train Loss: 0.078, Acc: 0.980\n",
      "epoch: 190/300 batch 118/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 190/300 batch 119/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 190/300 batch 120/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 190/300 batch 121/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 190/300 batch 122/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 190/300 batch 123/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 190/300 batch 124/188  Train Loss: 0.057, Acc: 0.980\n",
      "epoch: 190/300 batch 125/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 190/300 batch 126/188  Train Loss: 0.027, Acc: 0.988\n",
      "epoch: 190/300 batch 127/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 190/300 batch 128/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 190/300 batch 129/188  Train Loss: 0.051, Acc: 0.980\n",
      "epoch: 190/300 batch 130/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 190/300 batch 131/188  Train Loss: 0.054, Acc: 0.980\n",
      "epoch: 190/300 batch 132/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 190/300 batch 133/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 190/300 batch 134/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 190/300 batch 135/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 190/300 batch 136/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 190/300 batch 137/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 190/300 batch 138/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 190/300 batch 139/188  Train Loss: 0.071, Acc: 0.980\n",
      "epoch: 190/300 batch 140/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 190/300 batch 141/188  Train Loss: 0.063, Acc: 0.977\n",
      "epoch: 190/300 batch 142/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 190/300 batch 143/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 190/300 batch 144/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 190/300 batch 145/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 190/300 batch 146/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 190/300 batch 147/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 190/300 batch 148/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 190/300 batch 149/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 190/300 batch 150/188  Train Loss: 0.059, Acc: 0.980\n",
      "epoch: 190/300 batch 151/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 190/300 batch 152/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 190/300 batch 153/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 190/300 batch 154/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 190/300 batch 155/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 190/300 batch 156/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 190/300 batch 157/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 190/300 batch 158/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 190/300 batch 159/188  Train Loss: 0.068, Acc: 0.977\n",
      "epoch: 190/300 batch 160/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 190/300 batch 161/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 190/300 batch 162/188  Train Loss: 0.066, Acc: 0.977\n",
      "epoch: 190/300 batch 163/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 190/300 batch 164/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 190/300 batch 165/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 190/300 batch 166/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 190/300 batch 167/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 190/300 batch 168/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 190/300 batch 169/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 190/300 batch 170/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 190/300 batch 171/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 190/300 batch 172/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 190/300 batch 173/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 190/300 batch 174/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 190/300 batch 175/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 190/300 batch 176/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 190/300 batch 177/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 190/300 batch 178/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 190/300 batch 179/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 190/300 batch 180/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 190/300 batch 181/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 190/300 batch 182/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 190/300 batch 183/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 190/300 batch 184/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 190/300 batch 185/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 190/300 batch 186/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 190/300 batch 187/188  Train Loss: 0.022, Acc: 1.000\n",
      "Train Loss: 0.033423, Acc: 0.993\n",
      "Val Loss: 0.057613, Acc: 0.983\n",
      "epoch: 191/300 batch   0/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 191/300 batch   1/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 191/300 batch   2/188  Train Loss: 0.052, Acc: 0.992\n",
      "epoch: 191/300 batch   3/188  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 191/300 batch   4/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 191/300 batch   5/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 191/300 batch   6/188  Train Loss: 0.064, Acc: 0.988\n",
      "epoch: 191/300 batch   7/188  Train Loss: 0.059, Acc: 0.988\n",
      "epoch: 191/300 batch   8/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 191/300 batch   9/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 191/300 batch  10/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 191/300 batch  11/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 191/300 batch  12/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 191/300 batch  13/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 191/300 batch  14/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 191/300 batch  15/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 191/300 batch  16/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 191/300 batch  17/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 191/300 batch  18/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 191/300 batch  19/188  Train Loss: 0.040, Acc: 0.980\n",
      "epoch: 191/300 batch  20/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 191/300 batch  21/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 191/300 batch  22/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 191/300 batch  23/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 191/300 batch  24/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 191/300 batch  25/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 191/300 batch  26/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 191/300 batch  27/188  Train Loss: 0.044, Acc: 0.980\n",
      "epoch: 191/300 batch  28/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 191/300 batch  29/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 191/300 batch  30/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 191/300 batch  31/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 191/300 batch  32/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 191/300 batch  33/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 191/300 batch  34/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 191/300 batch  35/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 191/300 batch  36/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 191/300 batch  37/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 191/300 batch  38/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 191/300 batch  39/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 191/300 batch  40/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 191/300 batch  41/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 191/300 batch  42/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 191/300 batch  43/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 191/300 batch  44/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 191/300 batch  45/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 191/300 batch  46/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 191/300 batch  47/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 191/300 batch  48/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 191/300 batch  49/188  Train Loss: 0.046, Acc: 0.977\n",
      "epoch: 191/300 batch  50/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 191/300 batch  51/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 191/300 batch  52/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 191/300 batch  53/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 191/300 batch  54/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 191/300 batch  55/188  Train Loss: 0.043, Acc: 0.977\n",
      "epoch: 191/300 batch  56/188  Train Loss: 0.079, Acc: 0.977\n",
      "epoch: 191/300 batch  57/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 191/300 batch  58/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 191/300 batch  59/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 191/300 batch  60/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 191/300 batch  61/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 191/300 batch  62/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 191/300 batch  63/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 191/300 batch  64/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 191/300 batch  65/188  Train Loss: 0.056, Acc: 0.988\n",
      "epoch: 191/300 batch  66/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 191/300 batch  67/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 191/300 batch  68/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 191/300 batch  69/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 191/300 batch  70/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 191/300 batch  71/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 191/300 batch  72/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 191/300 batch  73/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 191/300 batch  74/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 191/300 batch  75/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 191/300 batch  76/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 191/300 batch  77/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 191/300 batch  78/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 191/300 batch  79/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 191/300 batch  80/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 191/300 batch  81/188  Train Loss: 0.060, Acc: 0.980\n",
      "epoch: 191/300 batch  82/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 191/300 batch  83/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 191/300 batch  84/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 191/300 batch  85/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 191/300 batch  86/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 191/300 batch  87/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 191/300 batch  88/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 191/300 batch  89/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 191/300 batch  90/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 191/300 batch  91/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 191/300 batch  92/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 191/300 batch  93/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 191/300 batch  94/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 191/300 batch  95/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 191/300 batch  96/188  Train Loss: 0.066, Acc: 0.973\n",
      "epoch: 191/300 batch  97/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 191/300 batch  98/188  Train Loss: 0.066, Acc: 0.977\n",
      "epoch: 191/300 batch  99/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 191/300 batch 100/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 191/300 batch 101/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 191/300 batch 102/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 191/300 batch 103/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 191/300 batch 104/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 191/300 batch 105/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 191/300 batch 106/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 191/300 batch 107/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 191/300 batch 108/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 191/300 batch 109/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 191/300 batch 110/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 191/300 batch 111/188  Train Loss: 0.038, Acc: 0.980\n",
      "epoch: 191/300 batch 112/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 191/300 batch 113/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 191/300 batch 114/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 191/300 batch 115/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 191/300 batch 116/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 191/300 batch 117/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 191/300 batch 118/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 191/300 batch 119/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 191/300 batch 120/188  Train Loss: 0.052, Acc: 0.980\n",
      "epoch: 191/300 batch 121/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 191/300 batch 122/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 191/300 batch 123/188  Train Loss: 0.060, Acc: 0.980\n",
      "epoch: 191/300 batch 124/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 191/300 batch 125/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 191/300 batch 126/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 191/300 batch 127/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 191/300 batch 128/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 191/300 batch 129/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 191/300 batch 130/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 191/300 batch 131/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 191/300 batch 132/188  Train Loss: 0.055, Acc: 0.980\n",
      "epoch: 191/300 batch 133/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 191/300 batch 134/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 191/300 batch 135/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 191/300 batch 136/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 191/300 batch 137/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 191/300 batch 138/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 191/300 batch 139/188  Train Loss: 0.079, Acc: 0.988\n",
      "epoch: 191/300 batch 140/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 191/300 batch 141/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 191/300 batch 142/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 191/300 batch 143/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 191/300 batch 144/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 191/300 batch 145/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 191/300 batch 146/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 191/300 batch 147/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 191/300 batch 148/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 191/300 batch 149/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 191/300 batch 150/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 191/300 batch 151/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 191/300 batch 152/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 191/300 batch 153/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 191/300 batch 154/188  Train Loss: 0.032, Acc: 1.000\n",
      "epoch: 191/300 batch 155/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 191/300 batch 156/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 191/300 batch 157/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 191/300 batch 158/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 191/300 batch 159/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 191/300 batch 160/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 191/300 batch 161/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 191/300 batch 162/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 191/300 batch 163/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 191/300 batch 164/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 191/300 batch 165/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 191/300 batch 166/188  Train Loss: 0.065, Acc: 0.984\n",
      "epoch: 191/300 batch 167/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 191/300 batch 168/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 191/300 batch 169/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 191/300 batch 170/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 191/300 batch 171/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 191/300 batch 172/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 191/300 batch 173/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 191/300 batch 174/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 191/300 batch 175/188  Train Loss: 0.074, Acc: 0.977\n",
      "epoch: 191/300 batch 176/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 191/300 batch 177/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 191/300 batch 178/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 191/300 batch 179/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 191/300 batch 180/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 191/300 batch 181/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 191/300 batch 182/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 191/300 batch 183/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 191/300 batch 184/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 191/300 batch 185/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 191/300 batch 186/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 191/300 batch 187/188  Train Loss: 0.066, Acc: 0.984\n",
      "Train Loss: 0.033478, Acc: 0.993\n",
      "Val Loss: 0.057349, Acc: 0.983\n",
      "epoch: 192/300 batch   0/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 192/300 batch   1/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 192/300 batch   2/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 192/300 batch   3/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 192/300 batch   4/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 192/300 batch   5/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 192/300 batch   6/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 192/300 batch   7/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 192/300 batch   8/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 192/300 batch   9/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 192/300 batch  10/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 192/300 batch  11/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 192/300 batch  12/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 192/300 batch  13/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 192/300 batch  14/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 192/300 batch  15/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 192/300 batch  16/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 192/300 batch  17/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 192/300 batch  18/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 192/300 batch  19/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 192/300 batch  20/188  Train Loss: 0.062, Acc: 0.980\n",
      "epoch: 192/300 batch  21/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 192/300 batch  22/188  Train Loss: 0.038, Acc: 0.980\n",
      "epoch: 192/300 batch  23/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 192/300 batch  24/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 192/300 batch  25/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 192/300 batch  26/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 192/300 batch  27/188  Train Loss: 0.071, Acc: 0.992\n",
      "epoch: 192/300 batch  28/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 192/300 batch  29/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 192/300 batch  30/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 192/300 batch  31/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 192/300 batch  32/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 192/300 batch  33/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 192/300 batch  34/188  Train Loss: 0.055, Acc: 0.992\n",
      "epoch: 192/300 batch  35/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 192/300 batch  36/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 192/300 batch  37/188  Train Loss: 0.051, Acc: 0.992\n",
      "epoch: 192/300 batch  38/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 192/300 batch  39/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 192/300 batch  40/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 192/300 batch  41/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 192/300 batch  42/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 192/300 batch  43/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 192/300 batch  44/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 192/300 batch  45/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 192/300 batch  46/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 192/300 batch  47/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 192/300 batch  48/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 192/300 batch  49/188  Train Loss: 0.056, Acc: 0.980\n",
      "epoch: 192/300 batch  50/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 192/300 batch  51/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 192/300 batch  52/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 192/300 batch  53/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 192/300 batch  54/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 192/300 batch  55/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 192/300 batch  56/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 192/300 batch  57/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 192/300 batch  58/188  Train Loss: 0.042, Acc: 0.980\n",
      "epoch: 192/300 batch  59/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 192/300 batch  60/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 192/300 batch  61/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 192/300 batch  62/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 192/300 batch  63/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 192/300 batch  64/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 192/300 batch  65/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 192/300 batch  66/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 192/300 batch  67/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 192/300 batch  68/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 192/300 batch  69/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 192/300 batch  70/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 192/300 batch  71/188  Train Loss: 0.064, Acc: 0.984\n",
      "epoch: 192/300 batch  72/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 192/300 batch  73/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 192/300 batch  74/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 192/300 batch  75/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 192/300 batch  76/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 192/300 batch  77/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 192/300 batch  78/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 192/300 batch  79/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 192/300 batch  80/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 192/300 batch  81/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 192/300 batch  82/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 192/300 batch  83/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 192/300 batch  84/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 192/300 batch  85/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 192/300 batch  86/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 192/300 batch  87/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 192/300 batch  88/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 192/300 batch  89/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 192/300 batch  90/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 192/300 batch  91/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 192/300 batch  92/188  Train Loss: 0.060, Acc: 0.984\n",
      "epoch: 192/300 batch  93/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 192/300 batch  94/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 192/300 batch  95/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 192/300 batch  96/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 192/300 batch  97/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 192/300 batch  98/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 192/300 batch  99/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 192/300 batch 100/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 192/300 batch 101/188  Train Loss: 0.047, Acc: 0.977\n",
      "epoch: 192/300 batch 102/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 192/300 batch 103/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 192/300 batch 104/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 192/300 batch 105/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 192/300 batch 106/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 192/300 batch 107/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 192/300 batch 108/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 192/300 batch 109/188  Train Loss: 0.061, Acc: 0.984\n",
      "epoch: 192/300 batch 110/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 192/300 batch 111/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 192/300 batch 112/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 192/300 batch 113/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 192/300 batch 114/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 192/300 batch 115/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 192/300 batch 116/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 192/300 batch 117/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 192/300 batch 118/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 192/300 batch 119/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 192/300 batch 120/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 192/300 batch 121/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 192/300 batch 122/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 192/300 batch 123/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 192/300 batch 124/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 192/300 batch 125/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 192/300 batch 126/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 192/300 batch 127/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 192/300 batch 128/188  Train Loss: 0.060, Acc: 0.977\n",
      "epoch: 192/300 batch 129/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 192/300 batch 130/188  Train Loss: 0.032, Acc: 0.984\n",
      "epoch: 192/300 batch 131/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 192/300 batch 132/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 192/300 batch 133/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 192/300 batch 134/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 192/300 batch 135/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 192/300 batch 136/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 192/300 batch 137/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 192/300 batch 138/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 192/300 batch 139/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 192/300 batch 140/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 192/300 batch 141/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 192/300 batch 142/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 192/300 batch 143/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 192/300 batch 144/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 192/300 batch 145/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 192/300 batch 146/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 192/300 batch 147/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 192/300 batch 148/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 192/300 batch 149/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 192/300 batch 150/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 192/300 batch 151/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 192/300 batch 152/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 192/300 batch 153/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 192/300 batch 154/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 192/300 batch 155/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 192/300 batch 156/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 192/300 batch 157/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 192/300 batch 158/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 192/300 batch 159/188  Train Loss: 0.034, Acc: 0.984\n",
      "epoch: 192/300 batch 160/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 192/300 batch 161/188  Train Loss: 0.041, Acc: 0.980\n",
      "epoch: 192/300 batch 162/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 192/300 batch 163/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 192/300 batch 164/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 192/300 batch 165/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 192/300 batch 166/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 192/300 batch 167/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 192/300 batch 168/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 192/300 batch 169/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 192/300 batch 170/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 192/300 batch 171/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 192/300 batch 172/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 192/300 batch 173/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 192/300 batch 174/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 192/300 batch 175/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 192/300 batch 176/188  Train Loss: 0.025, Acc: 0.988\n",
      "epoch: 192/300 batch 177/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 192/300 batch 178/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 192/300 batch 179/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 192/300 batch 180/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 192/300 batch 181/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 192/300 batch 182/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 192/300 batch 183/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 192/300 batch 184/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 192/300 batch 185/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 192/300 batch 186/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 192/300 batch 187/188  Train Loss: 0.043, Acc: 0.992\n",
      "Train Loss: 0.033469, Acc: 0.993\n",
      "Val Loss: 0.057420, Acc: 0.982\n",
      "epoch: 193/300 batch   0/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 193/300 batch   1/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 193/300 batch   2/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 193/300 batch   3/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 193/300 batch   4/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 193/300 batch   5/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 193/300 batch   6/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 193/300 batch   7/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 193/300 batch   8/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 193/300 batch   9/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 193/300 batch  10/188  Train Loss: 0.035, Acc: 1.000\n",
      "epoch: 193/300 batch  11/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 193/300 batch  12/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 193/300 batch  13/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 193/300 batch  14/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 193/300 batch  15/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 193/300 batch  16/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 193/300 batch  17/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 193/300 batch  18/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 193/300 batch  19/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 193/300 batch  20/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 193/300 batch  21/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 193/300 batch  22/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 193/300 batch  23/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 193/300 batch  24/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 193/300 batch  25/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 193/300 batch  26/188  Train Loss: 0.063, Acc: 0.984\n",
      "epoch: 193/300 batch  27/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 193/300 batch  28/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 193/300 batch  29/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 193/300 batch  30/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 193/300 batch  31/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 193/300 batch  32/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 193/300 batch  33/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 193/300 batch  34/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 193/300 batch  35/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 193/300 batch  36/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 193/300 batch  37/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 193/300 batch  38/188  Train Loss: 0.039, Acc: 0.980\n",
      "epoch: 193/300 batch  39/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 193/300 batch  40/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 193/300 batch  41/188  Train Loss: 0.051, Acc: 0.980\n",
      "epoch: 193/300 batch  42/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 193/300 batch  43/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 193/300 batch  44/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 193/300 batch  45/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 193/300 batch  46/188  Train Loss: 0.045, Acc: 0.996\n",
      "epoch: 193/300 batch  47/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 193/300 batch  48/188  Train Loss: 0.016, Acc: 0.996\n",
      "epoch: 193/300 batch  49/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 193/300 batch  50/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 193/300 batch  51/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 193/300 batch  52/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 193/300 batch  53/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 193/300 batch  54/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 193/300 batch  55/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 193/300 batch  56/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 193/300 batch  57/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 193/300 batch  58/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 193/300 batch  59/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 193/300 batch  60/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 193/300 batch  61/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 193/300 batch  62/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 193/300 batch  63/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 193/300 batch  64/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 193/300 batch  65/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 193/300 batch  66/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 193/300 batch  67/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 193/300 batch  68/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 193/300 batch  69/188  Train Loss: 0.045, Acc: 0.980\n",
      "epoch: 193/300 batch  70/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 193/300 batch  71/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 193/300 batch  72/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 193/300 batch  73/188  Train Loss: 0.031, Acc: 1.000\n",
      "epoch: 193/300 batch  74/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 193/300 batch  75/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 193/300 batch  76/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 193/300 batch  77/188  Train Loss: 0.044, Acc: 0.996\n",
      "epoch: 193/300 batch  78/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 193/300 batch  79/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 193/300 batch  80/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 193/300 batch  81/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 193/300 batch  82/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 193/300 batch  83/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 193/300 batch  84/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 193/300 batch  85/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 193/300 batch  86/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 193/300 batch  87/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 193/300 batch  88/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 193/300 batch  89/188  Train Loss: 0.070, Acc: 0.984\n",
      "epoch: 193/300 batch  90/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 193/300 batch  91/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 193/300 batch  92/188  Train Loss: 0.031, Acc: 0.984\n",
      "epoch: 193/300 batch  93/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 193/300 batch  94/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 193/300 batch  95/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 193/300 batch  96/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 193/300 batch  97/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 193/300 batch  98/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 193/300 batch  99/188  Train Loss: 0.065, Acc: 0.988\n",
      "epoch: 193/300 batch 100/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 193/300 batch 101/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 193/300 batch 102/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 193/300 batch 103/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 193/300 batch 104/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 193/300 batch 105/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 193/300 batch 106/188  Train Loss: 0.059, Acc: 0.980\n",
      "epoch: 193/300 batch 107/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 193/300 batch 108/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 193/300 batch 109/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 193/300 batch 110/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 193/300 batch 111/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 193/300 batch 112/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 193/300 batch 113/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 193/300 batch 114/188  Train Loss: 0.047, Acc: 0.996\n",
      "epoch: 193/300 batch 115/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 193/300 batch 116/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 193/300 batch 117/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 193/300 batch 118/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 193/300 batch 119/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 193/300 batch 120/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 193/300 batch 121/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 193/300 batch 122/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 193/300 batch 123/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 193/300 batch 124/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 193/300 batch 125/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 193/300 batch 126/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 193/300 batch 127/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 193/300 batch 128/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 193/300 batch 129/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 193/300 batch 130/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 193/300 batch 131/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 193/300 batch 132/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 193/300 batch 133/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 193/300 batch 134/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 193/300 batch 135/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 193/300 batch 136/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 193/300 batch 137/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 193/300 batch 138/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 193/300 batch 139/188  Train Loss: 0.054, Acc: 0.980\n",
      "epoch: 193/300 batch 140/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 193/300 batch 141/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 193/300 batch 142/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 193/300 batch 143/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 193/300 batch 144/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 193/300 batch 145/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 193/300 batch 146/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 193/300 batch 147/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 193/300 batch 148/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 193/300 batch 149/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 193/300 batch 150/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 193/300 batch 151/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 193/300 batch 152/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 193/300 batch 153/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 193/300 batch 154/188  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 193/300 batch 155/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 193/300 batch 156/188  Train Loss: 0.045, Acc: 0.980\n",
      "epoch: 193/300 batch 157/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 193/300 batch 158/188  Train Loss: 0.034, Acc: 1.000\n",
      "epoch: 193/300 batch 159/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 193/300 batch 160/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 193/300 batch 161/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 193/300 batch 162/188  Train Loss: 0.064, Acc: 0.984\n",
      "epoch: 193/300 batch 163/188  Train Loss: 0.074, Acc: 0.980\n",
      "epoch: 193/300 batch 164/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 193/300 batch 165/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 193/300 batch 166/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 193/300 batch 167/188  Train Loss: 0.064, Acc: 0.984\n",
      "epoch: 193/300 batch 168/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 193/300 batch 169/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 193/300 batch 170/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 193/300 batch 171/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 193/300 batch 172/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 193/300 batch 173/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 193/300 batch 174/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 193/300 batch 175/188  Train Loss: 0.057, Acc: 0.980\n",
      "epoch: 193/300 batch 176/188  Train Loss: 0.058, Acc: 0.988\n",
      "epoch: 193/300 batch 177/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 193/300 batch 178/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 193/300 batch 179/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 193/300 batch 180/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 193/300 batch 181/188  Train Loss: 0.046, Acc: 0.977\n",
      "epoch: 193/300 batch 182/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 193/300 batch 183/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 193/300 batch 184/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 193/300 batch 185/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 193/300 batch 186/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 193/300 batch 187/188  Train Loss: 0.034, Acc: 0.992\n",
      "Train Loss: 0.033419, Acc: 0.992\n",
      "Val Loss: 0.057143, Acc: 0.983\n",
      "epoch: 194/300 batch   0/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 194/300 batch   1/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 194/300 batch   2/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 194/300 batch   3/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 194/300 batch   4/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 194/300 batch   5/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 194/300 batch   6/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 194/300 batch   7/188  Train Loss: 0.060, Acc: 0.996\n",
      "epoch: 194/300 batch   8/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 194/300 batch   9/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 194/300 batch  10/188  Train Loss: 0.032, Acc: 0.984\n",
      "epoch: 194/300 batch  11/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 194/300 batch  12/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 194/300 batch  13/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 194/300 batch  14/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 194/300 batch  15/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 194/300 batch  16/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 194/300 batch  17/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 194/300 batch  18/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 194/300 batch  19/188  Train Loss: 0.014, Acc: 0.996\n",
      "epoch: 194/300 batch  20/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 194/300 batch  21/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 194/300 batch  22/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 194/300 batch  23/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 194/300 batch  24/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 194/300 batch  25/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 194/300 batch  26/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 194/300 batch  27/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 194/300 batch  28/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 194/300 batch  29/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 194/300 batch  30/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 194/300 batch  31/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 194/300 batch  32/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 194/300 batch  33/188  Train Loss: 0.034, Acc: 0.984\n",
      "epoch: 194/300 batch  34/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 194/300 batch  35/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 194/300 batch  36/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 194/300 batch  37/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 194/300 batch  38/188  Train Loss: 0.059, Acc: 0.984\n",
      "epoch: 194/300 batch  39/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 194/300 batch  40/188  Train Loss: 0.052, Acc: 0.980\n",
      "epoch: 194/300 batch  41/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 194/300 batch  42/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 194/300 batch  43/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 194/300 batch  44/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 194/300 batch  45/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 194/300 batch  46/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 194/300 batch  47/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 194/300 batch  48/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 194/300 batch  49/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 194/300 batch  50/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 194/300 batch  51/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 194/300 batch  52/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 194/300 batch  53/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 194/300 batch  54/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 194/300 batch  55/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 194/300 batch  56/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 194/300 batch  57/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 194/300 batch  58/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 194/300 batch  59/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 194/300 batch  60/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 194/300 batch  61/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 194/300 batch  62/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 194/300 batch  63/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 194/300 batch  64/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 194/300 batch  65/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 194/300 batch  66/188  Train Loss: 0.051, Acc: 0.980\n",
      "epoch: 194/300 batch  67/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 194/300 batch  68/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 194/300 batch  69/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 194/300 batch  70/188  Train Loss: 0.060, Acc: 0.984\n",
      "epoch: 194/300 batch  71/188  Train Loss: 0.073, Acc: 0.973\n",
      "epoch: 194/300 batch  72/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 194/300 batch  73/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 194/300 batch  74/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 194/300 batch  75/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 194/300 batch  76/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 194/300 batch  77/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 194/300 batch  78/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 194/300 batch  79/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 194/300 batch  80/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 194/300 batch  81/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 194/300 batch  82/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 194/300 batch  83/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 194/300 batch  84/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 194/300 batch  85/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 194/300 batch  86/188  Train Loss: 0.055, Acc: 0.980\n",
      "epoch: 194/300 batch  87/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 194/300 batch  88/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 194/300 batch  89/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 194/300 batch  90/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 194/300 batch  91/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 194/300 batch  92/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 194/300 batch  93/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 194/300 batch  94/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 194/300 batch  95/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 194/300 batch  96/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 194/300 batch  97/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 194/300 batch  98/188  Train Loss: 0.067, Acc: 0.980\n",
      "epoch: 194/300 batch  99/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 194/300 batch 100/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 194/300 batch 101/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 194/300 batch 102/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 194/300 batch 103/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 194/300 batch 104/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 194/300 batch 105/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 194/300 batch 106/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 194/300 batch 107/188  Train Loss: 0.048, Acc: 0.996\n",
      "epoch: 194/300 batch 108/188  Train Loss: 0.051, Acc: 0.992\n",
      "epoch: 194/300 batch 109/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 194/300 batch 110/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 194/300 batch 111/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 194/300 batch 112/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 194/300 batch 113/188  Train Loss: 0.043, Acc: 0.996\n",
      "epoch: 194/300 batch 114/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 194/300 batch 115/188  Train Loss: 0.056, Acc: 0.977\n",
      "epoch: 194/300 batch 116/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 194/300 batch 117/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 194/300 batch 118/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 194/300 batch 119/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 194/300 batch 120/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 194/300 batch 121/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 194/300 batch 122/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 194/300 batch 123/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 194/300 batch 124/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 194/300 batch 125/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 194/300 batch 126/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 194/300 batch 127/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 194/300 batch 128/188  Train Loss: 0.026, Acc: 0.988\n",
      "epoch: 194/300 batch 129/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 194/300 batch 130/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 194/300 batch 131/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 194/300 batch 132/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 194/300 batch 133/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 194/300 batch 134/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 194/300 batch 135/188  Train Loss: 0.044, Acc: 0.996\n",
      "epoch: 194/300 batch 136/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 194/300 batch 137/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 194/300 batch 138/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 194/300 batch 139/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 194/300 batch 140/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 194/300 batch 141/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 194/300 batch 142/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 194/300 batch 143/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 194/300 batch 144/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 194/300 batch 145/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 194/300 batch 146/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 194/300 batch 147/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 194/300 batch 148/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 194/300 batch 149/188  Train Loss: 0.056, Acc: 0.977\n",
      "epoch: 194/300 batch 150/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 194/300 batch 151/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 194/300 batch 152/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 194/300 batch 153/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 194/300 batch 154/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 194/300 batch 155/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 194/300 batch 156/188  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 194/300 batch 157/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 194/300 batch 158/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 194/300 batch 159/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 194/300 batch 160/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 194/300 batch 161/188  Train Loss: 0.016, Acc: 0.996\n",
      "epoch: 194/300 batch 162/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 194/300 batch 163/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 194/300 batch 164/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 194/300 batch 165/188  Train Loss: 0.063, Acc: 0.984\n",
      "epoch: 194/300 batch 166/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 194/300 batch 167/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 194/300 batch 168/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 194/300 batch 169/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 194/300 batch 170/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 194/300 batch 171/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 194/300 batch 172/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 194/300 batch 173/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 194/300 batch 174/188  Train Loss: 0.015, Acc: 0.996\n",
      "epoch: 194/300 batch 175/188  Train Loss: 0.044, Acc: 0.996\n",
      "epoch: 194/300 batch 176/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 194/300 batch 177/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 194/300 batch 178/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 194/300 batch 179/188  Train Loss: 0.051, Acc: 0.980\n",
      "epoch: 194/300 batch 180/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 194/300 batch 181/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 194/300 batch 182/188  Train Loss: 0.058, Acc: 0.992\n",
      "epoch: 194/300 batch 183/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 194/300 batch 184/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 194/300 batch 185/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 194/300 batch 186/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 194/300 batch 187/188  Train Loss: 0.041, Acc: 0.984\n",
      "Train Loss: 0.033419, Acc: 0.993\n",
      "Val Loss: 0.057339, Acc: 0.982\n",
      "epoch: 195/300 batch   0/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 195/300 batch   1/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 195/300 batch   2/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 195/300 batch   3/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 195/300 batch   4/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 195/300 batch   5/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 195/300 batch   6/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 195/300 batch   7/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 195/300 batch   8/188  Train Loss: 0.045, Acc: 0.980\n",
      "epoch: 195/300 batch   9/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 195/300 batch  10/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 195/300 batch  11/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 195/300 batch  12/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 195/300 batch  13/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 195/300 batch  14/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 195/300 batch  15/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 195/300 batch  16/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 195/300 batch  17/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 195/300 batch  18/188  Train Loss: 0.022, Acc: 0.988\n",
      "epoch: 195/300 batch  19/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 195/300 batch  20/188  Train Loss: 0.062, Acc: 0.984\n",
      "epoch: 195/300 batch  21/188  Train Loss: 0.053, Acc: 0.980\n",
      "epoch: 195/300 batch  22/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 195/300 batch  23/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 195/300 batch  24/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 195/300 batch  25/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 195/300 batch  26/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 195/300 batch  27/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 195/300 batch  28/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 195/300 batch  29/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 195/300 batch  30/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 195/300 batch  31/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 195/300 batch  32/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 195/300 batch  33/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 195/300 batch  34/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 195/300 batch  35/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 195/300 batch  36/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 195/300 batch  37/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 195/300 batch  38/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 195/300 batch  39/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 195/300 batch  40/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 195/300 batch  41/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 195/300 batch  42/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 195/300 batch  43/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 195/300 batch  44/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 195/300 batch  45/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 195/300 batch  46/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 195/300 batch  47/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 195/300 batch  48/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 195/300 batch  49/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 195/300 batch  50/188  Train Loss: 0.056, Acc: 0.977\n",
      "epoch: 195/300 batch  51/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 195/300 batch  52/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 195/300 batch  53/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 195/300 batch  54/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 195/300 batch  55/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 195/300 batch  56/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 195/300 batch  57/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 195/300 batch  58/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 195/300 batch  59/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 195/300 batch  60/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 195/300 batch  61/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 195/300 batch  62/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 195/300 batch  63/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 195/300 batch  64/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 195/300 batch  65/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 195/300 batch  66/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 195/300 batch  67/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 195/300 batch  68/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 195/300 batch  69/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 195/300 batch  70/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 195/300 batch  71/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 195/300 batch  72/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 195/300 batch  73/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 195/300 batch  74/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 195/300 batch  75/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 195/300 batch  76/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 195/300 batch  77/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 195/300 batch  78/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 195/300 batch  79/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 195/300 batch  80/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 195/300 batch  81/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 195/300 batch  82/188  Train Loss: 0.061, Acc: 0.980\n",
      "epoch: 195/300 batch  83/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 195/300 batch  84/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 195/300 batch  85/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 195/300 batch  86/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 195/300 batch  87/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 195/300 batch  88/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 195/300 batch  89/188  Train Loss: 0.065, Acc: 0.984\n",
      "epoch: 195/300 batch  90/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 195/300 batch  91/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 195/300 batch  92/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 195/300 batch  93/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 195/300 batch  94/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 195/300 batch  95/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 195/300 batch  96/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 195/300 batch  97/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 195/300 batch  98/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 195/300 batch  99/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 195/300 batch 100/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 195/300 batch 101/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 195/300 batch 102/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 195/300 batch 103/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 195/300 batch 104/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 195/300 batch 105/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 195/300 batch 106/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 195/300 batch 107/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 195/300 batch 108/188  Train Loss: 0.044, Acc: 0.980\n",
      "epoch: 195/300 batch 109/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 195/300 batch 110/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 195/300 batch 111/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 195/300 batch 112/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 195/300 batch 113/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 195/300 batch 114/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 195/300 batch 115/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 195/300 batch 116/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 195/300 batch 117/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 195/300 batch 118/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 195/300 batch 119/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 195/300 batch 120/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 195/300 batch 121/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 195/300 batch 122/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 195/300 batch 123/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 195/300 batch 124/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 195/300 batch 125/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 195/300 batch 126/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 195/300 batch 127/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 195/300 batch 128/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 195/300 batch 129/188  Train Loss: 0.052, Acc: 0.977\n",
      "epoch: 195/300 batch 130/188  Train Loss: 0.062, Acc: 0.996\n",
      "epoch: 195/300 batch 131/188  Train Loss: 0.031, Acc: 1.000\n",
      "epoch: 195/300 batch 132/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 195/300 batch 133/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 195/300 batch 134/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 195/300 batch 135/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 195/300 batch 136/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 195/300 batch 137/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 195/300 batch 138/188  Train Loss: 0.015, Acc: 0.996\n",
      "epoch: 195/300 batch 139/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 195/300 batch 140/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 195/300 batch 141/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 195/300 batch 142/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 195/300 batch 143/188  Train Loss: 0.052, Acc: 0.992\n",
      "epoch: 195/300 batch 144/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 195/300 batch 145/188  Train Loss: 0.073, Acc: 0.984\n",
      "epoch: 195/300 batch 146/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 195/300 batch 147/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 195/300 batch 148/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 195/300 batch 149/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 195/300 batch 150/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 195/300 batch 151/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 195/300 batch 152/188  Train Loss: 0.060, Acc: 0.984\n",
      "epoch: 195/300 batch 153/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 195/300 batch 154/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 195/300 batch 155/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 195/300 batch 156/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 195/300 batch 157/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 195/300 batch 158/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 195/300 batch 159/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 195/300 batch 160/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 195/300 batch 161/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 195/300 batch 162/188  Train Loss: 0.066, Acc: 0.984\n",
      "epoch: 195/300 batch 163/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 195/300 batch 164/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 195/300 batch 165/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 195/300 batch 166/188  Train Loss: 0.047, Acc: 0.996\n",
      "epoch: 195/300 batch 167/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 195/300 batch 168/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 195/300 batch 169/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 195/300 batch 170/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 195/300 batch 171/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 195/300 batch 172/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 195/300 batch 173/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 195/300 batch 174/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 195/300 batch 175/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 195/300 batch 176/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 195/300 batch 177/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 195/300 batch 178/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 195/300 batch 179/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 195/300 batch 180/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 195/300 batch 181/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 195/300 batch 182/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 195/300 batch 183/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 195/300 batch 184/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 195/300 batch 185/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 195/300 batch 186/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 195/300 batch 187/188  Train Loss: 0.017, Acc: 1.000\n",
      "Train Loss: 0.033399, Acc: 0.993\n",
      "Val Loss: 0.057324, Acc: 0.983\n",
      "epoch: 196/300 batch   0/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 196/300 batch   1/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 196/300 batch   2/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 196/300 batch   3/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 196/300 batch   4/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 196/300 batch   5/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 196/300 batch   6/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 196/300 batch   7/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 196/300 batch   8/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 196/300 batch   9/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 196/300 batch  10/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 196/300 batch  11/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 196/300 batch  12/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 196/300 batch  13/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 196/300 batch  14/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 196/300 batch  15/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 196/300 batch  16/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 196/300 batch  17/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 196/300 batch  18/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 196/300 batch  19/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 196/300 batch  20/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 196/300 batch  21/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 196/300 batch  22/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 196/300 batch  23/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 196/300 batch  24/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 196/300 batch  25/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 196/300 batch  26/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 196/300 batch  27/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 196/300 batch  28/188  Train Loss: 0.057, Acc: 0.980\n",
      "epoch: 196/300 batch  29/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 196/300 batch  30/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 196/300 batch  31/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 196/300 batch  32/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 196/300 batch  33/188  Train Loss: 0.016, Acc: 0.996\n",
      "epoch: 196/300 batch  34/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 196/300 batch  35/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 196/300 batch  36/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 196/300 batch  37/188  Train Loss: 0.043, Acc: 0.980\n",
      "epoch: 196/300 batch  38/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 196/300 batch  39/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 196/300 batch  40/188  Train Loss: 0.057, Acc: 0.992\n",
      "epoch: 196/300 batch  41/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 196/300 batch  42/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 196/300 batch  43/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 196/300 batch  44/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 196/300 batch  45/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 196/300 batch  46/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 196/300 batch  47/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 196/300 batch  48/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 196/300 batch  49/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 196/300 batch  50/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 196/300 batch  51/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 196/300 batch  52/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 196/300 batch  53/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 196/300 batch  54/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 196/300 batch  55/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 196/300 batch  56/188  Train Loss: 0.072, Acc: 0.984\n",
      "epoch: 196/300 batch  57/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 196/300 batch  58/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 196/300 batch  59/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 196/300 batch  60/188  Train Loss: 0.055, Acc: 0.980\n",
      "epoch: 196/300 batch  61/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 196/300 batch  62/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 196/300 batch  63/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 196/300 batch  64/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 196/300 batch  65/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 196/300 batch  66/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 196/300 batch  67/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 196/300 batch  68/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 196/300 batch  69/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 196/300 batch  70/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 196/300 batch  71/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 196/300 batch  72/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 196/300 batch  73/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 196/300 batch  74/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 196/300 batch  75/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 196/300 batch  76/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 196/300 batch  77/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 196/300 batch  78/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 196/300 batch  79/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 196/300 batch  80/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 196/300 batch  81/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 196/300 batch  82/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 196/300 batch  83/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 196/300 batch  84/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 196/300 batch  85/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 196/300 batch  86/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 196/300 batch  87/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 196/300 batch  88/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 196/300 batch  89/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 196/300 batch  90/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 196/300 batch  91/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 196/300 batch  92/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 196/300 batch  93/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 196/300 batch  94/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 196/300 batch  95/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 196/300 batch  96/188  Train Loss: 0.051, Acc: 0.992\n",
      "epoch: 196/300 batch  97/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 196/300 batch  98/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 196/300 batch  99/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 196/300 batch 100/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 196/300 batch 101/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 196/300 batch 102/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 196/300 batch 103/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 196/300 batch 104/188  Train Loss: 0.053, Acc: 0.977\n",
      "epoch: 196/300 batch 105/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 196/300 batch 106/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 196/300 batch 107/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 196/300 batch 108/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 196/300 batch 109/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 196/300 batch 110/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 196/300 batch 111/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 196/300 batch 112/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 196/300 batch 113/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 196/300 batch 114/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 196/300 batch 115/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 196/300 batch 116/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 196/300 batch 117/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 196/300 batch 118/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 196/300 batch 119/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 196/300 batch 120/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 196/300 batch 121/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 196/300 batch 122/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 196/300 batch 123/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 196/300 batch 124/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 196/300 batch 125/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 196/300 batch 126/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 196/300 batch 127/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 196/300 batch 128/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 196/300 batch 129/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 196/300 batch 130/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 196/300 batch 131/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 196/300 batch 132/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 196/300 batch 133/188  Train Loss: 0.042, Acc: 0.980\n",
      "epoch: 196/300 batch 134/188  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 196/300 batch 135/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 196/300 batch 136/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 196/300 batch 137/188  Train Loss: 0.043, Acc: 0.996\n",
      "epoch: 196/300 batch 138/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 196/300 batch 139/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 196/300 batch 140/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 196/300 batch 141/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 196/300 batch 142/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 196/300 batch 143/188  Train Loss: 0.080, Acc: 0.969\n",
      "epoch: 196/300 batch 144/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 196/300 batch 145/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 196/300 batch 146/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 196/300 batch 147/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 196/300 batch 148/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 196/300 batch 149/188  Train Loss: 0.064, Acc: 0.977\n",
      "epoch: 196/300 batch 150/188  Train Loss: 0.056, Acc: 0.980\n",
      "epoch: 196/300 batch 151/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 196/300 batch 152/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 196/300 batch 153/188  Train Loss: 0.049, Acc: 0.977\n",
      "epoch: 196/300 batch 154/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 196/300 batch 155/188  Train Loss: 0.059, Acc: 0.996\n",
      "epoch: 196/300 batch 156/188  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 196/300 batch 157/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 196/300 batch 158/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 196/300 batch 159/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 196/300 batch 160/188  Train Loss: 0.058, Acc: 0.992\n",
      "epoch: 196/300 batch 161/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 196/300 batch 162/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 196/300 batch 163/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 196/300 batch 164/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 196/300 batch 165/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 196/300 batch 166/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 196/300 batch 167/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 196/300 batch 168/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 196/300 batch 169/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 196/300 batch 170/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 196/300 batch 171/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 196/300 batch 172/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 196/300 batch 173/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 196/300 batch 174/188  Train Loss: 0.015, Acc: 0.996\n",
      "epoch: 196/300 batch 175/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 196/300 batch 176/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 196/300 batch 177/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 196/300 batch 178/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 196/300 batch 179/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 196/300 batch 180/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 196/300 batch 181/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 196/300 batch 182/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 196/300 batch 183/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 196/300 batch 184/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 196/300 batch 185/188  Train Loss: 0.044, Acc: 0.996\n",
      "epoch: 196/300 batch 186/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 196/300 batch 187/188  Train Loss: 0.029, Acc: 0.992\n",
      "Train Loss: 0.033308, Acc: 0.993\n",
      "Val Loss: 0.057320, Acc: 0.983\n",
      "epoch: 197/300 batch   0/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 197/300 batch   1/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 197/300 batch   2/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 197/300 batch   3/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 197/300 batch   4/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 197/300 batch   5/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 197/300 batch   6/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 197/300 batch   7/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 197/300 batch   8/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 197/300 batch   9/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 197/300 batch  10/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 197/300 batch  11/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 197/300 batch  12/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 197/300 batch  13/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 197/300 batch  14/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 197/300 batch  15/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 197/300 batch  16/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 197/300 batch  17/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 197/300 batch  18/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 197/300 batch  19/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 197/300 batch  20/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 197/300 batch  21/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 197/300 batch  22/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 197/300 batch  23/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 197/300 batch  24/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 197/300 batch  25/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 197/300 batch  26/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 197/300 batch  27/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 197/300 batch  28/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 197/300 batch  29/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 197/300 batch  30/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 197/300 batch  31/188  Train Loss: 0.059, Acc: 0.988\n",
      "epoch: 197/300 batch  32/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 197/300 batch  33/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 197/300 batch  34/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 197/300 batch  35/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 197/300 batch  36/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 197/300 batch  37/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 197/300 batch  38/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 197/300 batch  39/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 197/300 batch  40/188  Train Loss: 0.059, Acc: 0.988\n",
      "epoch: 197/300 batch  41/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 197/300 batch  42/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 197/300 batch  43/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 197/300 batch  44/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 197/300 batch  45/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 197/300 batch  46/188  Train Loss: 0.065, Acc: 0.988\n",
      "epoch: 197/300 batch  47/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 197/300 batch  48/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 197/300 batch  49/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 197/300 batch  50/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 197/300 batch  51/188  Train Loss: 0.073, Acc: 0.980\n",
      "epoch: 197/300 batch  52/188  Train Loss: 0.056, Acc: 0.988\n",
      "epoch: 197/300 batch  53/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 197/300 batch  54/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 197/300 batch  55/188  Train Loss: 0.032, Acc: 1.000\n",
      "epoch: 197/300 batch  56/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 197/300 batch  57/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 197/300 batch  58/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 197/300 batch  59/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 197/300 batch  60/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 197/300 batch  61/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 197/300 batch  62/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 197/300 batch  63/188  Train Loss: 0.051, Acc: 0.992\n",
      "epoch: 197/300 batch  64/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 197/300 batch  65/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 197/300 batch  66/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 197/300 batch  67/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 197/300 batch  68/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 197/300 batch  69/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 197/300 batch  70/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 197/300 batch  71/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 197/300 batch  72/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 197/300 batch  73/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 197/300 batch  74/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 197/300 batch  75/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 197/300 batch  76/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 197/300 batch  77/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 197/300 batch  78/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 197/300 batch  79/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 197/300 batch  80/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 197/300 batch  81/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 197/300 batch  82/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 197/300 batch  83/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 197/300 batch  84/188  Train Loss: 0.051, Acc: 0.977\n",
      "epoch: 197/300 batch  85/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 197/300 batch  86/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 197/300 batch  87/188  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 197/300 batch  88/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 197/300 batch  89/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 197/300 batch  90/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 197/300 batch  91/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 197/300 batch  92/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 197/300 batch  93/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 197/300 batch  94/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 197/300 batch  95/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 197/300 batch  96/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 197/300 batch  97/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 197/300 batch  98/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 197/300 batch  99/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 197/300 batch 100/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 197/300 batch 101/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 197/300 batch 102/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 197/300 batch 103/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 197/300 batch 104/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 197/300 batch 105/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 197/300 batch 106/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 197/300 batch 107/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 197/300 batch 108/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 197/300 batch 109/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 197/300 batch 110/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 197/300 batch 111/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 197/300 batch 112/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 197/300 batch 113/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 197/300 batch 114/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 197/300 batch 115/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 197/300 batch 116/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 197/300 batch 117/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 197/300 batch 118/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 197/300 batch 119/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 197/300 batch 120/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 197/300 batch 121/188  Train Loss: 0.074, Acc: 0.980\n",
      "epoch: 197/300 batch 122/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 197/300 batch 123/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 197/300 batch 124/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 197/300 batch 125/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 197/300 batch 126/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 197/300 batch 127/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 197/300 batch 128/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 197/300 batch 129/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 197/300 batch 130/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 197/300 batch 131/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 197/300 batch 132/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 197/300 batch 133/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 197/300 batch 134/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 197/300 batch 135/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 197/300 batch 136/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 197/300 batch 137/188  Train Loss: 0.052, Acc: 0.977\n",
      "epoch: 197/300 batch 138/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 197/300 batch 139/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 197/300 batch 140/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 197/300 batch 141/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 197/300 batch 142/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 197/300 batch 143/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 197/300 batch 144/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 197/300 batch 145/188  Train Loss: 0.058, Acc: 0.988\n",
      "epoch: 197/300 batch 146/188  Train Loss: 0.032, Acc: 0.984\n",
      "epoch: 197/300 batch 147/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 197/300 batch 148/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 197/300 batch 149/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 197/300 batch 150/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 197/300 batch 151/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 197/300 batch 152/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 197/300 batch 153/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 197/300 batch 154/188  Train Loss: 0.032, Acc: 1.000\n",
      "epoch: 197/300 batch 155/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 197/300 batch 156/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 197/300 batch 157/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 197/300 batch 158/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 197/300 batch 159/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 197/300 batch 160/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 197/300 batch 161/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 197/300 batch 162/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 197/300 batch 163/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 197/300 batch 164/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 197/300 batch 165/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 197/300 batch 166/188  Train Loss: 0.043, Acc: 0.980\n",
      "epoch: 197/300 batch 167/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 197/300 batch 168/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 197/300 batch 169/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 197/300 batch 170/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 197/300 batch 171/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 197/300 batch 172/188  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 197/300 batch 173/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 197/300 batch 174/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 197/300 batch 175/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 197/300 batch 176/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 197/300 batch 177/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 197/300 batch 178/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 197/300 batch 179/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 197/300 batch 180/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 197/300 batch 181/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 197/300 batch 182/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 197/300 batch 183/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 197/300 batch 184/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 197/300 batch 185/188  Train Loss: 0.057, Acc: 0.973\n",
      "epoch: 197/300 batch 186/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 197/300 batch 187/188  Train Loss: 0.033, Acc: 0.992\n",
      "Train Loss: 0.033361, Acc: 0.993\n",
      "Val Loss: 0.057424, Acc: 0.982\n",
      "epoch: 198/300 batch   0/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 198/300 batch   1/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 198/300 batch   2/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 198/300 batch   3/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 198/300 batch   4/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 198/300 batch   5/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 198/300 batch   6/188  Train Loss: 0.064, Acc: 0.988\n",
      "epoch: 198/300 batch   7/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 198/300 batch   8/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 198/300 batch   9/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 198/300 batch  10/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 198/300 batch  11/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 198/300 batch  12/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 198/300 batch  13/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 198/300 batch  14/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 198/300 batch  15/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 198/300 batch  16/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 198/300 batch  17/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 198/300 batch  18/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 198/300 batch  19/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 198/300 batch  20/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 198/300 batch  21/188  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 198/300 batch  22/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 198/300 batch  23/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 198/300 batch  24/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 198/300 batch  25/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 198/300 batch  26/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 198/300 batch  27/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 198/300 batch  28/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 198/300 batch  29/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 198/300 batch  30/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 198/300 batch  31/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 198/300 batch  32/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 198/300 batch  33/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 198/300 batch  34/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 198/300 batch  35/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 198/300 batch  36/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 198/300 batch  37/188  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 198/300 batch  38/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 198/300 batch  39/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 198/300 batch  40/188  Train Loss: 0.065, Acc: 0.992\n",
      "epoch: 198/300 batch  41/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 198/300 batch  42/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 198/300 batch  43/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 198/300 batch  44/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 198/300 batch  45/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 198/300 batch  46/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 198/300 batch  47/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 198/300 batch  48/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 198/300 batch  49/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 198/300 batch  50/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 198/300 batch  51/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 198/300 batch  52/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 198/300 batch  53/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 198/300 batch  54/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 198/300 batch  55/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 198/300 batch  56/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 198/300 batch  57/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 198/300 batch  58/188  Train Loss: 0.043, Acc: 0.980\n",
      "epoch: 198/300 batch  59/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 198/300 batch  60/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 198/300 batch  61/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 198/300 batch  62/188  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 198/300 batch  63/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 198/300 batch  64/188  Train Loss: 0.055, Acc: 0.980\n",
      "epoch: 198/300 batch  65/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 198/300 batch  66/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 198/300 batch  67/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 198/300 batch  68/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 198/300 batch  69/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 198/300 batch  70/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 198/300 batch  71/188  Train Loss: 0.052, Acc: 0.992\n",
      "epoch: 198/300 batch  72/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 198/300 batch  73/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 198/300 batch  74/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 198/300 batch  75/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 198/300 batch  76/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 198/300 batch  77/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 198/300 batch  78/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 198/300 batch  79/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 198/300 batch  80/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 198/300 batch  81/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 198/300 batch  82/188  Train Loss: 0.052, Acc: 0.980\n",
      "epoch: 198/300 batch  83/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 198/300 batch  84/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 198/300 batch  85/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 198/300 batch  86/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 198/300 batch  87/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 198/300 batch  88/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 198/300 batch  89/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 198/300 batch  90/188  Train Loss: 0.042, Acc: 0.996\n",
      "epoch: 198/300 batch  91/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 198/300 batch  92/188  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 198/300 batch  93/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 198/300 batch  94/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 198/300 batch  95/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 198/300 batch  96/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 198/300 batch  97/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 198/300 batch  98/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 198/300 batch  99/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 198/300 batch 100/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 198/300 batch 101/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 198/300 batch 102/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 198/300 batch 103/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 198/300 batch 104/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 198/300 batch 105/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 198/300 batch 106/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 198/300 batch 107/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 198/300 batch 108/188  Train Loss: 0.026, Acc: 0.988\n",
      "epoch: 198/300 batch 109/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 198/300 batch 110/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 198/300 batch 111/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 198/300 batch 112/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 198/300 batch 113/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 198/300 batch 114/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 198/300 batch 115/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 198/300 batch 116/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 198/300 batch 117/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 198/300 batch 118/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 198/300 batch 119/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 198/300 batch 120/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 198/300 batch 121/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 198/300 batch 122/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 198/300 batch 123/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 198/300 batch 124/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 198/300 batch 125/188  Train Loss: 0.034, Acc: 0.980\n",
      "epoch: 198/300 batch 126/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 198/300 batch 127/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 198/300 batch 128/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 198/300 batch 129/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 198/300 batch 130/188  Train Loss: 0.057, Acc: 0.988\n",
      "epoch: 198/300 batch 131/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 198/300 batch 132/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 198/300 batch 133/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 198/300 batch 134/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 198/300 batch 135/188  Train Loss: 0.045, Acc: 0.996\n",
      "epoch: 198/300 batch 136/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 198/300 batch 137/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 198/300 batch 138/188  Train Loss: 0.078, Acc: 0.980\n",
      "epoch: 198/300 batch 139/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 198/300 batch 140/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 198/300 batch 141/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 198/300 batch 142/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 198/300 batch 143/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 198/300 batch 144/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 198/300 batch 145/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 198/300 batch 146/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 198/300 batch 147/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 198/300 batch 148/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 198/300 batch 149/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 198/300 batch 150/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 198/300 batch 151/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 198/300 batch 152/188  Train Loss: 0.065, Acc: 0.980\n",
      "epoch: 198/300 batch 153/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 198/300 batch 154/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 198/300 batch 155/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 198/300 batch 156/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 198/300 batch 157/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 198/300 batch 158/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 198/300 batch 159/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 198/300 batch 160/188  Train Loss: 0.059, Acc: 0.988\n",
      "epoch: 198/300 batch 161/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 198/300 batch 162/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 198/300 batch 163/188  Train Loss: 0.058, Acc: 0.992\n",
      "epoch: 198/300 batch 164/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 198/300 batch 165/188  Train Loss: 0.062, Acc: 0.980\n",
      "epoch: 198/300 batch 166/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 198/300 batch 167/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 198/300 batch 168/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 198/300 batch 169/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 198/300 batch 170/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 198/300 batch 171/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 198/300 batch 172/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 198/300 batch 173/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 198/300 batch 174/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 198/300 batch 175/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 198/300 batch 176/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 198/300 batch 177/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 198/300 batch 178/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 198/300 batch 179/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 198/300 batch 180/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 198/300 batch 181/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 198/300 batch 182/188  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 198/300 batch 183/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 198/300 batch 184/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 198/300 batch 185/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 198/300 batch 186/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 198/300 batch 187/188  Train Loss: 0.033, Acc: 0.984\n",
      "Train Loss: 0.033341, Acc: 0.992\n",
      "Val Loss: 0.057631, Acc: 0.983\n",
      "epoch: 199/300 batch   0/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 199/300 batch   1/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 199/300 batch   2/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 199/300 batch   3/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 199/300 batch   4/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 199/300 batch   5/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 199/300 batch   6/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 199/300 batch   7/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 199/300 batch   8/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 199/300 batch   9/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 199/300 batch  10/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 199/300 batch  11/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 199/300 batch  12/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 199/300 batch  13/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 199/300 batch  14/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 199/300 batch  15/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 199/300 batch  16/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 199/300 batch  17/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 199/300 batch  18/188  Train Loss: 0.045, Acc: 0.996\n",
      "epoch: 199/300 batch  19/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 199/300 batch  20/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 199/300 batch  21/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 199/300 batch  22/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 199/300 batch  23/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 199/300 batch  24/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 199/300 batch  25/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 199/300 batch  26/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 199/300 batch  27/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 199/300 batch  28/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 199/300 batch  29/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 199/300 batch  30/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 199/300 batch  31/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 199/300 batch  32/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 199/300 batch  33/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 199/300 batch  34/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 199/300 batch  35/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 199/300 batch  36/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 199/300 batch  37/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 199/300 batch  38/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 199/300 batch  39/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 199/300 batch  40/188  Train Loss: 0.049, Acc: 0.977\n",
      "epoch: 199/300 batch  41/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 199/300 batch  42/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 199/300 batch  43/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 199/300 batch  44/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 199/300 batch  45/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 199/300 batch  46/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 199/300 batch  47/188  Train Loss: 0.033, Acc: 1.000\n",
      "epoch: 199/300 batch  48/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 199/300 batch  49/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 199/300 batch  50/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 199/300 batch  51/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 199/300 batch  52/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 199/300 batch  53/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 199/300 batch  54/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 199/300 batch  55/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 199/300 batch  56/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 199/300 batch  57/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 199/300 batch  58/188  Train Loss: 0.064, Acc: 0.988\n",
      "epoch: 199/300 batch  59/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 199/300 batch  60/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 199/300 batch  61/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 199/300 batch  62/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 199/300 batch  63/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 199/300 batch  64/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 199/300 batch  65/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 199/300 batch  66/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 199/300 batch  67/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 199/300 batch  68/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 199/300 batch  69/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 199/300 batch  70/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 199/300 batch  71/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 199/300 batch  72/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 199/300 batch  73/188  Train Loss: 0.034, Acc: 1.000\n",
      "epoch: 199/300 batch  74/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 199/300 batch  75/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 199/300 batch  76/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 199/300 batch  77/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 199/300 batch  78/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 199/300 batch  79/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 199/300 batch  80/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 199/300 batch  81/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 199/300 batch  82/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 199/300 batch  83/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 199/300 batch  84/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 199/300 batch  85/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 199/300 batch  86/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 199/300 batch  87/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 199/300 batch  88/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 199/300 batch  89/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 199/300 batch  90/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 199/300 batch  91/188  Train Loss: 0.059, Acc: 0.984\n",
      "epoch: 199/300 batch  92/188  Train Loss: 0.053, Acc: 0.977\n",
      "epoch: 199/300 batch  93/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 199/300 batch  94/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 199/300 batch  95/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 199/300 batch  96/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 199/300 batch  97/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 199/300 batch  98/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 199/300 batch  99/188  Train Loss: 0.038, Acc: 0.980\n",
      "epoch: 199/300 batch 100/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 199/300 batch 101/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 199/300 batch 102/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 199/300 batch 103/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 199/300 batch 104/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 199/300 batch 105/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 199/300 batch 106/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 199/300 batch 107/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 199/300 batch 108/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 199/300 batch 109/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 199/300 batch 110/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 199/300 batch 111/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 199/300 batch 112/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 199/300 batch 113/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 199/300 batch 114/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 199/300 batch 115/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 199/300 batch 116/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 199/300 batch 117/188  Train Loss: 0.053, Acc: 0.992\n",
      "epoch: 199/300 batch 118/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 199/300 batch 119/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 199/300 batch 120/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 199/300 batch 121/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 199/300 batch 122/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 199/300 batch 123/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 199/300 batch 124/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 199/300 batch 125/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 199/300 batch 126/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 199/300 batch 127/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 199/300 batch 128/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 199/300 batch 129/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 199/300 batch 130/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 199/300 batch 131/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 199/300 batch 132/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 199/300 batch 133/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 199/300 batch 134/188  Train Loss: 0.053, Acc: 0.992\n",
      "epoch: 199/300 batch 135/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 199/300 batch 136/188  Train Loss: 0.046, Acc: 0.996\n",
      "epoch: 199/300 batch 137/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 199/300 batch 138/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 199/300 batch 139/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 199/300 batch 140/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 199/300 batch 141/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 199/300 batch 142/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 199/300 batch 143/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 199/300 batch 144/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 199/300 batch 145/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 199/300 batch 146/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 199/300 batch 147/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 199/300 batch 148/188  Train Loss: 0.027, Acc: 0.988\n",
      "epoch: 199/300 batch 149/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 199/300 batch 150/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 199/300 batch 151/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 199/300 batch 152/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 199/300 batch 153/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 199/300 batch 154/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 199/300 batch 155/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 199/300 batch 156/188  Train Loss: 0.051, Acc: 0.980\n",
      "epoch: 199/300 batch 157/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 199/300 batch 158/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 199/300 batch 159/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 199/300 batch 160/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 199/300 batch 161/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 199/300 batch 162/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 199/300 batch 163/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 199/300 batch 164/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 199/300 batch 165/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 199/300 batch 166/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 199/300 batch 167/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 199/300 batch 168/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 199/300 batch 169/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 199/300 batch 170/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 199/300 batch 171/188  Train Loss: 0.067, Acc: 0.996\n",
      "epoch: 199/300 batch 172/188  Train Loss: 0.056, Acc: 0.988\n",
      "epoch: 199/300 batch 173/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 199/300 batch 174/188  Train Loss: 0.034, Acc: 0.984\n",
      "epoch: 199/300 batch 175/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 199/300 batch 176/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 199/300 batch 177/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 199/300 batch 178/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 199/300 batch 179/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 199/300 batch 180/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 199/300 batch 181/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 199/300 batch 182/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 199/300 batch 183/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 199/300 batch 184/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 199/300 batch 185/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 199/300 batch 186/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 199/300 batch 187/188  Train Loss: 0.017, Acc: 1.000\n",
      "Train Loss: 0.033352, Acc: 0.993\n",
      "Val Loss: 0.057830, Acc: 0.983\n",
      "epoch: 200/300 batch   0/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 200/300 batch   1/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 200/300 batch   2/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 200/300 batch   3/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 200/300 batch   4/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 200/300 batch   5/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 200/300 batch   6/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 200/300 batch   7/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 200/300 batch   8/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 200/300 batch   9/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 200/300 batch  10/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 200/300 batch  11/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 200/300 batch  12/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 200/300 batch  13/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 200/300 batch  14/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 200/300 batch  15/188  Train Loss: 0.036, Acc: 1.000\n",
      "epoch: 200/300 batch  16/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 200/300 batch  17/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 200/300 batch  18/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 200/300 batch  19/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 200/300 batch  20/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 200/300 batch  21/188  Train Loss: 0.055, Acc: 0.977\n",
      "epoch: 200/300 batch  22/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 200/300 batch  23/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 200/300 batch  24/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 200/300 batch  25/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 200/300 batch  26/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 200/300 batch  27/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 200/300 batch  28/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 200/300 batch  29/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 200/300 batch  30/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 200/300 batch  31/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 200/300 batch  32/188  Train Loss: 0.052, Acc: 0.992\n",
      "epoch: 200/300 batch  33/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 200/300 batch  34/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 200/300 batch  35/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 200/300 batch  36/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 200/300 batch  37/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 200/300 batch  38/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 200/300 batch  39/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 200/300 batch  40/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 200/300 batch  41/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 200/300 batch  42/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 200/300 batch  43/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 200/300 batch  44/188  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 200/300 batch  45/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 200/300 batch  46/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 200/300 batch  47/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 200/300 batch  48/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 200/300 batch  49/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 200/300 batch  50/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 200/300 batch  51/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 200/300 batch  52/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 200/300 batch  53/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 200/300 batch  54/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 200/300 batch  55/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 200/300 batch  56/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 200/300 batch  57/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 200/300 batch  58/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 200/300 batch  59/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 200/300 batch  60/188  Train Loss: 0.052, Acc: 0.980\n",
      "epoch: 200/300 batch  61/188  Train Loss: 0.043, Acc: 0.996\n",
      "epoch: 200/300 batch  62/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 200/300 batch  63/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 200/300 batch  64/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 200/300 batch  65/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 200/300 batch  66/188  Train Loss: 0.055, Acc: 0.980\n",
      "epoch: 200/300 batch  67/188  Train Loss: 0.060, Acc: 0.980\n",
      "epoch: 200/300 batch  68/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 200/300 batch  69/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 200/300 batch  70/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 200/300 batch  71/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 200/300 batch  72/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 200/300 batch  73/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 200/300 batch  74/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 200/300 batch  75/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 200/300 batch  76/188  Train Loss: 0.058, Acc: 0.980\n",
      "epoch: 200/300 batch  77/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 200/300 batch  78/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 200/300 batch  79/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 200/300 batch  80/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 200/300 batch  81/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 200/300 batch  82/188  Train Loss: 0.052, Acc: 0.969\n",
      "epoch: 200/300 batch  83/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 200/300 batch  84/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 200/300 batch  85/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 200/300 batch  86/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 200/300 batch  87/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 200/300 batch  88/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 200/300 batch  89/188  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 200/300 batch  90/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 200/300 batch  91/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 200/300 batch  92/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 200/300 batch  93/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 200/300 batch  94/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 200/300 batch  95/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 200/300 batch  96/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 200/300 batch  97/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 200/300 batch  98/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 200/300 batch  99/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 200/300 batch 100/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 200/300 batch 101/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 200/300 batch 102/188  Train Loss: 0.057, Acc: 0.977\n",
      "epoch: 200/300 batch 103/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 200/300 batch 104/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 200/300 batch 105/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 200/300 batch 106/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 200/300 batch 107/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 200/300 batch 108/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 200/300 batch 109/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 200/300 batch 110/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 200/300 batch 111/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 200/300 batch 112/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 200/300 batch 113/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 200/300 batch 114/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 200/300 batch 115/188  Train Loss: 0.061, Acc: 0.984\n",
      "epoch: 200/300 batch 116/188  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 200/300 batch 117/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 200/300 batch 118/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 200/300 batch 119/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 200/300 batch 120/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 200/300 batch 121/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 200/300 batch 122/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 200/300 batch 123/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 200/300 batch 124/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 200/300 batch 125/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 200/300 batch 126/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 200/300 batch 127/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 200/300 batch 128/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 200/300 batch 129/188  Train Loss: 0.051, Acc: 0.992\n",
      "epoch: 200/300 batch 130/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 200/300 batch 131/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 200/300 batch 132/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 200/300 batch 133/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 200/300 batch 134/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 200/300 batch 135/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 200/300 batch 136/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 200/300 batch 137/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 200/300 batch 138/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 200/300 batch 139/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 200/300 batch 140/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 200/300 batch 141/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 200/300 batch 142/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 200/300 batch 143/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 200/300 batch 144/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 200/300 batch 145/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 200/300 batch 146/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 200/300 batch 147/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 200/300 batch 148/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 200/300 batch 149/188  Train Loss: 0.043, Acc: 0.996\n",
      "epoch: 200/300 batch 150/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 200/300 batch 151/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 200/300 batch 152/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 200/300 batch 153/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 200/300 batch 154/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 200/300 batch 155/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 200/300 batch 156/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 200/300 batch 157/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 200/300 batch 158/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 200/300 batch 159/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 200/300 batch 160/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 200/300 batch 161/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 200/300 batch 162/188  Train Loss: 0.073, Acc: 0.973\n",
      "epoch: 200/300 batch 163/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 200/300 batch 164/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 200/300 batch 165/188  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 200/300 batch 166/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 200/300 batch 167/188  Train Loss: 0.061, Acc: 0.992\n",
      "epoch: 200/300 batch 168/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 200/300 batch 169/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 200/300 batch 170/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 200/300 batch 171/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 200/300 batch 172/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 200/300 batch 173/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 200/300 batch 174/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 200/300 batch 175/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 200/300 batch 176/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 200/300 batch 177/188  Train Loss: 0.057, Acc: 0.988\n",
      "epoch: 200/300 batch 178/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 200/300 batch 179/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 200/300 batch 180/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 200/300 batch 181/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 200/300 batch 182/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 200/300 batch 183/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 200/300 batch 184/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 200/300 batch 185/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 200/300 batch 186/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 200/300 batch 187/188  Train Loss: 0.027, Acc: 1.000\n",
      "Train Loss: 0.033299, Acc: 0.993\n",
      "Val Loss: 0.057342, Acc: 0.983\n",
      "epoch: 201/300 batch   0/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 201/300 batch   1/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 201/300 batch   2/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 201/300 batch   3/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 201/300 batch   4/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 201/300 batch   5/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 201/300 batch   6/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 201/300 batch   7/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 201/300 batch   8/188  Train Loss: 0.051, Acc: 0.992\n",
      "epoch: 201/300 batch   9/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 201/300 batch  10/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 201/300 batch  11/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 201/300 batch  12/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 201/300 batch  13/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 201/300 batch  14/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 201/300 batch  15/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 201/300 batch  16/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 201/300 batch  17/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 201/300 batch  18/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 201/300 batch  19/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 201/300 batch  20/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 201/300 batch  21/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 201/300 batch  22/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 201/300 batch  23/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 201/300 batch  24/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 201/300 batch  25/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 201/300 batch  26/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 201/300 batch  27/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 201/300 batch  28/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 201/300 batch  29/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 201/300 batch  30/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 201/300 batch  31/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 201/300 batch  32/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 201/300 batch  33/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 201/300 batch  34/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 201/300 batch  35/188  Train Loss: 0.040, Acc: 0.980\n",
      "epoch: 201/300 batch  36/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 201/300 batch  37/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 201/300 batch  38/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 201/300 batch  39/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 201/300 batch  40/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 201/300 batch  41/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 201/300 batch  42/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 201/300 batch  43/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 201/300 batch  44/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 201/300 batch  45/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 201/300 batch  46/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 201/300 batch  47/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 201/300 batch  48/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 201/300 batch  49/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 201/300 batch  50/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 201/300 batch  51/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 201/300 batch  52/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 201/300 batch  53/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 201/300 batch  54/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 201/300 batch  55/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 201/300 batch  56/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 201/300 batch  57/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 201/300 batch  58/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 201/300 batch  59/188  Train Loss: 0.067, Acc: 0.992\n",
      "epoch: 201/300 batch  60/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 201/300 batch  61/188  Train Loss: 0.057, Acc: 0.980\n",
      "epoch: 201/300 batch  62/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 201/300 batch  63/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 201/300 batch  64/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 201/300 batch  65/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 201/300 batch  66/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 201/300 batch  67/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 201/300 batch  68/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 201/300 batch  69/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 201/300 batch  70/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 201/300 batch  71/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 201/300 batch  72/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 201/300 batch  73/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 201/300 batch  74/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 201/300 batch  75/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 201/300 batch  76/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 201/300 batch  77/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 201/300 batch  78/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 201/300 batch  79/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 201/300 batch  80/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 201/300 batch  81/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 201/300 batch  82/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 201/300 batch  83/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 201/300 batch  84/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 201/300 batch  85/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 201/300 batch  86/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 201/300 batch  87/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 201/300 batch  88/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 201/300 batch  89/188  Train Loss: 0.059, Acc: 0.984\n",
      "epoch: 201/300 batch  90/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 201/300 batch  91/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 201/300 batch  92/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 201/300 batch  93/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 201/300 batch  94/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 201/300 batch  95/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 201/300 batch  96/188  Train Loss: 0.032, Acc: 1.000\n",
      "epoch: 201/300 batch  97/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 201/300 batch  98/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 201/300 batch  99/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 201/300 batch 100/188  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 201/300 batch 101/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 201/300 batch 102/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 201/300 batch 103/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 201/300 batch 104/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 201/300 batch 105/188  Train Loss: 0.063, Acc: 0.984\n",
      "epoch: 201/300 batch 106/188  Train Loss: 0.047, Acc: 0.996\n",
      "epoch: 201/300 batch 107/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 201/300 batch 108/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 201/300 batch 109/188  Train Loss: 0.056, Acc: 0.988\n",
      "epoch: 201/300 batch 110/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 201/300 batch 111/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 201/300 batch 112/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 201/300 batch 113/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 201/300 batch 114/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 201/300 batch 115/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 201/300 batch 116/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 201/300 batch 117/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 201/300 batch 118/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 201/300 batch 119/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 201/300 batch 120/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 201/300 batch 121/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 201/300 batch 122/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 201/300 batch 123/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 201/300 batch 124/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 201/300 batch 125/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 201/300 batch 126/188  Train Loss: 0.016, Acc: 0.996\n",
      "epoch: 201/300 batch 127/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 201/300 batch 128/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 201/300 batch 129/188  Train Loss: 0.032, Acc: 0.984\n",
      "epoch: 201/300 batch 130/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 201/300 batch 131/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 201/300 batch 132/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 201/300 batch 133/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 201/300 batch 134/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 201/300 batch 135/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 201/300 batch 136/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 201/300 batch 137/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 201/300 batch 138/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 201/300 batch 139/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 201/300 batch 140/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 201/300 batch 141/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 201/300 batch 142/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 201/300 batch 143/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 201/300 batch 144/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 201/300 batch 145/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 201/300 batch 146/188  Train Loss: 0.053, Acc: 0.992\n",
      "epoch: 201/300 batch 147/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 201/300 batch 148/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 201/300 batch 149/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 201/300 batch 150/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 201/300 batch 151/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 201/300 batch 152/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 201/300 batch 153/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 201/300 batch 154/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 201/300 batch 155/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 201/300 batch 156/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 201/300 batch 157/188  Train Loss: 0.013, Acc: 0.996\n",
      "epoch: 201/300 batch 158/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 201/300 batch 159/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 201/300 batch 160/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 201/300 batch 161/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 201/300 batch 162/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 201/300 batch 163/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 201/300 batch 164/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 201/300 batch 165/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 201/300 batch 166/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 201/300 batch 167/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 201/300 batch 168/188  Train Loss: 0.069, Acc: 0.973\n",
      "epoch: 201/300 batch 169/188  Train Loss: 0.043, Acc: 0.996\n",
      "epoch: 201/300 batch 170/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 201/300 batch 171/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 201/300 batch 172/188  Train Loss: 0.053, Acc: 0.996\n",
      "epoch: 201/300 batch 173/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 201/300 batch 174/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 201/300 batch 175/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 201/300 batch 176/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 201/300 batch 177/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 201/300 batch 178/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 201/300 batch 179/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 201/300 batch 180/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 201/300 batch 181/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 201/300 batch 182/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 201/300 batch 183/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 201/300 batch 184/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 201/300 batch 185/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 201/300 batch 186/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 201/300 batch 187/188  Train Loss: 0.020, Acc: 0.992\n",
      "Train Loss: 0.033270, Acc: 0.993\n",
      "Val Loss: 0.057455, Acc: 0.983\n",
      "epoch: 202/300 batch   0/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 202/300 batch   1/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 202/300 batch   2/188  Train Loss: 0.053, Acc: 0.980\n",
      "epoch: 202/300 batch   3/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 202/300 batch   4/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 202/300 batch   5/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 202/300 batch   6/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 202/300 batch   7/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 202/300 batch   8/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 202/300 batch   9/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 202/300 batch  10/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 202/300 batch  11/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 202/300 batch  12/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 202/300 batch  13/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 202/300 batch  14/188  Train Loss: 0.016, Acc: 0.996\n",
      "epoch: 202/300 batch  15/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 202/300 batch  16/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 202/300 batch  17/188  Train Loss: 0.072, Acc: 0.992\n",
      "epoch: 202/300 batch  18/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 202/300 batch  19/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 202/300 batch  20/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 202/300 batch  21/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 202/300 batch  22/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 202/300 batch  23/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 202/300 batch  24/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 202/300 batch  25/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 202/300 batch  26/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 202/300 batch  27/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 202/300 batch  28/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 202/300 batch  29/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 202/300 batch  30/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 202/300 batch  31/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 202/300 batch  32/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 202/300 batch  33/188  Train Loss: 0.046, Acc: 0.977\n",
      "epoch: 202/300 batch  34/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 202/300 batch  35/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 202/300 batch  36/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 202/300 batch  37/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 202/300 batch  38/188  Train Loss: 0.059, Acc: 0.973\n",
      "epoch: 202/300 batch  39/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 202/300 batch  40/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 202/300 batch  41/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 202/300 batch  42/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 202/300 batch  43/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 202/300 batch  44/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 202/300 batch  45/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 202/300 batch  46/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 202/300 batch  47/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 202/300 batch  48/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 202/300 batch  49/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 202/300 batch  50/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 202/300 batch  51/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 202/300 batch  52/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 202/300 batch  53/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 202/300 batch  54/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 202/300 batch  55/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 202/300 batch  56/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 202/300 batch  57/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 202/300 batch  58/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 202/300 batch  59/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 202/300 batch  60/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 202/300 batch  61/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 202/300 batch  62/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 202/300 batch  63/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 202/300 batch  64/188  Train Loss: 0.058, Acc: 0.992\n",
      "epoch: 202/300 batch  65/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 202/300 batch  66/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 202/300 batch  67/188  Train Loss: 0.045, Acc: 0.996\n",
      "epoch: 202/300 batch  68/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 202/300 batch  69/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 202/300 batch  70/188  Train Loss: 0.064, Acc: 0.980\n",
      "epoch: 202/300 batch  71/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 202/300 batch  72/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 202/300 batch  73/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 202/300 batch  74/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 202/300 batch  75/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 202/300 batch  76/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 202/300 batch  77/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 202/300 batch  78/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 202/300 batch  79/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 202/300 batch  80/188  Train Loss: 0.051, Acc: 0.977\n",
      "epoch: 202/300 batch  81/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 202/300 batch  82/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 202/300 batch  83/188  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 202/300 batch  84/188  Train Loss: 0.034, Acc: 0.984\n",
      "epoch: 202/300 batch  85/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 202/300 batch  86/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 202/300 batch  87/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 202/300 batch  88/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 202/300 batch  89/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 202/300 batch  90/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 202/300 batch  91/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 202/300 batch  92/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 202/300 batch  93/188  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 202/300 batch  94/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 202/300 batch  95/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 202/300 batch  96/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 202/300 batch  97/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 202/300 batch  98/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 202/300 batch  99/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 202/300 batch 100/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 202/300 batch 101/188  Train Loss: 0.031, Acc: 1.000\n",
      "epoch: 202/300 batch 102/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 202/300 batch 103/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 202/300 batch 104/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 202/300 batch 105/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 202/300 batch 106/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 202/300 batch 107/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 202/300 batch 108/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 202/300 batch 109/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 202/300 batch 110/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 202/300 batch 111/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 202/300 batch 112/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 202/300 batch 113/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 202/300 batch 114/188  Train Loss: 0.062, Acc: 0.988\n",
      "epoch: 202/300 batch 115/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 202/300 batch 116/188  Train Loss: 0.026, Acc: 0.988\n",
      "epoch: 202/300 batch 117/188  Train Loss: 0.074, Acc: 0.973\n",
      "epoch: 202/300 batch 118/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 202/300 batch 119/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 202/300 batch 120/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 202/300 batch 121/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 202/300 batch 122/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 202/300 batch 123/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 202/300 batch 124/188  Train Loss: 0.026, Acc: 0.988\n",
      "epoch: 202/300 batch 125/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 202/300 batch 126/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 202/300 batch 127/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 202/300 batch 128/188  Train Loss: 0.048, Acc: 0.980\n",
      "epoch: 202/300 batch 129/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 202/300 batch 130/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 202/300 batch 131/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 202/300 batch 132/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 202/300 batch 133/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 202/300 batch 134/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 202/300 batch 135/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 202/300 batch 136/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 202/300 batch 137/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 202/300 batch 138/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 202/300 batch 139/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 202/300 batch 140/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 202/300 batch 141/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 202/300 batch 142/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 202/300 batch 143/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 202/300 batch 144/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 202/300 batch 145/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 202/300 batch 146/188  Train Loss: 0.059, Acc: 0.977\n",
      "epoch: 202/300 batch 147/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 202/300 batch 148/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 202/300 batch 149/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 202/300 batch 150/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 202/300 batch 151/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 202/300 batch 152/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 202/300 batch 153/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 202/300 batch 154/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 202/300 batch 155/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 202/300 batch 156/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 202/300 batch 157/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 202/300 batch 158/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 202/300 batch 159/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 202/300 batch 160/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 202/300 batch 161/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 202/300 batch 162/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 202/300 batch 163/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 202/300 batch 164/188  Train Loss: 0.074, Acc: 0.977\n",
      "epoch: 202/300 batch 165/188  Train Loss: 0.077, Acc: 0.984\n",
      "epoch: 202/300 batch 166/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 202/300 batch 167/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 202/300 batch 168/188  Train Loss: 0.042, Acc: 0.996\n",
      "epoch: 202/300 batch 169/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 202/300 batch 170/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 202/300 batch 171/188  Train Loss: 0.016, Acc: 0.996\n",
      "epoch: 202/300 batch 172/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 202/300 batch 173/188  Train Loss: 0.027, Acc: 0.988\n",
      "epoch: 202/300 batch 174/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 202/300 batch 175/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 202/300 batch 176/188  Train Loss: 0.046, Acc: 0.996\n",
      "epoch: 202/300 batch 177/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 202/300 batch 178/188  Train Loss: 0.059, Acc: 0.980\n",
      "epoch: 202/300 batch 179/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 202/300 batch 180/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 202/300 batch 181/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 202/300 batch 182/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 202/300 batch 183/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 202/300 batch 184/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 202/300 batch 185/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 202/300 batch 186/188  Train Loss: 0.056, Acc: 0.973\n",
      "epoch: 202/300 batch 187/188  Train Loss: 0.039, Acc: 0.984\n",
      "Train Loss: 0.033312, Acc: 0.992\n",
      "Val Loss: 0.057634, Acc: 0.982\n",
      "epoch: 203/300 batch   0/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 203/300 batch   1/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 203/300 batch   2/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 203/300 batch   3/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 203/300 batch   4/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 203/300 batch   5/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 203/300 batch   6/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 203/300 batch   7/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 203/300 batch   8/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 203/300 batch   9/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 203/300 batch  10/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 203/300 batch  11/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 203/300 batch  12/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 203/300 batch  13/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 203/300 batch  14/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 203/300 batch  15/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 203/300 batch  16/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 203/300 batch  17/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 203/300 batch  18/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 203/300 batch  19/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 203/300 batch  20/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 203/300 batch  21/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 203/300 batch  22/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 203/300 batch  23/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 203/300 batch  24/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 203/300 batch  25/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 203/300 batch  26/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 203/300 batch  27/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 203/300 batch  28/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 203/300 batch  29/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 203/300 batch  30/188  Train Loss: 0.056, Acc: 0.988\n",
      "epoch: 203/300 batch  31/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 203/300 batch  32/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 203/300 batch  33/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 203/300 batch  34/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 203/300 batch  35/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 203/300 batch  36/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 203/300 batch  37/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 203/300 batch  38/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 203/300 batch  39/188  Train Loss: 0.056, Acc: 0.988\n",
      "epoch: 203/300 batch  40/188  Train Loss: 0.051, Acc: 0.992\n",
      "epoch: 203/300 batch  41/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 203/300 batch  42/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 203/300 batch  43/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 203/300 batch  44/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 203/300 batch  45/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 203/300 batch  46/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 203/300 batch  47/188  Train Loss: 0.044, Acc: 0.977\n",
      "epoch: 203/300 batch  48/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 203/300 batch  49/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 203/300 batch  50/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 203/300 batch  51/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 203/300 batch  52/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 203/300 batch  53/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 203/300 batch  54/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 203/300 batch  55/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 203/300 batch  56/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 203/300 batch  57/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 203/300 batch  58/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 203/300 batch  59/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 203/300 batch  60/188  Train Loss: 0.057, Acc: 0.988\n",
      "epoch: 203/300 batch  61/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 203/300 batch  62/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 203/300 batch  63/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 203/300 batch  64/188  Train Loss: 0.059, Acc: 0.988\n",
      "epoch: 203/300 batch  65/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 203/300 batch  66/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 203/300 batch  67/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 203/300 batch  68/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 203/300 batch  69/188  Train Loss: 0.025, Acc: 0.988\n",
      "epoch: 203/300 batch  70/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 203/300 batch  71/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 203/300 batch  72/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 203/300 batch  73/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 203/300 batch  74/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 203/300 batch  75/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 203/300 batch  76/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 203/300 batch  77/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 203/300 batch  78/188  Train Loss: 0.061, Acc: 0.984\n",
      "epoch: 203/300 batch  79/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 203/300 batch  80/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 203/300 batch  81/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 203/300 batch  82/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 203/300 batch  83/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 203/300 batch  84/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 203/300 batch  85/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 203/300 batch  86/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 203/300 batch  87/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 203/300 batch  88/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 203/300 batch  89/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 203/300 batch  90/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 203/300 batch  91/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 203/300 batch  92/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 203/300 batch  93/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 203/300 batch  94/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 203/300 batch  95/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 203/300 batch  96/188  Train Loss: 0.051, Acc: 0.980\n",
      "epoch: 203/300 batch  97/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 203/300 batch  98/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 203/300 batch  99/188  Train Loss: 0.063, Acc: 0.980\n",
      "epoch: 203/300 batch 100/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 203/300 batch 101/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 203/300 batch 102/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 203/300 batch 103/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 203/300 batch 104/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 203/300 batch 105/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 203/300 batch 106/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 203/300 batch 107/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 203/300 batch 108/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 203/300 batch 109/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 203/300 batch 110/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 203/300 batch 111/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 203/300 batch 112/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 203/300 batch 113/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 203/300 batch 114/188  Train Loss: 0.070, Acc: 0.980\n",
      "epoch: 203/300 batch 115/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 203/300 batch 116/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 203/300 batch 117/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 203/300 batch 118/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 203/300 batch 119/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 203/300 batch 120/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 203/300 batch 121/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 203/300 batch 122/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 203/300 batch 123/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 203/300 batch 124/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 203/300 batch 125/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 203/300 batch 126/188  Train Loss: 0.047, Acc: 0.980\n",
      "epoch: 203/300 batch 127/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 203/300 batch 128/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 203/300 batch 129/188  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 203/300 batch 130/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 203/300 batch 131/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 203/300 batch 132/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 203/300 batch 133/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 203/300 batch 134/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 203/300 batch 135/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 203/300 batch 136/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 203/300 batch 137/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 203/300 batch 138/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 203/300 batch 139/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 203/300 batch 140/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 203/300 batch 141/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 203/300 batch 142/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 203/300 batch 143/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 203/300 batch 144/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 203/300 batch 145/188  Train Loss: 0.057, Acc: 0.980\n",
      "epoch: 203/300 batch 146/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 203/300 batch 147/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 203/300 batch 148/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 203/300 batch 149/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 203/300 batch 150/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 203/300 batch 151/188  Train Loss: 0.059, Acc: 0.988\n",
      "epoch: 203/300 batch 152/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 203/300 batch 153/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 203/300 batch 154/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 203/300 batch 155/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 203/300 batch 156/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 203/300 batch 157/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 203/300 batch 158/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 203/300 batch 159/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 203/300 batch 160/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 203/300 batch 161/188  Train Loss: 0.044, Acc: 0.996\n",
      "epoch: 203/300 batch 162/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 203/300 batch 163/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 203/300 batch 164/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 203/300 batch 165/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 203/300 batch 166/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 203/300 batch 167/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 203/300 batch 168/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 203/300 batch 169/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 203/300 batch 170/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 203/300 batch 171/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 203/300 batch 172/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 203/300 batch 173/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 203/300 batch 174/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 203/300 batch 175/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 203/300 batch 176/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 203/300 batch 177/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 203/300 batch 178/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 203/300 batch 179/188  Train Loss: 0.068, Acc: 0.992\n",
      "epoch: 203/300 batch 180/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 203/300 batch 181/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 203/300 batch 182/188  Train Loss: 0.054, Acc: 0.977\n",
      "epoch: 203/300 batch 183/188  Train Loss: 0.041, Acc: 0.980\n",
      "epoch: 203/300 batch 184/188  Train Loss: 0.047, Acc: 0.996\n",
      "epoch: 203/300 batch 185/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 203/300 batch 186/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 203/300 batch 187/188  Train Loss: 0.025, Acc: 0.992\n",
      "Train Loss: 0.033217, Acc: 0.993\n",
      "Val Loss: 0.057774, Acc: 0.983\n",
      "epoch: 204/300 batch   0/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 204/300 batch   1/188  Train Loss: 0.044, Acc: 0.980\n",
      "epoch: 204/300 batch   2/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 204/300 batch   3/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 204/300 batch   4/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 204/300 batch   5/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 204/300 batch   6/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 204/300 batch   7/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 204/300 batch   8/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 204/300 batch   9/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 204/300 batch  10/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 204/300 batch  11/188  Train Loss: 0.025, Acc: 0.988\n",
      "epoch: 204/300 batch  12/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 204/300 batch  13/188  Train Loss: 0.016, Acc: 0.996\n",
      "epoch: 204/300 batch  14/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 204/300 batch  15/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 204/300 batch  16/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 204/300 batch  17/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 204/300 batch  18/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 204/300 batch  19/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 204/300 batch  20/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 204/300 batch  21/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 204/300 batch  22/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 204/300 batch  23/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 204/300 batch  24/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 204/300 batch  25/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 204/300 batch  26/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 204/300 batch  27/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 204/300 batch  28/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 204/300 batch  29/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 204/300 batch  30/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 204/300 batch  31/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 204/300 batch  32/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 204/300 batch  33/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 204/300 batch  34/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 204/300 batch  35/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 204/300 batch  36/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 204/300 batch  37/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 204/300 batch  38/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 204/300 batch  39/188  Train Loss: 0.059, Acc: 0.984\n",
      "epoch: 204/300 batch  40/188  Train Loss: 0.053, Acc: 0.977\n",
      "epoch: 204/300 batch  41/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 204/300 batch  42/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 204/300 batch  43/188  Train Loss: 0.057, Acc: 0.992\n",
      "epoch: 204/300 batch  44/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 204/300 batch  45/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 204/300 batch  46/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 204/300 batch  47/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 204/300 batch  48/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 204/300 batch  49/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 204/300 batch  50/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 204/300 batch  51/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 204/300 batch  52/188  Train Loss: 0.032, Acc: 1.000\n",
      "epoch: 204/300 batch  53/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 204/300 batch  54/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 204/300 batch  55/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 204/300 batch  56/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 204/300 batch  57/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 204/300 batch  58/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 204/300 batch  59/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 204/300 batch  60/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 204/300 batch  61/188  Train Loss: 0.049, Acc: 0.977\n",
      "epoch: 204/300 batch  62/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 204/300 batch  63/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 204/300 batch  64/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 204/300 batch  65/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 204/300 batch  66/188  Train Loss: 0.068, Acc: 0.984\n",
      "epoch: 204/300 batch  67/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 204/300 batch  68/188  Train Loss: 0.066, Acc: 0.984\n",
      "epoch: 204/300 batch  69/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 204/300 batch  70/188  Train Loss: 0.034, Acc: 1.000\n",
      "epoch: 204/300 batch  71/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 204/300 batch  72/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 204/300 batch  73/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 204/300 batch  74/188  Train Loss: 0.050, Acc: 0.996\n",
      "epoch: 204/300 batch  75/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 204/300 batch  76/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 204/300 batch  77/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 204/300 batch  78/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 204/300 batch  79/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 204/300 batch  80/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 204/300 batch  81/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 204/300 batch  82/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 204/300 batch  83/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 204/300 batch  84/188  Train Loss: 0.064, Acc: 0.977\n",
      "epoch: 204/300 batch  85/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 204/300 batch  86/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 204/300 batch  87/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 204/300 batch  88/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 204/300 batch  89/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 204/300 batch  90/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 204/300 batch  91/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 204/300 batch  92/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 204/300 batch  93/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 204/300 batch  94/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 204/300 batch  95/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 204/300 batch  96/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 204/300 batch  97/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 204/300 batch  98/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 204/300 batch  99/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 204/300 batch 100/188  Train Loss: 0.060, Acc: 0.984\n",
      "epoch: 204/300 batch 101/188  Train Loss: 0.071, Acc: 0.977\n",
      "epoch: 204/300 batch 102/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 204/300 batch 103/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 204/300 batch 104/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 204/300 batch 105/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 204/300 batch 106/188  Train Loss: 0.049, Acc: 0.980\n",
      "epoch: 204/300 batch 107/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 204/300 batch 108/188  Train Loss: 0.044, Acc: 0.980\n",
      "epoch: 204/300 batch 109/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 204/300 batch 110/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 204/300 batch 111/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 204/300 batch 112/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 204/300 batch 113/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 204/300 batch 114/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 204/300 batch 115/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 204/300 batch 116/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 204/300 batch 117/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 204/300 batch 118/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 204/300 batch 119/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 204/300 batch 120/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 204/300 batch 121/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 204/300 batch 122/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 204/300 batch 123/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 204/300 batch 124/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 204/300 batch 125/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 204/300 batch 126/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 204/300 batch 127/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 204/300 batch 128/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 204/300 batch 129/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 204/300 batch 130/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 204/300 batch 131/188  Train Loss: 0.067, Acc: 0.980\n",
      "epoch: 204/300 batch 132/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 204/300 batch 133/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 204/300 batch 134/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 204/300 batch 135/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 204/300 batch 136/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 204/300 batch 137/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 204/300 batch 138/188  Train Loss: 0.050, Acc: 0.980\n",
      "epoch: 204/300 batch 139/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 204/300 batch 140/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 204/300 batch 141/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 204/300 batch 142/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 204/300 batch 143/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 204/300 batch 144/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 204/300 batch 145/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 204/300 batch 146/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 204/300 batch 147/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 204/300 batch 148/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 204/300 batch 149/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 204/300 batch 150/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 204/300 batch 151/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 204/300 batch 152/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 204/300 batch 153/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 204/300 batch 154/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 204/300 batch 155/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 204/300 batch 156/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 204/300 batch 157/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 204/300 batch 158/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 204/300 batch 159/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 204/300 batch 160/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 204/300 batch 161/188  Train Loss: 0.050, Acc: 0.980\n",
      "epoch: 204/300 batch 162/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 204/300 batch 163/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 204/300 batch 164/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 204/300 batch 165/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 204/300 batch 166/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 204/300 batch 167/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 204/300 batch 168/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 204/300 batch 169/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 204/300 batch 170/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 204/300 batch 171/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 204/300 batch 172/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 204/300 batch 173/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 204/300 batch 174/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 204/300 batch 175/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 204/300 batch 176/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 204/300 batch 177/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 204/300 batch 178/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 204/300 batch 179/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 204/300 batch 180/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 204/300 batch 181/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 204/300 batch 182/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 204/300 batch 183/188  Train Loss: 0.057, Acc: 0.992\n",
      "epoch: 204/300 batch 184/188  Train Loss: 0.068, Acc: 0.984\n",
      "epoch: 204/300 batch 185/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 204/300 batch 186/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 204/300 batch 187/188  Train Loss: 0.011, Acc: 1.000\n",
      "Train Loss: 0.033191, Acc: 0.993\n",
      "Val Loss: 0.057739, Acc: 0.983\n",
      "epoch: 205/300 batch   0/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 205/300 batch   1/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 205/300 batch   2/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 205/300 batch   3/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 205/300 batch   4/188  Train Loss: 0.063, Acc: 0.988\n",
      "epoch: 205/300 batch   5/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 205/300 batch   6/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 205/300 batch   7/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 205/300 batch   8/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 205/300 batch   9/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 205/300 batch  10/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 205/300 batch  11/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 205/300 batch  12/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 205/300 batch  13/188  Train Loss: 0.036, Acc: 1.000\n",
      "epoch: 205/300 batch  14/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 205/300 batch  15/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 205/300 batch  16/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 205/300 batch  17/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 205/300 batch  18/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 205/300 batch  19/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 205/300 batch  20/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 205/300 batch  21/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 205/300 batch  22/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 205/300 batch  23/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 205/300 batch  24/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 205/300 batch  25/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 205/300 batch  26/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 205/300 batch  27/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 205/300 batch  28/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 205/300 batch  29/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 205/300 batch  30/188  Train Loss: 0.060, Acc: 0.980\n",
      "epoch: 205/300 batch  31/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 205/300 batch  32/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 205/300 batch  33/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 205/300 batch  34/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 205/300 batch  35/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 205/300 batch  36/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 205/300 batch  37/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 205/300 batch  38/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 205/300 batch  39/188  Train Loss: 0.039, Acc: 0.980\n",
      "epoch: 205/300 batch  40/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 205/300 batch  41/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 205/300 batch  42/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 205/300 batch  43/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 205/300 batch  44/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 205/300 batch  45/188  Train Loss: 0.070, Acc: 0.980\n",
      "epoch: 205/300 batch  46/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 205/300 batch  47/188  Train Loss: 0.055, Acc: 0.980\n",
      "epoch: 205/300 batch  48/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 205/300 batch  49/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 205/300 batch  50/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 205/300 batch  51/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 205/300 batch  52/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 205/300 batch  53/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 205/300 batch  54/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 205/300 batch  55/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 205/300 batch  56/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 205/300 batch  57/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 205/300 batch  58/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 205/300 batch  59/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 205/300 batch  60/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 205/300 batch  61/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 205/300 batch  62/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 205/300 batch  63/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 205/300 batch  64/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 205/300 batch  65/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 205/300 batch  66/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 205/300 batch  67/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 205/300 batch  68/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 205/300 batch  69/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 205/300 batch  70/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 205/300 batch  71/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 205/300 batch  72/188  Train Loss: 0.060, Acc: 0.992\n",
      "epoch: 205/300 batch  73/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 205/300 batch  74/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 205/300 batch  75/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 205/300 batch  76/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 205/300 batch  77/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 205/300 batch  78/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 205/300 batch  79/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 205/300 batch  80/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 205/300 batch  81/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 205/300 batch  82/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 205/300 batch  83/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 205/300 batch  84/188  Train Loss: 0.045, Acc: 0.980\n",
      "epoch: 205/300 batch  85/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 205/300 batch  86/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 205/300 batch  87/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 205/300 batch  88/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 205/300 batch  89/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 205/300 batch  90/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 205/300 batch  91/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 205/300 batch  92/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 205/300 batch  93/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 205/300 batch  94/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 205/300 batch  95/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 205/300 batch  96/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 205/300 batch  97/188  Train Loss: 0.050, Acc: 0.980\n",
      "epoch: 205/300 batch  98/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 205/300 batch  99/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 205/300 batch 100/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 205/300 batch 101/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 205/300 batch 102/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 205/300 batch 103/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 205/300 batch 104/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 205/300 batch 105/188  Train Loss: 0.015, Acc: 0.996\n",
      "epoch: 205/300 batch 106/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 205/300 batch 107/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 205/300 batch 108/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 205/300 batch 109/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 205/300 batch 110/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 205/300 batch 111/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 205/300 batch 112/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 205/300 batch 113/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 205/300 batch 114/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 205/300 batch 115/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 205/300 batch 116/188  Train Loss: 0.052, Acc: 0.977\n",
      "epoch: 205/300 batch 117/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 205/300 batch 118/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 205/300 batch 119/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 205/300 batch 120/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 205/300 batch 121/188  Train Loss: 0.045, Acc: 0.980\n",
      "epoch: 205/300 batch 122/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 205/300 batch 123/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 205/300 batch 124/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 205/300 batch 125/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 205/300 batch 126/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 205/300 batch 127/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 205/300 batch 128/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 205/300 batch 129/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 205/300 batch 130/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 205/300 batch 131/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 205/300 batch 132/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 205/300 batch 133/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 205/300 batch 134/188  Train Loss: 0.034, Acc: 1.000\n",
      "epoch: 205/300 batch 135/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 205/300 batch 136/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 205/300 batch 137/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 205/300 batch 138/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 205/300 batch 139/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 205/300 batch 140/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 205/300 batch 141/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 205/300 batch 142/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 205/300 batch 143/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 205/300 batch 144/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 205/300 batch 145/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 205/300 batch 146/188  Train Loss: 0.050, Acc: 0.980\n",
      "epoch: 205/300 batch 147/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 205/300 batch 148/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 205/300 batch 149/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 205/300 batch 150/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 205/300 batch 151/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 205/300 batch 152/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 205/300 batch 153/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 205/300 batch 154/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 205/300 batch 155/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 205/300 batch 156/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 205/300 batch 157/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 205/300 batch 158/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 205/300 batch 159/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 205/300 batch 160/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 205/300 batch 161/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 205/300 batch 162/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 205/300 batch 163/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 205/300 batch 164/188  Train Loss: 0.071, Acc: 0.977\n",
      "epoch: 205/300 batch 165/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 205/300 batch 166/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 205/300 batch 167/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 205/300 batch 168/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 205/300 batch 169/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 205/300 batch 170/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 205/300 batch 171/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 205/300 batch 172/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 205/300 batch 173/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 205/300 batch 174/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 205/300 batch 175/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 205/300 batch 176/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 205/300 batch 177/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 205/300 batch 178/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 205/300 batch 179/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 205/300 batch 180/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 205/300 batch 181/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 205/300 batch 182/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 205/300 batch 183/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 205/300 batch 184/188  Train Loss: 0.022, Acc: 0.988\n",
      "epoch: 205/300 batch 185/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 205/300 batch 186/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 205/300 batch 187/188  Train Loss: 0.032, Acc: 0.992\n",
      "Train Loss: 0.033245, Acc: 0.993\n",
      "Val Loss: 0.057726, Acc: 0.982\n",
      "epoch: 206/300 batch   0/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 206/300 batch   1/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 206/300 batch   2/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 206/300 batch   3/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 206/300 batch   4/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 206/300 batch   5/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 206/300 batch   6/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 206/300 batch   7/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 206/300 batch   8/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 206/300 batch   9/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 206/300 batch  10/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 206/300 batch  11/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 206/300 batch  12/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 206/300 batch  13/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 206/300 batch  14/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 206/300 batch  15/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 206/300 batch  16/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 206/300 batch  17/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 206/300 batch  18/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 206/300 batch  19/188  Train Loss: 0.057, Acc: 0.988\n",
      "epoch: 206/300 batch  20/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 206/300 batch  21/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 206/300 batch  22/188  Train Loss: 0.044, Acc: 0.980\n",
      "epoch: 206/300 batch  23/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 206/300 batch  24/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 206/300 batch  25/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 206/300 batch  26/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 206/300 batch  27/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 206/300 batch  28/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 206/300 batch  29/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 206/300 batch  30/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 206/300 batch  31/188  Train Loss: 0.075, Acc: 0.980\n",
      "epoch: 206/300 batch  32/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 206/300 batch  33/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 206/300 batch  34/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 206/300 batch  35/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 206/300 batch  36/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 206/300 batch  37/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 206/300 batch  38/188  Train Loss: 0.069, Acc: 0.988\n",
      "epoch: 206/300 batch  39/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 206/300 batch  40/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 206/300 batch  41/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 206/300 batch  42/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 206/300 batch  43/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 206/300 batch  44/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 206/300 batch  45/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 206/300 batch  46/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 206/300 batch  47/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 206/300 batch  48/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 206/300 batch  49/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 206/300 batch  50/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 206/300 batch  51/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 206/300 batch  52/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 206/300 batch  53/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 206/300 batch  54/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 206/300 batch  55/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 206/300 batch  56/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 206/300 batch  57/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 206/300 batch  58/188  Train Loss: 0.016, Acc: 0.996\n",
      "epoch: 206/300 batch  59/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 206/300 batch  60/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 206/300 batch  61/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 206/300 batch  62/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 206/300 batch  63/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 206/300 batch  64/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 206/300 batch  65/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 206/300 batch  66/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 206/300 batch  67/188  Train Loss: 0.053, Acc: 0.980\n",
      "epoch: 206/300 batch  68/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 206/300 batch  69/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 206/300 batch  70/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 206/300 batch  71/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 206/300 batch  72/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 206/300 batch  73/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 206/300 batch  74/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 206/300 batch  75/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 206/300 batch  76/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 206/300 batch  77/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 206/300 batch  78/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 206/300 batch  79/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 206/300 batch  80/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 206/300 batch  81/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 206/300 batch  82/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 206/300 batch  83/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 206/300 batch  84/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 206/300 batch  85/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 206/300 batch  86/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 206/300 batch  87/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 206/300 batch  88/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 206/300 batch  89/188  Train Loss: 0.045, Acc: 0.996\n",
      "epoch: 206/300 batch  90/188  Train Loss: 0.042, Acc: 0.980\n",
      "epoch: 206/300 batch  91/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 206/300 batch  92/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 206/300 batch  93/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 206/300 batch  94/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 206/300 batch  95/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 206/300 batch  96/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 206/300 batch  97/188  Train Loss: 0.042, Acc: 0.996\n",
      "epoch: 206/300 batch  98/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 206/300 batch  99/188  Train Loss: 0.051, Acc: 0.992\n",
      "epoch: 206/300 batch 100/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 206/300 batch 101/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 206/300 batch 102/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 206/300 batch 103/188  Train Loss: 0.056, Acc: 0.988\n",
      "epoch: 206/300 batch 104/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 206/300 batch 105/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 206/300 batch 106/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 206/300 batch 107/188  Train Loss: 0.013, Acc: 0.996\n",
      "epoch: 206/300 batch 108/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 206/300 batch 109/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 206/300 batch 110/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 206/300 batch 111/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 206/300 batch 112/188  Train Loss: 0.045, Acc: 0.996\n",
      "epoch: 206/300 batch 113/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 206/300 batch 114/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 206/300 batch 115/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 206/300 batch 116/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 206/300 batch 117/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 206/300 batch 118/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 206/300 batch 119/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 206/300 batch 120/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 206/300 batch 121/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 206/300 batch 122/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 206/300 batch 123/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 206/300 batch 124/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 206/300 batch 125/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 206/300 batch 126/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 206/300 batch 127/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 206/300 batch 128/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 206/300 batch 129/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 206/300 batch 130/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 206/300 batch 131/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 206/300 batch 132/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 206/300 batch 133/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 206/300 batch 134/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 206/300 batch 135/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 206/300 batch 136/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 206/300 batch 137/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 206/300 batch 138/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 206/300 batch 139/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 206/300 batch 140/188  Train Loss: 0.071, Acc: 0.988\n",
      "epoch: 206/300 batch 141/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 206/300 batch 142/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 206/300 batch 143/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 206/300 batch 144/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 206/300 batch 145/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 206/300 batch 146/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 206/300 batch 147/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 206/300 batch 148/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 206/300 batch 149/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 206/300 batch 150/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 206/300 batch 151/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 206/300 batch 152/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 206/300 batch 153/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 206/300 batch 154/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 206/300 batch 155/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 206/300 batch 156/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 206/300 batch 157/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 206/300 batch 158/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 206/300 batch 159/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 206/300 batch 160/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 206/300 batch 161/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 206/300 batch 162/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 206/300 batch 163/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 206/300 batch 164/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 206/300 batch 165/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 206/300 batch 166/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 206/300 batch 167/188  Train Loss: 0.031, Acc: 1.000\n",
      "epoch: 206/300 batch 168/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 206/300 batch 169/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 206/300 batch 170/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 206/300 batch 171/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 206/300 batch 172/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 206/300 batch 173/188  Train Loss: 0.032, Acc: 1.000\n",
      "epoch: 206/300 batch 174/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 206/300 batch 175/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 206/300 batch 176/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 206/300 batch 177/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 206/300 batch 178/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 206/300 batch 179/188  Train Loss: 0.053, Acc: 0.980\n",
      "epoch: 206/300 batch 180/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 206/300 batch 181/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 206/300 batch 182/188  Train Loss: 0.063, Acc: 0.980\n",
      "epoch: 206/300 batch 183/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 206/300 batch 184/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 206/300 batch 185/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 206/300 batch 186/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 206/300 batch 187/188  Train Loss: 0.035, Acc: 0.992\n",
      "Train Loss: 0.033331, Acc: 0.993\n",
      "Val Loss: 0.057397, Acc: 0.983\n",
      "epoch: 207/300 batch   0/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 207/300 batch   1/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 207/300 batch   2/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 207/300 batch   3/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 207/300 batch   4/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 207/300 batch   5/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 207/300 batch   6/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 207/300 batch   7/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 207/300 batch   8/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 207/300 batch   9/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 207/300 batch  10/188  Train Loss: 0.058, Acc: 0.988\n",
      "epoch: 207/300 batch  11/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 207/300 batch  12/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 207/300 batch  13/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 207/300 batch  14/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 207/300 batch  15/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 207/300 batch  16/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 207/300 batch  17/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 207/300 batch  18/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 207/300 batch  19/188  Train Loss: 0.044, Acc: 0.996\n",
      "epoch: 207/300 batch  20/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 207/300 batch  21/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 207/300 batch  22/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 207/300 batch  23/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 207/300 batch  24/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 207/300 batch  25/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 207/300 batch  26/188  Train Loss: 0.053, Acc: 0.992\n",
      "epoch: 207/300 batch  27/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 207/300 batch  28/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 207/300 batch  29/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 207/300 batch  30/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 207/300 batch  31/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 207/300 batch  32/188  Train Loss: 0.032, Acc: 0.984\n",
      "epoch: 207/300 batch  33/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 207/300 batch  34/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 207/300 batch  35/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 207/300 batch  36/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 207/300 batch  37/188  Train Loss: 0.060, Acc: 0.984\n",
      "epoch: 207/300 batch  38/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 207/300 batch  39/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 207/300 batch  40/188  Train Loss: 0.043, Acc: 0.980\n",
      "epoch: 207/300 batch  41/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 207/300 batch  42/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 207/300 batch  43/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 207/300 batch  44/188  Train Loss: 0.067, Acc: 0.980\n",
      "epoch: 207/300 batch  45/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 207/300 batch  46/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 207/300 batch  47/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 207/300 batch  48/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 207/300 batch  49/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 207/300 batch  50/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 207/300 batch  51/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 207/300 batch  52/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 207/300 batch  53/188  Train Loss: 0.056, Acc: 0.977\n",
      "epoch: 207/300 batch  54/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 207/300 batch  55/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 207/300 batch  56/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 207/300 batch  57/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 207/300 batch  58/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 207/300 batch  59/188  Train Loss: 0.051, Acc: 0.980\n",
      "epoch: 207/300 batch  60/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 207/300 batch  61/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 207/300 batch  62/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 207/300 batch  63/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 207/300 batch  64/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 207/300 batch  65/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 207/300 batch  66/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 207/300 batch  67/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 207/300 batch  68/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 207/300 batch  69/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 207/300 batch  70/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 207/300 batch  71/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 207/300 batch  72/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 207/300 batch  73/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 207/300 batch  74/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 207/300 batch  75/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 207/300 batch  76/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 207/300 batch  77/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 207/300 batch  78/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 207/300 batch  79/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 207/300 batch  80/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 207/300 batch  81/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 207/300 batch  82/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 207/300 batch  83/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 207/300 batch  84/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 207/300 batch  85/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 207/300 batch  86/188  Train Loss: 0.047, Acc: 0.980\n",
      "epoch: 207/300 batch  87/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 207/300 batch  88/188  Train Loss: 0.034, Acc: 0.984\n",
      "epoch: 207/300 batch  89/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 207/300 batch  90/188  Train Loss: 0.042, Acc: 0.996\n",
      "epoch: 207/300 batch  91/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 207/300 batch  92/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 207/300 batch  93/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 207/300 batch  94/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 207/300 batch  95/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 207/300 batch  96/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 207/300 batch  97/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 207/300 batch  98/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 207/300 batch  99/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 207/300 batch 100/188  Train Loss: 0.034, Acc: 0.984\n",
      "epoch: 207/300 batch 101/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 207/300 batch 102/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 207/300 batch 103/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 207/300 batch 104/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 207/300 batch 105/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 207/300 batch 106/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 207/300 batch 107/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 207/300 batch 108/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 207/300 batch 109/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 207/300 batch 110/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 207/300 batch 111/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 207/300 batch 112/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 207/300 batch 113/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 207/300 batch 114/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 207/300 batch 115/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 207/300 batch 116/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 207/300 batch 117/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 207/300 batch 118/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 207/300 batch 119/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 207/300 batch 120/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 207/300 batch 121/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 207/300 batch 122/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 207/300 batch 123/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 207/300 batch 124/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 207/300 batch 125/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 207/300 batch 126/188  Train Loss: 0.027, Acc: 0.988\n",
      "epoch: 207/300 batch 127/188  Train Loss: 0.033, Acc: 1.000\n",
      "epoch: 207/300 batch 128/188  Train Loss: 0.065, Acc: 0.984\n",
      "epoch: 207/300 batch 129/188  Train Loss: 0.015, Acc: 0.996\n",
      "epoch: 207/300 batch 130/188  Train Loss: 0.050, Acc: 0.980\n",
      "epoch: 207/300 batch 131/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 207/300 batch 132/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 207/300 batch 133/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 207/300 batch 134/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 207/300 batch 135/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 207/300 batch 136/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 207/300 batch 137/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 207/300 batch 138/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 207/300 batch 139/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 207/300 batch 140/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 207/300 batch 141/188  Train Loss: 0.078, Acc: 0.969\n",
      "epoch: 207/300 batch 142/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 207/300 batch 143/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 207/300 batch 144/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 207/300 batch 145/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 207/300 batch 146/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 207/300 batch 147/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 207/300 batch 148/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 207/300 batch 149/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 207/300 batch 150/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 207/300 batch 151/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 207/300 batch 152/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 207/300 batch 153/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 207/300 batch 154/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 207/300 batch 155/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 207/300 batch 156/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 207/300 batch 157/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 207/300 batch 158/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 207/300 batch 159/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 207/300 batch 160/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 207/300 batch 161/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 207/300 batch 162/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 207/300 batch 163/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 207/300 batch 164/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 207/300 batch 165/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 207/300 batch 166/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 207/300 batch 167/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 207/300 batch 168/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 207/300 batch 169/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 207/300 batch 170/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 207/300 batch 171/188  Train Loss: 0.046, Acc: 0.980\n",
      "epoch: 207/300 batch 172/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 207/300 batch 173/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 207/300 batch 174/188  Train Loss: 0.074, Acc: 0.984\n",
      "epoch: 207/300 batch 175/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 207/300 batch 176/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 207/300 batch 177/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 207/300 batch 178/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 207/300 batch 179/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 207/300 batch 180/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 207/300 batch 181/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 207/300 batch 182/188  Train Loss: 0.054, Acc: 0.992\n",
      "epoch: 207/300 batch 183/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 207/300 batch 184/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 207/300 batch 185/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 207/300 batch 186/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 207/300 batch 187/188  Train Loss: 0.036, Acc: 0.992\n",
      "Train Loss: 0.033239, Acc: 0.992\n",
      "Val Loss: 0.057676, Acc: 0.983\n",
      "epoch: 208/300 batch   0/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 208/300 batch   1/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 208/300 batch   2/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 208/300 batch   3/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 208/300 batch   4/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 208/300 batch   5/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 208/300 batch   6/188  Train Loss: 0.040, Acc: 0.980\n",
      "epoch: 208/300 batch   7/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 208/300 batch   8/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 208/300 batch   9/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 208/300 batch  10/188  Train Loss: 0.051, Acc: 0.980\n",
      "epoch: 208/300 batch  11/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 208/300 batch  12/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 208/300 batch  13/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 208/300 batch  14/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 208/300 batch  15/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 208/300 batch  16/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 208/300 batch  17/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 208/300 batch  18/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 208/300 batch  19/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 208/300 batch  20/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 208/300 batch  21/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 208/300 batch  22/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 208/300 batch  23/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 208/300 batch  24/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 208/300 batch  25/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 208/300 batch  26/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 208/300 batch  27/188  Train Loss: 0.024, Acc: 0.988\n",
      "epoch: 208/300 batch  28/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 208/300 batch  29/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 208/300 batch  30/188  Train Loss: 0.086, Acc: 0.984\n",
      "epoch: 208/300 batch  31/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 208/300 batch  32/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 208/300 batch  33/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 208/300 batch  34/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 208/300 batch  35/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 208/300 batch  36/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 208/300 batch  37/188  Train Loss: 0.065, Acc: 0.980\n",
      "epoch: 208/300 batch  38/188  Train Loss: 0.058, Acc: 0.988\n",
      "epoch: 208/300 batch  39/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 208/300 batch  40/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 208/300 batch  41/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 208/300 batch  42/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 208/300 batch  43/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 208/300 batch  44/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 208/300 batch  45/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 208/300 batch  46/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 208/300 batch  47/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 208/300 batch  48/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 208/300 batch  49/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 208/300 batch  50/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 208/300 batch  51/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 208/300 batch  52/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 208/300 batch  53/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 208/300 batch  54/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 208/300 batch  55/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 208/300 batch  56/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 208/300 batch  57/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 208/300 batch  58/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 208/300 batch  59/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 208/300 batch  60/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 208/300 batch  61/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 208/300 batch  62/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 208/300 batch  63/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 208/300 batch  64/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 208/300 batch  65/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 208/300 batch  66/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 208/300 batch  67/188  Train Loss: 0.053, Acc: 0.992\n",
      "epoch: 208/300 batch  68/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 208/300 batch  69/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 208/300 batch  70/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 208/300 batch  71/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 208/300 batch  72/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 208/300 batch  73/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 208/300 batch  74/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 208/300 batch  75/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 208/300 batch  76/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 208/300 batch  77/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 208/300 batch  78/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 208/300 batch  79/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 208/300 batch  80/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 208/300 batch  81/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 208/300 batch  82/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 208/300 batch  83/188  Train Loss: 0.055, Acc: 0.977\n",
      "epoch: 208/300 batch  84/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 208/300 batch  85/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 208/300 batch  86/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 208/300 batch  87/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 208/300 batch  88/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 208/300 batch  89/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 208/300 batch  90/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 208/300 batch  91/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 208/300 batch  92/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 208/300 batch  93/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 208/300 batch  94/188  Train Loss: 0.050, Acc: 0.980\n",
      "epoch: 208/300 batch  95/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 208/300 batch  96/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 208/300 batch  97/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 208/300 batch  98/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 208/300 batch  99/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 208/300 batch 100/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 208/300 batch 101/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 208/300 batch 102/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 208/300 batch 103/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 208/300 batch 104/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 208/300 batch 105/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 208/300 batch 106/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 208/300 batch 107/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 208/300 batch 108/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 208/300 batch 109/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 208/300 batch 110/188  Train Loss: 0.042, Acc: 0.996\n",
      "epoch: 208/300 batch 111/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 208/300 batch 112/188  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 208/300 batch 113/188  Train Loss: 0.057, Acc: 0.988\n",
      "epoch: 208/300 batch 114/188  Train Loss: 0.072, Acc: 0.988\n",
      "epoch: 208/300 batch 115/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 208/300 batch 116/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 208/300 batch 117/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 208/300 batch 118/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 208/300 batch 119/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 208/300 batch 120/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 208/300 batch 121/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 208/300 batch 122/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 208/300 batch 123/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 208/300 batch 124/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 208/300 batch 125/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 208/300 batch 126/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 208/300 batch 127/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 208/300 batch 128/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 208/300 batch 129/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 208/300 batch 130/188  Train Loss: 0.043, Acc: 0.980\n",
      "epoch: 208/300 batch 131/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 208/300 batch 132/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 208/300 batch 133/188  Train Loss: 0.039, Acc: 0.980\n",
      "epoch: 208/300 batch 134/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 208/300 batch 135/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 208/300 batch 136/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 208/300 batch 137/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 208/300 batch 138/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 208/300 batch 139/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 208/300 batch 140/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 208/300 batch 141/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 208/300 batch 142/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 208/300 batch 143/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 208/300 batch 144/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 208/300 batch 145/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 208/300 batch 146/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 208/300 batch 147/188  Train Loss: 0.049, Acc: 0.980\n",
      "epoch: 208/300 batch 148/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 208/300 batch 149/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 208/300 batch 150/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 208/300 batch 151/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 208/300 batch 152/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 208/300 batch 153/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 208/300 batch 154/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 208/300 batch 155/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 208/300 batch 156/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 208/300 batch 157/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 208/300 batch 158/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 208/300 batch 159/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 208/300 batch 160/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 208/300 batch 161/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 208/300 batch 162/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 208/300 batch 163/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 208/300 batch 164/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 208/300 batch 165/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 208/300 batch 166/188  Train Loss: 0.062, Acc: 0.984\n",
      "epoch: 208/300 batch 167/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 208/300 batch 168/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 208/300 batch 169/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 208/300 batch 170/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 208/300 batch 171/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 208/300 batch 172/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 208/300 batch 173/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 208/300 batch 174/188  Train Loss: 0.026, Acc: 0.988\n",
      "epoch: 208/300 batch 175/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 208/300 batch 176/188  Train Loss: 0.061, Acc: 0.977\n",
      "epoch: 208/300 batch 177/188  Train Loss: 0.058, Acc: 0.992\n",
      "epoch: 208/300 batch 178/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 208/300 batch 179/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 208/300 batch 180/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 208/300 batch 181/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 208/300 batch 182/188  Train Loss: 0.059, Acc: 0.984\n",
      "epoch: 208/300 batch 183/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 208/300 batch 184/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 208/300 batch 185/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 208/300 batch 186/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 208/300 batch 187/188  Train Loss: 0.037, Acc: 0.992\n",
      "Train Loss: 0.033292, Acc: 0.993\n",
      "Val Loss: 0.058519, Acc: 0.982\n",
      "epoch: 209/300 batch   0/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 209/300 batch   1/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 209/300 batch   2/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 209/300 batch   3/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 209/300 batch   4/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 209/300 batch   5/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 209/300 batch   6/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 209/300 batch   7/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 209/300 batch   8/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 209/300 batch   9/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 209/300 batch  10/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 209/300 batch  11/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 209/300 batch  12/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 209/300 batch  13/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 209/300 batch  14/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 209/300 batch  15/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 209/300 batch  16/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 209/300 batch  17/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 209/300 batch  18/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 209/300 batch  19/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 209/300 batch  20/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 209/300 batch  21/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 209/300 batch  22/188  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 209/300 batch  23/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 209/300 batch  24/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 209/300 batch  25/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 209/300 batch  26/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 209/300 batch  27/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 209/300 batch  28/188  Train Loss: 0.058, Acc: 0.980\n",
      "epoch: 209/300 batch  29/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 209/300 batch  30/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 209/300 batch  31/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 209/300 batch  32/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 209/300 batch  33/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 209/300 batch  34/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 209/300 batch  35/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 209/300 batch  36/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 209/300 batch  37/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 209/300 batch  38/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 209/300 batch  39/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 209/300 batch  40/188  Train Loss: 0.031, Acc: 0.984\n",
      "epoch: 209/300 batch  41/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 209/300 batch  42/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 209/300 batch  43/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 209/300 batch  44/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 209/300 batch  45/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 209/300 batch  46/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 209/300 batch  47/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 209/300 batch  48/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 209/300 batch  49/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 209/300 batch  50/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 209/300 batch  51/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 209/300 batch  52/188  Train Loss: 0.054, Acc: 0.992\n",
      "epoch: 209/300 batch  53/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 209/300 batch  54/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 209/300 batch  55/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 209/300 batch  56/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 209/300 batch  57/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 209/300 batch  58/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 209/300 batch  59/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 209/300 batch  60/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 209/300 batch  61/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 209/300 batch  62/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 209/300 batch  63/188  Train Loss: 0.042, Acc: 0.980\n",
      "epoch: 209/300 batch  64/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 209/300 batch  65/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 209/300 batch  66/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 209/300 batch  67/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 209/300 batch  68/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 209/300 batch  69/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 209/300 batch  70/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 209/300 batch  71/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 209/300 batch  72/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 209/300 batch  73/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 209/300 batch  74/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 209/300 batch  75/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 209/300 batch  76/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 209/300 batch  77/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 209/300 batch  78/188  Train Loss: 0.058, Acc: 0.988\n",
      "epoch: 209/300 batch  79/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 209/300 batch  80/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 209/300 batch  81/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 209/300 batch  82/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 209/300 batch  83/188  Train Loss: 0.038, Acc: 0.980\n",
      "epoch: 209/300 batch  84/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 209/300 batch  85/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 209/300 batch  86/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 209/300 batch  87/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 209/300 batch  88/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 209/300 batch  89/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 209/300 batch  90/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 209/300 batch  91/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 209/300 batch  92/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 209/300 batch  93/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 209/300 batch  94/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 209/300 batch  95/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 209/300 batch  96/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 209/300 batch  97/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 209/300 batch  98/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 209/300 batch  99/188  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 209/300 batch 100/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 209/300 batch 101/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 209/300 batch 102/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 209/300 batch 103/188  Train Loss: 0.023, Acc: 0.988\n",
      "epoch: 209/300 batch 104/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 209/300 batch 105/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 209/300 batch 106/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 209/300 batch 107/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 209/300 batch 108/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 209/300 batch 109/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 209/300 batch 110/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 209/300 batch 111/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 209/300 batch 112/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 209/300 batch 113/188  Train Loss: 0.079, Acc: 0.984\n",
      "epoch: 209/300 batch 114/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 209/300 batch 115/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 209/300 batch 116/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 209/300 batch 117/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 209/300 batch 118/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 209/300 batch 119/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 209/300 batch 120/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 209/300 batch 121/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 209/300 batch 122/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 209/300 batch 123/188  Train Loss: 0.049, Acc: 0.980\n",
      "epoch: 209/300 batch 124/188  Train Loss: 0.053, Acc: 0.977\n",
      "epoch: 209/300 batch 125/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 209/300 batch 126/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 209/300 batch 127/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 209/300 batch 128/188  Train Loss: 0.045, Acc: 0.996\n",
      "epoch: 209/300 batch 129/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 209/300 batch 130/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 209/300 batch 131/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 209/300 batch 132/188  Train Loss: 0.052, Acc: 0.992\n",
      "epoch: 209/300 batch 133/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 209/300 batch 134/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 209/300 batch 135/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 209/300 batch 136/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 209/300 batch 137/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 209/300 batch 138/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 209/300 batch 139/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 209/300 batch 140/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 209/300 batch 141/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 209/300 batch 142/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 209/300 batch 143/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 209/300 batch 144/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 209/300 batch 145/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 209/300 batch 146/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 209/300 batch 147/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 209/300 batch 148/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 209/300 batch 149/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 209/300 batch 150/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 209/300 batch 151/188  Train Loss: 0.073, Acc: 0.977\n",
      "epoch: 209/300 batch 152/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 209/300 batch 153/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 209/300 batch 154/188  Train Loss: 0.045, Acc: 0.980\n",
      "epoch: 209/300 batch 155/188  Train Loss: 0.057, Acc: 0.973\n",
      "epoch: 209/300 batch 156/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 209/300 batch 157/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 209/300 batch 158/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 209/300 batch 159/188  Train Loss: 0.067, Acc: 0.984\n",
      "epoch: 209/300 batch 160/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 209/300 batch 161/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 209/300 batch 162/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 209/300 batch 163/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 209/300 batch 164/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 209/300 batch 165/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 209/300 batch 166/188  Train Loss: 0.055, Acc: 0.992\n",
      "epoch: 209/300 batch 167/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 209/300 batch 168/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 209/300 batch 169/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 209/300 batch 170/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 209/300 batch 171/188  Train Loss: 0.046, Acc: 0.980\n",
      "epoch: 209/300 batch 172/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 209/300 batch 173/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 209/300 batch 174/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 209/300 batch 175/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 209/300 batch 176/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 209/300 batch 177/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 209/300 batch 178/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 209/300 batch 179/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 209/300 batch 180/188  Train Loss: 0.076, Acc: 0.980\n",
      "epoch: 209/300 batch 181/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 209/300 batch 182/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 209/300 batch 183/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 209/300 batch 184/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 209/300 batch 185/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 209/300 batch 186/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 209/300 batch 187/188  Train Loss: 0.020, Acc: 0.992\n",
      "Train Loss: 0.033269, Acc: 0.992\n",
      "Val Loss: 0.057540, Acc: 0.983\n",
      "epoch: 210/300 batch   0/188  Train Loss: 0.060, Acc: 0.984\n",
      "epoch: 210/300 batch   1/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 210/300 batch   2/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 210/300 batch   3/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 210/300 batch   4/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 210/300 batch   5/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 210/300 batch   6/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 210/300 batch   7/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 210/300 batch   8/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 210/300 batch   9/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 210/300 batch  10/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 210/300 batch  11/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 210/300 batch  12/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 210/300 batch  13/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 210/300 batch  14/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 210/300 batch  15/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 210/300 batch  16/188  Train Loss: 0.032, Acc: 0.984\n",
      "epoch: 210/300 batch  17/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 210/300 batch  18/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 210/300 batch  19/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 210/300 batch  20/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 210/300 batch  21/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 210/300 batch  22/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 210/300 batch  23/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 210/300 batch  24/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 210/300 batch  25/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 210/300 batch  26/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 210/300 batch  27/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 210/300 batch  28/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 210/300 batch  29/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 210/300 batch  30/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 210/300 batch  31/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 210/300 batch  32/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 210/300 batch  33/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 210/300 batch  34/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 210/300 batch  35/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 210/300 batch  36/188  Train Loss: 0.032, Acc: 0.984\n",
      "epoch: 210/300 batch  37/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 210/300 batch  38/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 210/300 batch  39/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 210/300 batch  40/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 210/300 batch  41/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 210/300 batch  42/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 210/300 batch  43/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 210/300 batch  44/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 210/300 batch  45/188  Train Loss: 0.053, Acc: 0.992\n",
      "epoch: 210/300 batch  46/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 210/300 batch  47/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 210/300 batch  48/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 210/300 batch  49/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 210/300 batch  50/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 210/300 batch  51/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 210/300 batch  52/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 210/300 batch  53/188  Train Loss: 0.043, Acc: 0.996\n",
      "epoch: 210/300 batch  54/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 210/300 batch  55/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 210/300 batch  56/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 210/300 batch  57/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 210/300 batch  58/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 210/300 batch  59/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 210/300 batch  60/188  Train Loss: 0.071, Acc: 0.988\n",
      "epoch: 210/300 batch  61/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 210/300 batch  62/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 210/300 batch  63/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 210/300 batch  64/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 210/300 batch  65/188  Train Loss: 0.051, Acc: 0.980\n",
      "epoch: 210/300 batch  66/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 210/300 batch  67/188  Train Loss: 0.050, Acc: 0.980\n",
      "epoch: 210/300 batch  68/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 210/300 batch  69/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 210/300 batch  70/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 210/300 batch  71/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 210/300 batch  72/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 210/300 batch  73/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 210/300 batch  74/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 210/300 batch  75/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 210/300 batch  76/188  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 210/300 batch  77/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 210/300 batch  78/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 210/300 batch  79/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 210/300 batch  80/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 210/300 batch  81/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 210/300 batch  82/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 210/300 batch  83/188  Train Loss: 0.080, Acc: 0.973\n",
      "epoch: 210/300 batch  84/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 210/300 batch  85/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 210/300 batch  86/188  Train Loss: 0.027, Acc: 0.988\n",
      "epoch: 210/300 batch  87/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 210/300 batch  88/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 210/300 batch  89/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 210/300 batch  90/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 210/300 batch  91/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 210/300 batch  92/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 210/300 batch  93/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 210/300 batch  94/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 210/300 batch  95/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 210/300 batch  96/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 210/300 batch  97/188  Train Loss: 0.044, Acc: 0.980\n",
      "epoch: 210/300 batch  98/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 210/300 batch  99/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 210/300 batch 100/188  Train Loss: 0.045, Acc: 0.980\n",
      "epoch: 210/300 batch 101/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 210/300 batch 102/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 210/300 batch 103/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 210/300 batch 104/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 210/300 batch 105/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 210/300 batch 106/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 210/300 batch 107/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 210/300 batch 108/188  Train Loss: 0.062, Acc: 0.980\n",
      "epoch: 210/300 batch 109/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 210/300 batch 110/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 210/300 batch 111/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 210/300 batch 112/188  Train Loss: 0.050, Acc: 0.980\n",
      "epoch: 210/300 batch 113/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 210/300 batch 114/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 210/300 batch 115/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 210/300 batch 116/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 210/300 batch 117/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 210/300 batch 118/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 210/300 batch 119/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 210/300 batch 120/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 210/300 batch 121/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 210/300 batch 122/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 210/300 batch 123/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 210/300 batch 124/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 210/300 batch 125/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 210/300 batch 126/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 210/300 batch 127/188  Train Loss: 0.059, Acc: 0.984\n",
      "epoch: 210/300 batch 128/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 210/300 batch 129/188  Train Loss: 0.027, Acc: 0.988\n",
      "epoch: 210/300 batch 130/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 210/300 batch 131/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 210/300 batch 132/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 210/300 batch 133/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 210/300 batch 134/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 210/300 batch 135/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 210/300 batch 136/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 210/300 batch 137/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 210/300 batch 138/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 210/300 batch 139/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 210/300 batch 140/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 210/300 batch 141/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 210/300 batch 142/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 210/300 batch 143/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 210/300 batch 144/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 210/300 batch 145/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 210/300 batch 146/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 210/300 batch 147/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 210/300 batch 148/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 210/300 batch 149/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 210/300 batch 150/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 210/300 batch 151/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 210/300 batch 152/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 210/300 batch 153/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 210/300 batch 154/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 210/300 batch 155/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 210/300 batch 156/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 210/300 batch 157/188  Train Loss: 0.058, Acc: 0.988\n",
      "epoch: 210/300 batch 158/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 210/300 batch 159/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 210/300 batch 160/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 210/300 batch 161/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 210/300 batch 162/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 210/300 batch 163/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 210/300 batch 164/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 210/300 batch 165/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 210/300 batch 166/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 210/300 batch 167/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 210/300 batch 168/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 210/300 batch 169/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 210/300 batch 170/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 210/300 batch 171/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 210/300 batch 172/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 210/300 batch 173/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 210/300 batch 174/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 210/300 batch 175/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 210/300 batch 176/188  Train Loss: 0.045, Acc: 0.980\n",
      "epoch: 210/300 batch 177/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 210/300 batch 178/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 210/300 batch 179/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 210/300 batch 180/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 210/300 batch 181/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 210/300 batch 182/188  Train Loss: 0.061, Acc: 0.992\n",
      "epoch: 210/300 batch 183/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 210/300 batch 184/188  Train Loss: 0.072, Acc: 0.984\n",
      "epoch: 210/300 batch 185/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 210/300 batch 186/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 210/300 batch 187/188  Train Loss: 0.039, Acc: 0.992\n",
      "Train Loss: 0.033200, Acc: 0.993\n",
      "Val Loss: 0.057344, Acc: 0.983\n",
      "epoch: 211/300 batch   0/188  Train Loss: 0.066, Acc: 0.980\n",
      "epoch: 211/300 batch   1/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 211/300 batch   2/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 211/300 batch   3/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 211/300 batch   4/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 211/300 batch   5/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 211/300 batch   6/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 211/300 batch   7/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 211/300 batch   8/188  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 211/300 batch   9/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 211/300 batch  10/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 211/300 batch  11/188  Train Loss: 0.059, Acc: 0.977\n",
      "epoch: 211/300 batch  12/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 211/300 batch  13/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 211/300 batch  14/188  Train Loss: 0.066, Acc: 0.992\n",
      "epoch: 211/300 batch  15/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 211/300 batch  16/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 211/300 batch  17/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 211/300 batch  18/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 211/300 batch  19/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 211/300 batch  20/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 211/300 batch  21/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 211/300 batch  22/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 211/300 batch  23/188  Train Loss: 0.044, Acc: 0.996\n",
      "epoch: 211/300 batch  24/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 211/300 batch  25/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 211/300 batch  26/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 211/300 batch  27/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 211/300 batch  28/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 211/300 batch  29/188  Train Loss: 0.058, Acc: 0.980\n",
      "epoch: 211/300 batch  30/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 211/300 batch  31/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 211/300 batch  32/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 211/300 batch  33/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 211/300 batch  34/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 211/300 batch  35/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 211/300 batch  36/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 211/300 batch  37/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 211/300 batch  38/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 211/300 batch  39/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 211/300 batch  40/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 211/300 batch  41/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 211/300 batch  42/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 211/300 batch  43/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 211/300 batch  44/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 211/300 batch  45/188  Train Loss: 0.043, Acc: 0.977\n",
      "epoch: 211/300 batch  46/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 211/300 batch  47/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 211/300 batch  48/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 211/300 batch  49/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 211/300 batch  50/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 211/300 batch  51/188  Train Loss: 0.052, Acc: 0.992\n",
      "epoch: 211/300 batch  52/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 211/300 batch  53/188  Train Loss: 0.062, Acc: 0.977\n",
      "epoch: 211/300 batch  54/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 211/300 batch  55/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 211/300 batch  56/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 211/300 batch  57/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 211/300 batch  58/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 211/300 batch  59/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 211/300 batch  60/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 211/300 batch  61/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 211/300 batch  62/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 211/300 batch  63/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 211/300 batch  64/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 211/300 batch  65/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 211/300 batch  66/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 211/300 batch  67/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 211/300 batch  68/188  Train Loss: 0.057, Acc: 0.992\n",
      "epoch: 211/300 batch  69/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 211/300 batch  70/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 211/300 batch  71/188  Train Loss: 0.015, Acc: 0.996\n",
      "epoch: 211/300 batch  72/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 211/300 batch  73/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 211/300 batch  74/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 211/300 batch  75/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 211/300 batch  76/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 211/300 batch  77/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 211/300 batch  78/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 211/300 batch  79/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 211/300 batch  80/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 211/300 batch  81/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 211/300 batch  82/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 211/300 batch  83/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 211/300 batch  84/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 211/300 batch  85/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 211/300 batch  86/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 211/300 batch  87/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 211/300 batch  88/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 211/300 batch  89/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 211/300 batch  90/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 211/300 batch  91/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 211/300 batch  92/188  Train Loss: 0.053, Acc: 0.992\n",
      "epoch: 211/300 batch  93/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 211/300 batch  94/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 211/300 batch  95/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 211/300 batch  96/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 211/300 batch  97/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 211/300 batch  98/188  Train Loss: 0.063, Acc: 0.980\n",
      "epoch: 211/300 batch  99/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 211/300 batch 100/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 211/300 batch 101/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 211/300 batch 102/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 211/300 batch 103/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 211/300 batch 104/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 211/300 batch 105/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 211/300 batch 106/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 211/300 batch 107/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 211/300 batch 108/188  Train Loss: 0.067, Acc: 0.984\n",
      "epoch: 211/300 batch 109/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 211/300 batch 110/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 211/300 batch 111/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 211/300 batch 112/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 211/300 batch 113/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 211/300 batch 114/188  Train Loss: 0.067, Acc: 0.977\n",
      "epoch: 211/300 batch 115/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 211/300 batch 116/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 211/300 batch 117/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 211/300 batch 118/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 211/300 batch 119/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 211/300 batch 120/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 211/300 batch 121/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 211/300 batch 122/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 211/300 batch 123/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 211/300 batch 124/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 211/300 batch 125/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 211/300 batch 126/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 211/300 batch 127/188  Train Loss: 0.069, Acc: 0.980\n",
      "epoch: 211/300 batch 128/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 211/300 batch 129/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 211/300 batch 130/188  Train Loss: 0.062, Acc: 0.988\n",
      "epoch: 211/300 batch 131/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 211/300 batch 132/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 211/300 batch 133/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 211/300 batch 134/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 211/300 batch 135/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 211/300 batch 136/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 211/300 batch 137/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 211/300 batch 138/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 211/300 batch 139/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 211/300 batch 140/188  Train Loss: 0.031, Acc: 1.000\n",
      "epoch: 211/300 batch 141/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 211/300 batch 142/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 211/300 batch 143/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 211/300 batch 144/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 211/300 batch 145/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 211/300 batch 146/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 211/300 batch 147/188  Train Loss: 0.015, Acc: 0.996\n",
      "epoch: 211/300 batch 148/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 211/300 batch 149/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 211/300 batch 150/188  Train Loss: 0.048, Acc: 0.980\n",
      "epoch: 211/300 batch 151/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 211/300 batch 152/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 211/300 batch 153/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 211/300 batch 154/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 211/300 batch 155/188  Train Loss: 0.070, Acc: 0.980\n",
      "epoch: 211/300 batch 156/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 211/300 batch 157/188  Train Loss: 0.044, Acc: 0.980\n",
      "epoch: 211/300 batch 158/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 211/300 batch 159/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 211/300 batch 160/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 211/300 batch 161/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 211/300 batch 162/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 211/300 batch 163/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 211/300 batch 164/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 211/300 batch 165/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 211/300 batch 166/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 211/300 batch 167/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 211/300 batch 168/188  Train Loss: 0.013, Acc: 0.996\n",
      "epoch: 211/300 batch 169/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 211/300 batch 170/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 211/300 batch 171/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 211/300 batch 172/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 211/300 batch 173/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 211/300 batch 174/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 211/300 batch 175/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 211/300 batch 176/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 211/300 batch 177/188  Train Loss: 0.036, Acc: 0.980\n",
      "epoch: 211/300 batch 178/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 211/300 batch 179/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 211/300 batch 180/188  Train Loss: 0.044, Acc: 0.996\n",
      "epoch: 211/300 batch 181/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 211/300 batch 182/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 211/300 batch 183/188  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 211/300 batch 184/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 211/300 batch 185/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 211/300 batch 186/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 211/300 batch 187/188  Train Loss: 0.024, Acc: 1.000\n",
      "Train Loss: 0.033186, Acc: 0.993\n",
      "Val Loss: 0.057429, Acc: 0.983\n",
      "epoch: 212/300 batch   0/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 212/300 batch   1/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 212/300 batch   2/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 212/300 batch   3/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 212/300 batch   4/188  Train Loss: 0.026, Acc: 0.988\n",
      "epoch: 212/300 batch   5/188  Train Loss: 0.043, Acc: 0.980\n",
      "epoch: 212/300 batch   6/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 212/300 batch   7/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 212/300 batch   8/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 212/300 batch   9/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 212/300 batch  10/188  Train Loss: 0.043, Acc: 0.996\n",
      "epoch: 212/300 batch  11/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 212/300 batch  12/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 212/300 batch  13/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 212/300 batch  14/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 212/300 batch  15/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 212/300 batch  16/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 212/300 batch  17/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 212/300 batch  18/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 212/300 batch  19/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 212/300 batch  20/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 212/300 batch  21/188  Train Loss: 0.062, Acc: 0.984\n",
      "epoch: 212/300 batch  22/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 212/300 batch  23/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 212/300 batch  24/188  Train Loss: 0.043, Acc: 0.977\n",
      "epoch: 212/300 batch  25/188  Train Loss: 0.015, Acc: 0.996\n",
      "epoch: 212/300 batch  26/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 212/300 batch  27/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 212/300 batch  28/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 212/300 batch  29/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 212/300 batch  30/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 212/300 batch  31/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 212/300 batch  32/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 212/300 batch  33/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 212/300 batch  34/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 212/300 batch  35/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 212/300 batch  36/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 212/300 batch  37/188  Train Loss: 0.029, Acc: 0.984\n",
      "epoch: 212/300 batch  38/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 212/300 batch  39/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 212/300 batch  40/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 212/300 batch  41/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 212/300 batch  42/188  Train Loss: 0.043, Acc: 0.996\n",
      "epoch: 212/300 batch  43/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 212/300 batch  44/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 212/300 batch  45/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 212/300 batch  46/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 212/300 batch  47/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 212/300 batch  48/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 212/300 batch  49/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 212/300 batch  50/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 212/300 batch  51/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 212/300 batch  52/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 212/300 batch  53/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 212/300 batch  54/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 212/300 batch  55/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 212/300 batch  56/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 212/300 batch  57/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 212/300 batch  58/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 212/300 batch  59/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 212/300 batch  60/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 212/300 batch  61/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 212/300 batch  62/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 212/300 batch  63/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 212/300 batch  64/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 212/300 batch  65/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 212/300 batch  66/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 212/300 batch  67/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 212/300 batch  68/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 212/300 batch  69/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 212/300 batch  70/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 212/300 batch  71/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 212/300 batch  72/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 212/300 batch  73/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 212/300 batch  74/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 212/300 batch  75/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 212/300 batch  76/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 212/300 batch  77/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 212/300 batch  78/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 212/300 batch  79/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 212/300 batch  80/188  Train Loss: 0.047, Acc: 0.977\n",
      "epoch: 212/300 batch  81/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 212/300 batch  82/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 212/300 batch  83/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 212/300 batch  84/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 212/300 batch  85/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 212/300 batch  86/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 212/300 batch  87/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 212/300 batch  88/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 212/300 batch  89/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 212/300 batch  90/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 212/300 batch  91/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 212/300 batch  92/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 212/300 batch  93/188  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 212/300 batch  94/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 212/300 batch  95/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 212/300 batch  96/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 212/300 batch  97/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 212/300 batch  98/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 212/300 batch  99/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 212/300 batch 100/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 212/300 batch 101/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 212/300 batch 102/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 212/300 batch 103/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 212/300 batch 104/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 212/300 batch 105/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 212/300 batch 106/188  Train Loss: 0.063, Acc: 0.988\n",
      "epoch: 212/300 batch 107/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 212/300 batch 108/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 212/300 batch 109/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 212/300 batch 110/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 212/300 batch 111/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 212/300 batch 112/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 212/300 batch 113/188  Train Loss: 0.062, Acc: 0.973\n",
      "epoch: 212/300 batch 114/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 212/300 batch 115/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 212/300 batch 116/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 212/300 batch 117/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 212/300 batch 118/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 212/300 batch 119/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 212/300 batch 120/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 212/300 batch 121/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 212/300 batch 122/188  Train Loss: 0.032, Acc: 1.000\n",
      "epoch: 212/300 batch 123/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 212/300 batch 124/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 212/300 batch 125/188  Train Loss: 0.026, Acc: 0.988\n",
      "epoch: 212/300 batch 126/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 212/300 batch 127/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 212/300 batch 128/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 212/300 batch 129/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 212/300 batch 130/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 212/300 batch 131/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 212/300 batch 132/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 212/300 batch 133/188  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 212/300 batch 134/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 212/300 batch 135/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 212/300 batch 136/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 212/300 batch 137/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 212/300 batch 138/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 212/300 batch 139/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 212/300 batch 140/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 212/300 batch 141/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 212/300 batch 142/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 212/300 batch 143/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 212/300 batch 144/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 212/300 batch 145/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 212/300 batch 146/188  Train Loss: 0.053, Acc: 0.992\n",
      "epoch: 212/300 batch 147/188  Train Loss: 0.043, Acc: 0.980\n",
      "epoch: 212/300 batch 148/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 212/300 batch 149/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 212/300 batch 150/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 212/300 batch 151/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 212/300 batch 152/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 212/300 batch 153/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 212/300 batch 154/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 212/300 batch 155/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 212/300 batch 156/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 212/300 batch 157/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 212/300 batch 158/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 212/300 batch 159/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 212/300 batch 160/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 212/300 batch 161/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 212/300 batch 162/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 212/300 batch 163/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 212/300 batch 164/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 212/300 batch 165/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 212/300 batch 166/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 212/300 batch 167/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 212/300 batch 168/188  Train Loss: 0.054, Acc: 0.992\n",
      "epoch: 212/300 batch 169/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 212/300 batch 170/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 212/300 batch 171/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 212/300 batch 172/188  Train Loss: 0.066, Acc: 0.980\n",
      "epoch: 212/300 batch 173/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 212/300 batch 174/188  Train Loss: 0.073, Acc: 0.988\n",
      "epoch: 212/300 batch 175/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 212/300 batch 176/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 212/300 batch 177/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 212/300 batch 178/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 212/300 batch 179/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 212/300 batch 180/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 212/300 batch 181/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 212/300 batch 182/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 212/300 batch 183/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 212/300 batch 184/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 212/300 batch 185/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 212/300 batch 186/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 212/300 batch 187/188  Train Loss: 0.029, Acc: 1.000\n",
      "Train Loss: 0.033175, Acc: 0.992\n",
      "Val Loss: 0.057210, Acc: 0.983\n",
      "epoch: 213/300 batch   0/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 213/300 batch   1/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 213/300 batch   2/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 213/300 batch   3/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 213/300 batch   4/188  Train Loss: 0.064, Acc: 0.980\n",
      "epoch: 213/300 batch   5/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 213/300 batch   6/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 213/300 batch   7/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 213/300 batch   8/188  Train Loss: 0.084, Acc: 0.984\n",
      "epoch: 213/300 batch   9/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 213/300 batch  10/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 213/300 batch  11/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 213/300 batch  12/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 213/300 batch  13/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 213/300 batch  14/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 213/300 batch  15/188  Train Loss: 0.058, Acc: 0.980\n",
      "epoch: 213/300 batch  16/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 213/300 batch  17/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 213/300 batch  18/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 213/300 batch  19/188  Train Loss: 0.044, Acc: 0.980\n",
      "epoch: 213/300 batch  20/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 213/300 batch  21/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 213/300 batch  22/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 213/300 batch  23/188  Train Loss: 0.041, Acc: 0.980\n",
      "epoch: 213/300 batch  24/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 213/300 batch  25/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 213/300 batch  26/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 213/300 batch  27/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 213/300 batch  28/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 213/300 batch  29/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 213/300 batch  30/188  Train Loss: 0.060, Acc: 0.984\n",
      "epoch: 213/300 batch  31/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 213/300 batch  32/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 213/300 batch  33/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 213/300 batch  34/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 213/300 batch  35/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 213/300 batch  36/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 213/300 batch  37/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 213/300 batch  38/188  Train Loss: 0.061, Acc: 0.980\n",
      "epoch: 213/300 batch  39/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 213/300 batch  40/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 213/300 batch  41/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 213/300 batch  42/188  Train Loss: 0.034, Acc: 0.984\n",
      "epoch: 213/300 batch  43/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 213/300 batch  44/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 213/300 batch  45/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 213/300 batch  46/188  Train Loss: 0.051, Acc: 0.992\n",
      "epoch: 213/300 batch  47/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 213/300 batch  48/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 213/300 batch  49/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 213/300 batch  50/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 213/300 batch  51/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 213/300 batch  52/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 213/300 batch  53/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 213/300 batch  54/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 213/300 batch  55/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 213/300 batch  56/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 213/300 batch  57/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 213/300 batch  58/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 213/300 batch  59/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 213/300 batch  60/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 213/300 batch  61/188  Train Loss: 0.024, Acc: 0.988\n",
      "epoch: 213/300 batch  62/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 213/300 batch  63/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 213/300 batch  64/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 213/300 batch  65/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 213/300 batch  66/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 213/300 batch  67/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 213/300 batch  68/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 213/300 batch  69/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 213/300 batch  70/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 213/300 batch  71/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 213/300 batch  72/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 213/300 batch  73/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 213/300 batch  74/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 213/300 batch  75/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 213/300 batch  76/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 213/300 batch  77/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 213/300 batch  78/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 213/300 batch  79/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 213/300 batch  80/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 213/300 batch  81/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 213/300 batch  82/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 213/300 batch  83/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 213/300 batch  84/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 213/300 batch  85/188  Train Loss: 0.016, Acc: 0.996\n",
      "epoch: 213/300 batch  86/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 213/300 batch  87/188  Train Loss: 0.053, Acc: 0.992\n",
      "epoch: 213/300 batch  88/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 213/300 batch  89/188  Train Loss: 0.060, Acc: 0.992\n",
      "epoch: 213/300 batch  90/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 213/300 batch  91/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 213/300 batch  92/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 213/300 batch  93/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 213/300 batch  94/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 213/300 batch  95/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 213/300 batch  96/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 213/300 batch  97/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 213/300 batch  98/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 213/300 batch  99/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 213/300 batch 100/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 213/300 batch 101/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 213/300 batch 102/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 213/300 batch 103/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 213/300 batch 104/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 213/300 batch 105/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 213/300 batch 106/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 213/300 batch 107/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 213/300 batch 108/188  Train Loss: 0.051, Acc: 0.992\n",
      "epoch: 213/300 batch 109/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 213/300 batch 110/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 213/300 batch 111/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 213/300 batch 112/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 213/300 batch 113/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 213/300 batch 114/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 213/300 batch 115/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 213/300 batch 116/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 213/300 batch 117/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 213/300 batch 118/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 213/300 batch 119/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 213/300 batch 120/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 213/300 batch 121/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 213/300 batch 122/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 213/300 batch 123/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 213/300 batch 124/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 213/300 batch 125/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 213/300 batch 126/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 213/300 batch 127/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 213/300 batch 128/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 213/300 batch 129/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 213/300 batch 130/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 213/300 batch 131/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 213/300 batch 132/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 213/300 batch 133/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 213/300 batch 134/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 213/300 batch 135/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 213/300 batch 136/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 213/300 batch 137/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 213/300 batch 138/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 213/300 batch 139/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 213/300 batch 140/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 213/300 batch 141/188  Train Loss: 0.044, Acc: 0.980\n",
      "epoch: 213/300 batch 142/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 213/300 batch 143/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 213/300 batch 144/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 213/300 batch 145/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 213/300 batch 146/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 213/300 batch 147/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 213/300 batch 148/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 213/300 batch 149/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 213/300 batch 150/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 213/300 batch 151/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 213/300 batch 152/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 213/300 batch 153/188  Train Loss: 0.087, Acc: 0.980\n",
      "epoch: 213/300 batch 154/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 213/300 batch 155/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 213/300 batch 156/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 213/300 batch 157/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 213/300 batch 158/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 213/300 batch 159/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 213/300 batch 160/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 213/300 batch 161/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 213/300 batch 162/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 213/300 batch 163/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 213/300 batch 164/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 213/300 batch 165/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 213/300 batch 166/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 213/300 batch 167/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 213/300 batch 168/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 213/300 batch 169/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 213/300 batch 170/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 213/300 batch 171/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 213/300 batch 172/188  Train Loss: 0.059, Acc: 0.980\n",
      "epoch: 213/300 batch 173/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 213/300 batch 174/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 213/300 batch 175/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 213/300 batch 176/188  Train Loss: 0.059, Acc: 0.977\n",
      "epoch: 213/300 batch 177/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 213/300 batch 178/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 213/300 batch 179/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 213/300 batch 180/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 213/300 batch 181/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 213/300 batch 182/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 213/300 batch 183/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 213/300 batch 184/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 213/300 batch 185/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 213/300 batch 186/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 213/300 batch 187/188  Train Loss: 0.014, Acc: 1.000\n",
      "Train Loss: 0.033094, Acc: 0.992\n",
      "Val Loss: 0.057284, Acc: 0.983\n",
      "epoch: 214/300 batch   0/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 214/300 batch   1/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 214/300 batch   2/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 214/300 batch   3/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 214/300 batch   4/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 214/300 batch   5/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 214/300 batch   6/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 214/300 batch   7/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 214/300 batch   8/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 214/300 batch   9/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 214/300 batch  10/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 214/300 batch  11/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 214/300 batch  12/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 214/300 batch  13/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 214/300 batch  14/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 214/300 batch  15/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 214/300 batch  16/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 214/300 batch  17/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 214/300 batch  18/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 214/300 batch  19/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 214/300 batch  20/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 214/300 batch  21/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 214/300 batch  22/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 214/300 batch  23/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 214/300 batch  24/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 214/300 batch  25/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 214/300 batch  26/188  Train Loss: 0.042, Acc: 0.996\n",
      "epoch: 214/300 batch  27/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 214/300 batch  28/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 214/300 batch  29/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 214/300 batch  30/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 214/300 batch  31/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 214/300 batch  32/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 214/300 batch  33/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 214/300 batch  34/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 214/300 batch  35/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 214/300 batch  36/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 214/300 batch  37/188  Train Loss: 0.046, Acc: 0.977\n",
      "epoch: 214/300 batch  38/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 214/300 batch  39/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 214/300 batch  40/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 214/300 batch  41/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 214/300 batch  42/188  Train Loss: 0.034, Acc: 1.000\n",
      "epoch: 214/300 batch  43/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 214/300 batch  44/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 214/300 batch  45/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 214/300 batch  46/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 214/300 batch  47/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 214/300 batch  48/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 214/300 batch  49/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 214/300 batch  50/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 214/300 batch  51/188  Train Loss: 0.035, Acc: 1.000\n",
      "epoch: 214/300 batch  52/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 214/300 batch  53/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 214/300 batch  54/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 214/300 batch  55/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 214/300 batch  56/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 214/300 batch  57/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 214/300 batch  58/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 214/300 batch  59/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 214/300 batch  60/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 214/300 batch  61/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 214/300 batch  62/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 214/300 batch  63/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 214/300 batch  64/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 214/300 batch  65/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 214/300 batch  66/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 214/300 batch  67/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 214/300 batch  68/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 214/300 batch  69/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 214/300 batch  70/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 214/300 batch  71/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 214/300 batch  72/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 214/300 batch  73/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 214/300 batch  74/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 214/300 batch  75/188  Train Loss: 0.062, Acc: 0.984\n",
      "epoch: 214/300 batch  76/188  Train Loss: 0.037, Acc: 0.980\n",
      "epoch: 214/300 batch  77/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 214/300 batch  78/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 214/300 batch  79/188  Train Loss: 0.051, Acc: 0.980\n",
      "epoch: 214/300 batch  80/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 214/300 batch  81/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 214/300 batch  82/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 214/300 batch  83/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 214/300 batch  84/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 214/300 batch  85/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 214/300 batch  86/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 214/300 batch  87/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 214/300 batch  88/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 214/300 batch  89/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 214/300 batch  90/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 214/300 batch  91/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 214/300 batch  92/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 214/300 batch  93/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 214/300 batch  94/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 214/300 batch  95/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 214/300 batch  96/188  Train Loss: 0.052, Acc: 0.992\n",
      "epoch: 214/300 batch  97/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 214/300 batch  98/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 214/300 batch  99/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 214/300 batch 100/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 214/300 batch 101/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 214/300 batch 102/188  Train Loss: 0.074, Acc: 0.984\n",
      "epoch: 214/300 batch 103/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 214/300 batch 104/188  Train Loss: 0.048, Acc: 0.980\n",
      "epoch: 214/300 batch 105/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 214/300 batch 106/188  Train Loss: 0.034, Acc: 0.984\n",
      "epoch: 214/300 batch 107/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 214/300 batch 108/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 214/300 batch 109/188  Train Loss: 0.033, Acc: 1.000\n",
      "epoch: 214/300 batch 110/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 214/300 batch 111/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 214/300 batch 112/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 214/300 batch 113/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 214/300 batch 114/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 214/300 batch 115/188  Train Loss: 0.042, Acc: 0.996\n",
      "epoch: 214/300 batch 116/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 214/300 batch 117/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 214/300 batch 118/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 214/300 batch 119/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 214/300 batch 120/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 214/300 batch 121/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 214/300 batch 122/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 214/300 batch 123/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 214/300 batch 124/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 214/300 batch 125/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 214/300 batch 126/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 214/300 batch 127/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 214/300 batch 128/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 214/300 batch 129/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 214/300 batch 130/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 214/300 batch 131/188  Train Loss: 0.043, Acc: 0.980\n",
      "epoch: 214/300 batch 132/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 214/300 batch 133/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 214/300 batch 134/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 214/300 batch 135/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 214/300 batch 136/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 214/300 batch 137/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 214/300 batch 138/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 214/300 batch 139/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 214/300 batch 140/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 214/300 batch 141/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 214/300 batch 142/188  Train Loss: 0.027, Acc: 0.988\n",
      "epoch: 214/300 batch 143/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 214/300 batch 144/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 214/300 batch 145/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 214/300 batch 146/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 214/300 batch 147/188  Train Loss: 0.046, Acc: 0.980\n",
      "epoch: 214/300 batch 148/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 214/300 batch 149/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 214/300 batch 150/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 214/300 batch 151/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 214/300 batch 152/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 214/300 batch 153/188  Train Loss: 0.045, Acc: 0.996\n",
      "epoch: 214/300 batch 154/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 214/300 batch 155/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 214/300 batch 156/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 214/300 batch 157/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 214/300 batch 158/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 214/300 batch 159/188  Train Loss: 0.055, Acc: 0.992\n",
      "epoch: 214/300 batch 160/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 214/300 batch 161/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 214/300 batch 162/188  Train Loss: 0.073, Acc: 0.980\n",
      "epoch: 214/300 batch 163/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 214/300 batch 164/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 214/300 batch 165/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 214/300 batch 166/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 214/300 batch 167/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 214/300 batch 168/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 214/300 batch 169/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 214/300 batch 170/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 214/300 batch 171/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 214/300 batch 172/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 214/300 batch 173/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 214/300 batch 174/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 214/300 batch 175/188  Train Loss: 0.057, Acc: 0.980\n",
      "epoch: 214/300 batch 176/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 214/300 batch 177/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 214/300 batch 178/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 214/300 batch 179/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 214/300 batch 180/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 214/300 batch 181/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 214/300 batch 182/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 214/300 batch 183/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 214/300 batch 184/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 214/300 batch 185/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 214/300 batch 186/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 214/300 batch 187/188  Train Loss: 0.049, Acc: 0.992\n",
      "Train Loss: 0.033171, Acc: 0.993\n",
      "Val Loss: 0.057486, Acc: 0.983\n",
      "epoch: 215/300 batch   0/188  Train Loss: 0.049, Acc: 0.996\n",
      "epoch: 215/300 batch   1/188  Train Loss: 0.032, Acc: 0.980\n",
      "epoch: 215/300 batch   2/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 215/300 batch   3/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 215/300 batch   4/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 215/300 batch   5/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 215/300 batch   6/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 215/300 batch   7/188  Train Loss: 0.065, Acc: 0.988\n",
      "epoch: 215/300 batch   8/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 215/300 batch   9/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 215/300 batch  10/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 215/300 batch  11/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 215/300 batch  12/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 215/300 batch  13/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 215/300 batch  14/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 215/300 batch  15/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 215/300 batch  16/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 215/300 batch  17/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 215/300 batch  18/188  Train Loss: 0.047, Acc: 0.980\n",
      "epoch: 215/300 batch  19/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 215/300 batch  20/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 215/300 batch  21/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 215/300 batch  22/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 215/300 batch  23/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 215/300 batch  24/188  Train Loss: 0.050, Acc: 0.980\n",
      "epoch: 215/300 batch  25/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 215/300 batch  26/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 215/300 batch  27/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 215/300 batch  28/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 215/300 batch  29/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 215/300 batch  30/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 215/300 batch  31/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 215/300 batch  32/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 215/300 batch  33/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 215/300 batch  34/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 215/300 batch  35/188  Train Loss: 0.053, Acc: 0.980\n",
      "epoch: 215/300 batch  36/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 215/300 batch  37/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 215/300 batch  38/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 215/300 batch  39/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 215/300 batch  40/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 215/300 batch  41/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 215/300 batch  42/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 215/300 batch  43/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 215/300 batch  44/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 215/300 batch  45/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 215/300 batch  46/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 215/300 batch  47/188  Train Loss: 0.053, Acc: 0.996\n",
      "epoch: 215/300 batch  48/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 215/300 batch  49/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 215/300 batch  50/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 215/300 batch  51/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 215/300 batch  52/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 215/300 batch  53/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 215/300 batch  54/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 215/300 batch  55/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 215/300 batch  56/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 215/300 batch  57/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 215/300 batch  58/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 215/300 batch  59/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 215/300 batch  60/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 215/300 batch  61/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 215/300 batch  62/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 215/300 batch  63/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 215/300 batch  64/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 215/300 batch  65/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 215/300 batch  66/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 215/300 batch  67/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 215/300 batch  68/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 215/300 batch  69/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 215/300 batch  70/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 215/300 batch  71/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 215/300 batch  72/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 215/300 batch  73/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 215/300 batch  74/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 215/300 batch  75/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 215/300 batch  76/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 215/300 batch  77/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 215/300 batch  78/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 215/300 batch  79/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 215/300 batch  80/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 215/300 batch  81/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 215/300 batch  82/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 215/300 batch  83/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 215/300 batch  84/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 215/300 batch  85/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 215/300 batch  86/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 215/300 batch  87/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 215/300 batch  88/188  Train Loss: 0.051, Acc: 0.977\n",
      "epoch: 215/300 batch  89/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 215/300 batch  90/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 215/300 batch  91/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 215/300 batch  92/188  Train Loss: 0.053, Acc: 0.980\n",
      "epoch: 215/300 batch  93/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 215/300 batch  94/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 215/300 batch  95/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 215/300 batch  96/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 215/300 batch  97/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 215/300 batch  98/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 215/300 batch  99/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 215/300 batch 100/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 215/300 batch 101/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 215/300 batch 102/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 215/300 batch 103/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 215/300 batch 104/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 215/300 batch 105/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 215/300 batch 106/188  Train Loss: 0.061, Acc: 0.984\n",
      "epoch: 215/300 batch 107/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 215/300 batch 108/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 215/300 batch 109/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 215/300 batch 110/188  Train Loss: 0.054, Acc: 0.992\n",
      "epoch: 215/300 batch 111/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 215/300 batch 112/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 215/300 batch 113/188  Train Loss: 0.059, Acc: 0.984\n",
      "epoch: 215/300 batch 114/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 215/300 batch 115/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 215/300 batch 116/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 215/300 batch 117/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 215/300 batch 118/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 215/300 batch 119/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 215/300 batch 120/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 215/300 batch 121/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 215/300 batch 122/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 215/300 batch 123/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 215/300 batch 124/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 215/300 batch 125/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 215/300 batch 126/188  Train Loss: 0.059, Acc: 0.984\n",
      "epoch: 215/300 batch 127/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 215/300 batch 128/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 215/300 batch 129/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 215/300 batch 130/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 215/300 batch 131/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 215/300 batch 132/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 215/300 batch 133/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 215/300 batch 134/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 215/300 batch 135/188  Train Loss: 0.056, Acc: 0.973\n",
      "epoch: 215/300 batch 136/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 215/300 batch 137/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 215/300 batch 138/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 215/300 batch 139/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 215/300 batch 140/188  Train Loss: 0.033, Acc: 0.984\n",
      "epoch: 215/300 batch 141/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 215/300 batch 142/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 215/300 batch 143/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 215/300 batch 144/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 215/300 batch 145/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 215/300 batch 146/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 215/300 batch 147/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 215/300 batch 148/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 215/300 batch 149/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 215/300 batch 150/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 215/300 batch 151/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 215/300 batch 152/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 215/300 batch 153/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 215/300 batch 154/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 215/300 batch 155/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 215/300 batch 156/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 215/300 batch 157/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 215/300 batch 158/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 215/300 batch 159/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 215/300 batch 160/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 215/300 batch 161/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 215/300 batch 162/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 215/300 batch 163/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 215/300 batch 164/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 215/300 batch 165/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 215/300 batch 166/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 215/300 batch 167/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 215/300 batch 168/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 215/300 batch 169/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 215/300 batch 170/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 215/300 batch 171/188  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 215/300 batch 172/188  Train Loss: 0.063, Acc: 0.977\n",
      "epoch: 215/300 batch 173/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 215/300 batch 174/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 215/300 batch 175/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 215/300 batch 176/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 215/300 batch 177/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 215/300 batch 178/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 215/300 batch 179/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 215/300 batch 180/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 215/300 batch 181/188  Train Loss: 0.058, Acc: 0.988\n",
      "epoch: 215/300 batch 182/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 215/300 batch 183/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 215/300 batch 184/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 215/300 batch 185/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 215/300 batch 186/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 215/300 batch 187/188  Train Loss: 0.016, Acc: 1.000\n",
      "Train Loss: 0.033110, Acc: 0.992\n",
      "Val Loss: 0.057460, Acc: 0.983\n",
      "epoch: 216/300 batch   0/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 216/300 batch   1/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 216/300 batch   2/188  Train Loss: 0.059, Acc: 0.984\n",
      "epoch: 216/300 batch   3/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 216/300 batch   4/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 216/300 batch   5/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 216/300 batch   6/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 216/300 batch   7/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 216/300 batch   8/188  Train Loss: 0.061, Acc: 0.984\n",
      "epoch: 216/300 batch   9/188  Train Loss: 0.062, Acc: 0.984\n",
      "epoch: 216/300 batch  10/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 216/300 batch  11/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 216/300 batch  12/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 216/300 batch  13/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 216/300 batch  14/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 216/300 batch  15/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 216/300 batch  16/188  Train Loss: 0.054, Acc: 0.996\n",
      "epoch: 216/300 batch  17/188  Train Loss: 0.061, Acc: 0.980\n",
      "epoch: 216/300 batch  18/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 216/300 batch  19/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 216/300 batch  20/188  Train Loss: 0.078, Acc: 0.977\n",
      "epoch: 216/300 batch  21/188  Train Loss: 0.031, Acc: 1.000\n",
      "epoch: 216/300 batch  22/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 216/300 batch  23/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 216/300 batch  24/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 216/300 batch  25/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 216/300 batch  26/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 216/300 batch  27/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 216/300 batch  28/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 216/300 batch  29/188  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 216/300 batch  30/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 216/300 batch  31/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 216/300 batch  32/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 216/300 batch  33/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 216/300 batch  34/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 216/300 batch  35/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 216/300 batch  36/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 216/300 batch  37/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 216/300 batch  38/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 216/300 batch  39/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 216/300 batch  40/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 216/300 batch  41/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 216/300 batch  42/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 216/300 batch  43/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 216/300 batch  44/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 216/300 batch  45/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 216/300 batch  46/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 216/300 batch  47/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 216/300 batch  48/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 216/300 batch  49/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 216/300 batch  50/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 216/300 batch  51/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 216/300 batch  52/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 216/300 batch  53/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 216/300 batch  54/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 216/300 batch  55/188  Train Loss: 0.026, Acc: 0.988\n",
      "epoch: 216/300 batch  56/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 216/300 batch  57/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 216/300 batch  58/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 216/300 batch  59/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 216/300 batch  60/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 216/300 batch  61/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 216/300 batch  62/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 216/300 batch  63/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 216/300 batch  64/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 216/300 batch  65/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 216/300 batch  66/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 216/300 batch  67/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 216/300 batch  68/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 216/300 batch  69/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 216/300 batch  70/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 216/300 batch  71/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 216/300 batch  72/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 216/300 batch  73/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 216/300 batch  74/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 216/300 batch  75/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 216/300 batch  76/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 216/300 batch  77/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 216/300 batch  78/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 216/300 batch  79/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 216/300 batch  80/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 216/300 batch  81/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 216/300 batch  82/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 216/300 batch  83/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 216/300 batch  84/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 216/300 batch  85/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 216/300 batch  86/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 216/300 batch  87/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 216/300 batch  88/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 216/300 batch  89/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 216/300 batch  90/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 216/300 batch  91/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 216/300 batch  92/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 216/300 batch  93/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 216/300 batch  94/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 216/300 batch  95/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 216/300 batch  96/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 216/300 batch  97/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 216/300 batch  98/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 216/300 batch  99/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 216/300 batch 100/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 216/300 batch 101/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 216/300 batch 102/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 216/300 batch 103/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 216/300 batch 104/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 216/300 batch 105/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 216/300 batch 106/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 216/300 batch 107/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 216/300 batch 108/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 216/300 batch 109/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 216/300 batch 110/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 216/300 batch 111/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 216/300 batch 112/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 216/300 batch 113/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 216/300 batch 114/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 216/300 batch 115/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 216/300 batch 116/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 216/300 batch 117/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 216/300 batch 118/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 216/300 batch 119/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 216/300 batch 120/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 216/300 batch 121/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 216/300 batch 122/188  Train Loss: 0.056, Acc: 0.980\n",
      "epoch: 216/300 batch 123/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 216/300 batch 124/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 216/300 batch 125/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 216/300 batch 126/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 216/300 batch 127/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 216/300 batch 128/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 216/300 batch 129/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 216/300 batch 130/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 216/300 batch 131/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 216/300 batch 132/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 216/300 batch 133/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 216/300 batch 134/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 216/300 batch 135/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 216/300 batch 136/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 216/300 batch 137/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 216/300 batch 138/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 216/300 batch 139/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 216/300 batch 140/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 216/300 batch 141/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 216/300 batch 142/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 216/300 batch 143/188  Train Loss: 0.016, Acc: 0.996\n",
      "epoch: 216/300 batch 144/188  Train Loss: 0.051, Acc: 0.992\n",
      "epoch: 216/300 batch 145/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 216/300 batch 146/188  Train Loss: 0.075, Acc: 0.977\n",
      "epoch: 216/300 batch 147/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 216/300 batch 148/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 216/300 batch 149/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 216/300 batch 150/188  Train Loss: 0.045, Acc: 0.996\n",
      "epoch: 216/300 batch 151/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 216/300 batch 152/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 216/300 batch 153/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 216/300 batch 154/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 216/300 batch 155/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 216/300 batch 156/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 216/300 batch 157/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 216/300 batch 158/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 216/300 batch 159/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 216/300 batch 160/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 216/300 batch 161/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 216/300 batch 162/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 216/300 batch 163/188  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 216/300 batch 164/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 216/300 batch 165/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 216/300 batch 166/188  Train Loss: 0.062, Acc: 0.980\n",
      "epoch: 216/300 batch 167/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 216/300 batch 168/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 216/300 batch 169/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 216/300 batch 170/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 216/300 batch 171/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 216/300 batch 172/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 216/300 batch 173/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 216/300 batch 174/188  Train Loss: 0.052, Acc: 0.996\n",
      "epoch: 216/300 batch 175/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 216/300 batch 176/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 216/300 batch 177/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 216/300 batch 178/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 216/300 batch 179/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 216/300 batch 180/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 216/300 batch 181/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 216/300 batch 182/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 216/300 batch 183/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 216/300 batch 184/188  Train Loss: 0.047, Acc: 0.980\n",
      "epoch: 216/300 batch 185/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 216/300 batch 186/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 216/300 batch 187/188  Train Loss: 0.094, Acc: 0.992\n",
      "Train Loss: 0.033285, Acc: 0.993\n",
      "Val Loss: 0.057316, Acc: 0.983\n",
      "epoch: 217/300 batch   0/188  Train Loss: 0.053, Acc: 0.980\n",
      "epoch: 217/300 batch   1/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 217/300 batch   2/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 217/300 batch   3/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 217/300 batch   4/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 217/300 batch   5/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 217/300 batch   6/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 217/300 batch   7/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 217/300 batch   8/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 217/300 batch   9/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 217/300 batch  10/188  Train Loss: 0.056, Acc: 0.992\n",
      "epoch: 217/300 batch  11/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 217/300 batch  12/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 217/300 batch  13/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 217/300 batch  14/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 217/300 batch  15/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 217/300 batch  16/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 217/300 batch  17/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 217/300 batch  18/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 217/300 batch  19/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 217/300 batch  20/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 217/300 batch  21/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 217/300 batch  22/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 217/300 batch  23/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 217/300 batch  24/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 217/300 batch  25/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 217/300 batch  26/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 217/300 batch  27/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 217/300 batch  28/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 217/300 batch  29/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 217/300 batch  30/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 217/300 batch  31/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 217/300 batch  32/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 217/300 batch  33/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 217/300 batch  34/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 217/300 batch  35/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 217/300 batch  36/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 217/300 batch  37/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 217/300 batch  38/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 217/300 batch  39/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 217/300 batch  40/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 217/300 batch  41/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 217/300 batch  42/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 217/300 batch  43/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 217/300 batch  44/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 217/300 batch  45/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 217/300 batch  46/188  Train Loss: 0.074, Acc: 0.980\n",
      "epoch: 217/300 batch  47/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 217/300 batch  48/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 217/300 batch  49/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 217/300 batch  50/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 217/300 batch  51/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 217/300 batch  52/188  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 217/300 batch  53/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 217/300 batch  54/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 217/300 batch  55/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 217/300 batch  56/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 217/300 batch  57/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 217/300 batch  58/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 217/300 batch  59/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 217/300 batch  60/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 217/300 batch  61/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 217/300 batch  62/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 217/300 batch  63/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 217/300 batch  64/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 217/300 batch  65/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 217/300 batch  66/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 217/300 batch  67/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 217/300 batch  68/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 217/300 batch  69/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 217/300 batch  70/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 217/300 batch  71/188  Train Loss: 0.044, Acc: 0.980\n",
      "epoch: 217/300 batch  72/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 217/300 batch  73/188  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 217/300 batch  74/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 217/300 batch  75/188  Train Loss: 0.058, Acc: 0.980\n",
      "epoch: 217/300 batch  76/188  Train Loss: 0.064, Acc: 0.992\n",
      "epoch: 217/300 batch  77/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 217/300 batch  78/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 217/300 batch  79/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 217/300 batch  80/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 217/300 batch  81/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 217/300 batch  82/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 217/300 batch  83/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 217/300 batch  84/188  Train Loss: 0.058, Acc: 0.980\n",
      "epoch: 217/300 batch  85/188  Train Loss: 0.057, Acc: 0.996\n",
      "epoch: 217/300 batch  86/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 217/300 batch  87/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 217/300 batch  88/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 217/300 batch  89/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 217/300 batch  90/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 217/300 batch  91/188  Train Loss: 0.056, Acc: 0.988\n",
      "epoch: 217/300 batch  92/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 217/300 batch  93/188  Train Loss: 0.049, Acc: 0.996\n",
      "epoch: 217/300 batch  94/188  Train Loss: 0.048, Acc: 0.996\n",
      "epoch: 217/300 batch  95/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 217/300 batch  96/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 217/300 batch  97/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 217/300 batch  98/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 217/300 batch  99/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 217/300 batch 100/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 217/300 batch 101/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 217/300 batch 102/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 217/300 batch 103/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 217/300 batch 104/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 217/300 batch 105/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 217/300 batch 106/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 217/300 batch 107/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 217/300 batch 108/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 217/300 batch 109/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 217/300 batch 110/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 217/300 batch 111/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 217/300 batch 112/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 217/300 batch 113/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 217/300 batch 114/188  Train Loss: 0.047, Acc: 0.980\n",
      "epoch: 217/300 batch 115/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 217/300 batch 116/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 217/300 batch 117/188  Train Loss: 0.060, Acc: 0.984\n",
      "epoch: 217/300 batch 118/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 217/300 batch 119/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 217/300 batch 120/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 217/300 batch 121/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 217/300 batch 122/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 217/300 batch 123/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 217/300 batch 124/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 217/300 batch 125/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 217/300 batch 126/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 217/300 batch 127/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 217/300 batch 128/188  Train Loss: 0.055, Acc: 0.980\n",
      "epoch: 217/300 batch 129/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 217/300 batch 130/188  Train Loss: 0.050, Acc: 0.973\n",
      "epoch: 217/300 batch 131/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 217/300 batch 132/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 217/300 batch 133/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 217/300 batch 134/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 217/300 batch 135/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 217/300 batch 136/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 217/300 batch 137/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 217/300 batch 138/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 217/300 batch 139/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 217/300 batch 140/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 217/300 batch 141/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 217/300 batch 142/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 217/300 batch 143/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 217/300 batch 144/188  Train Loss: 0.043, Acc: 0.996\n",
      "epoch: 217/300 batch 145/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 217/300 batch 146/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 217/300 batch 147/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 217/300 batch 148/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 217/300 batch 149/188  Train Loss: 0.056, Acc: 0.988\n",
      "epoch: 217/300 batch 150/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 217/300 batch 151/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 217/300 batch 152/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 217/300 batch 153/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 217/300 batch 154/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 217/300 batch 155/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 217/300 batch 156/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 217/300 batch 157/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 217/300 batch 158/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 217/300 batch 159/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 217/300 batch 160/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 217/300 batch 161/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 217/300 batch 162/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 217/300 batch 163/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 217/300 batch 164/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 217/300 batch 165/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 217/300 batch 166/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 217/300 batch 167/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 217/300 batch 168/188  Train Loss: 0.042, Acc: 0.996\n",
      "epoch: 217/300 batch 169/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 217/300 batch 170/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 217/300 batch 171/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 217/300 batch 172/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 217/300 batch 173/188  Train Loss: 0.059, Acc: 0.984\n",
      "epoch: 217/300 batch 174/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 217/300 batch 175/188  Train Loss: 0.081, Acc: 0.977\n",
      "epoch: 217/300 batch 176/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 217/300 batch 177/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 217/300 batch 178/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 217/300 batch 179/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 217/300 batch 180/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 217/300 batch 181/188  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 217/300 batch 182/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 217/300 batch 183/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 217/300 batch 184/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 217/300 batch 185/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 217/300 batch 186/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 217/300 batch 187/188  Train Loss: 0.051, Acc: 0.992\n",
      "Train Loss: 0.033146, Acc: 0.993\n",
      "Val Loss: 0.058124, Acc: 0.982\n",
      "epoch: 218/300 batch   0/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 218/300 batch   1/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 218/300 batch   2/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 218/300 batch   3/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 218/300 batch   4/188  Train Loss: 0.059, Acc: 0.980\n",
      "epoch: 218/300 batch   5/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 218/300 batch   6/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 218/300 batch   7/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 218/300 batch   8/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 218/300 batch   9/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 218/300 batch  10/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 218/300 batch  11/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 218/300 batch  12/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 218/300 batch  13/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 218/300 batch  14/188  Train Loss: 0.068, Acc: 0.973\n",
      "epoch: 218/300 batch  15/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 218/300 batch  16/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 218/300 batch  17/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 218/300 batch  18/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 218/300 batch  19/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 218/300 batch  20/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 218/300 batch  21/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 218/300 batch  22/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 218/300 batch  23/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 218/300 batch  24/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 218/300 batch  25/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 218/300 batch  26/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 218/300 batch  27/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 218/300 batch  28/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 218/300 batch  29/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 218/300 batch  30/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 218/300 batch  31/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 218/300 batch  32/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 218/300 batch  33/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 218/300 batch  34/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 218/300 batch  35/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 218/300 batch  36/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 218/300 batch  37/188  Train Loss: 0.038, Acc: 0.980\n",
      "epoch: 218/300 batch  38/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 218/300 batch  39/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 218/300 batch  40/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 218/300 batch  41/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 218/300 batch  42/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 218/300 batch  43/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 218/300 batch  44/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 218/300 batch  45/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 218/300 batch  46/188  Train Loss: 0.103, Acc: 0.969\n",
      "epoch: 218/300 batch  47/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 218/300 batch  48/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 218/300 batch  49/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 218/300 batch  50/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 218/300 batch  51/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 218/300 batch  52/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 218/300 batch  53/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 218/300 batch  54/188  Train Loss: 0.056, Acc: 0.980\n",
      "epoch: 218/300 batch  55/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 218/300 batch  56/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 218/300 batch  57/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 218/300 batch  58/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 218/300 batch  59/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 218/300 batch  60/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 218/300 batch  61/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 218/300 batch  62/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 218/300 batch  63/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 218/300 batch  64/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 218/300 batch  65/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 218/300 batch  66/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 218/300 batch  67/188  Train Loss: 0.064, Acc: 0.984\n",
      "epoch: 218/300 batch  68/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 218/300 batch  69/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 218/300 batch  70/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 218/300 batch  71/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 218/300 batch  72/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 218/300 batch  73/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 218/300 batch  74/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 218/300 batch  75/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 218/300 batch  76/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 218/300 batch  77/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 218/300 batch  78/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 218/300 batch  79/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 218/300 batch  80/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 218/300 batch  81/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 218/300 batch  82/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 218/300 batch  83/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 218/300 batch  84/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 218/300 batch  85/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 218/300 batch  86/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 218/300 batch  87/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 218/300 batch  88/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 218/300 batch  89/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 218/300 batch  90/188  Train Loss: 0.088, Acc: 0.977\n",
      "epoch: 218/300 batch  91/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 218/300 batch  92/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 218/300 batch  93/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 218/300 batch  94/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 218/300 batch  95/188  Train Loss: 0.033, Acc: 0.984\n",
      "epoch: 218/300 batch  96/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 218/300 batch  97/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 218/300 batch  98/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 218/300 batch  99/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 218/300 batch 100/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 218/300 batch 101/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 218/300 batch 102/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 218/300 batch 103/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 218/300 batch 104/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 218/300 batch 105/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 218/300 batch 106/188  Train Loss: 0.033, Acc: 0.984\n",
      "epoch: 218/300 batch 107/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 218/300 batch 108/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 218/300 batch 109/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 218/300 batch 110/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 218/300 batch 111/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 218/300 batch 112/188  Train Loss: 0.052, Acc: 0.977\n",
      "epoch: 218/300 batch 113/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 218/300 batch 114/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 218/300 batch 115/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 218/300 batch 116/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 218/300 batch 117/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 218/300 batch 118/188  Train Loss: 0.036, Acc: 1.000\n",
      "epoch: 218/300 batch 119/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 218/300 batch 120/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 218/300 batch 121/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 218/300 batch 122/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 218/300 batch 123/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 218/300 batch 124/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 218/300 batch 125/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 218/300 batch 126/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 218/300 batch 127/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 218/300 batch 128/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 218/300 batch 129/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 218/300 batch 130/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 218/300 batch 131/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 218/300 batch 132/188  Train Loss: 0.032, Acc: 1.000\n",
      "epoch: 218/300 batch 133/188  Train Loss: 0.051, Acc: 0.980\n",
      "epoch: 218/300 batch 134/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 218/300 batch 135/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 218/300 batch 136/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 218/300 batch 137/188  Train Loss: 0.057, Acc: 0.980\n",
      "epoch: 218/300 batch 138/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 218/300 batch 139/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 218/300 batch 140/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 218/300 batch 141/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 218/300 batch 142/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 218/300 batch 143/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 218/300 batch 144/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 218/300 batch 145/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 218/300 batch 146/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 218/300 batch 147/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 218/300 batch 148/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 218/300 batch 149/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 218/300 batch 150/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 218/300 batch 151/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 218/300 batch 152/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 218/300 batch 153/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 218/300 batch 154/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 218/300 batch 155/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 218/300 batch 156/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 218/300 batch 157/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 218/300 batch 158/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 218/300 batch 159/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 218/300 batch 160/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 218/300 batch 161/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 218/300 batch 162/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 218/300 batch 163/188  Train Loss: 0.045, Acc: 0.980\n",
      "epoch: 218/300 batch 164/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 218/300 batch 165/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 218/300 batch 166/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 218/300 batch 167/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 218/300 batch 168/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 218/300 batch 169/188  Train Loss: 0.061, Acc: 0.992\n",
      "epoch: 218/300 batch 170/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 218/300 batch 171/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 218/300 batch 172/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 218/300 batch 173/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 218/300 batch 174/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 218/300 batch 175/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 218/300 batch 176/188  Train Loss: 0.038, Acc: 0.980\n",
      "epoch: 218/300 batch 177/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 218/300 batch 178/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 218/300 batch 179/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 218/300 batch 180/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 218/300 batch 181/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 218/300 batch 182/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 218/300 batch 183/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 218/300 batch 184/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 218/300 batch 185/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 218/300 batch 186/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 218/300 batch 187/188  Train Loss: 0.022, Acc: 1.000\n",
      "Train Loss: 0.033103, Acc: 0.993\n",
      "Val Loss: 0.057279, Acc: 0.983\n",
      "epoch: 219/300 batch   0/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 219/300 batch   1/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 219/300 batch   2/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 219/300 batch   3/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 219/300 batch   4/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 219/300 batch   5/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 219/300 batch   6/188  Train Loss: 0.061, Acc: 0.984\n",
      "epoch: 219/300 batch   7/188  Train Loss: 0.052, Acc: 0.980\n",
      "epoch: 219/300 batch   8/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 219/300 batch   9/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 219/300 batch  10/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 219/300 batch  11/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 219/300 batch  12/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 219/300 batch  13/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 219/300 batch  14/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 219/300 batch  15/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 219/300 batch  16/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 219/300 batch  17/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 219/300 batch  18/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 219/300 batch  19/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 219/300 batch  20/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 219/300 batch  21/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 219/300 batch  22/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 219/300 batch  23/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 219/300 batch  24/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 219/300 batch  25/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 219/300 batch  26/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 219/300 batch  27/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 219/300 batch  28/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 219/300 batch  29/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 219/300 batch  30/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 219/300 batch  31/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 219/300 batch  32/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 219/300 batch  33/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 219/300 batch  34/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 219/300 batch  35/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 219/300 batch  36/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 219/300 batch  37/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 219/300 batch  38/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 219/300 batch  39/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 219/300 batch  40/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 219/300 batch  41/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 219/300 batch  42/188  Train Loss: 0.016, Acc: 0.996\n",
      "epoch: 219/300 batch  43/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 219/300 batch  44/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 219/300 batch  45/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 219/300 batch  46/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 219/300 batch  47/188  Train Loss: 0.057, Acc: 0.988\n",
      "epoch: 219/300 batch  48/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 219/300 batch  49/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 219/300 batch  50/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 219/300 batch  51/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 219/300 batch  52/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 219/300 batch  53/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 219/300 batch  54/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 219/300 batch  55/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 219/300 batch  56/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 219/300 batch  57/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 219/300 batch  58/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 219/300 batch  59/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 219/300 batch  60/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 219/300 batch  61/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 219/300 batch  62/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 219/300 batch  63/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 219/300 batch  64/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 219/300 batch  65/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 219/300 batch  66/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 219/300 batch  67/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 219/300 batch  68/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 219/300 batch  69/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 219/300 batch  70/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 219/300 batch  71/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 219/300 batch  72/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 219/300 batch  73/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 219/300 batch  74/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 219/300 batch  75/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 219/300 batch  76/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 219/300 batch  77/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 219/300 batch  78/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 219/300 batch  79/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 219/300 batch  80/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 219/300 batch  81/188  Train Loss: 0.049, Acc: 0.977\n",
      "epoch: 219/300 batch  82/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 219/300 batch  83/188  Train Loss: 0.052, Acc: 0.992\n",
      "epoch: 219/300 batch  84/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 219/300 batch  85/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 219/300 batch  86/188  Train Loss: 0.033, Acc: 1.000\n",
      "epoch: 219/300 batch  87/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 219/300 batch  88/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 219/300 batch  89/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 219/300 batch  90/188  Train Loss: 0.015, Acc: 0.996\n",
      "epoch: 219/300 batch  91/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 219/300 batch  92/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 219/300 batch  93/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 219/300 batch  94/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 219/300 batch  95/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 219/300 batch  96/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 219/300 batch  97/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 219/300 batch  98/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 219/300 batch  99/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 219/300 batch 100/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 219/300 batch 101/188  Train Loss: 0.059, Acc: 0.984\n",
      "epoch: 219/300 batch 102/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 219/300 batch 103/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 219/300 batch 104/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 219/300 batch 105/188  Train Loss: 0.062, Acc: 0.992\n",
      "epoch: 219/300 batch 106/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 219/300 batch 107/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 219/300 batch 108/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 219/300 batch 109/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 219/300 batch 110/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 219/300 batch 111/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 219/300 batch 112/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 219/300 batch 113/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 219/300 batch 114/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 219/300 batch 115/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 219/300 batch 116/188  Train Loss: 0.047, Acc: 0.996\n",
      "epoch: 219/300 batch 117/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 219/300 batch 118/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 219/300 batch 119/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 219/300 batch 120/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 219/300 batch 121/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 219/300 batch 122/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 219/300 batch 123/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 219/300 batch 124/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 219/300 batch 125/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 219/300 batch 126/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 219/300 batch 127/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 219/300 batch 128/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 219/300 batch 129/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 219/300 batch 130/188  Train Loss: 0.062, Acc: 0.988\n",
      "epoch: 219/300 batch 131/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 219/300 batch 132/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 219/300 batch 133/188  Train Loss: 0.049, Acc: 0.980\n",
      "epoch: 219/300 batch 134/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 219/300 batch 135/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 219/300 batch 136/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 219/300 batch 137/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 219/300 batch 138/188  Train Loss: 0.061, Acc: 0.984\n",
      "epoch: 219/300 batch 139/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 219/300 batch 140/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 219/300 batch 141/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 219/300 batch 142/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 219/300 batch 143/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 219/300 batch 144/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 219/300 batch 145/188  Train Loss: 0.079, Acc: 0.992\n",
      "epoch: 219/300 batch 146/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 219/300 batch 147/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 219/300 batch 148/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 219/300 batch 149/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 219/300 batch 150/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 219/300 batch 151/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 219/300 batch 152/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 219/300 batch 153/188  Train Loss: 0.068, Acc: 0.980\n",
      "epoch: 219/300 batch 154/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 219/300 batch 155/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 219/300 batch 156/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 219/300 batch 157/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 219/300 batch 158/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 219/300 batch 159/188  Train Loss: 0.057, Acc: 0.988\n",
      "epoch: 219/300 batch 160/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 219/300 batch 161/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 219/300 batch 162/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 219/300 batch 163/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 219/300 batch 164/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 219/300 batch 165/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 219/300 batch 166/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 219/300 batch 167/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 219/300 batch 168/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 219/300 batch 169/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 219/300 batch 170/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 219/300 batch 171/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 219/300 batch 172/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 219/300 batch 173/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 219/300 batch 174/188  Train Loss: 0.044, Acc: 0.980\n",
      "epoch: 219/300 batch 175/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 219/300 batch 176/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 219/300 batch 177/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 219/300 batch 178/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 219/300 batch 179/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 219/300 batch 180/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 219/300 batch 181/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 219/300 batch 182/188  Train Loss: 0.033, Acc: 0.984\n",
      "epoch: 219/300 batch 183/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 219/300 batch 184/188  Train Loss: 0.034, Acc: 0.984\n",
      "epoch: 219/300 batch 185/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 219/300 batch 186/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 219/300 batch 187/188  Train Loss: 0.058, Acc: 0.984\n",
      "Train Loss: 0.033149, Acc: 0.993\n",
      "Val Loss: 0.057777, Acc: 0.983\n",
      "epoch: 220/300 batch   0/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 220/300 batch   1/188  Train Loss: 0.033, Acc: 0.984\n",
      "epoch: 220/300 batch   2/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 220/300 batch   3/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 220/300 batch   4/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 220/300 batch   5/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 220/300 batch   6/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 220/300 batch   7/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 220/300 batch   8/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 220/300 batch   9/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 220/300 batch  10/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 220/300 batch  11/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 220/300 batch  12/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 220/300 batch  13/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 220/300 batch  14/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 220/300 batch  15/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 220/300 batch  16/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 220/300 batch  17/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 220/300 batch  18/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 220/300 batch  19/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 220/300 batch  20/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 220/300 batch  21/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 220/300 batch  22/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 220/300 batch  23/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 220/300 batch  24/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 220/300 batch  25/188  Train Loss: 0.034, Acc: 0.984\n",
      "epoch: 220/300 batch  26/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 220/300 batch  27/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 220/300 batch  28/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 220/300 batch  29/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 220/300 batch  30/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 220/300 batch  31/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 220/300 batch  32/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 220/300 batch  33/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 220/300 batch  34/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 220/300 batch  35/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 220/300 batch  36/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 220/300 batch  37/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 220/300 batch  38/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 220/300 batch  39/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 220/300 batch  40/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 220/300 batch  41/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 220/300 batch  42/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 220/300 batch  43/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 220/300 batch  44/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 220/300 batch  45/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 220/300 batch  46/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 220/300 batch  47/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 220/300 batch  48/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 220/300 batch  49/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 220/300 batch  50/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 220/300 batch  51/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 220/300 batch  52/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 220/300 batch  53/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 220/300 batch  54/188  Train Loss: 0.050, Acc: 0.996\n",
      "epoch: 220/300 batch  55/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 220/300 batch  56/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 220/300 batch  57/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 220/300 batch  58/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 220/300 batch  59/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 220/300 batch  60/188  Train Loss: 0.024, Acc: 0.988\n",
      "epoch: 220/300 batch  61/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 220/300 batch  62/188  Train Loss: 0.067, Acc: 0.980\n",
      "epoch: 220/300 batch  63/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 220/300 batch  64/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 220/300 batch  65/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 220/300 batch  66/188  Train Loss: 0.035, Acc: 0.980\n",
      "epoch: 220/300 batch  67/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 220/300 batch  68/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 220/300 batch  69/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 220/300 batch  70/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 220/300 batch  71/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 220/300 batch  72/188  Train Loss: 0.063, Acc: 0.988\n",
      "epoch: 220/300 batch  73/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 220/300 batch  74/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 220/300 batch  75/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 220/300 batch  76/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 220/300 batch  77/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 220/300 batch  78/188  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 220/300 batch  79/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 220/300 batch  80/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 220/300 batch  81/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 220/300 batch  82/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 220/300 batch  83/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 220/300 batch  84/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 220/300 batch  85/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 220/300 batch  86/188  Train Loss: 0.046, Acc: 0.996\n",
      "epoch: 220/300 batch  87/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 220/300 batch  88/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 220/300 batch  89/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 220/300 batch  90/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 220/300 batch  91/188  Train Loss: 0.043, Acc: 0.980\n",
      "epoch: 220/300 batch  92/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 220/300 batch  93/188  Train Loss: 0.068, Acc: 0.988\n",
      "epoch: 220/300 batch  94/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 220/300 batch  95/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 220/300 batch  96/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 220/300 batch  97/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 220/300 batch  98/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 220/300 batch  99/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 220/300 batch 100/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 220/300 batch 101/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 220/300 batch 102/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 220/300 batch 103/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 220/300 batch 104/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 220/300 batch 105/188  Train Loss: 0.045, Acc: 0.977\n",
      "epoch: 220/300 batch 106/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 220/300 batch 107/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 220/300 batch 108/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 220/300 batch 109/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 220/300 batch 110/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 220/300 batch 111/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 220/300 batch 112/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 220/300 batch 113/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 220/300 batch 114/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 220/300 batch 115/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 220/300 batch 116/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 220/300 batch 117/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 220/300 batch 118/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 220/300 batch 119/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 220/300 batch 120/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 220/300 batch 121/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 220/300 batch 122/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 220/300 batch 123/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 220/300 batch 124/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 220/300 batch 125/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 220/300 batch 126/188  Train Loss: 0.040, Acc: 0.980\n",
      "epoch: 220/300 batch 127/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 220/300 batch 128/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 220/300 batch 129/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 220/300 batch 130/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 220/300 batch 131/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 220/300 batch 132/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 220/300 batch 133/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 220/300 batch 134/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 220/300 batch 135/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 220/300 batch 136/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 220/300 batch 137/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 220/300 batch 138/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 220/300 batch 139/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 220/300 batch 140/188  Train Loss: 0.032, Acc: 1.000\n",
      "epoch: 220/300 batch 141/188  Train Loss: 0.032, Acc: 1.000\n",
      "epoch: 220/300 batch 142/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 220/300 batch 143/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 220/300 batch 144/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 220/300 batch 145/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 220/300 batch 146/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 220/300 batch 147/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 220/300 batch 148/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 220/300 batch 149/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 220/300 batch 150/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 220/300 batch 151/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 220/300 batch 152/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 220/300 batch 153/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 220/300 batch 154/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 220/300 batch 155/188  Train Loss: 0.071, Acc: 0.988\n",
      "epoch: 220/300 batch 156/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 220/300 batch 157/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 220/300 batch 158/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 220/300 batch 159/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 220/300 batch 160/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 220/300 batch 161/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 220/300 batch 162/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 220/300 batch 163/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 220/300 batch 164/188  Train Loss: 0.052, Acc: 0.992\n",
      "epoch: 220/300 batch 165/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 220/300 batch 166/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 220/300 batch 167/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 220/300 batch 168/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 220/300 batch 169/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 220/300 batch 170/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 220/300 batch 171/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 220/300 batch 172/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 220/300 batch 173/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 220/300 batch 174/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 220/300 batch 175/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 220/300 batch 176/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 220/300 batch 177/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 220/300 batch 178/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 220/300 batch 179/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 220/300 batch 180/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 220/300 batch 181/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 220/300 batch 182/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 220/300 batch 183/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 220/300 batch 184/188  Train Loss: 0.070, Acc: 0.977\n",
      "epoch: 220/300 batch 185/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 220/300 batch 186/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 220/300 batch 187/188  Train Loss: 0.021, Acc: 1.000\n",
      "Train Loss: 0.033145, Acc: 0.993\n",
      "Val Loss: 0.057232, Acc: 0.983\n",
      "epoch: 221/300 batch   0/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 221/300 batch   1/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 221/300 batch   2/188  Train Loss: 0.056, Acc: 0.980\n",
      "epoch: 221/300 batch   3/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 221/300 batch   4/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 221/300 batch   5/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 221/300 batch   6/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 221/300 batch   7/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 221/300 batch   8/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 221/300 batch   9/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 221/300 batch  10/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 221/300 batch  11/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 221/300 batch  12/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 221/300 batch  13/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 221/300 batch  14/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 221/300 batch  15/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 221/300 batch  16/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 221/300 batch  17/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 221/300 batch  18/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 221/300 batch  19/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 221/300 batch  20/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 221/300 batch  21/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 221/300 batch  22/188  Train Loss: 0.048, Acc: 0.980\n",
      "epoch: 221/300 batch  23/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 221/300 batch  24/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 221/300 batch  25/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 221/300 batch  26/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 221/300 batch  27/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 221/300 batch  28/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 221/300 batch  29/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 221/300 batch  30/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 221/300 batch  31/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 221/300 batch  32/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 221/300 batch  33/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 221/300 batch  34/188  Train Loss: 0.055, Acc: 0.980\n",
      "epoch: 221/300 batch  35/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 221/300 batch  36/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 221/300 batch  37/188  Train Loss: 0.051, Acc: 0.980\n",
      "epoch: 221/300 batch  38/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 221/300 batch  39/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 221/300 batch  40/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 221/300 batch  41/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 221/300 batch  42/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 221/300 batch  43/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 221/300 batch  44/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 221/300 batch  45/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 221/300 batch  46/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 221/300 batch  47/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 221/300 batch  48/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 221/300 batch  49/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 221/300 batch  50/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 221/300 batch  51/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 221/300 batch  52/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 221/300 batch  53/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 221/300 batch  54/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 221/300 batch  55/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 221/300 batch  56/188  Train Loss: 0.039, Acc: 0.980\n",
      "epoch: 221/300 batch  57/188  Train Loss: 0.016, Acc: 0.996\n",
      "epoch: 221/300 batch  58/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 221/300 batch  59/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 221/300 batch  60/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 221/300 batch  61/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 221/300 batch  62/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 221/300 batch  63/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 221/300 batch  64/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 221/300 batch  65/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 221/300 batch  66/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 221/300 batch  67/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 221/300 batch  68/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 221/300 batch  69/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 221/300 batch  70/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 221/300 batch  71/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 221/300 batch  72/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 221/300 batch  73/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 221/300 batch  74/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 221/300 batch  75/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 221/300 batch  76/188  Train Loss: 0.023, Acc: 0.988\n",
      "epoch: 221/300 batch  77/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 221/300 batch  78/188  Train Loss: 0.084, Acc: 0.977\n",
      "epoch: 221/300 batch  79/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 221/300 batch  80/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 221/300 batch  81/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 221/300 batch  82/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 221/300 batch  83/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 221/300 batch  84/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 221/300 batch  85/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 221/300 batch  86/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 221/300 batch  87/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 221/300 batch  88/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 221/300 batch  89/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 221/300 batch  90/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 221/300 batch  91/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 221/300 batch  92/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 221/300 batch  93/188  Train Loss: 0.051, Acc: 0.992\n",
      "epoch: 221/300 batch  94/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 221/300 batch  95/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 221/300 batch  96/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 221/300 batch  97/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 221/300 batch  98/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 221/300 batch  99/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 221/300 batch 100/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 221/300 batch 101/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 221/300 batch 102/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 221/300 batch 103/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 221/300 batch 104/188  Train Loss: 0.059, Acc: 0.992\n",
      "epoch: 221/300 batch 105/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 221/300 batch 106/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 221/300 batch 107/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 221/300 batch 108/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 221/300 batch 109/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 221/300 batch 110/188  Train Loss: 0.069, Acc: 0.980\n",
      "epoch: 221/300 batch 111/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 221/300 batch 112/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 221/300 batch 113/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 221/300 batch 114/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 221/300 batch 115/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 221/300 batch 116/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 221/300 batch 117/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 221/300 batch 118/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 221/300 batch 119/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 221/300 batch 120/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 221/300 batch 121/188  Train Loss: 0.068, Acc: 0.980\n",
      "epoch: 221/300 batch 122/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 221/300 batch 123/188  Train Loss: 0.049, Acc: 0.977\n",
      "epoch: 221/300 batch 124/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 221/300 batch 125/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 221/300 batch 126/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 221/300 batch 127/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 221/300 batch 128/188  Train Loss: 0.026, Acc: 0.988\n",
      "epoch: 221/300 batch 129/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 221/300 batch 130/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 221/300 batch 131/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 221/300 batch 132/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 221/300 batch 133/188  Train Loss: 0.096, Acc: 0.977\n",
      "epoch: 221/300 batch 134/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 221/300 batch 135/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 221/300 batch 136/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 221/300 batch 137/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 221/300 batch 138/188  Train Loss: 0.057, Acc: 0.980\n",
      "epoch: 221/300 batch 139/188  Train Loss: 0.069, Acc: 0.984\n",
      "epoch: 221/300 batch 140/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 221/300 batch 141/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 221/300 batch 142/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 221/300 batch 143/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 221/300 batch 144/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 221/300 batch 145/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 221/300 batch 146/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 221/300 batch 147/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 221/300 batch 148/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 221/300 batch 149/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 221/300 batch 150/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 221/300 batch 151/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 221/300 batch 152/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 221/300 batch 153/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 221/300 batch 154/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 221/300 batch 155/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 221/300 batch 156/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 221/300 batch 157/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 221/300 batch 158/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 221/300 batch 159/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 221/300 batch 160/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 221/300 batch 161/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 221/300 batch 162/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 221/300 batch 163/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 221/300 batch 164/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 221/300 batch 165/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 221/300 batch 166/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 221/300 batch 167/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 221/300 batch 168/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 221/300 batch 169/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 221/300 batch 170/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 221/300 batch 171/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 221/300 batch 172/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 221/300 batch 173/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 221/300 batch 174/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 221/300 batch 175/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 221/300 batch 176/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 221/300 batch 177/188  Train Loss: 0.033, Acc: 1.000\n",
      "epoch: 221/300 batch 178/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 221/300 batch 179/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 221/300 batch 180/188  Train Loss: 0.042, Acc: 0.996\n",
      "epoch: 221/300 batch 181/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 221/300 batch 182/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 221/300 batch 183/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 221/300 batch 184/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 221/300 batch 185/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 221/300 batch 186/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 221/300 batch 187/188  Train Loss: 0.016, Acc: 1.000\n",
      "Train Loss: 0.032963, Acc: 0.992\n",
      "Val Loss: 0.057263, Acc: 0.983\n",
      "epoch: 222/300 batch   0/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 222/300 batch   1/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 222/300 batch   2/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 222/300 batch   3/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 222/300 batch   4/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 222/300 batch   5/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 222/300 batch   6/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 222/300 batch   7/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 222/300 batch   8/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 222/300 batch   9/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 222/300 batch  10/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 222/300 batch  11/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 222/300 batch  12/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 222/300 batch  13/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 222/300 batch  14/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 222/300 batch  15/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 222/300 batch  16/188  Train Loss: 0.052, Acc: 0.992\n",
      "epoch: 222/300 batch  17/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 222/300 batch  18/188  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 222/300 batch  19/188  Train Loss: 0.054, Acc: 0.980\n",
      "epoch: 222/300 batch  20/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 222/300 batch  21/188  Train Loss: 0.060, Acc: 0.988\n",
      "epoch: 222/300 batch  22/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 222/300 batch  23/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 222/300 batch  24/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 222/300 batch  25/188  Train Loss: 0.026, Acc: 0.988\n",
      "epoch: 222/300 batch  26/188  Train Loss: 0.014, Acc: 0.996\n",
      "epoch: 222/300 batch  27/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 222/300 batch  28/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 222/300 batch  29/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 222/300 batch  30/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 222/300 batch  31/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 222/300 batch  32/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 222/300 batch  33/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 222/300 batch  34/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 222/300 batch  35/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 222/300 batch  36/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 222/300 batch  37/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 222/300 batch  38/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 222/300 batch  39/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 222/300 batch  40/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 222/300 batch  41/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 222/300 batch  42/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 222/300 batch  43/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 222/300 batch  44/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 222/300 batch  45/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 222/300 batch  46/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 222/300 batch  47/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 222/300 batch  48/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 222/300 batch  49/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 222/300 batch  50/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 222/300 batch  51/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 222/300 batch  52/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 222/300 batch  53/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 222/300 batch  54/188  Train Loss: 0.043, Acc: 0.996\n",
      "epoch: 222/300 batch  55/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 222/300 batch  56/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 222/300 batch  57/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 222/300 batch  58/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 222/300 batch  59/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 222/300 batch  60/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 222/300 batch  61/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 222/300 batch  62/188  Train Loss: 0.038, Acc: 0.980\n",
      "epoch: 222/300 batch  63/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 222/300 batch  64/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 222/300 batch  65/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 222/300 batch  66/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 222/300 batch  67/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 222/300 batch  68/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 222/300 batch  69/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 222/300 batch  70/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 222/300 batch  71/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 222/300 batch  72/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 222/300 batch  73/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 222/300 batch  74/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 222/300 batch  75/188  Train Loss: 0.043, Acc: 0.980\n",
      "epoch: 222/300 batch  76/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 222/300 batch  77/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 222/300 batch  78/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 222/300 batch  79/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 222/300 batch  80/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 222/300 batch  81/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 222/300 batch  82/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 222/300 batch  83/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 222/300 batch  84/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 222/300 batch  85/188  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 222/300 batch  86/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 222/300 batch  87/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 222/300 batch  88/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 222/300 batch  89/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 222/300 batch  90/188  Train Loss: 0.064, Acc: 0.996\n",
      "epoch: 222/300 batch  91/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 222/300 batch  92/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 222/300 batch  93/188  Train Loss: 0.026, Acc: 0.988\n",
      "epoch: 222/300 batch  94/188  Train Loss: 0.027, Acc: 0.988\n",
      "epoch: 222/300 batch  95/188  Train Loss: 0.074, Acc: 0.980\n",
      "epoch: 222/300 batch  96/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 222/300 batch  97/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 222/300 batch  98/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 222/300 batch  99/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 222/300 batch 100/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 222/300 batch 101/188  Train Loss: 0.042, Acc: 0.980\n",
      "epoch: 222/300 batch 102/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 222/300 batch 103/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 222/300 batch 104/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 222/300 batch 105/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 222/300 batch 106/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 222/300 batch 107/188  Train Loss: 0.054, Acc: 0.977\n",
      "epoch: 222/300 batch 108/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 222/300 batch 109/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 222/300 batch 110/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 222/300 batch 111/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 222/300 batch 112/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 222/300 batch 113/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 222/300 batch 114/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 222/300 batch 115/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 222/300 batch 116/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 222/300 batch 117/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 222/300 batch 118/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 222/300 batch 119/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 222/300 batch 120/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 222/300 batch 121/188  Train Loss: 0.048, Acc: 0.980\n",
      "epoch: 222/300 batch 122/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 222/300 batch 123/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 222/300 batch 124/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 222/300 batch 125/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 222/300 batch 126/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 222/300 batch 127/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 222/300 batch 128/188  Train Loss: 0.060, Acc: 0.973\n",
      "epoch: 222/300 batch 129/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 222/300 batch 130/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 222/300 batch 131/188  Train Loss: 0.033, Acc: 1.000\n",
      "epoch: 222/300 batch 132/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 222/300 batch 133/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 222/300 batch 134/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 222/300 batch 135/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 222/300 batch 136/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 222/300 batch 137/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 222/300 batch 138/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 222/300 batch 139/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 222/300 batch 140/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 222/300 batch 141/188  Train Loss: 0.058, Acc: 0.977\n",
      "epoch: 222/300 batch 142/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 222/300 batch 143/188  Train Loss: 0.058, Acc: 0.992\n",
      "epoch: 222/300 batch 144/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 222/300 batch 145/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 222/300 batch 146/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 222/300 batch 147/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 222/300 batch 148/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 222/300 batch 149/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 222/300 batch 150/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 222/300 batch 151/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 222/300 batch 152/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 222/300 batch 153/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 222/300 batch 154/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 222/300 batch 155/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 222/300 batch 156/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 222/300 batch 157/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 222/300 batch 158/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 222/300 batch 159/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 222/300 batch 160/188  Train Loss: 0.052, Acc: 0.992\n",
      "epoch: 222/300 batch 161/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 222/300 batch 162/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 222/300 batch 163/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 222/300 batch 164/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 222/300 batch 165/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 222/300 batch 166/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 222/300 batch 167/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 222/300 batch 168/188  Train Loss: 0.047, Acc: 0.996\n",
      "epoch: 222/300 batch 169/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 222/300 batch 170/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 222/300 batch 171/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 222/300 batch 172/188  Train Loss: 0.034, Acc: 0.984\n",
      "epoch: 222/300 batch 173/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 222/300 batch 174/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 222/300 batch 175/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 222/300 batch 176/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 222/300 batch 177/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 222/300 batch 178/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 222/300 batch 179/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 222/300 batch 180/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 222/300 batch 181/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 222/300 batch 182/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 222/300 batch 183/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 222/300 batch 184/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 222/300 batch 185/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 222/300 batch 186/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 222/300 batch 187/188  Train Loss: 0.033, Acc: 0.992\n",
      "Train Loss: 0.032989, Acc: 0.993\n",
      "Val Loss: 0.057183, Acc: 0.984\n",
      "epoch: 223/300 batch   0/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 223/300 batch   1/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 223/300 batch   2/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 223/300 batch   3/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 223/300 batch   4/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 223/300 batch   5/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 223/300 batch   6/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 223/300 batch   7/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 223/300 batch   8/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 223/300 batch   9/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 223/300 batch  10/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 223/300 batch  11/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 223/300 batch  12/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 223/300 batch  13/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 223/300 batch  14/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 223/300 batch  15/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 223/300 batch  16/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 223/300 batch  17/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 223/300 batch  18/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 223/300 batch  19/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 223/300 batch  20/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 223/300 batch  21/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 223/300 batch  22/188  Train Loss: 0.044, Acc: 0.996\n",
      "epoch: 223/300 batch  23/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 223/300 batch  24/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 223/300 batch  25/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 223/300 batch  26/188  Train Loss: 0.024, Acc: 0.988\n",
      "epoch: 223/300 batch  27/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 223/300 batch  28/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 223/300 batch  29/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 223/300 batch  30/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 223/300 batch  31/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 223/300 batch  32/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 223/300 batch  33/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 223/300 batch  34/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 223/300 batch  35/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 223/300 batch  36/188  Train Loss: 0.031, Acc: 0.984\n",
      "epoch: 223/300 batch  37/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 223/300 batch  38/188  Train Loss: 0.071, Acc: 0.969\n",
      "epoch: 223/300 batch  39/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 223/300 batch  40/188  Train Loss: 0.032, Acc: 0.984\n",
      "epoch: 223/300 batch  41/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 223/300 batch  42/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 223/300 batch  43/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 223/300 batch  44/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 223/300 batch  45/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 223/300 batch  46/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 223/300 batch  47/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 223/300 batch  48/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 223/300 batch  49/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 223/300 batch  50/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 223/300 batch  51/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 223/300 batch  52/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 223/300 batch  53/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 223/300 batch  54/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 223/300 batch  55/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 223/300 batch  56/188  Train Loss: 0.045, Acc: 0.977\n",
      "epoch: 223/300 batch  57/188  Train Loss: 0.042, Acc: 0.996\n",
      "epoch: 223/300 batch  58/188  Train Loss: 0.048, Acc: 0.996\n",
      "epoch: 223/300 batch  59/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 223/300 batch  60/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 223/300 batch  61/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 223/300 batch  62/188  Train Loss: 0.054, Acc: 0.980\n",
      "epoch: 223/300 batch  63/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 223/300 batch  64/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 223/300 batch  65/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 223/300 batch  66/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 223/300 batch  67/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 223/300 batch  68/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 223/300 batch  69/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 223/300 batch  70/188  Train Loss: 0.026, Acc: 0.988\n",
      "epoch: 223/300 batch  71/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 223/300 batch  72/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 223/300 batch  73/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 223/300 batch  74/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 223/300 batch  75/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 223/300 batch  76/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 223/300 batch  77/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 223/300 batch  78/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 223/300 batch  79/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 223/300 batch  80/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 223/300 batch  81/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 223/300 batch  82/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 223/300 batch  83/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 223/300 batch  84/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 223/300 batch  85/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 223/300 batch  86/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 223/300 batch  87/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 223/300 batch  88/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 223/300 batch  89/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 223/300 batch  90/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 223/300 batch  91/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 223/300 batch  92/188  Train Loss: 0.015, Acc: 0.996\n",
      "epoch: 223/300 batch  93/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 223/300 batch  94/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 223/300 batch  95/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 223/300 batch  96/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 223/300 batch  97/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 223/300 batch  98/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 223/300 batch  99/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 223/300 batch 100/188  Train Loss: 0.069, Acc: 0.977\n",
      "epoch: 223/300 batch 101/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 223/300 batch 102/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 223/300 batch 103/188  Train Loss: 0.016, Acc: 0.996\n",
      "epoch: 223/300 batch 104/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 223/300 batch 105/188  Train Loss: 0.070, Acc: 0.992\n",
      "epoch: 223/300 batch 106/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 223/300 batch 107/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 223/300 batch 108/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 223/300 batch 109/188  Train Loss: 0.042, Acc: 0.980\n",
      "epoch: 223/300 batch 110/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 223/300 batch 111/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 223/300 batch 112/188  Train Loss: 0.060, Acc: 0.980\n",
      "epoch: 223/300 batch 113/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 223/300 batch 114/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 223/300 batch 115/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 223/300 batch 116/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 223/300 batch 117/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 223/300 batch 118/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 223/300 batch 119/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 223/300 batch 120/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 223/300 batch 121/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 223/300 batch 122/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 223/300 batch 123/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 223/300 batch 124/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 223/300 batch 125/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 223/300 batch 126/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 223/300 batch 127/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 223/300 batch 128/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 223/300 batch 129/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 223/300 batch 130/188  Train Loss: 0.054, Acc: 0.980\n",
      "epoch: 223/300 batch 131/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 223/300 batch 132/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 223/300 batch 133/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 223/300 batch 134/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 223/300 batch 135/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 223/300 batch 136/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 223/300 batch 137/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 223/300 batch 138/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 223/300 batch 139/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 223/300 batch 140/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 223/300 batch 141/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 223/300 batch 142/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 223/300 batch 143/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 223/300 batch 144/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 223/300 batch 145/188  Train Loss: 0.027, Acc: 0.988\n",
      "epoch: 223/300 batch 146/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 223/300 batch 147/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 223/300 batch 148/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 223/300 batch 149/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 223/300 batch 150/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 223/300 batch 151/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 223/300 batch 152/188  Train Loss: 0.061, Acc: 0.977\n",
      "epoch: 223/300 batch 153/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 223/300 batch 154/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 223/300 batch 155/188  Train Loss: 0.058, Acc: 0.980\n",
      "epoch: 223/300 batch 156/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 223/300 batch 157/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 223/300 batch 158/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 223/300 batch 159/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 223/300 batch 160/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 223/300 batch 161/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 223/300 batch 162/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 223/300 batch 163/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 223/300 batch 164/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 223/300 batch 165/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 223/300 batch 166/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 223/300 batch 167/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 223/300 batch 168/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 223/300 batch 169/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 223/300 batch 170/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 223/300 batch 171/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 223/300 batch 172/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 223/300 batch 173/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 223/300 batch 174/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 223/300 batch 175/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 223/300 batch 176/188  Train Loss: 0.025, Acc: 0.988\n",
      "epoch: 223/300 batch 177/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 223/300 batch 178/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 223/300 batch 179/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 223/300 batch 180/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 223/300 batch 181/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 223/300 batch 182/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 223/300 batch 183/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 223/300 batch 184/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 223/300 batch 185/188  Train Loss: 0.087, Acc: 0.980\n",
      "epoch: 223/300 batch 186/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 223/300 batch 187/188  Train Loss: 0.014, Acc: 1.000\n",
      "Train Loss: 0.032961, Acc: 0.993\n",
      "Val Loss: 0.057658, Acc: 0.982\n",
      "epoch: 224/300 batch   0/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 224/300 batch   1/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 224/300 batch   2/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 224/300 batch   3/188  Train Loss: 0.060, Acc: 0.973\n",
      "epoch: 224/300 batch   4/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 224/300 batch   5/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 224/300 batch   6/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 224/300 batch   7/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 224/300 batch   8/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 224/300 batch   9/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 224/300 batch  10/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 224/300 batch  11/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 224/300 batch  12/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 224/300 batch  13/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 224/300 batch  14/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 224/300 batch  15/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 224/300 batch  16/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 224/300 batch  17/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 224/300 batch  18/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 224/300 batch  19/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 224/300 batch  20/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 224/300 batch  21/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 224/300 batch  22/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 224/300 batch  23/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 224/300 batch  24/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 224/300 batch  25/188  Train Loss: 0.052, Acc: 0.980\n",
      "epoch: 224/300 batch  26/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 224/300 batch  27/188  Train Loss: 0.072, Acc: 0.980\n",
      "epoch: 224/300 batch  28/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 224/300 batch  29/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 224/300 batch  30/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 224/300 batch  31/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 224/300 batch  32/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 224/300 batch  33/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 224/300 batch  34/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 224/300 batch  35/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 224/300 batch  36/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 224/300 batch  37/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 224/300 batch  38/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 224/300 batch  39/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 224/300 batch  40/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 224/300 batch  41/188  Train Loss: 0.029, Acc: 0.984\n",
      "epoch: 224/300 batch  42/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 224/300 batch  43/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 224/300 batch  44/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 224/300 batch  45/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 224/300 batch  46/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 224/300 batch  47/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 224/300 batch  48/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 224/300 batch  49/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 224/300 batch  50/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 224/300 batch  51/188  Train Loss: 0.027, Acc: 0.988\n",
      "epoch: 224/300 batch  52/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 224/300 batch  53/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 224/300 batch  54/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 224/300 batch  55/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 224/300 batch  56/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 224/300 batch  57/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 224/300 batch  58/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 224/300 batch  59/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 224/300 batch  60/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 224/300 batch  61/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 224/300 batch  62/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 224/300 batch  63/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 224/300 batch  64/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 224/300 batch  65/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 224/300 batch  66/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 224/300 batch  67/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 224/300 batch  68/188  Train Loss: 0.075, Acc: 0.988\n",
      "epoch: 224/300 batch  69/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 224/300 batch  70/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 224/300 batch  71/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 224/300 batch  72/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 224/300 batch  73/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 224/300 batch  74/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 224/300 batch  75/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 224/300 batch  76/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 224/300 batch  77/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 224/300 batch  78/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 224/300 batch  79/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 224/300 batch  80/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 224/300 batch  81/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 224/300 batch  82/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 224/300 batch  83/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 224/300 batch  84/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 224/300 batch  85/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 224/300 batch  86/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 224/300 batch  87/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 224/300 batch  88/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 224/300 batch  89/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 224/300 batch  90/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 224/300 batch  91/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 224/300 batch  92/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 224/300 batch  93/188  Train Loss: 0.043, Acc: 0.996\n",
      "epoch: 224/300 batch  94/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 224/300 batch  95/188  Train Loss: 0.052, Acc: 0.992\n",
      "epoch: 224/300 batch  96/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 224/300 batch  97/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 224/300 batch  98/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 224/300 batch  99/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 224/300 batch 100/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 224/300 batch 101/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 224/300 batch 102/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 224/300 batch 103/188  Train Loss: 0.015, Acc: 0.996\n",
      "epoch: 224/300 batch 104/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 224/300 batch 105/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 224/300 batch 106/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 224/300 batch 107/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 224/300 batch 108/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 224/300 batch 109/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 224/300 batch 110/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 224/300 batch 111/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 224/300 batch 112/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 224/300 batch 113/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 224/300 batch 114/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 224/300 batch 115/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 224/300 batch 116/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 224/300 batch 117/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 224/300 batch 118/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 224/300 batch 119/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 224/300 batch 120/188  Train Loss: 0.047, Acc: 0.980\n",
      "epoch: 224/300 batch 121/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 224/300 batch 122/188  Train Loss: 0.053, Acc: 0.996\n",
      "epoch: 224/300 batch 123/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 224/300 batch 124/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 224/300 batch 125/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 224/300 batch 126/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 224/300 batch 127/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 224/300 batch 128/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 224/300 batch 129/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 224/300 batch 130/188  Train Loss: 0.044, Acc: 0.996\n",
      "epoch: 224/300 batch 131/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 224/300 batch 132/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 224/300 batch 133/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 224/300 batch 134/188  Train Loss: 0.091, Acc: 0.977\n",
      "epoch: 224/300 batch 135/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 224/300 batch 136/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 224/300 batch 137/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 224/300 batch 138/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 224/300 batch 139/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 224/300 batch 140/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 224/300 batch 141/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 224/300 batch 142/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 224/300 batch 143/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 224/300 batch 144/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 224/300 batch 145/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 224/300 batch 146/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 224/300 batch 147/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 224/300 batch 148/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 224/300 batch 149/188  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 224/300 batch 150/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 224/300 batch 151/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 224/300 batch 152/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 224/300 batch 153/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 224/300 batch 154/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 224/300 batch 155/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 224/300 batch 156/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 224/300 batch 157/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 224/300 batch 158/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 224/300 batch 159/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 224/300 batch 160/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 224/300 batch 161/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 224/300 batch 162/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 224/300 batch 163/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 224/300 batch 164/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 224/300 batch 165/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 224/300 batch 166/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 224/300 batch 167/188  Train Loss: 0.047, Acc: 0.996\n",
      "epoch: 224/300 batch 168/188  Train Loss: 0.041, Acc: 0.980\n",
      "epoch: 224/300 batch 169/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 224/300 batch 170/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 224/300 batch 171/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 224/300 batch 172/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 224/300 batch 173/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 224/300 batch 174/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 224/300 batch 175/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 224/300 batch 176/188  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 224/300 batch 177/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 224/300 batch 178/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 224/300 batch 179/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 224/300 batch 180/188  Train Loss: 0.063, Acc: 0.973\n",
      "epoch: 224/300 batch 181/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 224/300 batch 182/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 224/300 batch 183/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 224/300 batch 184/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 224/300 batch 185/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 224/300 batch 186/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 224/300 batch 187/188  Train Loss: 0.029, Acc: 1.000\n",
      "Train Loss: 0.033062, Acc: 0.993\n",
      "Val Loss: 0.057552, Acc: 0.982\n",
      "epoch: 225/300 batch   0/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 225/300 batch   1/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 225/300 batch   2/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 225/300 batch   3/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 225/300 batch   4/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 225/300 batch   5/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 225/300 batch   6/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 225/300 batch   7/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 225/300 batch   8/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 225/300 batch   9/188  Train Loss: 0.062, Acc: 0.992\n",
      "epoch: 225/300 batch  10/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 225/300 batch  11/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 225/300 batch  12/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 225/300 batch  13/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 225/300 batch  14/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 225/300 batch  15/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 225/300 batch  16/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 225/300 batch  17/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 225/300 batch  18/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 225/300 batch  19/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 225/300 batch  20/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 225/300 batch  21/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 225/300 batch  22/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 225/300 batch  23/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 225/300 batch  24/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 225/300 batch  25/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 225/300 batch  26/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 225/300 batch  27/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 225/300 batch  28/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 225/300 batch  29/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 225/300 batch  30/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 225/300 batch  31/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 225/300 batch  32/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 225/300 batch  33/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 225/300 batch  34/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 225/300 batch  35/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 225/300 batch  36/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 225/300 batch  37/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 225/300 batch  38/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 225/300 batch  39/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 225/300 batch  40/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 225/300 batch  41/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 225/300 batch  42/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 225/300 batch  43/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 225/300 batch  44/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 225/300 batch  45/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 225/300 batch  46/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 225/300 batch  47/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 225/300 batch  48/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 225/300 batch  49/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 225/300 batch  50/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 225/300 batch  51/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 225/300 batch  52/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 225/300 batch  53/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 225/300 batch  54/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 225/300 batch  55/188  Train Loss: 0.051, Acc: 0.980\n",
      "epoch: 225/300 batch  56/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 225/300 batch  57/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 225/300 batch  58/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 225/300 batch  59/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 225/300 batch  60/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 225/300 batch  61/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 225/300 batch  62/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 225/300 batch  63/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 225/300 batch  64/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 225/300 batch  65/188  Train Loss: 0.060, Acc: 0.980\n",
      "epoch: 225/300 batch  66/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 225/300 batch  67/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 225/300 batch  68/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 225/300 batch  69/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 225/300 batch  70/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 225/300 batch  71/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 225/300 batch  72/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 225/300 batch  73/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 225/300 batch  74/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 225/300 batch  75/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 225/300 batch  76/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 225/300 batch  77/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 225/300 batch  78/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 225/300 batch  79/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 225/300 batch  80/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 225/300 batch  81/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 225/300 batch  82/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 225/300 batch  83/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 225/300 batch  84/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 225/300 batch  85/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 225/300 batch  86/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 225/300 batch  87/188  Train Loss: 0.032, Acc: 0.984\n",
      "epoch: 225/300 batch  88/188  Train Loss: 0.067, Acc: 0.992\n",
      "epoch: 225/300 batch  89/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 225/300 batch  90/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 225/300 batch  91/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 225/300 batch  92/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 225/300 batch  93/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 225/300 batch  94/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 225/300 batch  95/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 225/300 batch  96/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 225/300 batch  97/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 225/300 batch  98/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 225/300 batch  99/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 225/300 batch 100/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 225/300 batch 101/188  Train Loss: 0.033, Acc: 0.984\n",
      "epoch: 225/300 batch 102/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 225/300 batch 103/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 225/300 batch 104/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 225/300 batch 105/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 225/300 batch 106/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 225/300 batch 107/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 225/300 batch 108/188  Train Loss: 0.034, Acc: 1.000\n",
      "epoch: 225/300 batch 109/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 225/300 batch 110/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 225/300 batch 111/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 225/300 batch 112/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 225/300 batch 113/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 225/300 batch 114/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 225/300 batch 115/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 225/300 batch 116/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 225/300 batch 117/188  Train Loss: 0.068, Acc: 0.980\n",
      "epoch: 225/300 batch 118/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 225/300 batch 119/188  Train Loss: 0.058, Acc: 0.988\n",
      "epoch: 225/300 batch 120/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 225/300 batch 121/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 225/300 batch 122/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 225/300 batch 123/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 225/300 batch 124/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 225/300 batch 125/188  Train Loss: 0.048, Acc: 0.980\n",
      "epoch: 225/300 batch 126/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 225/300 batch 127/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 225/300 batch 128/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 225/300 batch 129/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 225/300 batch 130/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 225/300 batch 131/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 225/300 batch 132/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 225/300 batch 133/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 225/300 batch 134/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 225/300 batch 135/188  Train Loss: 0.062, Acc: 0.984\n",
      "epoch: 225/300 batch 136/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 225/300 batch 137/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 225/300 batch 138/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 225/300 batch 139/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 225/300 batch 140/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 225/300 batch 141/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 225/300 batch 142/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 225/300 batch 143/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 225/300 batch 144/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 225/300 batch 145/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 225/300 batch 146/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 225/300 batch 147/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 225/300 batch 148/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 225/300 batch 149/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 225/300 batch 150/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 225/300 batch 151/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 225/300 batch 152/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 225/300 batch 153/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 225/300 batch 154/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 225/300 batch 155/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 225/300 batch 156/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 225/300 batch 157/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 225/300 batch 158/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 225/300 batch 159/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 225/300 batch 160/188  Train Loss: 0.049, Acc: 0.980\n",
      "epoch: 225/300 batch 161/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 225/300 batch 162/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 225/300 batch 163/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 225/300 batch 164/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 225/300 batch 165/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 225/300 batch 166/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 225/300 batch 167/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 225/300 batch 168/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 225/300 batch 169/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 225/300 batch 170/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 225/300 batch 171/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 225/300 batch 172/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 225/300 batch 173/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 225/300 batch 174/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 225/300 batch 175/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 225/300 batch 176/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 225/300 batch 177/188  Train Loss: 0.053, Acc: 0.996\n",
      "epoch: 225/300 batch 178/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 225/300 batch 179/188  Train Loss: 0.049, Acc: 0.996\n",
      "epoch: 225/300 batch 180/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 225/300 batch 181/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 225/300 batch 182/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 225/300 batch 183/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 225/300 batch 184/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 225/300 batch 185/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 225/300 batch 186/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 225/300 batch 187/188  Train Loss: 0.034, Acc: 1.000\n",
      "Train Loss: 0.033057, Acc: 0.993\n",
      "Val Loss: 0.057857, Acc: 0.982\n",
      "epoch: 226/300 batch   0/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 226/300 batch   1/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 226/300 batch   2/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 226/300 batch   3/188  Train Loss: 0.054, Acc: 0.980\n",
      "epoch: 226/300 batch   4/188  Train Loss: 0.034, Acc: 1.000\n",
      "epoch: 226/300 batch   5/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 226/300 batch   6/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 226/300 batch   7/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 226/300 batch   8/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 226/300 batch   9/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 226/300 batch  10/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 226/300 batch  11/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 226/300 batch  12/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 226/300 batch  13/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 226/300 batch  14/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 226/300 batch  15/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 226/300 batch  16/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 226/300 batch  17/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 226/300 batch  18/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 226/300 batch  19/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 226/300 batch  20/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 226/300 batch  21/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 226/300 batch  22/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 226/300 batch  23/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 226/300 batch  24/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 226/300 batch  25/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 226/300 batch  26/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 226/300 batch  27/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 226/300 batch  28/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 226/300 batch  29/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 226/300 batch  30/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 226/300 batch  31/188  Train Loss: 0.056, Acc: 0.996\n",
      "epoch: 226/300 batch  32/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 226/300 batch  33/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 226/300 batch  34/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 226/300 batch  35/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 226/300 batch  36/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 226/300 batch  37/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 226/300 batch  38/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 226/300 batch  39/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 226/300 batch  40/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 226/300 batch  41/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 226/300 batch  42/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 226/300 batch  43/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 226/300 batch  44/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 226/300 batch  45/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 226/300 batch  46/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 226/300 batch  47/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 226/300 batch  48/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 226/300 batch  49/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 226/300 batch  50/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 226/300 batch  51/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 226/300 batch  52/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 226/300 batch  53/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 226/300 batch  54/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 226/300 batch  55/188  Train Loss: 0.064, Acc: 0.980\n",
      "epoch: 226/300 batch  56/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 226/300 batch  57/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 226/300 batch  58/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 226/300 batch  59/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 226/300 batch  60/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 226/300 batch  61/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 226/300 batch  62/188  Train Loss: 0.015, Acc: 0.996\n",
      "epoch: 226/300 batch  63/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 226/300 batch  64/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 226/300 batch  65/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 226/300 batch  66/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 226/300 batch  67/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 226/300 batch  68/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 226/300 batch  69/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 226/300 batch  70/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 226/300 batch  71/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 226/300 batch  72/188  Train Loss: 0.051, Acc: 0.992\n",
      "epoch: 226/300 batch  73/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 226/300 batch  74/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 226/300 batch  75/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 226/300 batch  76/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 226/300 batch  77/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 226/300 batch  78/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 226/300 batch  79/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 226/300 batch  80/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 226/300 batch  81/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 226/300 batch  82/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 226/300 batch  83/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 226/300 batch  84/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 226/300 batch  85/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 226/300 batch  86/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 226/300 batch  87/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 226/300 batch  88/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 226/300 batch  89/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 226/300 batch  90/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 226/300 batch  91/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 226/300 batch  92/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 226/300 batch  93/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 226/300 batch  94/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 226/300 batch  95/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 226/300 batch  96/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 226/300 batch  97/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 226/300 batch  98/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 226/300 batch  99/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 226/300 batch 100/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 226/300 batch 101/188  Train Loss: 0.068, Acc: 0.980\n",
      "epoch: 226/300 batch 102/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 226/300 batch 103/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 226/300 batch 104/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 226/300 batch 105/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 226/300 batch 106/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 226/300 batch 107/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 226/300 batch 108/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 226/300 batch 109/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 226/300 batch 110/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 226/300 batch 111/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 226/300 batch 112/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 226/300 batch 113/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 226/300 batch 114/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 226/300 batch 115/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 226/300 batch 116/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 226/300 batch 117/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 226/300 batch 118/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 226/300 batch 119/188  Train Loss: 0.061, Acc: 0.984\n",
      "epoch: 226/300 batch 120/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 226/300 batch 121/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 226/300 batch 122/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 226/300 batch 123/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 226/300 batch 124/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 226/300 batch 125/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 226/300 batch 126/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 226/300 batch 127/188  Train Loss: 0.061, Acc: 0.988\n",
      "epoch: 226/300 batch 128/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 226/300 batch 129/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 226/300 batch 130/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 226/300 batch 131/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 226/300 batch 132/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 226/300 batch 133/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 226/300 batch 134/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 226/300 batch 135/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 226/300 batch 136/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 226/300 batch 137/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 226/300 batch 138/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 226/300 batch 139/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 226/300 batch 140/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 226/300 batch 141/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 226/300 batch 142/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 226/300 batch 143/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 226/300 batch 144/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 226/300 batch 145/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 226/300 batch 146/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 226/300 batch 147/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 226/300 batch 148/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 226/300 batch 149/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 226/300 batch 150/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 226/300 batch 151/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 226/300 batch 152/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 226/300 batch 153/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 226/300 batch 154/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 226/300 batch 155/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 226/300 batch 156/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 226/300 batch 157/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 226/300 batch 158/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 226/300 batch 159/188  Train Loss: 0.016, Acc: 0.996\n",
      "epoch: 226/300 batch 160/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 226/300 batch 161/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 226/300 batch 162/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 226/300 batch 163/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 226/300 batch 164/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 226/300 batch 165/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 226/300 batch 166/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 226/300 batch 167/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 226/300 batch 168/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 226/300 batch 169/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 226/300 batch 170/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 226/300 batch 171/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 226/300 batch 172/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 226/300 batch 173/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 226/300 batch 174/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 226/300 batch 175/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 226/300 batch 176/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 226/300 batch 177/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 226/300 batch 178/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 226/300 batch 179/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 226/300 batch 180/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 226/300 batch 181/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 226/300 batch 182/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 226/300 batch 183/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 226/300 batch 184/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 226/300 batch 185/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 226/300 batch 186/188  Train Loss: 0.063, Acc: 0.992\n",
      "epoch: 226/300 batch 187/188  Train Loss: 0.028, Acc: 0.992\n",
      "Train Loss: 0.033030, Acc: 0.993\n",
      "Val Loss: 0.057263, Acc: 0.983\n",
      "epoch: 227/300 batch   0/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 227/300 batch   1/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 227/300 batch   2/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 227/300 batch   3/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 227/300 batch   4/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 227/300 batch   5/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 227/300 batch   6/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 227/300 batch   7/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 227/300 batch   8/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 227/300 batch   9/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 227/300 batch  10/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 227/300 batch  11/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 227/300 batch  12/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 227/300 batch  13/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 227/300 batch  14/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 227/300 batch  15/188  Train Loss: 0.043, Acc: 0.996\n",
      "epoch: 227/300 batch  16/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 227/300 batch  17/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 227/300 batch  18/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 227/300 batch  19/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 227/300 batch  20/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 227/300 batch  21/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 227/300 batch  22/188  Train Loss: 0.056, Acc: 0.988\n",
      "epoch: 227/300 batch  23/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 227/300 batch  24/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 227/300 batch  25/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 227/300 batch  26/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 227/300 batch  27/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 227/300 batch  28/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 227/300 batch  29/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 227/300 batch  30/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 227/300 batch  31/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 227/300 batch  32/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 227/300 batch  33/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 227/300 batch  34/188  Train Loss: 0.066, Acc: 0.992\n",
      "epoch: 227/300 batch  35/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 227/300 batch  36/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 227/300 batch  37/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 227/300 batch  38/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 227/300 batch  39/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 227/300 batch  40/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 227/300 batch  41/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 227/300 batch  42/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 227/300 batch  43/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 227/300 batch  44/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 227/300 batch  45/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 227/300 batch  46/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 227/300 batch  47/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 227/300 batch  48/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 227/300 batch  49/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 227/300 batch  50/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 227/300 batch  51/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 227/300 batch  52/188  Train Loss: 0.050, Acc: 0.977\n",
      "epoch: 227/300 batch  53/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 227/300 batch  54/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 227/300 batch  55/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 227/300 batch  56/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 227/300 batch  57/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 227/300 batch  58/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 227/300 batch  59/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 227/300 batch  60/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 227/300 batch  61/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 227/300 batch  62/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 227/300 batch  63/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 227/300 batch  64/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 227/300 batch  65/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 227/300 batch  66/188  Train Loss: 0.049, Acc: 0.996\n",
      "epoch: 227/300 batch  67/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 227/300 batch  68/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 227/300 batch  69/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 227/300 batch  70/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 227/300 batch  71/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 227/300 batch  72/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 227/300 batch  73/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 227/300 batch  74/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 227/300 batch  75/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 227/300 batch  76/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 227/300 batch  77/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 227/300 batch  78/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 227/300 batch  79/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 227/300 batch  80/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 227/300 batch  81/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 227/300 batch  82/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 227/300 batch  83/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 227/300 batch  84/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 227/300 batch  85/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 227/300 batch  86/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 227/300 batch  87/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 227/300 batch  88/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 227/300 batch  89/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 227/300 batch  90/188  Train Loss: 0.059, Acc: 0.973\n",
      "epoch: 227/300 batch  91/188  Train Loss: 0.056, Acc: 0.980\n",
      "epoch: 227/300 batch  92/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 227/300 batch  93/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 227/300 batch  94/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 227/300 batch  95/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 227/300 batch  96/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 227/300 batch  97/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 227/300 batch  98/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 227/300 batch  99/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 227/300 batch 100/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 227/300 batch 101/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 227/300 batch 102/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 227/300 batch 103/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 227/300 batch 104/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 227/300 batch 105/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 227/300 batch 106/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 227/300 batch 107/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 227/300 batch 108/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 227/300 batch 109/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 227/300 batch 110/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 227/300 batch 111/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 227/300 batch 112/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 227/300 batch 113/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 227/300 batch 114/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 227/300 batch 115/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 227/300 batch 116/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 227/300 batch 117/188  Train Loss: 0.032, Acc: 0.984\n",
      "epoch: 227/300 batch 118/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 227/300 batch 119/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 227/300 batch 120/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 227/300 batch 121/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 227/300 batch 122/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 227/300 batch 123/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 227/300 batch 124/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 227/300 batch 125/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 227/300 batch 126/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 227/300 batch 127/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 227/300 batch 128/188  Train Loss: 0.033, Acc: 0.984\n",
      "epoch: 227/300 batch 129/188  Train Loss: 0.046, Acc: 0.980\n",
      "epoch: 227/300 batch 130/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 227/300 batch 131/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 227/300 batch 132/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 227/300 batch 133/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 227/300 batch 134/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 227/300 batch 135/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 227/300 batch 136/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 227/300 batch 137/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 227/300 batch 138/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 227/300 batch 139/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 227/300 batch 140/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 227/300 batch 141/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 227/300 batch 142/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 227/300 batch 143/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 227/300 batch 144/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 227/300 batch 145/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 227/300 batch 146/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 227/300 batch 147/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 227/300 batch 148/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 227/300 batch 149/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 227/300 batch 150/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 227/300 batch 151/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 227/300 batch 152/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 227/300 batch 153/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 227/300 batch 154/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 227/300 batch 155/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 227/300 batch 156/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 227/300 batch 157/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 227/300 batch 158/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 227/300 batch 159/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 227/300 batch 160/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 227/300 batch 161/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 227/300 batch 162/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 227/300 batch 163/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 227/300 batch 164/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 227/300 batch 165/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 227/300 batch 166/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 227/300 batch 167/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 227/300 batch 168/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 227/300 batch 169/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 227/300 batch 170/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 227/300 batch 171/188  Train Loss: 0.032, Acc: 0.984\n",
      "epoch: 227/300 batch 172/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 227/300 batch 173/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 227/300 batch 174/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 227/300 batch 175/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 227/300 batch 176/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 227/300 batch 177/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 227/300 batch 178/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 227/300 batch 179/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 227/300 batch 180/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 227/300 batch 181/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 227/300 batch 182/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 227/300 batch 183/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 227/300 batch 184/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 227/300 batch 185/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 227/300 batch 186/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 227/300 batch 187/188  Train Loss: 0.030, Acc: 1.000\n",
      "Train Loss: 0.033058, Acc: 0.993\n",
      "Val Loss: 0.057459, Acc: 0.983\n",
      "epoch: 228/300 batch   0/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 228/300 batch   1/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 228/300 batch   2/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 228/300 batch   3/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 228/300 batch   4/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 228/300 batch   5/188  Train Loss: 0.016, Acc: 0.996\n",
      "epoch: 228/300 batch   6/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 228/300 batch   7/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 228/300 batch   8/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 228/300 batch   9/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 228/300 batch  10/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 228/300 batch  11/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 228/300 batch  12/188  Train Loss: 0.025, Acc: 0.988\n",
      "epoch: 228/300 batch  13/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 228/300 batch  14/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 228/300 batch  15/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 228/300 batch  16/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 228/300 batch  17/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 228/300 batch  18/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 228/300 batch  19/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 228/300 batch  20/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 228/300 batch  21/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 228/300 batch  22/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 228/300 batch  23/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 228/300 batch  24/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 228/300 batch  25/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 228/300 batch  26/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 228/300 batch  27/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 228/300 batch  28/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 228/300 batch  29/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 228/300 batch  30/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 228/300 batch  31/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 228/300 batch  32/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 228/300 batch  33/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 228/300 batch  34/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 228/300 batch  35/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 228/300 batch  36/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 228/300 batch  37/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 228/300 batch  38/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 228/300 batch  39/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 228/300 batch  40/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 228/300 batch  41/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 228/300 batch  42/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 228/300 batch  43/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 228/300 batch  44/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 228/300 batch  45/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 228/300 batch  46/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 228/300 batch  47/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 228/300 batch  48/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 228/300 batch  49/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 228/300 batch  50/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 228/300 batch  51/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 228/300 batch  52/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 228/300 batch  53/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 228/300 batch  54/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 228/300 batch  55/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 228/300 batch  56/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 228/300 batch  57/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 228/300 batch  58/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 228/300 batch  59/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 228/300 batch  60/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 228/300 batch  61/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 228/300 batch  62/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 228/300 batch  63/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 228/300 batch  64/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 228/300 batch  65/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 228/300 batch  66/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 228/300 batch  67/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 228/300 batch  68/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 228/300 batch  69/188  Train Loss: 0.051, Acc: 0.992\n",
      "epoch: 228/300 batch  70/188  Train Loss: 0.079, Acc: 0.984\n",
      "epoch: 228/300 batch  71/188  Train Loss: 0.061, Acc: 0.984\n",
      "epoch: 228/300 batch  72/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 228/300 batch  73/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 228/300 batch  74/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 228/300 batch  75/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 228/300 batch  76/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 228/300 batch  77/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 228/300 batch  78/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 228/300 batch  79/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 228/300 batch  80/188  Train Loss: 0.031, Acc: 1.000\n",
      "epoch: 228/300 batch  81/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 228/300 batch  82/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 228/300 batch  83/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 228/300 batch  84/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 228/300 batch  85/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 228/300 batch  86/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 228/300 batch  87/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 228/300 batch  88/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 228/300 batch  89/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 228/300 batch  90/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 228/300 batch  91/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 228/300 batch  92/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 228/300 batch  93/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 228/300 batch  94/188  Train Loss: 0.054, Acc: 0.977\n",
      "epoch: 228/300 batch  95/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 228/300 batch  96/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 228/300 batch  97/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 228/300 batch  98/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 228/300 batch  99/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 228/300 batch 100/188  Train Loss: 0.026, Acc: 0.988\n",
      "epoch: 228/300 batch 101/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 228/300 batch 102/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 228/300 batch 103/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 228/300 batch 104/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 228/300 batch 105/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 228/300 batch 106/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 228/300 batch 107/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 228/300 batch 108/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 228/300 batch 109/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 228/300 batch 110/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 228/300 batch 111/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 228/300 batch 112/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 228/300 batch 113/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 228/300 batch 114/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 228/300 batch 115/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 228/300 batch 116/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 228/300 batch 117/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 228/300 batch 118/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 228/300 batch 119/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 228/300 batch 120/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 228/300 batch 121/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 228/300 batch 122/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 228/300 batch 123/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 228/300 batch 124/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 228/300 batch 125/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 228/300 batch 126/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 228/300 batch 127/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 228/300 batch 128/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 228/300 batch 129/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 228/300 batch 130/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 228/300 batch 131/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 228/300 batch 132/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 228/300 batch 133/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 228/300 batch 134/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 228/300 batch 135/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 228/300 batch 136/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 228/300 batch 137/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 228/300 batch 138/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 228/300 batch 139/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 228/300 batch 140/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 228/300 batch 141/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 228/300 batch 142/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 228/300 batch 143/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 228/300 batch 144/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 228/300 batch 145/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 228/300 batch 146/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 228/300 batch 147/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 228/300 batch 148/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 228/300 batch 149/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 228/300 batch 150/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 228/300 batch 151/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 228/300 batch 152/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 228/300 batch 153/188  Train Loss: 0.067, Acc: 0.980\n",
      "epoch: 228/300 batch 154/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 228/300 batch 155/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 228/300 batch 156/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 228/300 batch 157/188  Train Loss: 0.054, Acc: 0.977\n",
      "epoch: 228/300 batch 158/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 228/300 batch 159/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 228/300 batch 160/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 228/300 batch 161/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 228/300 batch 162/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 228/300 batch 163/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 228/300 batch 164/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 228/300 batch 165/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 228/300 batch 166/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 228/300 batch 167/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 228/300 batch 168/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 228/300 batch 169/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 228/300 batch 170/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 228/300 batch 171/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 228/300 batch 172/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 228/300 batch 173/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 228/300 batch 174/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 228/300 batch 175/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 228/300 batch 176/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 228/300 batch 177/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 228/300 batch 178/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 228/300 batch 179/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 228/300 batch 180/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 228/300 batch 181/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 228/300 batch 182/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 228/300 batch 183/188  Train Loss: 0.032, Acc: 1.000\n",
      "epoch: 228/300 batch 184/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 228/300 batch 185/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 228/300 batch 186/188  Train Loss: 0.065, Acc: 0.984\n",
      "epoch: 228/300 batch 187/188  Train Loss: 0.048, Acc: 0.992\n",
      "Train Loss: 0.033098, Acc: 0.993\n",
      "Val Loss: 0.057410, Acc: 0.983\n",
      "epoch: 229/300 batch   0/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 229/300 batch   1/188  Train Loss: 0.014, Acc: 0.996\n",
      "epoch: 229/300 batch   2/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 229/300 batch   3/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 229/300 batch   4/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 229/300 batch   5/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 229/300 batch   6/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 229/300 batch   7/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 229/300 batch   8/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 229/300 batch   9/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 229/300 batch  10/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 229/300 batch  11/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 229/300 batch  12/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 229/300 batch  13/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 229/300 batch  14/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 229/300 batch  15/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 229/300 batch  16/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 229/300 batch  17/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 229/300 batch  18/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 229/300 batch  19/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 229/300 batch  20/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 229/300 batch  21/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 229/300 batch  22/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 229/300 batch  23/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 229/300 batch  24/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 229/300 batch  25/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 229/300 batch  26/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 229/300 batch  27/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 229/300 batch  28/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 229/300 batch  29/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 229/300 batch  30/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 229/300 batch  31/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 229/300 batch  32/188  Train Loss: 0.052, Acc: 0.992\n",
      "epoch: 229/300 batch  33/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 229/300 batch  34/188  Train Loss: 0.052, Acc: 0.980\n",
      "epoch: 229/300 batch  35/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 229/300 batch  36/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 229/300 batch  37/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 229/300 batch  38/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 229/300 batch  39/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 229/300 batch  40/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 229/300 batch  41/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 229/300 batch  42/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 229/300 batch  43/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 229/300 batch  44/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 229/300 batch  45/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 229/300 batch  46/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 229/300 batch  47/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 229/300 batch  48/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 229/300 batch  49/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 229/300 batch  50/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 229/300 batch  51/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 229/300 batch  52/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 229/300 batch  53/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 229/300 batch  54/188  Train Loss: 0.051, Acc: 0.973\n",
      "epoch: 229/300 batch  55/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 229/300 batch  56/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 229/300 batch  57/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 229/300 batch  58/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 229/300 batch  59/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 229/300 batch  60/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 229/300 batch  61/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 229/300 batch  62/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 229/300 batch  63/188  Train Loss: 0.054, Acc: 0.992\n",
      "epoch: 229/300 batch  64/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 229/300 batch  65/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 229/300 batch  66/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 229/300 batch  67/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 229/300 batch  68/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 229/300 batch  69/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 229/300 batch  70/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 229/300 batch  71/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 229/300 batch  72/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 229/300 batch  73/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 229/300 batch  74/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 229/300 batch  75/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 229/300 batch  76/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 229/300 batch  77/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 229/300 batch  78/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 229/300 batch  79/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 229/300 batch  80/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 229/300 batch  81/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 229/300 batch  82/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 229/300 batch  83/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 229/300 batch  84/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 229/300 batch  85/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 229/300 batch  86/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 229/300 batch  87/188  Train Loss: 0.043, Acc: 0.980\n",
      "epoch: 229/300 batch  88/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 229/300 batch  89/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 229/300 batch  90/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 229/300 batch  91/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 229/300 batch  92/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 229/300 batch  93/188  Train Loss: 0.077, Acc: 0.977\n",
      "epoch: 229/300 batch  94/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 229/300 batch  95/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 229/300 batch  96/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 229/300 batch  97/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 229/300 batch  98/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 229/300 batch  99/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 229/300 batch 100/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 229/300 batch 101/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 229/300 batch 102/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 229/300 batch 103/188  Train Loss: 0.032, Acc: 0.984\n",
      "epoch: 229/300 batch 104/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 229/300 batch 105/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 229/300 batch 106/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 229/300 batch 107/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 229/300 batch 108/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 229/300 batch 109/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 229/300 batch 110/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 229/300 batch 111/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 229/300 batch 112/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 229/300 batch 113/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 229/300 batch 114/188  Train Loss: 0.057, Acc: 0.980\n",
      "epoch: 229/300 batch 115/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 229/300 batch 116/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 229/300 batch 117/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 229/300 batch 118/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 229/300 batch 119/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 229/300 batch 120/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 229/300 batch 121/188  Train Loss: 0.050, Acc: 0.980\n",
      "epoch: 229/300 batch 122/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 229/300 batch 123/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 229/300 batch 124/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 229/300 batch 125/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 229/300 batch 126/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 229/300 batch 127/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 229/300 batch 128/188  Train Loss: 0.053, Acc: 0.980\n",
      "epoch: 229/300 batch 129/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 229/300 batch 130/188  Train Loss: 0.043, Acc: 0.980\n",
      "epoch: 229/300 batch 131/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 229/300 batch 132/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 229/300 batch 133/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 229/300 batch 134/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 229/300 batch 135/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 229/300 batch 136/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 229/300 batch 137/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 229/300 batch 138/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 229/300 batch 139/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 229/300 batch 140/188  Train Loss: 0.060, Acc: 0.988\n",
      "epoch: 229/300 batch 141/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 229/300 batch 142/188  Train Loss: 0.046, Acc: 0.980\n",
      "epoch: 229/300 batch 143/188  Train Loss: 0.061, Acc: 0.984\n",
      "epoch: 229/300 batch 144/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 229/300 batch 145/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 229/300 batch 146/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 229/300 batch 147/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 229/300 batch 148/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 229/300 batch 149/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 229/300 batch 150/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 229/300 batch 151/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 229/300 batch 152/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 229/300 batch 153/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 229/300 batch 154/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 229/300 batch 155/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 229/300 batch 156/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 229/300 batch 157/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 229/300 batch 158/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 229/300 batch 159/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 229/300 batch 160/188  Train Loss: 0.059, Acc: 0.996\n",
      "epoch: 229/300 batch 161/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 229/300 batch 162/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 229/300 batch 163/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 229/300 batch 164/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 229/300 batch 165/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 229/300 batch 166/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 229/300 batch 167/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 229/300 batch 168/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 229/300 batch 169/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 229/300 batch 170/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 229/300 batch 171/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 229/300 batch 172/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 229/300 batch 173/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 229/300 batch 174/188  Train Loss: 0.032, Acc: 0.984\n",
      "epoch: 229/300 batch 175/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 229/300 batch 176/188  Train Loss: 0.034, Acc: 0.984\n",
      "epoch: 229/300 batch 177/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 229/300 batch 178/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 229/300 batch 179/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 229/300 batch 180/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 229/300 batch 181/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 229/300 batch 182/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 229/300 batch 183/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 229/300 batch 184/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 229/300 batch 185/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 229/300 batch 186/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 229/300 batch 187/188  Train Loss: 0.035, Acc: 1.000\n",
      "Train Loss: 0.033049, Acc: 0.993\n",
      "Val Loss: 0.057451, Acc: 0.983\n",
      "epoch: 230/300 batch   0/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 230/300 batch   1/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 230/300 batch   2/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 230/300 batch   3/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 230/300 batch   4/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 230/300 batch   5/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 230/300 batch   6/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 230/300 batch   7/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 230/300 batch   8/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 230/300 batch   9/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 230/300 batch  10/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 230/300 batch  11/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 230/300 batch  12/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 230/300 batch  13/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 230/300 batch  14/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 230/300 batch  15/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 230/300 batch  16/188  Train Loss: 0.058, Acc: 0.973\n",
      "epoch: 230/300 batch  17/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 230/300 batch  18/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 230/300 batch  19/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 230/300 batch  20/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 230/300 batch  21/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 230/300 batch  22/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 230/300 batch  23/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 230/300 batch  24/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 230/300 batch  25/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 230/300 batch  26/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 230/300 batch  27/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 230/300 batch  28/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 230/300 batch  29/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 230/300 batch  30/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 230/300 batch  31/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 230/300 batch  32/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 230/300 batch  33/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 230/300 batch  34/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 230/300 batch  35/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 230/300 batch  36/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 230/300 batch  37/188  Train Loss: 0.016, Acc: 0.996\n",
      "epoch: 230/300 batch  38/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 230/300 batch  39/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 230/300 batch  40/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 230/300 batch  41/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 230/300 batch  42/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 230/300 batch  43/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 230/300 batch  44/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 230/300 batch  45/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 230/300 batch  46/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 230/300 batch  47/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 230/300 batch  48/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 230/300 batch  49/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 230/300 batch  50/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 230/300 batch  51/188  Train Loss: 0.027, Acc: 0.984\n",
      "epoch: 230/300 batch  52/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 230/300 batch  53/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 230/300 batch  54/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 230/300 batch  55/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 230/300 batch  56/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 230/300 batch  57/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 230/300 batch  58/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 230/300 batch  59/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 230/300 batch  60/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 230/300 batch  61/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 230/300 batch  62/188  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 230/300 batch  63/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 230/300 batch  64/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 230/300 batch  65/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 230/300 batch  66/188  Train Loss: 0.056, Acc: 0.980\n",
      "epoch: 230/300 batch  67/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 230/300 batch  68/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 230/300 batch  69/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 230/300 batch  70/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 230/300 batch  71/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 230/300 batch  72/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 230/300 batch  73/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 230/300 batch  74/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 230/300 batch  75/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 230/300 batch  76/188  Train Loss: 0.059, Acc: 0.988\n",
      "epoch: 230/300 batch  77/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 230/300 batch  78/188  Train Loss: 0.061, Acc: 0.988\n",
      "epoch: 230/300 batch  79/188  Train Loss: 0.059, Acc: 0.973\n",
      "epoch: 230/300 batch  80/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 230/300 batch  81/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 230/300 batch  82/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 230/300 batch  83/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 230/300 batch  84/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 230/300 batch  85/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 230/300 batch  86/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 230/300 batch  87/188  Train Loss: 0.042, Acc: 0.996\n",
      "epoch: 230/300 batch  88/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 230/300 batch  89/188  Train Loss: 0.025, Acc: 0.988\n",
      "epoch: 230/300 batch  90/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 230/300 batch  91/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 230/300 batch  92/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 230/300 batch  93/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 230/300 batch  94/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 230/300 batch  95/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 230/300 batch  96/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 230/300 batch  97/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 230/300 batch  98/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 230/300 batch  99/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 230/300 batch 100/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 230/300 batch 101/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 230/300 batch 102/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 230/300 batch 103/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 230/300 batch 104/188  Train Loss: 0.068, Acc: 0.980\n",
      "epoch: 230/300 batch 105/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 230/300 batch 106/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 230/300 batch 107/188  Train Loss: 0.046, Acc: 0.980\n",
      "epoch: 230/300 batch 108/188  Train Loss: 0.061, Acc: 0.980\n",
      "epoch: 230/300 batch 109/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 230/300 batch 110/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 230/300 batch 111/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 230/300 batch 112/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 230/300 batch 113/188  Train Loss: 0.057, Acc: 0.992\n",
      "epoch: 230/300 batch 114/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 230/300 batch 115/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 230/300 batch 116/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 230/300 batch 117/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 230/300 batch 118/188  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 230/300 batch 119/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 230/300 batch 120/188  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 230/300 batch 121/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 230/300 batch 122/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 230/300 batch 123/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 230/300 batch 124/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 230/300 batch 125/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 230/300 batch 126/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 230/300 batch 127/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 230/300 batch 128/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 230/300 batch 129/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 230/300 batch 130/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 230/300 batch 131/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 230/300 batch 132/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 230/300 batch 133/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 230/300 batch 134/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 230/300 batch 135/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 230/300 batch 136/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 230/300 batch 137/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 230/300 batch 138/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 230/300 batch 139/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 230/300 batch 140/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 230/300 batch 141/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 230/300 batch 142/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 230/300 batch 143/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 230/300 batch 144/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 230/300 batch 145/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 230/300 batch 146/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 230/300 batch 147/188  Train Loss: 0.056, Acc: 0.988\n",
      "epoch: 230/300 batch 148/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 230/300 batch 149/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 230/300 batch 150/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 230/300 batch 151/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 230/300 batch 152/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 230/300 batch 153/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 230/300 batch 154/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 230/300 batch 155/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 230/300 batch 156/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 230/300 batch 157/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 230/300 batch 158/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 230/300 batch 159/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 230/300 batch 160/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 230/300 batch 161/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 230/300 batch 162/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 230/300 batch 163/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 230/300 batch 164/188  Train Loss: 0.058, Acc: 0.988\n",
      "epoch: 230/300 batch 165/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 230/300 batch 166/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 230/300 batch 167/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 230/300 batch 168/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 230/300 batch 169/188  Train Loss: 0.076, Acc: 0.977\n",
      "epoch: 230/300 batch 170/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 230/300 batch 171/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 230/300 batch 172/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 230/300 batch 173/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 230/300 batch 174/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 230/300 batch 175/188  Train Loss: 0.050, Acc: 0.980\n",
      "epoch: 230/300 batch 176/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 230/300 batch 177/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 230/300 batch 178/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 230/300 batch 179/188  Train Loss: 0.058, Acc: 0.977\n",
      "epoch: 230/300 batch 180/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 230/300 batch 181/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 230/300 batch 182/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 230/300 batch 183/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 230/300 batch 184/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 230/300 batch 185/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 230/300 batch 186/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 230/300 batch 187/188  Train Loss: 0.026, Acc: 0.992\n",
      "Train Loss: 0.032906, Acc: 0.993\n",
      "Val Loss: 0.057964, Acc: 0.983\n",
      "epoch: 231/300 batch   0/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 231/300 batch   1/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 231/300 batch   2/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 231/300 batch   3/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 231/300 batch   4/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 231/300 batch   5/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 231/300 batch   6/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 231/300 batch   7/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 231/300 batch   8/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 231/300 batch   9/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 231/300 batch  10/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 231/300 batch  11/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 231/300 batch  12/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 231/300 batch  13/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 231/300 batch  14/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 231/300 batch  15/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 231/300 batch  16/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 231/300 batch  17/188  Train Loss: 0.058, Acc: 0.996\n",
      "epoch: 231/300 batch  18/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 231/300 batch  19/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 231/300 batch  20/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 231/300 batch  21/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 231/300 batch  22/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 231/300 batch  23/188  Train Loss: 0.043, Acc: 0.996\n",
      "epoch: 231/300 batch  24/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 231/300 batch  25/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 231/300 batch  26/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 231/300 batch  27/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 231/300 batch  28/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 231/300 batch  29/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 231/300 batch  30/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 231/300 batch  31/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 231/300 batch  32/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 231/300 batch  33/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 231/300 batch  34/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 231/300 batch  35/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 231/300 batch  36/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 231/300 batch  37/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 231/300 batch  38/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 231/300 batch  39/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 231/300 batch  40/188  Train Loss: 0.062, Acc: 0.984\n",
      "epoch: 231/300 batch  41/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 231/300 batch  42/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 231/300 batch  43/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 231/300 batch  44/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 231/300 batch  45/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 231/300 batch  46/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 231/300 batch  47/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 231/300 batch  48/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 231/300 batch  49/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 231/300 batch  50/188  Train Loss: 0.042, Acc: 0.980\n",
      "epoch: 231/300 batch  51/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 231/300 batch  52/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 231/300 batch  53/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 231/300 batch  54/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 231/300 batch  55/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 231/300 batch  56/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 231/300 batch  57/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 231/300 batch  58/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 231/300 batch  59/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 231/300 batch  60/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 231/300 batch  61/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 231/300 batch  62/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 231/300 batch  63/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 231/300 batch  64/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 231/300 batch  65/188  Train Loss: 0.049, Acc: 0.977\n",
      "epoch: 231/300 batch  66/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 231/300 batch  67/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 231/300 batch  68/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 231/300 batch  69/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 231/300 batch  70/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 231/300 batch  71/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 231/300 batch  72/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 231/300 batch  73/188  Train Loss: 0.037, Acc: 0.980\n",
      "epoch: 231/300 batch  74/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 231/300 batch  75/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 231/300 batch  76/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 231/300 batch  77/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 231/300 batch  78/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 231/300 batch  79/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 231/300 batch  80/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 231/300 batch  81/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 231/300 batch  82/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 231/300 batch  83/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 231/300 batch  84/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 231/300 batch  85/188  Train Loss: 0.059, Acc: 0.988\n",
      "epoch: 231/300 batch  86/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 231/300 batch  87/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 231/300 batch  88/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 231/300 batch  89/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 231/300 batch  90/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 231/300 batch  91/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 231/300 batch  92/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 231/300 batch  93/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 231/300 batch  94/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 231/300 batch  95/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 231/300 batch  96/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 231/300 batch  97/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 231/300 batch  98/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 231/300 batch  99/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 231/300 batch 100/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 231/300 batch 101/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 231/300 batch 102/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 231/300 batch 103/188  Train Loss: 0.040, Acc: 0.980\n",
      "epoch: 231/300 batch 104/188  Train Loss: 0.062, Acc: 0.977\n",
      "epoch: 231/300 batch 105/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 231/300 batch 106/188  Train Loss: 0.064, Acc: 0.988\n",
      "epoch: 231/300 batch 107/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 231/300 batch 108/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 231/300 batch 109/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 231/300 batch 110/188  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 231/300 batch 111/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 231/300 batch 112/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 231/300 batch 113/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 231/300 batch 114/188  Train Loss: 0.040, Acc: 0.980\n",
      "epoch: 231/300 batch 115/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 231/300 batch 116/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 231/300 batch 117/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 231/300 batch 118/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 231/300 batch 119/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 231/300 batch 120/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 231/300 batch 121/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 231/300 batch 122/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 231/300 batch 123/188  Train Loss: 0.041, Acc: 0.980\n",
      "epoch: 231/300 batch 124/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 231/300 batch 125/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 231/300 batch 126/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 231/300 batch 127/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 231/300 batch 128/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 231/300 batch 129/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 231/300 batch 130/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 231/300 batch 131/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 231/300 batch 132/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 231/300 batch 133/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 231/300 batch 134/188  Train Loss: 0.057, Acc: 0.980\n",
      "epoch: 231/300 batch 135/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 231/300 batch 136/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 231/300 batch 137/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 231/300 batch 138/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 231/300 batch 139/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 231/300 batch 140/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 231/300 batch 141/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 231/300 batch 142/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 231/300 batch 143/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 231/300 batch 144/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 231/300 batch 145/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 231/300 batch 146/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 231/300 batch 147/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 231/300 batch 148/188  Train Loss: 0.057, Acc: 0.977\n",
      "epoch: 231/300 batch 149/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 231/300 batch 150/188  Train Loss: 0.057, Acc: 0.992\n",
      "epoch: 231/300 batch 151/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 231/300 batch 152/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 231/300 batch 153/188  Train Loss: 0.062, Acc: 0.980\n",
      "epoch: 231/300 batch 154/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 231/300 batch 155/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 231/300 batch 156/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 231/300 batch 157/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 231/300 batch 158/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 231/300 batch 159/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 231/300 batch 160/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 231/300 batch 161/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 231/300 batch 162/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 231/300 batch 163/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 231/300 batch 164/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 231/300 batch 165/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 231/300 batch 166/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 231/300 batch 167/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 231/300 batch 168/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 231/300 batch 169/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 231/300 batch 170/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 231/300 batch 171/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 231/300 batch 172/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 231/300 batch 173/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 231/300 batch 174/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 231/300 batch 175/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 231/300 batch 176/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 231/300 batch 177/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 231/300 batch 178/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 231/300 batch 179/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 231/300 batch 180/188  Train Loss: 0.060, Acc: 0.980\n",
      "epoch: 231/300 batch 181/188  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 231/300 batch 182/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 231/300 batch 183/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 231/300 batch 184/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 231/300 batch 185/188  Train Loss: 0.046, Acc: 0.977\n",
      "epoch: 231/300 batch 186/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 231/300 batch 187/188  Train Loss: 0.075, Acc: 0.984\n",
      "Train Loss: 0.033092, Acc: 0.993\n",
      "Val Loss: 0.057359, Acc: 0.983\n",
      "epoch: 232/300 batch   0/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 232/300 batch   1/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 232/300 batch   2/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 232/300 batch   3/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 232/300 batch   4/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 232/300 batch   5/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 232/300 batch   6/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 232/300 batch   7/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 232/300 batch   8/188  Train Loss: 0.057, Acc: 0.977\n",
      "epoch: 232/300 batch   9/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 232/300 batch  10/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 232/300 batch  11/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 232/300 batch  12/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 232/300 batch  13/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 232/300 batch  14/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 232/300 batch  15/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 232/300 batch  16/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 232/300 batch  17/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 232/300 batch  18/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 232/300 batch  19/188  Train Loss: 0.016, Acc: 0.996\n",
      "epoch: 232/300 batch  20/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 232/300 batch  21/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 232/300 batch  22/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 232/300 batch  23/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 232/300 batch  24/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 232/300 batch  25/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 232/300 batch  26/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 232/300 batch  27/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 232/300 batch  28/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 232/300 batch  29/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 232/300 batch  30/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 232/300 batch  31/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 232/300 batch  32/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 232/300 batch  33/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 232/300 batch  34/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 232/300 batch  35/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 232/300 batch  36/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 232/300 batch  37/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 232/300 batch  38/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 232/300 batch  39/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 232/300 batch  40/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 232/300 batch  41/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 232/300 batch  42/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 232/300 batch  43/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 232/300 batch  44/188  Train Loss: 0.039, Acc: 0.980\n",
      "epoch: 232/300 batch  45/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 232/300 batch  46/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 232/300 batch  47/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 232/300 batch  48/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 232/300 batch  49/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 232/300 batch  50/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 232/300 batch  51/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 232/300 batch  52/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 232/300 batch  53/188  Train Loss: 0.061, Acc: 0.996\n",
      "epoch: 232/300 batch  54/188  Train Loss: 0.032, Acc: 1.000\n",
      "epoch: 232/300 batch  55/188  Train Loss: 0.054, Acc: 0.992\n",
      "epoch: 232/300 batch  56/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 232/300 batch  57/188  Train Loss: 0.072, Acc: 0.984\n",
      "epoch: 232/300 batch  58/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 232/300 batch  59/188  Train Loss: 0.044, Acc: 0.980\n",
      "epoch: 232/300 batch  60/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 232/300 batch  61/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 232/300 batch  62/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 232/300 batch  63/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 232/300 batch  64/188  Train Loss: 0.048, Acc: 0.980\n",
      "epoch: 232/300 batch  65/188  Train Loss: 0.046, Acc: 0.996\n",
      "epoch: 232/300 batch  66/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 232/300 batch  67/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 232/300 batch  68/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 232/300 batch  69/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 232/300 batch  70/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 232/300 batch  71/188  Train Loss: 0.025, Acc: 0.988\n",
      "epoch: 232/300 batch  72/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 232/300 batch  73/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 232/300 batch  74/188  Train Loss: 0.056, Acc: 0.988\n",
      "epoch: 232/300 batch  75/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 232/300 batch  76/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 232/300 batch  77/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 232/300 batch  78/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 232/300 batch  79/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 232/300 batch  80/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 232/300 batch  81/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 232/300 batch  82/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 232/300 batch  83/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 232/300 batch  84/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 232/300 batch  85/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 232/300 batch  86/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 232/300 batch  87/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 232/300 batch  88/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 232/300 batch  89/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 232/300 batch  90/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 232/300 batch  91/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 232/300 batch  92/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 232/300 batch  93/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 232/300 batch  94/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 232/300 batch  95/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 232/300 batch  96/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 232/300 batch  97/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 232/300 batch  98/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 232/300 batch  99/188  Train Loss: 0.052, Acc: 0.980\n",
      "epoch: 232/300 batch 100/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 232/300 batch 101/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 232/300 batch 102/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 232/300 batch 103/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 232/300 batch 104/188  Train Loss: 0.050, Acc: 0.977\n",
      "epoch: 232/300 batch 105/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 232/300 batch 106/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 232/300 batch 107/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 232/300 batch 108/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 232/300 batch 109/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 232/300 batch 110/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 232/300 batch 111/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 232/300 batch 112/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 232/300 batch 113/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 232/300 batch 114/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 232/300 batch 115/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 232/300 batch 116/188  Train Loss: 0.057, Acc: 0.988\n",
      "epoch: 232/300 batch 117/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 232/300 batch 118/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 232/300 batch 119/188  Train Loss: 0.035, Acc: 1.000\n",
      "epoch: 232/300 batch 120/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 232/300 batch 121/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 232/300 batch 122/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 232/300 batch 123/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 232/300 batch 124/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 232/300 batch 125/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 232/300 batch 126/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 232/300 batch 127/188  Train Loss: 0.037, Acc: 1.000\n",
      "epoch: 232/300 batch 128/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 232/300 batch 129/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 232/300 batch 130/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 232/300 batch 131/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 232/300 batch 132/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 232/300 batch 133/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 232/300 batch 134/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 232/300 batch 135/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 232/300 batch 136/188  Train Loss: 0.067, Acc: 0.984\n",
      "epoch: 232/300 batch 137/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 232/300 batch 138/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 232/300 batch 139/188  Train Loss: 0.063, Acc: 0.984\n",
      "epoch: 232/300 batch 140/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 232/300 batch 141/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 232/300 batch 142/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 232/300 batch 143/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 232/300 batch 144/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 232/300 batch 145/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 232/300 batch 146/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 232/300 batch 147/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 232/300 batch 148/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 232/300 batch 149/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 232/300 batch 150/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 232/300 batch 151/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 232/300 batch 152/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 232/300 batch 153/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 232/300 batch 154/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 232/300 batch 155/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 232/300 batch 156/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 232/300 batch 157/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 232/300 batch 158/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 232/300 batch 159/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 232/300 batch 160/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 232/300 batch 161/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 232/300 batch 162/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 232/300 batch 163/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 232/300 batch 164/188  Train Loss: 0.056, Acc: 0.988\n",
      "epoch: 232/300 batch 165/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 232/300 batch 166/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 232/300 batch 167/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 232/300 batch 168/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 232/300 batch 169/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 232/300 batch 170/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 232/300 batch 171/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 232/300 batch 172/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 232/300 batch 173/188  Train Loss: 0.045, Acc: 0.980\n",
      "epoch: 232/300 batch 174/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 232/300 batch 175/188  Train Loss: 0.031, Acc: 0.984\n",
      "epoch: 232/300 batch 176/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 232/300 batch 177/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 232/300 batch 178/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 232/300 batch 179/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 232/300 batch 180/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 232/300 batch 181/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 232/300 batch 182/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 232/300 batch 183/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 232/300 batch 184/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 232/300 batch 185/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 232/300 batch 186/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 232/300 batch 187/188  Train Loss: 0.027, Acc: 0.992\n",
      "Train Loss: 0.032892, Acc: 0.993\n",
      "Val Loss: 0.057326, Acc: 0.983\n",
      "epoch: 233/300 batch   0/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 233/300 batch   1/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 233/300 batch   2/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 233/300 batch   3/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 233/300 batch   4/188  Train Loss: 0.026, Acc: 0.988\n",
      "epoch: 233/300 batch   5/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 233/300 batch   6/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 233/300 batch   7/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 233/300 batch   8/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 233/300 batch   9/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 233/300 batch  10/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 233/300 batch  11/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 233/300 batch  12/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 233/300 batch  13/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 233/300 batch  14/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 233/300 batch  15/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 233/300 batch  16/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 233/300 batch  17/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 233/300 batch  18/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 233/300 batch  19/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 233/300 batch  20/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 233/300 batch  21/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 233/300 batch  22/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 233/300 batch  23/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 233/300 batch  24/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 233/300 batch  25/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 233/300 batch  26/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 233/300 batch  27/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 233/300 batch  28/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 233/300 batch  29/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 233/300 batch  30/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 233/300 batch  31/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 233/300 batch  32/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 233/300 batch  33/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 233/300 batch  34/188  Train Loss: 0.072, Acc: 0.973\n",
      "epoch: 233/300 batch  35/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 233/300 batch  36/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 233/300 batch  37/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 233/300 batch  38/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 233/300 batch  39/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 233/300 batch  40/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 233/300 batch  41/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 233/300 batch  42/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 233/300 batch  43/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 233/300 batch  44/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 233/300 batch  45/188  Train Loss: 0.054, Acc: 0.980\n",
      "epoch: 233/300 batch  46/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 233/300 batch  47/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 233/300 batch  48/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 233/300 batch  49/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 233/300 batch  50/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 233/300 batch  51/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 233/300 batch  52/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 233/300 batch  53/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 233/300 batch  54/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 233/300 batch  55/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 233/300 batch  56/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 233/300 batch  57/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 233/300 batch  58/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 233/300 batch  59/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 233/300 batch  60/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 233/300 batch  61/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 233/300 batch  62/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 233/300 batch  63/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 233/300 batch  64/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 233/300 batch  65/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 233/300 batch  66/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 233/300 batch  67/188  Train Loss: 0.056, Acc: 0.980\n",
      "epoch: 233/300 batch  68/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 233/300 batch  69/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 233/300 batch  70/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 233/300 batch  71/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 233/300 batch  72/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 233/300 batch  73/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 233/300 batch  74/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 233/300 batch  75/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 233/300 batch  76/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 233/300 batch  77/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 233/300 batch  78/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 233/300 batch  79/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 233/300 batch  80/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 233/300 batch  81/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 233/300 batch  82/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 233/300 batch  83/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 233/300 batch  84/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 233/300 batch  85/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 233/300 batch  86/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 233/300 batch  87/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 233/300 batch  88/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 233/300 batch  89/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 233/300 batch  90/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 233/300 batch  91/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 233/300 batch  92/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 233/300 batch  93/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 233/300 batch  94/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 233/300 batch  95/188  Train Loss: 0.050, Acc: 0.980\n",
      "epoch: 233/300 batch  96/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 233/300 batch  97/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 233/300 batch  98/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 233/300 batch  99/188  Train Loss: 0.068, Acc: 0.988\n",
      "epoch: 233/300 batch 100/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 233/300 batch 101/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 233/300 batch 102/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 233/300 batch 103/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 233/300 batch 104/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 233/300 batch 105/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 233/300 batch 106/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 233/300 batch 107/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 233/300 batch 108/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 233/300 batch 109/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 233/300 batch 110/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 233/300 batch 111/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 233/300 batch 112/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 233/300 batch 113/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 233/300 batch 114/188  Train Loss: 0.073, Acc: 0.984\n",
      "epoch: 233/300 batch 115/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 233/300 batch 116/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 233/300 batch 117/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 233/300 batch 118/188  Train Loss: 0.062, Acc: 0.984\n",
      "epoch: 233/300 batch 119/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 233/300 batch 120/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 233/300 batch 121/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 233/300 batch 122/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 233/300 batch 123/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 233/300 batch 124/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 233/300 batch 125/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 233/300 batch 126/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 233/300 batch 127/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 233/300 batch 128/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 233/300 batch 129/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 233/300 batch 130/188  Train Loss: 0.070, Acc: 0.977\n",
      "epoch: 233/300 batch 131/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 233/300 batch 132/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 233/300 batch 133/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 233/300 batch 134/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 233/300 batch 135/188  Train Loss: 0.060, Acc: 0.988\n",
      "epoch: 233/300 batch 136/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 233/300 batch 137/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 233/300 batch 138/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 233/300 batch 139/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 233/300 batch 140/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 233/300 batch 141/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 233/300 batch 142/188  Train Loss: 0.080, Acc: 0.984\n",
      "epoch: 233/300 batch 143/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 233/300 batch 144/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 233/300 batch 145/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 233/300 batch 146/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 233/300 batch 147/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 233/300 batch 148/188  Train Loss: 0.057, Acc: 0.992\n",
      "epoch: 233/300 batch 149/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 233/300 batch 150/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 233/300 batch 151/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 233/300 batch 152/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 233/300 batch 153/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 233/300 batch 154/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 233/300 batch 155/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 233/300 batch 156/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 233/300 batch 157/188  Train Loss: 0.087, Acc: 0.973\n",
      "epoch: 233/300 batch 158/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 233/300 batch 159/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 233/300 batch 160/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 233/300 batch 161/188  Train Loss: 0.031, Acc: 0.984\n",
      "epoch: 233/300 batch 162/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 233/300 batch 163/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 233/300 batch 164/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 233/300 batch 165/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 233/300 batch 166/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 233/300 batch 167/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 233/300 batch 168/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 233/300 batch 169/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 233/300 batch 170/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 233/300 batch 171/188  Train Loss: 0.066, Acc: 0.980\n",
      "epoch: 233/300 batch 172/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 233/300 batch 173/188  Train Loss: 0.056, Acc: 0.980\n",
      "epoch: 233/300 batch 174/188  Train Loss: 0.015, Acc: 0.996\n",
      "epoch: 233/300 batch 175/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 233/300 batch 176/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 233/300 batch 177/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 233/300 batch 178/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 233/300 batch 179/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 233/300 batch 180/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 233/300 batch 181/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 233/300 batch 182/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 233/300 batch 183/188  Train Loss: 0.024, Acc: 0.988\n",
      "epoch: 233/300 batch 184/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 233/300 batch 185/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 233/300 batch 186/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 233/300 batch 187/188  Train Loss: 0.022, Acc: 0.992\n",
      "Train Loss: 0.032913, Acc: 0.993\n",
      "Val Loss: 0.057389, Acc: 0.983\n",
      "epoch: 234/300 batch   0/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 234/300 batch   1/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 234/300 batch   2/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 234/300 batch   3/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 234/300 batch   4/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 234/300 batch   5/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 234/300 batch   6/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 234/300 batch   7/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 234/300 batch   8/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 234/300 batch   9/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 234/300 batch  10/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 234/300 batch  11/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 234/300 batch  12/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 234/300 batch  13/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 234/300 batch  14/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 234/300 batch  15/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 234/300 batch  16/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 234/300 batch  17/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 234/300 batch  18/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 234/300 batch  19/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 234/300 batch  20/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 234/300 batch  21/188  Train Loss: 0.050, Acc: 0.980\n",
      "epoch: 234/300 batch  22/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 234/300 batch  23/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 234/300 batch  24/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 234/300 batch  25/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 234/300 batch  26/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 234/300 batch  27/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 234/300 batch  28/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 234/300 batch  29/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 234/300 batch  30/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 234/300 batch  31/188  Train Loss: 0.051, Acc: 0.992\n",
      "epoch: 234/300 batch  32/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 234/300 batch  33/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 234/300 batch  34/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 234/300 batch  35/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 234/300 batch  36/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 234/300 batch  37/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 234/300 batch  38/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 234/300 batch  39/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 234/300 batch  40/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 234/300 batch  41/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 234/300 batch  42/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 234/300 batch  43/188  Train Loss: 0.048, Acc: 0.980\n",
      "epoch: 234/300 batch  44/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 234/300 batch  45/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 234/300 batch  46/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 234/300 batch  47/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 234/300 batch  48/188  Train Loss: 0.045, Acc: 0.977\n",
      "epoch: 234/300 batch  49/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 234/300 batch  50/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 234/300 batch  51/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 234/300 batch  52/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 234/300 batch  53/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 234/300 batch  54/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 234/300 batch  55/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 234/300 batch  56/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 234/300 batch  57/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 234/300 batch  58/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 234/300 batch  59/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 234/300 batch  60/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 234/300 batch  61/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 234/300 batch  62/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 234/300 batch  63/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 234/300 batch  64/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 234/300 batch  65/188  Train Loss: 0.052, Acc: 0.992\n",
      "epoch: 234/300 batch  66/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 234/300 batch  67/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 234/300 batch  68/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 234/300 batch  69/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 234/300 batch  70/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 234/300 batch  71/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 234/300 batch  72/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 234/300 batch  73/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 234/300 batch  74/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 234/300 batch  75/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 234/300 batch  76/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 234/300 batch  77/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 234/300 batch  78/188  Train Loss: 0.040, Acc: 0.980\n",
      "epoch: 234/300 batch  79/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 234/300 batch  80/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 234/300 batch  81/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 234/300 batch  82/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 234/300 batch  83/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 234/300 batch  84/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 234/300 batch  85/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 234/300 batch  86/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 234/300 batch  87/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 234/300 batch  88/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 234/300 batch  89/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 234/300 batch  90/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 234/300 batch  91/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 234/300 batch  92/188  Train Loss: 0.035, Acc: 1.000\n",
      "epoch: 234/300 batch  93/188  Train Loss: 0.020, Acc: 0.988\n",
      "epoch: 234/300 batch  94/188  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 234/300 batch  95/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 234/300 batch  96/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 234/300 batch  97/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 234/300 batch  98/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 234/300 batch  99/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 234/300 batch 100/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 234/300 batch 101/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 234/300 batch 102/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 234/300 batch 103/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 234/300 batch 104/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 234/300 batch 105/188  Train Loss: 0.032, Acc: 0.984\n",
      "epoch: 234/300 batch 106/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 234/300 batch 107/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 234/300 batch 108/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 234/300 batch 109/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 234/300 batch 110/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 234/300 batch 111/188  Train Loss: 0.068, Acc: 0.973\n",
      "epoch: 234/300 batch 112/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 234/300 batch 113/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 234/300 batch 114/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 234/300 batch 115/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 234/300 batch 116/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 234/300 batch 117/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 234/300 batch 118/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 234/300 batch 119/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 234/300 batch 120/188  Train Loss: 0.037, Acc: 0.980\n",
      "epoch: 234/300 batch 121/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 234/300 batch 122/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 234/300 batch 123/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 234/300 batch 124/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 234/300 batch 125/188  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 234/300 batch 126/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 234/300 batch 127/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 234/300 batch 128/188  Train Loss: 0.039, Acc: 1.000\n",
      "epoch: 234/300 batch 129/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 234/300 batch 130/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 234/300 batch 131/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 234/300 batch 132/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 234/300 batch 133/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 234/300 batch 134/188  Train Loss: 0.016, Acc: 0.996\n",
      "epoch: 234/300 batch 135/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 234/300 batch 136/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 234/300 batch 137/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 234/300 batch 138/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 234/300 batch 139/188  Train Loss: 0.048, Acc: 0.980\n",
      "epoch: 234/300 batch 140/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 234/300 batch 141/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 234/300 batch 142/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 234/300 batch 143/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 234/300 batch 144/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 234/300 batch 145/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 234/300 batch 146/188  Train Loss: 0.058, Acc: 0.992\n",
      "epoch: 234/300 batch 147/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 234/300 batch 148/188  Train Loss: 0.027, Acc: 0.988\n",
      "epoch: 234/300 batch 149/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 234/300 batch 150/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 234/300 batch 151/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 234/300 batch 152/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 234/300 batch 153/188  Train Loss: 0.052, Acc: 0.996\n",
      "epoch: 234/300 batch 154/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 234/300 batch 155/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 234/300 batch 156/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 234/300 batch 157/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 234/300 batch 158/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 234/300 batch 159/188  Train Loss: 0.053, Acc: 0.992\n",
      "epoch: 234/300 batch 160/188  Train Loss: 0.068, Acc: 0.980\n",
      "epoch: 234/300 batch 161/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 234/300 batch 162/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 234/300 batch 163/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 234/300 batch 164/188  Train Loss: 0.070, Acc: 0.977\n",
      "epoch: 234/300 batch 165/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 234/300 batch 166/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 234/300 batch 167/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 234/300 batch 168/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 234/300 batch 169/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 234/300 batch 170/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 234/300 batch 171/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 234/300 batch 172/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 234/300 batch 173/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 234/300 batch 174/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 234/300 batch 175/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 234/300 batch 176/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 234/300 batch 177/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 234/300 batch 178/188  Train Loss: 0.062, Acc: 0.996\n",
      "epoch: 234/300 batch 179/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 234/300 batch 180/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 234/300 batch 181/188  Train Loss: 0.065, Acc: 0.980\n",
      "epoch: 234/300 batch 182/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 234/300 batch 183/188  Train Loss: 0.066, Acc: 0.980\n",
      "epoch: 234/300 batch 184/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 234/300 batch 185/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 234/300 batch 186/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 234/300 batch 187/188  Train Loss: 0.017, Acc: 1.000\n",
      "Train Loss: 0.032871, Acc: 0.993\n",
      "Val Loss: 0.057929, Acc: 0.983\n",
      "epoch: 235/300 batch   0/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 235/300 batch   1/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 235/300 batch   2/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 235/300 batch   3/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 235/300 batch   4/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 235/300 batch   5/188  Train Loss: 0.042, Acc: 0.977\n",
      "epoch: 235/300 batch   6/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 235/300 batch   7/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 235/300 batch   8/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 235/300 batch   9/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 235/300 batch  10/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 235/300 batch  11/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 235/300 batch  12/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 235/300 batch  13/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 235/300 batch  14/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 235/300 batch  15/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 235/300 batch  16/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 235/300 batch  17/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 235/300 batch  18/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 235/300 batch  19/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 235/300 batch  20/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 235/300 batch  21/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 235/300 batch  22/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 235/300 batch  23/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 235/300 batch  24/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 235/300 batch  25/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 235/300 batch  26/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 235/300 batch  27/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 235/300 batch  28/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 235/300 batch  29/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 235/300 batch  30/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 235/300 batch  31/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 235/300 batch  32/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 235/300 batch  33/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 235/300 batch  34/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 235/300 batch  35/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 235/300 batch  36/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 235/300 batch  37/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 235/300 batch  38/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 235/300 batch  39/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 235/300 batch  40/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 235/300 batch  41/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 235/300 batch  42/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 235/300 batch  43/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 235/300 batch  44/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 235/300 batch  45/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 235/300 batch  46/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 235/300 batch  47/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 235/300 batch  48/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 235/300 batch  49/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 235/300 batch  50/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 235/300 batch  51/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 235/300 batch  52/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 235/300 batch  53/188  Train Loss: 0.077, Acc: 0.984\n",
      "epoch: 235/300 batch  54/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 235/300 batch  55/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 235/300 batch  56/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 235/300 batch  57/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 235/300 batch  58/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 235/300 batch  59/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 235/300 batch  60/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 235/300 batch  61/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 235/300 batch  62/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 235/300 batch  63/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 235/300 batch  64/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 235/300 batch  65/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 235/300 batch  66/188  Train Loss: 0.040, Acc: 0.980\n",
      "epoch: 235/300 batch  67/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 235/300 batch  68/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 235/300 batch  69/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 235/300 batch  70/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 235/300 batch  71/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 235/300 batch  72/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 235/300 batch  73/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 235/300 batch  74/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 235/300 batch  75/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 235/300 batch  76/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 235/300 batch  77/188  Train Loss: 0.063, Acc: 0.988\n",
      "epoch: 235/300 batch  78/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 235/300 batch  79/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 235/300 batch  80/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 235/300 batch  81/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 235/300 batch  82/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 235/300 batch  83/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 235/300 batch  84/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 235/300 batch  85/188  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 235/300 batch  86/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 235/300 batch  87/188  Train Loss: 0.074, Acc: 0.984\n",
      "epoch: 235/300 batch  88/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 235/300 batch  89/188  Train Loss: 0.059, Acc: 0.988\n",
      "epoch: 235/300 batch  90/188  Train Loss: 0.034, Acc: 1.000\n",
      "epoch: 235/300 batch  91/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 235/300 batch  92/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 235/300 batch  93/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 235/300 batch  94/188  Train Loss: 0.057, Acc: 0.977\n",
      "epoch: 235/300 batch  95/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 235/300 batch  96/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 235/300 batch  97/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 235/300 batch  98/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 235/300 batch  99/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 235/300 batch 100/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 235/300 batch 101/188  Train Loss: 0.075, Acc: 0.988\n",
      "epoch: 235/300 batch 102/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 235/300 batch 103/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 235/300 batch 104/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 235/300 batch 105/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 235/300 batch 106/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 235/300 batch 107/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 235/300 batch 108/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 235/300 batch 109/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 235/300 batch 110/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 235/300 batch 111/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 235/300 batch 112/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 235/300 batch 113/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 235/300 batch 114/188  Train Loss: 0.027, Acc: 0.988\n",
      "epoch: 235/300 batch 115/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 235/300 batch 116/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 235/300 batch 117/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 235/300 batch 118/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 235/300 batch 119/188  Train Loss: 0.061, Acc: 0.977\n",
      "epoch: 235/300 batch 120/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 235/300 batch 121/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 235/300 batch 122/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 235/300 batch 123/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 235/300 batch 124/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 235/300 batch 125/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 235/300 batch 126/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 235/300 batch 127/188  Train Loss: 0.034, Acc: 0.984\n",
      "epoch: 235/300 batch 128/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 235/300 batch 129/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 235/300 batch 130/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 235/300 batch 131/188  Train Loss: 0.032, Acc: 0.984\n",
      "epoch: 235/300 batch 132/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 235/300 batch 133/188  Train Loss: 0.060, Acc: 0.988\n",
      "epoch: 235/300 batch 134/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 235/300 batch 135/188  Train Loss: 0.057, Acc: 0.977\n",
      "epoch: 235/300 batch 136/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 235/300 batch 137/188  Train Loss: 0.031, Acc: 1.000\n",
      "epoch: 235/300 batch 138/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 235/300 batch 139/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 235/300 batch 140/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 235/300 batch 141/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 235/300 batch 142/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 235/300 batch 143/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 235/300 batch 144/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 235/300 batch 145/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 235/300 batch 146/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 235/300 batch 147/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 235/300 batch 148/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 235/300 batch 149/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 235/300 batch 150/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 235/300 batch 151/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 235/300 batch 152/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 235/300 batch 153/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 235/300 batch 154/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 235/300 batch 155/188  Train Loss: 0.033, Acc: 0.984\n",
      "epoch: 235/300 batch 156/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 235/300 batch 157/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 235/300 batch 158/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 235/300 batch 159/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 235/300 batch 160/188  Train Loss: 0.025, Acc: 0.988\n",
      "epoch: 235/300 batch 161/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 235/300 batch 162/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 235/300 batch 163/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 235/300 batch 164/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 235/300 batch 165/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 235/300 batch 166/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 235/300 batch 167/188  Train Loss: 0.023, Acc: 0.988\n",
      "epoch: 235/300 batch 168/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 235/300 batch 169/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 235/300 batch 170/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 235/300 batch 171/188  Train Loss: 0.042, Acc: 0.996\n",
      "epoch: 235/300 batch 172/188  Train Loss: 0.047, Acc: 0.980\n",
      "epoch: 235/300 batch 173/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 235/300 batch 174/188  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 235/300 batch 175/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 235/300 batch 176/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 235/300 batch 177/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 235/300 batch 178/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 235/300 batch 179/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 235/300 batch 180/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 235/300 batch 181/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 235/300 batch 182/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 235/300 batch 183/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 235/300 batch 184/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 235/300 batch 185/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 235/300 batch 186/188  Train Loss: 0.065, Acc: 0.984\n",
      "epoch: 235/300 batch 187/188  Train Loss: 0.021, Acc: 1.000\n",
      "Train Loss: 0.032932, Acc: 0.992\n",
      "Val Loss: 0.057535, Acc: 0.983\n",
      "epoch: 236/300 batch   0/188  Train Loss: 0.059, Acc: 0.984\n",
      "epoch: 236/300 batch   1/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 236/300 batch   2/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 236/300 batch   3/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 236/300 batch   4/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 236/300 batch   5/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 236/300 batch   6/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 236/300 batch   7/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 236/300 batch   8/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 236/300 batch   9/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 236/300 batch  10/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 236/300 batch  11/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 236/300 batch  12/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 236/300 batch  13/188  Train Loss: 0.057, Acc: 0.977\n",
      "epoch: 236/300 batch  14/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 236/300 batch  15/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 236/300 batch  16/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 236/300 batch  17/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 236/300 batch  18/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 236/300 batch  19/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 236/300 batch  20/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 236/300 batch  21/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 236/300 batch  22/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 236/300 batch  23/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 236/300 batch  24/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 236/300 batch  25/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 236/300 batch  26/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 236/300 batch  27/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 236/300 batch  28/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 236/300 batch  29/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 236/300 batch  30/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 236/300 batch  31/188  Train Loss: 0.034, Acc: 0.984\n",
      "epoch: 236/300 batch  32/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 236/300 batch  33/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 236/300 batch  34/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 236/300 batch  35/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 236/300 batch  36/188  Train Loss: 0.060, Acc: 0.992\n",
      "epoch: 236/300 batch  37/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 236/300 batch  38/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 236/300 batch  39/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 236/300 batch  40/188  Train Loss: 0.053, Acc: 0.980\n",
      "epoch: 236/300 batch  41/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 236/300 batch  42/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 236/300 batch  43/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 236/300 batch  44/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 236/300 batch  45/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 236/300 batch  46/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 236/300 batch  47/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 236/300 batch  48/188  Train Loss: 0.069, Acc: 0.980\n",
      "epoch: 236/300 batch  49/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 236/300 batch  50/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 236/300 batch  51/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 236/300 batch  52/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 236/300 batch  53/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 236/300 batch  54/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 236/300 batch  55/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 236/300 batch  56/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 236/300 batch  57/188  Train Loss: 0.068, Acc: 0.980\n",
      "epoch: 236/300 batch  58/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 236/300 batch  59/188  Train Loss: 0.061, Acc: 0.988\n",
      "epoch: 236/300 batch  60/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 236/300 batch  61/188  Train Loss: 0.059, Acc: 0.984\n",
      "epoch: 236/300 batch  62/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 236/300 batch  63/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 236/300 batch  64/188  Train Loss: 0.042, Acc: 0.996\n",
      "epoch: 236/300 batch  65/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 236/300 batch  66/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 236/300 batch  67/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 236/300 batch  68/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 236/300 batch  69/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 236/300 batch  70/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 236/300 batch  71/188  Train Loss: 0.034, Acc: 0.980\n",
      "epoch: 236/300 batch  72/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 236/300 batch  73/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 236/300 batch  74/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 236/300 batch  75/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 236/300 batch  76/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 236/300 batch  77/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 236/300 batch  78/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 236/300 batch  79/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 236/300 batch  80/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 236/300 batch  81/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 236/300 batch  82/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 236/300 batch  83/188  Train Loss: 0.064, Acc: 0.980\n",
      "epoch: 236/300 batch  84/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 236/300 batch  85/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 236/300 batch  86/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 236/300 batch  87/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 236/300 batch  88/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 236/300 batch  89/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 236/300 batch  90/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 236/300 batch  91/188  Train Loss: 0.051, Acc: 0.992\n",
      "epoch: 236/300 batch  92/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 236/300 batch  93/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 236/300 batch  94/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 236/300 batch  95/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 236/300 batch  96/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 236/300 batch  97/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 236/300 batch  98/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 236/300 batch  99/188  Train Loss: 0.051, Acc: 0.980\n",
      "epoch: 236/300 batch 100/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 236/300 batch 101/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 236/300 batch 102/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 236/300 batch 103/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 236/300 batch 104/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 236/300 batch 105/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 236/300 batch 106/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 236/300 batch 107/188  Train Loss: 0.060, Acc: 0.980\n",
      "epoch: 236/300 batch 108/188  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 236/300 batch 109/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 236/300 batch 110/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 236/300 batch 111/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 236/300 batch 112/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 236/300 batch 113/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 236/300 batch 114/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 236/300 batch 115/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 236/300 batch 116/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 236/300 batch 117/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 236/300 batch 118/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 236/300 batch 119/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 236/300 batch 120/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 236/300 batch 121/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 236/300 batch 122/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 236/300 batch 123/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 236/300 batch 124/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 236/300 batch 125/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 236/300 batch 126/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 236/300 batch 127/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 236/300 batch 128/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 236/300 batch 129/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 236/300 batch 130/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 236/300 batch 131/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 236/300 batch 132/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 236/300 batch 133/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 236/300 batch 134/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 236/300 batch 135/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 236/300 batch 136/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 236/300 batch 137/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 236/300 batch 138/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 236/300 batch 139/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 236/300 batch 140/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 236/300 batch 141/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 236/300 batch 142/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 236/300 batch 143/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 236/300 batch 144/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 236/300 batch 145/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 236/300 batch 146/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 236/300 batch 147/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 236/300 batch 148/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 236/300 batch 149/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 236/300 batch 150/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 236/300 batch 151/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 236/300 batch 152/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 236/300 batch 153/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 236/300 batch 154/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 236/300 batch 155/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 236/300 batch 156/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 236/300 batch 157/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 236/300 batch 158/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 236/300 batch 159/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 236/300 batch 160/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 236/300 batch 161/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 236/300 batch 162/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 236/300 batch 163/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 236/300 batch 164/188  Train Loss: 0.052, Acc: 0.992\n",
      "epoch: 236/300 batch 165/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 236/300 batch 166/188  Train Loss: 0.058, Acc: 0.980\n",
      "epoch: 236/300 batch 167/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 236/300 batch 168/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 236/300 batch 169/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 236/300 batch 170/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 236/300 batch 171/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 236/300 batch 172/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 236/300 batch 173/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 236/300 batch 174/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 236/300 batch 175/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 236/300 batch 176/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 236/300 batch 177/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 236/300 batch 178/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 236/300 batch 179/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 236/300 batch 180/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 236/300 batch 181/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 236/300 batch 182/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 236/300 batch 183/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 236/300 batch 184/188  Train Loss: 0.034, Acc: 1.000\n",
      "epoch: 236/300 batch 185/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 236/300 batch 186/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 236/300 batch 187/188  Train Loss: 0.026, Acc: 0.992\n",
      "Train Loss: 0.032945, Acc: 0.993\n",
      "Val Loss: 0.057484, Acc: 0.984\n",
      "epoch: 237/300 batch   0/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 237/300 batch   1/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 237/300 batch   2/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 237/300 batch   3/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 237/300 batch   4/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 237/300 batch   5/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 237/300 batch   6/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 237/300 batch   7/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 237/300 batch   8/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 237/300 batch   9/188  Train Loss: 0.024, Acc: 0.988\n",
      "epoch: 237/300 batch  10/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 237/300 batch  11/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 237/300 batch  12/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 237/300 batch  13/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 237/300 batch  14/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 237/300 batch  15/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 237/300 batch  16/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 237/300 batch  17/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 237/300 batch  18/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 237/300 batch  19/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 237/300 batch  20/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 237/300 batch  21/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 237/300 batch  22/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 237/300 batch  23/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 237/300 batch  24/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 237/300 batch  25/188  Train Loss: 0.044, Acc: 0.996\n",
      "epoch: 237/300 batch  26/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 237/300 batch  27/188  Train Loss: 0.057, Acc: 0.988\n",
      "epoch: 237/300 batch  28/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 237/300 batch  29/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 237/300 batch  30/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 237/300 batch  31/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 237/300 batch  32/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 237/300 batch  33/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 237/300 batch  34/188  Train Loss: 0.015, Acc: 0.996\n",
      "epoch: 237/300 batch  35/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 237/300 batch  36/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 237/300 batch  37/188  Train Loss: 0.058, Acc: 0.977\n",
      "epoch: 237/300 batch  38/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 237/300 batch  39/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 237/300 batch  40/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 237/300 batch  41/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 237/300 batch  42/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 237/300 batch  43/188  Train Loss: 0.042, Acc: 0.980\n",
      "epoch: 237/300 batch  44/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 237/300 batch  45/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 237/300 batch  46/188  Train Loss: 0.060, Acc: 0.984\n",
      "epoch: 237/300 batch  47/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 237/300 batch  48/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 237/300 batch  49/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 237/300 batch  50/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 237/300 batch  51/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 237/300 batch  52/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 237/300 batch  53/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 237/300 batch  54/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 237/300 batch  55/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 237/300 batch  56/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 237/300 batch  57/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 237/300 batch  58/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 237/300 batch  59/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 237/300 batch  60/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 237/300 batch  61/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 237/300 batch  62/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 237/300 batch  63/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 237/300 batch  64/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 237/300 batch  65/188  Train Loss: 0.066, Acc: 0.992\n",
      "epoch: 237/300 batch  66/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 237/300 batch  67/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 237/300 batch  68/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 237/300 batch  69/188  Train Loss: 0.057, Acc: 0.988\n",
      "epoch: 237/300 batch  70/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 237/300 batch  71/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 237/300 batch  72/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 237/300 batch  73/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 237/300 batch  74/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 237/300 batch  75/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 237/300 batch  76/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 237/300 batch  77/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 237/300 batch  78/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 237/300 batch  79/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 237/300 batch  80/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 237/300 batch  81/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 237/300 batch  82/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 237/300 batch  83/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 237/300 batch  84/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 237/300 batch  85/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 237/300 batch  86/188  Train Loss: 0.046, Acc: 0.980\n",
      "epoch: 237/300 batch  87/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 237/300 batch  88/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 237/300 batch  89/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 237/300 batch  90/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 237/300 batch  91/188  Train Loss: 0.060, Acc: 0.980\n",
      "epoch: 237/300 batch  92/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 237/300 batch  93/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 237/300 batch  94/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 237/300 batch  95/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 237/300 batch  96/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 237/300 batch  97/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 237/300 batch  98/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 237/300 batch  99/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 237/300 batch 100/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 237/300 batch 101/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 237/300 batch 102/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 237/300 batch 103/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 237/300 batch 104/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 237/300 batch 105/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 237/300 batch 106/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 237/300 batch 107/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 237/300 batch 108/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 237/300 batch 109/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 237/300 batch 110/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 237/300 batch 111/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 237/300 batch 112/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 237/300 batch 113/188  Train Loss: 0.059, Acc: 0.980\n",
      "epoch: 237/300 batch 114/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 237/300 batch 115/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 237/300 batch 116/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 237/300 batch 117/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 237/300 batch 118/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 237/300 batch 119/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 237/300 batch 120/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 237/300 batch 121/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 237/300 batch 122/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 237/300 batch 123/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 237/300 batch 124/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 237/300 batch 125/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 237/300 batch 126/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 237/300 batch 127/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 237/300 batch 128/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 237/300 batch 129/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 237/300 batch 130/188  Train Loss: 0.065, Acc: 0.984\n",
      "epoch: 237/300 batch 131/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 237/300 batch 132/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 237/300 batch 133/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 237/300 batch 134/188  Train Loss: 0.047, Acc: 0.980\n",
      "epoch: 237/300 batch 135/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 237/300 batch 136/188  Train Loss: 0.088, Acc: 0.969\n",
      "epoch: 237/300 batch 137/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 237/300 batch 138/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 237/300 batch 139/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 237/300 batch 140/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 237/300 batch 141/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 237/300 batch 142/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 237/300 batch 143/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 237/300 batch 144/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 237/300 batch 145/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 237/300 batch 146/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 237/300 batch 147/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 237/300 batch 148/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 237/300 batch 149/188  Train Loss: 0.065, Acc: 0.984\n",
      "epoch: 237/300 batch 150/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 237/300 batch 151/188  Train Loss: 0.043, Acc: 0.980\n",
      "epoch: 237/300 batch 152/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 237/300 batch 153/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 237/300 batch 154/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 237/300 batch 155/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 237/300 batch 156/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 237/300 batch 157/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 237/300 batch 158/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 237/300 batch 159/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 237/300 batch 160/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 237/300 batch 161/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 237/300 batch 162/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 237/300 batch 163/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 237/300 batch 164/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 237/300 batch 165/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 237/300 batch 166/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 237/300 batch 167/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 237/300 batch 168/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 237/300 batch 169/188  Train Loss: 0.055, Acc: 0.992\n",
      "epoch: 237/300 batch 170/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 237/300 batch 171/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 237/300 batch 172/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 237/300 batch 173/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 237/300 batch 174/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 237/300 batch 175/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 237/300 batch 176/188  Train Loss: 0.033, Acc: 1.000\n",
      "epoch: 237/300 batch 177/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 237/300 batch 178/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 237/300 batch 179/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 237/300 batch 180/188  Train Loss: 0.045, Acc: 0.980\n",
      "epoch: 237/300 batch 181/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 237/300 batch 182/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 237/300 batch 183/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 237/300 batch 184/188  Train Loss: 0.053, Acc: 0.980\n",
      "epoch: 237/300 batch 185/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 237/300 batch 186/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 237/300 batch 187/188  Train Loss: 0.013, Acc: 1.000\n",
      "Train Loss: 0.032889, Acc: 0.993\n",
      "Val Loss: 0.057341, Acc: 0.983\n",
      "epoch: 238/300 batch   0/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 238/300 batch   1/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 238/300 batch   2/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 238/300 batch   3/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 238/300 batch   4/188  Train Loss: 0.051, Acc: 0.980\n",
      "epoch: 238/300 batch   5/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 238/300 batch   6/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 238/300 batch   7/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 238/300 batch   8/188  Train Loss: 0.034, Acc: 0.984\n",
      "epoch: 238/300 batch   9/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 238/300 batch  10/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 238/300 batch  11/188  Train Loss: 0.032, Acc: 0.984\n",
      "epoch: 238/300 batch  12/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 238/300 batch  13/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 238/300 batch  14/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 238/300 batch  15/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 238/300 batch  16/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 238/300 batch  17/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 238/300 batch  18/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 238/300 batch  19/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 238/300 batch  20/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 238/300 batch  21/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 238/300 batch  22/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 238/300 batch  23/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 238/300 batch  24/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 238/300 batch  25/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 238/300 batch  26/188  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 238/300 batch  27/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 238/300 batch  28/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 238/300 batch  29/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 238/300 batch  30/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 238/300 batch  31/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 238/300 batch  32/188  Train Loss: 0.076, Acc: 0.988\n",
      "epoch: 238/300 batch  33/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 238/300 batch  34/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 238/300 batch  35/188  Train Loss: 0.042, Acc: 0.996\n",
      "epoch: 238/300 batch  36/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 238/300 batch  37/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 238/300 batch  38/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 238/300 batch  39/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 238/300 batch  40/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 238/300 batch  41/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 238/300 batch  42/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 238/300 batch  43/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 238/300 batch  44/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 238/300 batch  45/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 238/300 batch  46/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 238/300 batch  47/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 238/300 batch  48/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 238/300 batch  49/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 238/300 batch  50/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 238/300 batch  51/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 238/300 batch  52/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 238/300 batch  53/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 238/300 batch  54/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 238/300 batch  55/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 238/300 batch  56/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 238/300 batch  57/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 238/300 batch  58/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 238/300 batch  59/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 238/300 batch  60/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 238/300 batch  61/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 238/300 batch  62/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 238/300 batch  63/188  Train Loss: 0.062, Acc: 0.980\n",
      "epoch: 238/300 batch  64/188  Train Loss: 0.048, Acc: 0.980\n",
      "epoch: 238/300 batch  65/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 238/300 batch  66/188  Train Loss: 0.059, Acc: 0.988\n",
      "epoch: 238/300 batch  67/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 238/300 batch  68/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 238/300 batch  69/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 238/300 batch  70/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 238/300 batch  71/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 238/300 batch  72/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 238/300 batch  73/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 238/300 batch  74/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 238/300 batch  75/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 238/300 batch  76/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 238/300 batch  77/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 238/300 batch  78/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 238/300 batch  79/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 238/300 batch  80/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 238/300 batch  81/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 238/300 batch  82/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 238/300 batch  83/188  Train Loss: 0.034, Acc: 0.984\n",
      "epoch: 238/300 batch  84/188  Train Loss: 0.064, Acc: 0.980\n",
      "epoch: 238/300 batch  85/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 238/300 batch  86/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 238/300 batch  87/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 238/300 batch  88/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 238/300 batch  89/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 238/300 batch  90/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 238/300 batch  91/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 238/300 batch  92/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 238/300 batch  93/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 238/300 batch  94/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 238/300 batch  95/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 238/300 batch  96/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 238/300 batch  97/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 238/300 batch  98/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 238/300 batch  99/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 238/300 batch 100/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 238/300 batch 101/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 238/300 batch 102/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 238/300 batch 103/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 238/300 batch 104/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 238/300 batch 105/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 238/300 batch 106/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 238/300 batch 107/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 238/300 batch 108/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 238/300 batch 109/188  Train Loss: 0.059, Acc: 0.984\n",
      "epoch: 238/300 batch 110/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 238/300 batch 111/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 238/300 batch 112/188  Train Loss: 0.014, Acc: 0.996\n",
      "epoch: 238/300 batch 113/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 238/300 batch 114/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 238/300 batch 115/188  Train Loss: 0.044, Acc: 0.980\n",
      "epoch: 238/300 batch 116/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 238/300 batch 117/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 238/300 batch 118/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 238/300 batch 119/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 238/300 batch 120/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 238/300 batch 121/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 238/300 batch 122/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 238/300 batch 123/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 238/300 batch 124/188  Train Loss: 0.071, Acc: 0.988\n",
      "epoch: 238/300 batch 125/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 238/300 batch 126/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 238/300 batch 127/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 238/300 batch 128/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 238/300 batch 129/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 238/300 batch 130/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 238/300 batch 131/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 238/300 batch 132/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 238/300 batch 133/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 238/300 batch 134/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 238/300 batch 135/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 238/300 batch 136/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 238/300 batch 137/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 238/300 batch 138/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 238/300 batch 139/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 238/300 batch 140/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 238/300 batch 141/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 238/300 batch 142/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 238/300 batch 143/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 238/300 batch 144/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 238/300 batch 145/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 238/300 batch 146/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 238/300 batch 147/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 238/300 batch 148/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 238/300 batch 149/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 238/300 batch 150/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 238/300 batch 151/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 238/300 batch 152/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 238/300 batch 153/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 238/300 batch 154/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 238/300 batch 155/188  Train Loss: 0.063, Acc: 0.984\n",
      "epoch: 238/300 batch 156/188  Train Loss: 0.049, Acc: 0.980\n",
      "epoch: 238/300 batch 157/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 238/300 batch 158/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 238/300 batch 159/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 238/300 batch 160/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 238/300 batch 161/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 238/300 batch 162/188  Train Loss: 0.051, Acc: 0.977\n",
      "epoch: 238/300 batch 163/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 238/300 batch 164/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 238/300 batch 165/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 238/300 batch 166/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 238/300 batch 167/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 238/300 batch 168/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 238/300 batch 169/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 238/300 batch 170/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 238/300 batch 171/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 238/300 batch 172/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 238/300 batch 173/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 238/300 batch 174/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 238/300 batch 175/188  Train Loss: 0.047, Acc: 0.980\n",
      "epoch: 238/300 batch 176/188  Train Loss: 0.054, Acc: 0.980\n",
      "epoch: 238/300 batch 177/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 238/300 batch 178/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 238/300 batch 179/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 238/300 batch 180/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 238/300 batch 181/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 238/300 batch 182/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 238/300 batch 183/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 238/300 batch 184/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 238/300 batch 185/188  Train Loss: 0.039, Acc: 0.980\n",
      "epoch: 238/300 batch 186/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 238/300 batch 187/188  Train Loss: 0.045, Acc: 0.984\n",
      "Train Loss: 0.032915, Acc: 0.993\n",
      "Val Loss: 0.057179, Acc: 0.983\n",
      "epoch: 239/300 batch   0/188  Train Loss: 0.046, Acc: 0.980\n",
      "epoch: 239/300 batch   1/188  Train Loss: 0.061, Acc: 0.980\n",
      "epoch: 239/300 batch   2/188  Train Loss: 0.026, Acc: 0.988\n",
      "epoch: 239/300 batch   3/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 239/300 batch   4/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 239/300 batch   5/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 239/300 batch   6/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 239/300 batch   7/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 239/300 batch   8/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 239/300 batch   9/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 239/300 batch  10/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 239/300 batch  11/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 239/300 batch  12/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 239/300 batch  13/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 239/300 batch  14/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 239/300 batch  15/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 239/300 batch  16/188  Train Loss: 0.060, Acc: 0.996\n",
      "epoch: 239/300 batch  17/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 239/300 batch  18/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 239/300 batch  19/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 239/300 batch  20/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 239/300 batch  21/188  Train Loss: 0.061, Acc: 0.992\n",
      "epoch: 239/300 batch  22/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 239/300 batch  23/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 239/300 batch  24/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 239/300 batch  25/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 239/300 batch  26/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 239/300 batch  27/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 239/300 batch  28/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 239/300 batch  29/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 239/300 batch  30/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 239/300 batch  31/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 239/300 batch  32/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 239/300 batch  33/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 239/300 batch  34/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 239/300 batch  35/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 239/300 batch  36/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 239/300 batch  37/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 239/300 batch  38/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 239/300 batch  39/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 239/300 batch  40/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 239/300 batch  41/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 239/300 batch  42/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 239/300 batch  43/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 239/300 batch  44/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 239/300 batch  45/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 239/300 batch  46/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 239/300 batch  47/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 239/300 batch  48/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 239/300 batch  49/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 239/300 batch  50/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 239/300 batch  51/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 239/300 batch  52/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 239/300 batch  53/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 239/300 batch  54/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 239/300 batch  55/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 239/300 batch  56/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 239/300 batch  57/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 239/300 batch  58/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 239/300 batch  59/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 239/300 batch  60/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 239/300 batch  61/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 239/300 batch  62/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 239/300 batch  63/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 239/300 batch  64/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 239/300 batch  65/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 239/300 batch  66/188  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 239/300 batch  67/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 239/300 batch  68/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 239/300 batch  69/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 239/300 batch  70/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 239/300 batch  71/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 239/300 batch  72/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 239/300 batch  73/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 239/300 batch  74/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 239/300 batch  75/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 239/300 batch  76/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 239/300 batch  77/188  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 239/300 batch  78/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 239/300 batch  79/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 239/300 batch  80/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 239/300 batch  81/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 239/300 batch  82/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 239/300 batch  83/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 239/300 batch  84/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 239/300 batch  85/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 239/300 batch  86/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 239/300 batch  87/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 239/300 batch  88/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 239/300 batch  89/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 239/300 batch  90/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 239/300 batch  91/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 239/300 batch  92/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 239/300 batch  93/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 239/300 batch  94/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 239/300 batch  95/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 239/300 batch  96/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 239/300 batch  97/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 239/300 batch  98/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 239/300 batch  99/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 239/300 batch 100/188  Train Loss: 0.057, Acc: 0.980\n",
      "epoch: 239/300 batch 101/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 239/300 batch 102/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 239/300 batch 103/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 239/300 batch 104/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 239/300 batch 105/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 239/300 batch 106/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 239/300 batch 107/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 239/300 batch 108/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 239/300 batch 109/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 239/300 batch 110/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 239/300 batch 111/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 239/300 batch 112/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 239/300 batch 113/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 239/300 batch 114/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 239/300 batch 115/188  Train Loss: 0.033, Acc: 0.984\n",
      "epoch: 239/300 batch 116/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 239/300 batch 117/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 239/300 batch 118/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 239/300 batch 119/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 239/300 batch 120/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 239/300 batch 121/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 239/300 batch 122/188  Train Loss: 0.064, Acc: 0.980\n",
      "epoch: 239/300 batch 123/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 239/300 batch 124/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 239/300 batch 125/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 239/300 batch 126/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 239/300 batch 127/188  Train Loss: 0.016, Acc: 0.996\n",
      "epoch: 239/300 batch 128/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 239/300 batch 129/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 239/300 batch 130/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 239/300 batch 131/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 239/300 batch 132/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 239/300 batch 133/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 239/300 batch 134/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 239/300 batch 135/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 239/300 batch 136/188  Train Loss: 0.031, Acc: 1.000\n",
      "epoch: 239/300 batch 137/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 239/300 batch 138/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 239/300 batch 139/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 239/300 batch 140/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 239/300 batch 141/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 239/300 batch 142/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 239/300 batch 143/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 239/300 batch 144/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 239/300 batch 145/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 239/300 batch 146/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 239/300 batch 147/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 239/300 batch 148/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 239/300 batch 149/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 239/300 batch 150/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 239/300 batch 151/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 239/300 batch 152/188  Train Loss: 0.065, Acc: 0.973\n",
      "epoch: 239/300 batch 153/188  Train Loss: 0.062, Acc: 0.977\n",
      "epoch: 239/300 batch 154/188  Train Loss: 0.048, Acc: 0.996\n",
      "epoch: 239/300 batch 155/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 239/300 batch 156/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 239/300 batch 157/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 239/300 batch 158/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 239/300 batch 159/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 239/300 batch 160/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 239/300 batch 161/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 239/300 batch 162/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 239/300 batch 163/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 239/300 batch 164/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 239/300 batch 165/188  Train Loss: 0.067, Acc: 0.980\n",
      "epoch: 239/300 batch 166/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 239/300 batch 167/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 239/300 batch 168/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 239/300 batch 169/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 239/300 batch 170/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 239/300 batch 171/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 239/300 batch 172/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 239/300 batch 173/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 239/300 batch 174/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 239/300 batch 175/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 239/300 batch 176/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 239/300 batch 177/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 239/300 batch 178/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 239/300 batch 179/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 239/300 batch 180/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 239/300 batch 181/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 239/300 batch 182/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 239/300 batch 183/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 239/300 batch 184/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 239/300 batch 185/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 239/300 batch 186/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 239/300 batch 187/188  Train Loss: 0.032, Acc: 0.984\n",
      "Train Loss: 0.032940, Acc: 0.993\n",
      "Val Loss: 0.057223, Acc: 0.983\n",
      "epoch: 240/300 batch   0/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 240/300 batch   1/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 240/300 batch   2/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 240/300 batch   3/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 240/300 batch   4/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 240/300 batch   5/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 240/300 batch   6/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 240/300 batch   7/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 240/300 batch   8/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 240/300 batch   9/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 240/300 batch  10/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 240/300 batch  11/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 240/300 batch  12/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 240/300 batch  13/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 240/300 batch  14/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 240/300 batch  15/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 240/300 batch  16/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 240/300 batch  17/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 240/300 batch  18/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 240/300 batch  19/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 240/300 batch  20/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 240/300 batch  21/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 240/300 batch  22/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 240/300 batch  23/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 240/300 batch  24/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 240/300 batch  25/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 240/300 batch  26/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 240/300 batch  27/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 240/300 batch  28/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 240/300 batch  29/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 240/300 batch  30/188  Train Loss: 0.055, Acc: 0.980\n",
      "epoch: 240/300 batch  31/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 240/300 batch  32/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 240/300 batch  33/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 240/300 batch  34/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 240/300 batch  35/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 240/300 batch  36/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 240/300 batch  37/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 240/300 batch  38/188  Train Loss: 0.053, Acc: 0.980\n",
      "epoch: 240/300 batch  39/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 240/300 batch  40/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 240/300 batch  41/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 240/300 batch  42/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 240/300 batch  43/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 240/300 batch  44/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 240/300 batch  45/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 240/300 batch  46/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 240/300 batch  47/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 240/300 batch  48/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 240/300 batch  49/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 240/300 batch  50/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 240/300 batch  51/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 240/300 batch  52/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 240/300 batch  53/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 240/300 batch  54/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 240/300 batch  55/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 240/300 batch  56/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 240/300 batch  57/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 240/300 batch  58/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 240/300 batch  59/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 240/300 batch  60/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 240/300 batch  61/188  Train Loss: 0.051, Acc: 0.992\n",
      "epoch: 240/300 batch  62/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 240/300 batch  63/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 240/300 batch  64/188  Train Loss: 0.103, Acc: 0.980\n",
      "epoch: 240/300 batch  65/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 240/300 batch  66/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 240/300 batch  67/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 240/300 batch  68/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 240/300 batch  69/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 240/300 batch  70/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 240/300 batch  71/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 240/300 batch  72/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 240/300 batch  73/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 240/300 batch  74/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 240/300 batch  75/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 240/300 batch  76/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 240/300 batch  77/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 240/300 batch  78/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 240/300 batch  79/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 240/300 batch  80/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 240/300 batch  81/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 240/300 batch  82/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 240/300 batch  83/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 240/300 batch  84/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 240/300 batch  85/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 240/300 batch  86/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 240/300 batch  87/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 240/300 batch  88/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 240/300 batch  89/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 240/300 batch  90/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 240/300 batch  91/188  Train Loss: 0.052, Acc: 0.977\n",
      "epoch: 240/300 batch  92/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 240/300 batch  93/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 240/300 batch  94/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 240/300 batch  95/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 240/300 batch  96/188  Train Loss: 0.031, Acc: 1.000\n",
      "epoch: 240/300 batch  97/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 240/300 batch  98/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 240/300 batch  99/188  Train Loss: 0.036, Acc: 0.980\n",
      "epoch: 240/300 batch 100/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 240/300 batch 101/188  Train Loss: 0.043, Acc: 0.996\n",
      "epoch: 240/300 batch 102/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 240/300 batch 103/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 240/300 batch 104/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 240/300 batch 105/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 240/300 batch 106/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 240/300 batch 107/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 240/300 batch 108/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 240/300 batch 109/188  Train Loss: 0.047, Acc: 0.996\n",
      "epoch: 240/300 batch 110/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 240/300 batch 111/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 240/300 batch 112/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 240/300 batch 113/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 240/300 batch 114/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 240/300 batch 115/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 240/300 batch 116/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 240/300 batch 117/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 240/300 batch 118/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 240/300 batch 119/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 240/300 batch 120/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 240/300 batch 121/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 240/300 batch 122/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 240/300 batch 123/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 240/300 batch 124/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 240/300 batch 125/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 240/300 batch 126/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 240/300 batch 127/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 240/300 batch 128/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 240/300 batch 129/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 240/300 batch 130/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 240/300 batch 131/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 240/300 batch 132/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 240/300 batch 133/188  Train Loss: 0.027, Acc: 0.988\n",
      "epoch: 240/300 batch 134/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 240/300 batch 135/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 240/300 batch 136/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 240/300 batch 137/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 240/300 batch 138/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 240/300 batch 139/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 240/300 batch 140/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 240/300 batch 141/188  Train Loss: 0.025, Acc: 0.988\n",
      "epoch: 240/300 batch 142/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 240/300 batch 143/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 240/300 batch 144/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 240/300 batch 145/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 240/300 batch 146/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 240/300 batch 147/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 240/300 batch 148/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 240/300 batch 149/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 240/300 batch 150/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 240/300 batch 151/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 240/300 batch 152/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 240/300 batch 153/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 240/300 batch 154/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 240/300 batch 155/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 240/300 batch 156/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 240/300 batch 157/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 240/300 batch 158/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 240/300 batch 159/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 240/300 batch 160/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 240/300 batch 161/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 240/300 batch 162/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 240/300 batch 163/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 240/300 batch 164/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 240/300 batch 165/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 240/300 batch 166/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 240/300 batch 167/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 240/300 batch 168/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 240/300 batch 169/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 240/300 batch 170/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 240/300 batch 171/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 240/300 batch 172/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 240/300 batch 173/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 240/300 batch 174/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 240/300 batch 175/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 240/300 batch 176/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 240/300 batch 177/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 240/300 batch 178/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 240/300 batch 179/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 240/300 batch 180/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 240/300 batch 181/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 240/300 batch 182/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 240/300 batch 183/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 240/300 batch 184/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 240/300 batch 185/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 240/300 batch 186/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 240/300 batch 187/188  Train Loss: 0.031, Acc: 0.984\n",
      "Train Loss: 0.032914, Acc: 0.993\n",
      "Val Loss: 0.057497, Acc: 0.983\n",
      "epoch: 241/300 batch   0/188  Train Loss: 0.053, Acc: 0.992\n",
      "epoch: 241/300 batch   1/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 241/300 batch   2/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 241/300 batch   3/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 241/300 batch   4/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 241/300 batch   5/188  Train Loss: 0.035, Acc: 1.000\n",
      "epoch: 241/300 batch   6/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 241/300 batch   7/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 241/300 batch   8/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 241/300 batch   9/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 241/300 batch  10/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 241/300 batch  11/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 241/300 batch  12/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 241/300 batch  13/188  Train Loss: 0.066, Acc: 0.988\n",
      "epoch: 241/300 batch  14/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 241/300 batch  15/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 241/300 batch  16/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 241/300 batch  17/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 241/300 batch  18/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 241/300 batch  19/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 241/300 batch  20/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 241/300 batch  21/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 241/300 batch  22/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 241/300 batch  23/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 241/300 batch  24/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 241/300 batch  25/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 241/300 batch  26/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 241/300 batch  27/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 241/300 batch  28/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 241/300 batch  29/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 241/300 batch  30/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 241/300 batch  31/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 241/300 batch  32/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 241/300 batch  33/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 241/300 batch  34/188  Train Loss: 0.031, Acc: 1.000\n",
      "epoch: 241/300 batch  35/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 241/300 batch  36/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 241/300 batch  37/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 241/300 batch  38/188  Train Loss: 0.046, Acc: 0.996\n",
      "epoch: 241/300 batch  39/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 241/300 batch  40/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 241/300 batch  41/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 241/300 batch  42/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 241/300 batch  43/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 241/300 batch  44/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 241/300 batch  45/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 241/300 batch  46/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 241/300 batch  47/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 241/300 batch  48/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 241/300 batch  49/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 241/300 batch  50/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 241/300 batch  51/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 241/300 batch  52/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 241/300 batch  53/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 241/300 batch  54/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 241/300 batch  55/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 241/300 batch  56/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 241/300 batch  57/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 241/300 batch  58/188  Train Loss: 0.060, Acc: 0.984\n",
      "epoch: 241/300 batch  59/188  Train Loss: 0.061, Acc: 0.988\n",
      "epoch: 241/300 batch  60/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 241/300 batch  61/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 241/300 batch  62/188  Train Loss: 0.050, Acc: 0.980\n",
      "epoch: 241/300 batch  63/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 241/300 batch  64/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 241/300 batch  65/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 241/300 batch  66/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 241/300 batch  67/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 241/300 batch  68/188  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 241/300 batch  69/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 241/300 batch  70/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 241/300 batch  71/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 241/300 batch  72/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 241/300 batch  73/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 241/300 batch  74/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 241/300 batch  75/188  Train Loss: 0.049, Acc: 0.980\n",
      "epoch: 241/300 batch  76/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 241/300 batch  77/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 241/300 batch  78/188  Train Loss: 0.053, Acc: 0.980\n",
      "epoch: 241/300 batch  79/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 241/300 batch  80/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 241/300 batch  81/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 241/300 batch  82/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 241/300 batch  83/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 241/300 batch  84/188  Train Loss: 0.043, Acc: 0.996\n",
      "epoch: 241/300 batch  85/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 241/300 batch  86/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 241/300 batch  87/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 241/300 batch  88/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 241/300 batch  89/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 241/300 batch  90/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 241/300 batch  91/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 241/300 batch  92/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 241/300 batch  93/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 241/300 batch  94/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 241/300 batch  95/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 241/300 batch  96/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 241/300 batch  97/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 241/300 batch  98/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 241/300 batch  99/188  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 241/300 batch 100/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 241/300 batch 101/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 241/300 batch 102/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 241/300 batch 103/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 241/300 batch 104/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 241/300 batch 105/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 241/300 batch 106/188  Train Loss: 0.049, Acc: 0.980\n",
      "epoch: 241/300 batch 107/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 241/300 batch 108/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 241/300 batch 109/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 241/300 batch 110/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 241/300 batch 111/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 241/300 batch 112/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 241/300 batch 113/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 241/300 batch 114/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 241/300 batch 115/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 241/300 batch 116/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 241/300 batch 117/188  Train Loss: 0.064, Acc: 0.977\n",
      "epoch: 241/300 batch 118/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 241/300 batch 119/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 241/300 batch 120/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 241/300 batch 121/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 241/300 batch 122/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 241/300 batch 123/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 241/300 batch 124/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 241/300 batch 125/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 241/300 batch 126/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 241/300 batch 127/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 241/300 batch 128/188  Train Loss: 0.049, Acc: 0.980\n",
      "epoch: 241/300 batch 129/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 241/300 batch 130/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 241/300 batch 131/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 241/300 batch 132/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 241/300 batch 133/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 241/300 batch 134/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 241/300 batch 135/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 241/300 batch 136/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 241/300 batch 137/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 241/300 batch 138/188  Train Loss: 0.042, Acc: 0.996\n",
      "epoch: 241/300 batch 139/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 241/300 batch 140/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 241/300 batch 141/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 241/300 batch 142/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 241/300 batch 143/188  Train Loss: 0.056, Acc: 0.988\n",
      "epoch: 241/300 batch 144/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 241/300 batch 145/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 241/300 batch 146/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 241/300 batch 147/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 241/300 batch 148/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 241/300 batch 149/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 241/300 batch 150/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 241/300 batch 151/188  Train Loss: 0.062, Acc: 0.980\n",
      "epoch: 241/300 batch 152/188  Train Loss: 0.027, Acc: 0.988\n",
      "epoch: 241/300 batch 153/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 241/300 batch 154/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 241/300 batch 155/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 241/300 batch 156/188  Train Loss: 0.034, Acc: 1.000\n",
      "epoch: 241/300 batch 157/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 241/300 batch 158/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 241/300 batch 159/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 241/300 batch 160/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 241/300 batch 161/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 241/300 batch 162/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 241/300 batch 163/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 241/300 batch 164/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 241/300 batch 165/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 241/300 batch 166/188  Train Loss: 0.053, Acc: 0.992\n",
      "epoch: 241/300 batch 167/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 241/300 batch 168/188  Train Loss: 0.058, Acc: 0.992\n",
      "epoch: 241/300 batch 169/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 241/300 batch 170/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 241/300 batch 171/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 241/300 batch 172/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 241/300 batch 173/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 241/300 batch 174/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 241/300 batch 175/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 241/300 batch 176/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 241/300 batch 177/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 241/300 batch 178/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 241/300 batch 179/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 241/300 batch 180/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 241/300 batch 181/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 241/300 batch 182/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 241/300 batch 183/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 241/300 batch 184/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 241/300 batch 185/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 241/300 batch 186/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 241/300 batch 187/188  Train Loss: 0.013, Acc: 1.000\n",
      "Train Loss: 0.032775, Acc: 0.993\n",
      "Val Loss: 0.057520, Acc: 0.983\n",
      "epoch: 242/300 batch   0/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 242/300 batch   1/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 242/300 batch   2/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 242/300 batch   3/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 242/300 batch   4/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 242/300 batch   5/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 242/300 batch   6/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 242/300 batch   7/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 242/300 batch   8/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 242/300 batch   9/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 242/300 batch  10/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 242/300 batch  11/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 242/300 batch  12/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 242/300 batch  13/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 242/300 batch  14/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 242/300 batch  15/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 242/300 batch  16/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 242/300 batch  17/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 242/300 batch  18/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 242/300 batch  19/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 242/300 batch  20/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 242/300 batch  21/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 242/300 batch  22/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 242/300 batch  23/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 242/300 batch  24/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 242/300 batch  25/188  Train Loss: 0.059, Acc: 0.988\n",
      "epoch: 242/300 batch  26/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 242/300 batch  27/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 242/300 batch  28/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 242/300 batch  29/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 242/300 batch  30/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 242/300 batch  31/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 242/300 batch  32/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 242/300 batch  33/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 242/300 batch  34/188  Train Loss: 0.026, Acc: 0.988\n",
      "epoch: 242/300 batch  35/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 242/300 batch  36/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 242/300 batch  37/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 242/300 batch  38/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 242/300 batch  39/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 242/300 batch  40/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 242/300 batch  41/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 242/300 batch  42/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 242/300 batch  43/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 242/300 batch  44/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 242/300 batch  45/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 242/300 batch  46/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 242/300 batch  47/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 242/300 batch  48/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 242/300 batch  49/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 242/300 batch  50/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 242/300 batch  51/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 242/300 batch  52/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 242/300 batch  53/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 242/300 batch  54/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 242/300 batch  55/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 242/300 batch  56/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 242/300 batch  57/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 242/300 batch  58/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 242/300 batch  59/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 242/300 batch  60/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 242/300 batch  61/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 242/300 batch  62/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 242/300 batch  63/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 242/300 batch  64/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 242/300 batch  65/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 242/300 batch  66/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 242/300 batch  67/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 242/300 batch  68/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 242/300 batch  69/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 242/300 batch  70/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 242/300 batch  71/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 242/300 batch  72/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 242/300 batch  73/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 242/300 batch  74/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 242/300 batch  75/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 242/300 batch  76/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 242/300 batch  77/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 242/300 batch  78/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 242/300 batch  79/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 242/300 batch  80/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 242/300 batch  81/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 242/300 batch  82/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 242/300 batch  83/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 242/300 batch  84/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 242/300 batch  85/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 242/300 batch  86/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 242/300 batch  87/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 242/300 batch  88/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 242/300 batch  89/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 242/300 batch  90/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 242/300 batch  91/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 242/300 batch  92/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 242/300 batch  93/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 242/300 batch  94/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 242/300 batch  95/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 242/300 batch  96/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 242/300 batch  97/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 242/300 batch  98/188  Train Loss: 0.063, Acc: 0.984\n",
      "epoch: 242/300 batch  99/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 242/300 batch 100/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 242/300 batch 101/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 242/300 batch 102/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 242/300 batch 103/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 242/300 batch 104/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 242/300 batch 105/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 242/300 batch 106/188  Train Loss: 0.052, Acc: 0.992\n",
      "epoch: 242/300 batch 107/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 242/300 batch 108/188  Train Loss: 0.050, Acc: 0.996\n",
      "epoch: 242/300 batch 109/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 242/300 batch 110/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 242/300 batch 111/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 242/300 batch 112/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 242/300 batch 113/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 242/300 batch 114/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 242/300 batch 115/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 242/300 batch 116/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 242/300 batch 117/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 242/300 batch 118/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 242/300 batch 119/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 242/300 batch 120/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 242/300 batch 121/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 242/300 batch 122/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 242/300 batch 123/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 242/300 batch 124/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 242/300 batch 125/188  Train Loss: 0.057, Acc: 0.988\n",
      "epoch: 242/300 batch 126/188  Train Loss: 0.055, Acc: 0.980\n",
      "epoch: 242/300 batch 127/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 242/300 batch 128/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 242/300 batch 129/188  Train Loss: 0.051, Acc: 0.992\n",
      "epoch: 242/300 batch 130/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 242/300 batch 131/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 242/300 batch 132/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 242/300 batch 133/188  Train Loss: 0.041, Acc: 0.980\n",
      "epoch: 242/300 batch 134/188  Train Loss: 0.061, Acc: 0.996\n",
      "epoch: 242/300 batch 135/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 242/300 batch 136/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 242/300 batch 137/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 242/300 batch 138/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 242/300 batch 139/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 242/300 batch 140/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 242/300 batch 141/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 242/300 batch 142/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 242/300 batch 143/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 242/300 batch 144/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 242/300 batch 145/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 242/300 batch 146/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 242/300 batch 147/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 242/300 batch 148/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 242/300 batch 149/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 242/300 batch 150/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 242/300 batch 151/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 242/300 batch 152/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 242/300 batch 153/188  Train Loss: 0.048, Acc: 0.977\n",
      "epoch: 242/300 batch 154/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 242/300 batch 155/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 242/300 batch 156/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 242/300 batch 157/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 242/300 batch 158/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 242/300 batch 159/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 242/300 batch 160/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 242/300 batch 161/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 242/300 batch 162/188  Train Loss: 0.057, Acc: 0.973\n",
      "epoch: 242/300 batch 163/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 242/300 batch 164/188  Train Loss: 0.046, Acc: 0.996\n",
      "epoch: 242/300 batch 165/188  Train Loss: 0.052, Acc: 0.980\n",
      "epoch: 242/300 batch 166/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 242/300 batch 167/188  Train Loss: 0.062, Acc: 0.977\n",
      "epoch: 242/300 batch 168/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 242/300 batch 169/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 242/300 batch 170/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 242/300 batch 171/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 242/300 batch 172/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 242/300 batch 173/188  Train Loss: 0.045, Acc: 0.980\n",
      "epoch: 242/300 batch 174/188  Train Loss: 0.064, Acc: 0.980\n",
      "epoch: 242/300 batch 175/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 242/300 batch 176/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 242/300 batch 177/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 242/300 batch 178/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 242/300 batch 179/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 242/300 batch 180/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 242/300 batch 181/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 242/300 batch 182/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 242/300 batch 183/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 242/300 batch 184/188  Train Loss: 0.027, Acc: 0.984\n",
      "epoch: 242/300 batch 185/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 242/300 batch 186/188  Train Loss: 0.051, Acc: 0.992\n",
      "epoch: 242/300 batch 187/188  Train Loss: 0.084, Acc: 0.969\n",
      "Train Loss: 0.033058, Acc: 0.993\n",
      "Val Loss: 0.057304, Acc: 0.983\n",
      "epoch: 243/300 batch   0/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 243/300 batch   1/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 243/300 batch   2/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 243/300 batch   3/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 243/300 batch   4/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 243/300 batch   5/188  Train Loss: 0.069, Acc: 0.984\n",
      "epoch: 243/300 batch   6/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 243/300 batch   7/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 243/300 batch   8/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 243/300 batch   9/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 243/300 batch  10/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 243/300 batch  11/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 243/300 batch  12/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 243/300 batch  13/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 243/300 batch  14/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 243/300 batch  15/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 243/300 batch  16/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 243/300 batch  17/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 243/300 batch  18/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 243/300 batch  19/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 243/300 batch  20/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 243/300 batch  21/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 243/300 batch  22/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 243/300 batch  23/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 243/300 batch  24/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 243/300 batch  25/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 243/300 batch  26/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 243/300 batch  27/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 243/300 batch  28/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 243/300 batch  29/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 243/300 batch  30/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 243/300 batch  31/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 243/300 batch  32/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 243/300 batch  33/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 243/300 batch  34/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 243/300 batch  35/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 243/300 batch  36/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 243/300 batch  37/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 243/300 batch  38/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 243/300 batch  39/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 243/300 batch  40/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 243/300 batch  41/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 243/300 batch  42/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 243/300 batch  43/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 243/300 batch  44/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 243/300 batch  45/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 243/300 batch  46/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 243/300 batch  47/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 243/300 batch  48/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 243/300 batch  49/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 243/300 batch  50/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 243/300 batch  51/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 243/300 batch  52/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 243/300 batch  53/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 243/300 batch  54/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 243/300 batch  55/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 243/300 batch  56/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 243/300 batch  57/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 243/300 batch  58/188  Train Loss: 0.060, Acc: 0.984\n",
      "epoch: 243/300 batch  59/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 243/300 batch  60/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 243/300 batch  61/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 243/300 batch  62/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 243/300 batch  63/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 243/300 batch  64/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 243/300 batch  65/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 243/300 batch  66/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 243/300 batch  67/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 243/300 batch  68/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 243/300 batch  69/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 243/300 batch  70/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 243/300 batch  71/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 243/300 batch  72/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 243/300 batch  73/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 243/300 batch  74/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 243/300 batch  75/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 243/300 batch  76/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 243/300 batch  77/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 243/300 batch  78/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 243/300 batch  79/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 243/300 batch  80/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 243/300 batch  81/188  Train Loss: 0.075, Acc: 0.984\n",
      "epoch: 243/300 batch  82/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 243/300 batch  83/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 243/300 batch  84/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 243/300 batch  85/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 243/300 batch  86/188  Train Loss: 0.015, Acc: 0.996\n",
      "epoch: 243/300 batch  87/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 243/300 batch  88/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 243/300 batch  89/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 243/300 batch  90/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 243/300 batch  91/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 243/300 batch  92/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 243/300 batch  93/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 243/300 batch  94/188  Train Loss: 0.066, Acc: 0.980\n",
      "epoch: 243/300 batch  95/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 243/300 batch  96/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 243/300 batch  97/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 243/300 batch  98/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 243/300 batch  99/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 243/300 batch 100/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 243/300 batch 101/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 243/300 batch 102/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 243/300 batch 103/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 243/300 batch 104/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 243/300 batch 105/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 243/300 batch 106/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 243/300 batch 107/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 243/300 batch 108/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 243/300 batch 109/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 243/300 batch 110/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 243/300 batch 111/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 243/300 batch 112/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 243/300 batch 113/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 243/300 batch 114/188  Train Loss: 0.016, Acc: 0.996\n",
      "epoch: 243/300 batch 115/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 243/300 batch 116/188  Train Loss: 0.058, Acc: 0.988\n",
      "epoch: 243/300 batch 117/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 243/300 batch 118/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 243/300 batch 119/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 243/300 batch 120/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 243/300 batch 121/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 243/300 batch 122/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 243/300 batch 123/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 243/300 batch 124/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 243/300 batch 125/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 243/300 batch 126/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 243/300 batch 127/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 243/300 batch 128/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 243/300 batch 129/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 243/300 batch 130/188  Train Loss: 0.057, Acc: 0.980\n",
      "epoch: 243/300 batch 131/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 243/300 batch 132/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 243/300 batch 133/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 243/300 batch 134/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 243/300 batch 135/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 243/300 batch 136/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 243/300 batch 137/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 243/300 batch 138/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 243/300 batch 139/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 243/300 batch 140/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 243/300 batch 141/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 243/300 batch 142/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 243/300 batch 143/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 243/300 batch 144/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 243/300 batch 145/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 243/300 batch 146/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 243/300 batch 147/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 243/300 batch 148/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 243/300 batch 149/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 243/300 batch 150/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 243/300 batch 151/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 243/300 batch 152/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 243/300 batch 153/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 243/300 batch 154/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 243/300 batch 155/188  Train Loss: 0.055, Acc: 0.980\n",
      "epoch: 243/300 batch 156/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 243/300 batch 157/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 243/300 batch 158/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 243/300 batch 159/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 243/300 batch 160/188  Train Loss: 0.049, Acc: 0.980\n",
      "epoch: 243/300 batch 161/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 243/300 batch 162/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 243/300 batch 163/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 243/300 batch 164/188  Train Loss: 0.026, Acc: 0.988\n",
      "epoch: 243/300 batch 165/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 243/300 batch 166/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 243/300 batch 167/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 243/300 batch 168/188  Train Loss: 0.063, Acc: 0.984\n",
      "epoch: 243/300 batch 169/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 243/300 batch 170/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 243/300 batch 171/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 243/300 batch 172/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 243/300 batch 173/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 243/300 batch 174/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 243/300 batch 175/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 243/300 batch 176/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 243/300 batch 177/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 243/300 batch 178/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 243/300 batch 179/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 243/300 batch 180/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 243/300 batch 181/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 243/300 batch 182/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 243/300 batch 183/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 243/300 batch 184/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 243/300 batch 185/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 243/300 batch 186/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 243/300 batch 187/188  Train Loss: 0.059, Acc: 0.992\n",
      "Train Loss: 0.032989, Acc: 0.993\n",
      "Val Loss: 0.057185, Acc: 0.983\n",
      "epoch: 244/300 batch   0/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 244/300 batch   1/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 244/300 batch   2/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 244/300 batch   3/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 244/300 batch   4/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 244/300 batch   5/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 244/300 batch   6/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 244/300 batch   7/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 244/300 batch   8/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 244/300 batch   9/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 244/300 batch  10/188  Train Loss: 0.060, Acc: 0.992\n",
      "epoch: 244/300 batch  11/188  Train Loss: 0.061, Acc: 0.992\n",
      "epoch: 244/300 batch  12/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 244/300 batch  13/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 244/300 batch  14/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 244/300 batch  15/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 244/300 batch  16/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 244/300 batch  17/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 244/300 batch  18/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 244/300 batch  19/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 244/300 batch  20/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 244/300 batch  21/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 244/300 batch  22/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 244/300 batch  23/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 244/300 batch  24/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 244/300 batch  25/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 244/300 batch  26/188  Train Loss: 0.051, Acc: 0.980\n",
      "epoch: 244/300 batch  27/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 244/300 batch  28/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 244/300 batch  29/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 244/300 batch  30/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 244/300 batch  31/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 244/300 batch  32/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 244/300 batch  33/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 244/300 batch  34/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 244/300 batch  35/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 244/300 batch  36/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 244/300 batch  37/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 244/300 batch  38/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 244/300 batch  39/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 244/300 batch  40/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 244/300 batch  41/188  Train Loss: 0.015, Acc: 0.996\n",
      "epoch: 244/300 batch  42/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 244/300 batch  43/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 244/300 batch  44/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 244/300 batch  45/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 244/300 batch  46/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 244/300 batch  47/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 244/300 batch  48/188  Train Loss: 0.059, Acc: 0.984\n",
      "epoch: 244/300 batch  49/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 244/300 batch  50/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 244/300 batch  51/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 244/300 batch  52/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 244/300 batch  53/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 244/300 batch  54/188  Train Loss: 0.047, Acc: 0.980\n",
      "epoch: 244/300 batch  55/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 244/300 batch  56/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 244/300 batch  57/188  Train Loss: 0.033, Acc: 1.000\n",
      "epoch: 244/300 batch  58/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 244/300 batch  59/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 244/300 batch  60/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 244/300 batch  61/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 244/300 batch  62/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 244/300 batch  63/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 244/300 batch  64/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 244/300 batch  65/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 244/300 batch  66/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 244/300 batch  67/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 244/300 batch  68/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 244/300 batch  69/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 244/300 batch  70/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 244/300 batch  71/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 244/300 batch  72/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 244/300 batch  73/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 244/300 batch  74/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 244/300 batch  75/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 244/300 batch  76/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 244/300 batch  77/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 244/300 batch  78/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 244/300 batch  79/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 244/300 batch  80/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 244/300 batch  81/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 244/300 batch  82/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 244/300 batch  83/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 244/300 batch  84/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 244/300 batch  85/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 244/300 batch  86/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 244/300 batch  87/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 244/300 batch  88/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 244/300 batch  89/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 244/300 batch  90/188  Train Loss: 0.053, Acc: 0.980\n",
      "epoch: 244/300 batch  91/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 244/300 batch  92/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 244/300 batch  93/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 244/300 batch  94/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 244/300 batch  95/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 244/300 batch  96/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 244/300 batch  97/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 244/300 batch  98/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 244/300 batch  99/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 244/300 batch 100/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 244/300 batch 101/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 244/300 batch 102/188  Train Loss: 0.063, Acc: 0.980\n",
      "epoch: 244/300 batch 103/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 244/300 batch 104/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 244/300 batch 105/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 244/300 batch 106/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 244/300 batch 107/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 244/300 batch 108/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 244/300 batch 109/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 244/300 batch 110/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 244/300 batch 111/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 244/300 batch 112/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 244/300 batch 113/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 244/300 batch 114/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 244/300 batch 115/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 244/300 batch 116/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 244/300 batch 117/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 244/300 batch 118/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 244/300 batch 119/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 244/300 batch 120/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 244/300 batch 121/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 244/300 batch 122/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 244/300 batch 123/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 244/300 batch 124/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 244/300 batch 125/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 244/300 batch 126/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 244/300 batch 127/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 244/300 batch 128/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 244/300 batch 129/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 244/300 batch 130/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 244/300 batch 131/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 244/300 batch 132/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 244/300 batch 133/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 244/300 batch 134/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 244/300 batch 135/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 244/300 batch 136/188  Train Loss: 0.048, Acc: 0.996\n",
      "epoch: 244/300 batch 137/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 244/300 batch 138/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 244/300 batch 139/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 244/300 batch 140/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 244/300 batch 141/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 244/300 batch 142/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 244/300 batch 143/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 244/300 batch 144/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 244/300 batch 145/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 244/300 batch 146/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 244/300 batch 147/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 244/300 batch 148/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 244/300 batch 149/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 244/300 batch 150/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 244/300 batch 151/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 244/300 batch 152/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 244/300 batch 153/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 244/300 batch 154/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 244/300 batch 155/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 244/300 batch 156/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 244/300 batch 157/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 244/300 batch 158/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 244/300 batch 159/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 244/300 batch 160/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 244/300 batch 161/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 244/300 batch 162/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 244/300 batch 163/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 244/300 batch 164/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 244/300 batch 165/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 244/300 batch 166/188  Train Loss: 0.029, Acc: 0.984\n",
      "epoch: 244/300 batch 167/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 244/300 batch 168/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 244/300 batch 169/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 244/300 batch 170/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 244/300 batch 171/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 244/300 batch 172/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 244/300 batch 173/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 244/300 batch 174/188  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 244/300 batch 175/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 244/300 batch 176/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 244/300 batch 177/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 244/300 batch 178/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 244/300 batch 179/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 244/300 batch 180/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 244/300 batch 181/188  Train Loss: 0.047, Acc: 0.980\n",
      "epoch: 244/300 batch 182/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 244/300 batch 183/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 244/300 batch 184/188  Train Loss: 0.014, Acc: 0.996\n",
      "epoch: 244/300 batch 185/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 244/300 batch 186/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 244/300 batch 187/188  Train Loss: 0.048, Acc: 0.984\n",
      "Train Loss: 0.032963, Acc: 0.993\n",
      "Val Loss: 0.057131, Acc: 0.983\n",
      "epoch: 245/300 batch   0/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 245/300 batch   1/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 245/300 batch   2/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 245/300 batch   3/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 245/300 batch   4/188  Train Loss: 0.042, Acc: 0.980\n",
      "epoch: 245/300 batch   5/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 245/300 batch   6/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 245/300 batch   7/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 245/300 batch   8/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 245/300 batch   9/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 245/300 batch  10/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 245/300 batch  11/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 245/300 batch  12/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 245/300 batch  13/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 245/300 batch  14/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 245/300 batch  15/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 245/300 batch  16/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 245/300 batch  17/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 245/300 batch  18/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 245/300 batch  19/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 245/300 batch  20/188  Train Loss: 0.056, Acc: 0.988\n",
      "epoch: 245/300 batch  21/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 245/300 batch  22/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 245/300 batch  23/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 245/300 batch  24/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 245/300 batch  25/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 245/300 batch  26/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 245/300 batch  27/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 245/300 batch  28/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 245/300 batch  29/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 245/300 batch  30/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 245/300 batch  31/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 245/300 batch  32/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 245/300 batch  33/188  Train Loss: 0.065, Acc: 0.980\n",
      "epoch: 245/300 batch  34/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 245/300 batch  35/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 245/300 batch  36/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 245/300 batch  37/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 245/300 batch  38/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 245/300 batch  39/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 245/300 batch  40/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 245/300 batch  41/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 245/300 batch  42/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 245/300 batch  43/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 245/300 batch  44/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 245/300 batch  45/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 245/300 batch  46/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 245/300 batch  47/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 245/300 batch  48/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 245/300 batch  49/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 245/300 batch  50/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 245/300 batch  51/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 245/300 batch  52/188  Train Loss: 0.061, Acc: 0.988\n",
      "epoch: 245/300 batch  53/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 245/300 batch  54/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 245/300 batch  55/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 245/300 batch  56/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 245/300 batch  57/188  Train Loss: 0.064, Acc: 0.988\n",
      "epoch: 245/300 batch  58/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 245/300 batch  59/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 245/300 batch  60/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 245/300 batch  61/188  Train Loss: 0.067, Acc: 0.984\n",
      "epoch: 245/300 batch  62/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 245/300 batch  63/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 245/300 batch  64/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 245/300 batch  65/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 245/300 batch  66/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 245/300 batch  67/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 245/300 batch  68/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 245/300 batch  69/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 245/300 batch  70/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 245/300 batch  71/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 245/300 batch  72/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 245/300 batch  73/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 245/300 batch  74/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 245/300 batch  75/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 245/300 batch  76/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 245/300 batch  77/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 245/300 batch  78/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 245/300 batch  79/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 245/300 batch  80/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 245/300 batch  81/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 245/300 batch  82/188  Train Loss: 0.015, Acc: 0.996\n",
      "epoch: 245/300 batch  83/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 245/300 batch  84/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 245/300 batch  85/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 245/300 batch  86/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 245/300 batch  87/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 245/300 batch  88/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 245/300 batch  89/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 245/300 batch  90/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 245/300 batch  91/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 245/300 batch  92/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 245/300 batch  93/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 245/300 batch  94/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 245/300 batch  95/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 245/300 batch  96/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 245/300 batch  97/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 245/300 batch  98/188  Train Loss: 0.058, Acc: 0.980\n",
      "epoch: 245/300 batch  99/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 245/300 batch 100/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 245/300 batch 101/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 245/300 batch 102/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 245/300 batch 103/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 245/300 batch 104/188  Train Loss: 0.026, Acc: 0.988\n",
      "epoch: 245/300 batch 105/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 245/300 batch 106/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 245/300 batch 107/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 245/300 batch 108/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 245/300 batch 109/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 245/300 batch 110/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 245/300 batch 111/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 245/300 batch 112/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 245/300 batch 113/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 245/300 batch 114/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 245/300 batch 115/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 245/300 batch 116/188  Train Loss: 0.066, Acc: 0.980\n",
      "epoch: 245/300 batch 117/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 245/300 batch 118/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 245/300 batch 119/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 245/300 batch 120/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 245/300 batch 121/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 245/300 batch 122/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 245/300 batch 123/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 245/300 batch 124/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 245/300 batch 125/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 245/300 batch 126/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 245/300 batch 127/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 245/300 batch 128/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 245/300 batch 129/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 245/300 batch 130/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 245/300 batch 131/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 245/300 batch 132/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 245/300 batch 133/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 245/300 batch 134/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 245/300 batch 135/188  Train Loss: 0.040, Acc: 0.980\n",
      "epoch: 245/300 batch 136/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 245/300 batch 137/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 245/300 batch 138/188  Train Loss: 0.085, Acc: 0.984\n",
      "epoch: 245/300 batch 139/188  Train Loss: 0.016, Acc: 0.996\n",
      "epoch: 245/300 batch 140/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 245/300 batch 141/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 245/300 batch 142/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 245/300 batch 143/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 245/300 batch 144/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 245/300 batch 145/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 245/300 batch 146/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 245/300 batch 147/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 245/300 batch 148/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 245/300 batch 149/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 245/300 batch 150/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 245/300 batch 151/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 245/300 batch 152/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 245/300 batch 153/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 245/300 batch 154/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 245/300 batch 155/188  Train Loss: 0.044, Acc: 0.996\n",
      "epoch: 245/300 batch 156/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 245/300 batch 157/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 245/300 batch 158/188  Train Loss: 0.061, Acc: 0.984\n",
      "epoch: 245/300 batch 159/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 245/300 batch 160/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 245/300 batch 161/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 245/300 batch 162/188  Train Loss: 0.033, Acc: 1.000\n",
      "epoch: 245/300 batch 163/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 245/300 batch 164/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 245/300 batch 165/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 245/300 batch 166/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 245/300 batch 167/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 245/300 batch 168/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 245/300 batch 169/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 245/300 batch 170/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 245/300 batch 171/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 245/300 batch 172/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 245/300 batch 173/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 245/300 batch 174/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 245/300 batch 175/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 245/300 batch 176/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 245/300 batch 177/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 245/300 batch 178/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 245/300 batch 179/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 245/300 batch 180/188  Train Loss: 0.051, Acc: 0.977\n",
      "epoch: 245/300 batch 181/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 245/300 batch 182/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 245/300 batch 183/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 245/300 batch 184/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 245/300 batch 185/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 245/300 batch 186/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 245/300 batch 187/188  Train Loss: 0.020, Acc: 0.992\n",
      "Train Loss: 0.032825, Acc: 0.993\n",
      "Val Loss: 0.057336, Acc: 0.983\n",
      "epoch: 246/300 batch   0/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 246/300 batch   1/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 246/300 batch   2/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 246/300 batch   3/188  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 246/300 batch   4/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 246/300 batch   5/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 246/300 batch   6/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 246/300 batch   7/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 246/300 batch   8/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 246/300 batch   9/188  Train Loss: 0.061, Acc: 0.988\n",
      "epoch: 246/300 batch  10/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 246/300 batch  11/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 246/300 batch  12/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 246/300 batch  13/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 246/300 batch  14/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 246/300 batch  15/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 246/300 batch  16/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 246/300 batch  17/188  Train Loss: 0.034, Acc: 0.984\n",
      "epoch: 246/300 batch  18/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 246/300 batch  19/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 246/300 batch  20/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 246/300 batch  21/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 246/300 batch  22/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 246/300 batch  23/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 246/300 batch  24/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 246/300 batch  25/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 246/300 batch  26/188  Train Loss: 0.076, Acc: 0.980\n",
      "epoch: 246/300 batch  27/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 246/300 batch  28/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 246/300 batch  29/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 246/300 batch  30/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 246/300 batch  31/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 246/300 batch  32/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 246/300 batch  33/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 246/300 batch  34/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 246/300 batch  35/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 246/300 batch  36/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 246/300 batch  37/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 246/300 batch  38/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 246/300 batch  39/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 246/300 batch  40/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 246/300 batch  41/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 246/300 batch  42/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 246/300 batch  43/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 246/300 batch  44/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 246/300 batch  45/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 246/300 batch  46/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 246/300 batch  47/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 246/300 batch  48/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 246/300 batch  49/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 246/300 batch  50/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 246/300 batch  51/188  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 246/300 batch  52/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 246/300 batch  53/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 246/300 batch  54/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 246/300 batch  55/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 246/300 batch  56/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 246/300 batch  57/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 246/300 batch  58/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 246/300 batch  59/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 246/300 batch  60/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 246/300 batch  61/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 246/300 batch  62/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 246/300 batch  63/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 246/300 batch  64/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 246/300 batch  65/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 246/300 batch  66/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 246/300 batch  67/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 246/300 batch  68/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 246/300 batch  69/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 246/300 batch  70/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 246/300 batch  71/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 246/300 batch  72/188  Train Loss: 0.061, Acc: 0.996\n",
      "epoch: 246/300 batch  73/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 246/300 batch  74/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 246/300 batch  75/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 246/300 batch  76/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 246/300 batch  77/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 246/300 batch  78/188  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 246/300 batch  79/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 246/300 batch  80/188  Train Loss: 0.045, Acc: 0.996\n",
      "epoch: 246/300 batch  81/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 246/300 batch  82/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 246/300 batch  83/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 246/300 batch  84/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 246/300 batch  85/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 246/300 batch  86/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 246/300 batch  87/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 246/300 batch  88/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 246/300 batch  89/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 246/300 batch  90/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 246/300 batch  91/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 246/300 batch  92/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 246/300 batch  93/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 246/300 batch  94/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 246/300 batch  95/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 246/300 batch  96/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 246/300 batch  97/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 246/300 batch  98/188  Train Loss: 0.060, Acc: 0.980\n",
      "epoch: 246/300 batch  99/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 246/300 batch 100/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 246/300 batch 101/188  Train Loss: 0.045, Acc: 0.980\n",
      "epoch: 246/300 batch 102/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 246/300 batch 103/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 246/300 batch 104/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 246/300 batch 105/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 246/300 batch 106/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 246/300 batch 107/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 246/300 batch 108/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 246/300 batch 109/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 246/300 batch 110/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 246/300 batch 111/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 246/300 batch 112/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 246/300 batch 113/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 246/300 batch 114/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 246/300 batch 115/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 246/300 batch 116/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 246/300 batch 117/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 246/300 batch 118/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 246/300 batch 119/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 246/300 batch 120/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 246/300 batch 121/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 246/300 batch 122/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 246/300 batch 123/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 246/300 batch 124/188  Train Loss: 0.054, Acc: 0.973\n",
      "epoch: 246/300 batch 125/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 246/300 batch 126/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 246/300 batch 127/188  Train Loss: 0.049, Acc: 0.980\n",
      "epoch: 246/300 batch 128/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 246/300 batch 129/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 246/300 batch 130/188  Train Loss: 0.047, Acc: 0.996\n",
      "epoch: 246/300 batch 131/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 246/300 batch 132/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 246/300 batch 133/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 246/300 batch 134/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 246/300 batch 135/188  Train Loss: 0.051, Acc: 0.992\n",
      "epoch: 246/300 batch 136/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 246/300 batch 137/188  Train Loss: 0.048, Acc: 0.980\n",
      "epoch: 246/300 batch 138/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 246/300 batch 139/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 246/300 batch 140/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 246/300 batch 141/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 246/300 batch 142/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 246/300 batch 143/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 246/300 batch 144/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 246/300 batch 145/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 246/300 batch 146/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 246/300 batch 147/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 246/300 batch 148/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 246/300 batch 149/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 246/300 batch 150/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 246/300 batch 151/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 246/300 batch 152/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 246/300 batch 153/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 246/300 batch 154/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 246/300 batch 155/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 246/300 batch 156/188  Train Loss: 0.066, Acc: 0.984\n",
      "epoch: 246/300 batch 157/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 246/300 batch 158/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 246/300 batch 159/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 246/300 batch 160/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 246/300 batch 161/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 246/300 batch 162/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 246/300 batch 163/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 246/300 batch 164/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 246/300 batch 165/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 246/300 batch 166/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 246/300 batch 167/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 246/300 batch 168/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 246/300 batch 169/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 246/300 batch 170/188  Train Loss: 0.057, Acc: 0.980\n",
      "epoch: 246/300 batch 171/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 246/300 batch 172/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 246/300 batch 173/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 246/300 batch 174/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 246/300 batch 175/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 246/300 batch 176/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 246/300 batch 177/188  Train Loss: 0.063, Acc: 0.984\n",
      "epoch: 246/300 batch 178/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 246/300 batch 179/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 246/300 batch 180/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 246/300 batch 181/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 246/300 batch 182/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 246/300 batch 183/188  Train Loss: 0.060, Acc: 0.980\n",
      "epoch: 246/300 batch 184/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 246/300 batch 185/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 246/300 batch 186/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 246/300 batch 187/188  Train Loss: 0.019, Acc: 0.992\n",
      "Train Loss: 0.032909, Acc: 0.993\n",
      "Val Loss: 0.057393, Acc: 0.983\n",
      "epoch: 247/300 batch   0/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 247/300 batch   1/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 247/300 batch   2/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 247/300 batch   3/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 247/300 batch   4/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 247/300 batch   5/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 247/300 batch   6/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 247/300 batch   7/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 247/300 batch   8/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 247/300 batch   9/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 247/300 batch  10/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 247/300 batch  11/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 247/300 batch  12/188  Train Loss: 0.051, Acc: 0.996\n",
      "epoch: 247/300 batch  13/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 247/300 batch  14/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 247/300 batch  15/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 247/300 batch  16/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 247/300 batch  17/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 247/300 batch  18/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 247/300 batch  19/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 247/300 batch  20/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 247/300 batch  21/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 247/300 batch  22/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 247/300 batch  23/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 247/300 batch  24/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 247/300 batch  25/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 247/300 batch  26/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 247/300 batch  27/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 247/300 batch  28/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 247/300 batch  29/188  Train Loss: 0.044, Acc: 0.980\n",
      "epoch: 247/300 batch  30/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 247/300 batch  31/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 247/300 batch  32/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 247/300 batch  33/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 247/300 batch  34/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 247/300 batch  35/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 247/300 batch  36/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 247/300 batch  37/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 247/300 batch  38/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 247/300 batch  39/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 247/300 batch  40/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 247/300 batch  41/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 247/300 batch  42/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 247/300 batch  43/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 247/300 batch  44/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 247/300 batch  45/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 247/300 batch  46/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 247/300 batch  47/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 247/300 batch  48/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 247/300 batch  49/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 247/300 batch  50/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 247/300 batch  51/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 247/300 batch  52/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 247/300 batch  53/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 247/300 batch  54/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 247/300 batch  55/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 247/300 batch  56/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 247/300 batch  57/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 247/300 batch  58/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 247/300 batch  59/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 247/300 batch  60/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 247/300 batch  61/188  Train Loss: 0.044, Acc: 0.980\n",
      "epoch: 247/300 batch  62/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 247/300 batch  63/188  Train Loss: 0.061, Acc: 0.988\n",
      "epoch: 247/300 batch  64/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 247/300 batch  65/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 247/300 batch  66/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 247/300 batch  67/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 247/300 batch  68/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 247/300 batch  69/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 247/300 batch  70/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 247/300 batch  71/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 247/300 batch  72/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 247/300 batch  73/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 247/300 batch  74/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 247/300 batch  75/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 247/300 batch  76/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 247/300 batch  77/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 247/300 batch  78/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 247/300 batch  79/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 247/300 batch  80/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 247/300 batch  81/188  Train Loss: 0.054, Acc: 0.980\n",
      "epoch: 247/300 batch  82/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 247/300 batch  83/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 247/300 batch  84/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 247/300 batch  85/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 247/300 batch  86/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 247/300 batch  87/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 247/300 batch  88/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 247/300 batch  89/188  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 247/300 batch  90/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 247/300 batch  91/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 247/300 batch  92/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 247/300 batch  93/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 247/300 batch  94/188  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 247/300 batch  95/188  Train Loss: 0.062, Acc: 0.980\n",
      "epoch: 247/300 batch  96/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 247/300 batch  97/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 247/300 batch  98/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 247/300 batch  99/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 247/300 batch 100/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 247/300 batch 101/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 247/300 batch 102/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 247/300 batch 103/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 247/300 batch 104/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 247/300 batch 105/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 247/300 batch 106/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 247/300 batch 107/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 247/300 batch 108/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 247/300 batch 109/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 247/300 batch 110/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 247/300 batch 111/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 247/300 batch 112/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 247/300 batch 113/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 247/300 batch 114/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 247/300 batch 115/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 247/300 batch 116/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 247/300 batch 117/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 247/300 batch 118/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 247/300 batch 119/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 247/300 batch 120/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 247/300 batch 121/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 247/300 batch 122/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 247/300 batch 123/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 247/300 batch 124/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 247/300 batch 125/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 247/300 batch 126/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 247/300 batch 127/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 247/300 batch 128/188  Train Loss: 0.062, Acc: 0.980\n",
      "epoch: 247/300 batch 129/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 247/300 batch 130/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 247/300 batch 131/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 247/300 batch 132/188  Train Loss: 0.043, Acc: 0.980\n",
      "epoch: 247/300 batch 133/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 247/300 batch 134/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 247/300 batch 135/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 247/300 batch 136/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 247/300 batch 137/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 247/300 batch 138/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 247/300 batch 139/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 247/300 batch 140/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 247/300 batch 141/188  Train Loss: 0.063, Acc: 0.992\n",
      "epoch: 247/300 batch 142/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 247/300 batch 143/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 247/300 batch 144/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 247/300 batch 145/188  Train Loss: 0.034, Acc: 0.984\n",
      "epoch: 247/300 batch 146/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 247/300 batch 147/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 247/300 batch 148/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 247/300 batch 149/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 247/300 batch 150/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 247/300 batch 151/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 247/300 batch 152/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 247/300 batch 153/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 247/300 batch 154/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 247/300 batch 155/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 247/300 batch 156/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 247/300 batch 157/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 247/300 batch 158/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 247/300 batch 159/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 247/300 batch 160/188  Train Loss: 0.054, Acc: 0.992\n",
      "epoch: 247/300 batch 161/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 247/300 batch 162/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 247/300 batch 163/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 247/300 batch 164/188  Train Loss: 0.063, Acc: 0.980\n",
      "epoch: 247/300 batch 165/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 247/300 batch 166/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 247/300 batch 167/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 247/300 batch 168/188  Train Loss: 0.036, Acc: 0.980\n",
      "epoch: 247/300 batch 169/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 247/300 batch 170/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 247/300 batch 171/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 247/300 batch 172/188  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 247/300 batch 173/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 247/300 batch 174/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 247/300 batch 175/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 247/300 batch 176/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 247/300 batch 177/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 247/300 batch 178/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 247/300 batch 179/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 247/300 batch 180/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 247/300 batch 181/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 247/300 batch 182/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 247/300 batch 183/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 247/300 batch 184/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 247/300 batch 185/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 247/300 batch 186/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 247/300 batch 187/188  Train Loss: 0.020, Acc: 1.000\n",
      "Train Loss: 0.032764, Acc: 0.993\n",
      "Val Loss: 0.057250, Acc: 0.984\n",
      "epoch: 248/300 batch   0/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 248/300 batch   1/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 248/300 batch   2/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 248/300 batch   3/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 248/300 batch   4/188  Train Loss: 0.045, Acc: 0.980\n",
      "epoch: 248/300 batch   5/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 248/300 batch   6/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 248/300 batch   7/188  Train Loss: 0.064, Acc: 0.980\n",
      "epoch: 248/300 batch   8/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 248/300 batch   9/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 248/300 batch  10/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 248/300 batch  11/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 248/300 batch  12/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 248/300 batch  13/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 248/300 batch  14/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 248/300 batch  15/188  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 248/300 batch  16/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 248/300 batch  17/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 248/300 batch  18/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 248/300 batch  19/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 248/300 batch  20/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 248/300 batch  21/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 248/300 batch  22/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 248/300 batch  23/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 248/300 batch  24/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 248/300 batch  25/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 248/300 batch  26/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 248/300 batch  27/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 248/300 batch  28/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 248/300 batch  29/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 248/300 batch  30/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 248/300 batch  31/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 248/300 batch  32/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 248/300 batch  33/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 248/300 batch  34/188  Train Loss: 0.043, Acc: 0.996\n",
      "epoch: 248/300 batch  35/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 248/300 batch  36/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 248/300 batch  37/188  Train Loss: 0.087, Acc: 0.980\n",
      "epoch: 248/300 batch  38/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 248/300 batch  39/188  Train Loss: 0.046, Acc: 0.980\n",
      "epoch: 248/300 batch  40/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 248/300 batch  41/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 248/300 batch  42/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 248/300 batch  43/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 248/300 batch  44/188  Train Loss: 0.043, Acc: 0.996\n",
      "epoch: 248/300 batch  45/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 248/300 batch  46/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 248/300 batch  47/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 248/300 batch  48/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 248/300 batch  49/188  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 248/300 batch  50/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 248/300 batch  51/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 248/300 batch  52/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 248/300 batch  53/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 248/300 batch  54/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 248/300 batch  55/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 248/300 batch  56/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 248/300 batch  57/188  Train Loss: 0.059, Acc: 0.980\n",
      "epoch: 248/300 batch  58/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 248/300 batch  59/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 248/300 batch  60/188  Train Loss: 0.031, Acc: 0.984\n",
      "epoch: 248/300 batch  61/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 248/300 batch  62/188  Train Loss: 0.061, Acc: 0.988\n",
      "epoch: 248/300 batch  63/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 248/300 batch  64/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 248/300 batch  65/188  Train Loss: 0.046, Acc: 0.980\n",
      "epoch: 248/300 batch  66/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 248/300 batch  67/188  Train Loss: 0.026, Acc: 0.988\n",
      "epoch: 248/300 batch  68/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 248/300 batch  69/188  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 248/300 batch  70/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 248/300 batch  71/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 248/300 batch  72/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 248/300 batch  73/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 248/300 batch  74/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 248/300 batch  75/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 248/300 batch  76/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 248/300 batch  77/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 248/300 batch  78/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 248/300 batch  79/188  Train Loss: 0.056, Acc: 0.980\n",
      "epoch: 248/300 batch  80/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 248/300 batch  81/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 248/300 batch  82/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 248/300 batch  83/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 248/300 batch  84/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 248/300 batch  85/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 248/300 batch  86/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 248/300 batch  87/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 248/300 batch  88/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 248/300 batch  89/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 248/300 batch  90/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 248/300 batch  91/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 248/300 batch  92/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 248/300 batch  93/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 248/300 batch  94/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 248/300 batch  95/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 248/300 batch  96/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 248/300 batch  97/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 248/300 batch  98/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 248/300 batch  99/188  Train Loss: 0.033, Acc: 1.000\n",
      "epoch: 248/300 batch 100/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 248/300 batch 101/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 248/300 batch 102/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 248/300 batch 103/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 248/300 batch 104/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 248/300 batch 105/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 248/300 batch 106/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 248/300 batch 107/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 248/300 batch 108/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 248/300 batch 109/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 248/300 batch 110/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 248/300 batch 111/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 248/300 batch 112/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 248/300 batch 113/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 248/300 batch 114/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 248/300 batch 115/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 248/300 batch 116/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 248/300 batch 117/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 248/300 batch 118/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 248/300 batch 119/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 248/300 batch 120/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 248/300 batch 121/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 248/300 batch 122/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 248/300 batch 123/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 248/300 batch 124/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 248/300 batch 125/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 248/300 batch 126/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 248/300 batch 127/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 248/300 batch 128/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 248/300 batch 129/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 248/300 batch 130/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 248/300 batch 131/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 248/300 batch 132/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 248/300 batch 133/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 248/300 batch 134/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 248/300 batch 135/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 248/300 batch 136/188  Train Loss: 0.066, Acc: 0.984\n",
      "epoch: 248/300 batch 137/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 248/300 batch 138/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 248/300 batch 139/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 248/300 batch 140/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 248/300 batch 141/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 248/300 batch 142/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 248/300 batch 143/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 248/300 batch 144/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 248/300 batch 145/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 248/300 batch 146/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 248/300 batch 147/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 248/300 batch 148/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 248/300 batch 149/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 248/300 batch 150/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 248/300 batch 151/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 248/300 batch 152/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 248/300 batch 153/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 248/300 batch 154/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 248/300 batch 155/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 248/300 batch 156/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 248/300 batch 157/188  Train Loss: 0.097, Acc: 0.969\n",
      "epoch: 248/300 batch 158/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 248/300 batch 159/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 248/300 batch 160/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 248/300 batch 161/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 248/300 batch 162/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 248/300 batch 163/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 248/300 batch 164/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 248/300 batch 165/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 248/300 batch 166/188  Train Loss: 0.060, Acc: 0.984\n",
      "epoch: 248/300 batch 167/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 248/300 batch 168/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 248/300 batch 169/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 248/300 batch 170/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 248/300 batch 171/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 248/300 batch 172/188  Train Loss: 0.059, Acc: 0.992\n",
      "epoch: 248/300 batch 173/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 248/300 batch 174/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 248/300 batch 175/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 248/300 batch 176/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 248/300 batch 177/188  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 248/300 batch 178/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 248/300 batch 179/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 248/300 batch 180/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 248/300 batch 181/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 248/300 batch 182/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 248/300 batch 183/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 248/300 batch 184/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 248/300 batch 185/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 248/300 batch 186/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 248/300 batch 187/188  Train Loss: 0.040, Acc: 0.992\n",
      "Train Loss: 0.032889, Acc: 0.993\n",
      "Val Loss: 0.057408, Acc: 0.983\n",
      "epoch: 249/300 batch   0/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 249/300 batch   1/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 249/300 batch   2/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 249/300 batch   3/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 249/300 batch   4/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 249/300 batch   5/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 249/300 batch   6/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 249/300 batch   7/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 249/300 batch   8/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 249/300 batch   9/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 249/300 batch  10/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 249/300 batch  11/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 249/300 batch  12/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 249/300 batch  13/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 249/300 batch  14/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 249/300 batch  15/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 249/300 batch  16/188  Train Loss: 0.032, Acc: 0.984\n",
      "epoch: 249/300 batch  17/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 249/300 batch  18/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 249/300 batch  19/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 249/300 batch  20/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 249/300 batch  21/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 249/300 batch  22/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 249/300 batch  23/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 249/300 batch  24/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 249/300 batch  25/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 249/300 batch  26/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 249/300 batch  27/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 249/300 batch  28/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 249/300 batch  29/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 249/300 batch  30/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 249/300 batch  31/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 249/300 batch  32/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 249/300 batch  33/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 249/300 batch  34/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 249/300 batch  35/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 249/300 batch  36/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 249/300 batch  37/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 249/300 batch  38/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 249/300 batch  39/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 249/300 batch  40/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 249/300 batch  41/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 249/300 batch  42/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 249/300 batch  43/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 249/300 batch  44/188  Train Loss: 0.058, Acc: 0.988\n",
      "epoch: 249/300 batch  45/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 249/300 batch  46/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 249/300 batch  47/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 249/300 batch  48/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 249/300 batch  49/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 249/300 batch  50/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 249/300 batch  51/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 249/300 batch  52/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 249/300 batch  53/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 249/300 batch  54/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 249/300 batch  55/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 249/300 batch  56/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 249/300 batch  57/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 249/300 batch  58/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 249/300 batch  59/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 249/300 batch  60/188  Train Loss: 0.057, Acc: 0.988\n",
      "epoch: 249/300 batch  61/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 249/300 batch  62/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 249/300 batch  63/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 249/300 batch  64/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 249/300 batch  65/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 249/300 batch  66/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 249/300 batch  67/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 249/300 batch  68/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 249/300 batch  69/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 249/300 batch  70/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 249/300 batch  71/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 249/300 batch  72/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 249/300 batch  73/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 249/300 batch  74/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 249/300 batch  75/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 249/300 batch  76/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 249/300 batch  77/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 249/300 batch  78/188  Train Loss: 0.070, Acc: 0.980\n",
      "epoch: 249/300 batch  79/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 249/300 batch  80/188  Train Loss: 0.045, Acc: 0.996\n",
      "epoch: 249/300 batch  81/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 249/300 batch  82/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 249/300 batch  83/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 249/300 batch  84/188  Train Loss: 0.043, Acc: 0.980\n",
      "epoch: 249/300 batch  85/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 249/300 batch  86/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 249/300 batch  87/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 249/300 batch  88/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 249/300 batch  89/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 249/300 batch  90/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 249/300 batch  91/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 249/300 batch  92/188  Train Loss: 0.063, Acc: 0.984\n",
      "epoch: 249/300 batch  93/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 249/300 batch  94/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 249/300 batch  95/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 249/300 batch  96/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 249/300 batch  97/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 249/300 batch  98/188  Train Loss: 0.054, Acc: 0.980\n",
      "epoch: 249/300 batch  99/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 249/300 batch 100/188  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 249/300 batch 101/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 249/300 batch 102/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 249/300 batch 103/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 249/300 batch 104/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 249/300 batch 105/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 249/300 batch 106/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 249/300 batch 107/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 249/300 batch 108/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 249/300 batch 109/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 249/300 batch 110/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 249/300 batch 111/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 249/300 batch 112/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 249/300 batch 113/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 249/300 batch 114/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 249/300 batch 115/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 249/300 batch 116/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 249/300 batch 117/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 249/300 batch 118/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 249/300 batch 119/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 249/300 batch 120/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 249/300 batch 121/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 249/300 batch 122/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 249/300 batch 123/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 249/300 batch 124/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 249/300 batch 125/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 249/300 batch 126/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 249/300 batch 127/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 249/300 batch 128/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 249/300 batch 129/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 249/300 batch 130/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 249/300 batch 131/188  Train Loss: 0.026, Acc: 0.988\n",
      "epoch: 249/300 batch 132/188  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 249/300 batch 133/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 249/300 batch 134/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 249/300 batch 135/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 249/300 batch 136/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 249/300 batch 137/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 249/300 batch 138/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 249/300 batch 139/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 249/300 batch 140/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 249/300 batch 141/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 249/300 batch 142/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 249/300 batch 143/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 249/300 batch 144/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 249/300 batch 145/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 249/300 batch 146/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 249/300 batch 147/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 249/300 batch 148/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 249/300 batch 149/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 249/300 batch 150/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 249/300 batch 151/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 249/300 batch 152/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 249/300 batch 153/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 249/300 batch 154/188  Train Loss: 0.054, Acc: 0.973\n",
      "epoch: 249/300 batch 155/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 249/300 batch 156/188  Train Loss: 0.042, Acc: 0.980\n",
      "epoch: 249/300 batch 157/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 249/300 batch 158/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 249/300 batch 159/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 249/300 batch 160/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 249/300 batch 161/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 249/300 batch 162/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 249/300 batch 163/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 249/300 batch 164/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 249/300 batch 165/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 249/300 batch 166/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 249/300 batch 167/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 249/300 batch 168/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 249/300 batch 169/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 249/300 batch 170/188  Train Loss: 0.067, Acc: 0.992\n",
      "epoch: 249/300 batch 171/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 249/300 batch 172/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 249/300 batch 173/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 249/300 batch 174/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 249/300 batch 175/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 249/300 batch 176/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 249/300 batch 177/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 249/300 batch 178/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 249/300 batch 179/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 249/300 batch 180/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 249/300 batch 181/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 249/300 batch 182/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 249/300 batch 183/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 249/300 batch 184/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 249/300 batch 185/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 249/300 batch 186/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 249/300 batch 187/188  Train Loss: 0.051, Acc: 0.992\n",
      "Train Loss: 0.032834, Acc: 0.993\n",
      "Val Loss: 0.057844, Acc: 0.982\n",
      "epoch: 250/300 batch   0/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 250/300 batch   1/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 250/300 batch   2/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 250/300 batch   3/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 250/300 batch   4/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 250/300 batch   5/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 250/300 batch   6/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 250/300 batch   7/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 250/300 batch   8/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 250/300 batch   9/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 250/300 batch  10/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 250/300 batch  11/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 250/300 batch  12/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 250/300 batch  13/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 250/300 batch  14/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 250/300 batch  15/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 250/300 batch  16/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 250/300 batch  17/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 250/300 batch  18/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 250/300 batch  19/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 250/300 batch  20/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 250/300 batch  21/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 250/300 batch  22/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 250/300 batch  23/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 250/300 batch  24/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 250/300 batch  25/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 250/300 batch  26/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 250/300 batch  27/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 250/300 batch  28/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 250/300 batch  29/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 250/300 batch  30/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 250/300 batch  31/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 250/300 batch  32/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 250/300 batch  33/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 250/300 batch  34/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 250/300 batch  35/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 250/300 batch  36/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 250/300 batch  37/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 250/300 batch  38/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 250/300 batch  39/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 250/300 batch  40/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 250/300 batch  41/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 250/300 batch  42/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 250/300 batch  43/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 250/300 batch  44/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 250/300 batch  45/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 250/300 batch  46/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 250/300 batch  47/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 250/300 batch  48/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 250/300 batch  49/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 250/300 batch  50/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 250/300 batch  51/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 250/300 batch  52/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 250/300 batch  53/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 250/300 batch  54/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 250/300 batch  55/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 250/300 batch  56/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 250/300 batch  57/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 250/300 batch  58/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 250/300 batch  59/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 250/300 batch  60/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 250/300 batch  61/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 250/300 batch  62/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 250/300 batch  63/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 250/300 batch  64/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 250/300 batch  65/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 250/300 batch  66/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 250/300 batch  67/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 250/300 batch  68/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 250/300 batch  69/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 250/300 batch  70/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 250/300 batch  71/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 250/300 batch  72/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 250/300 batch  73/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 250/300 batch  74/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 250/300 batch  75/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 250/300 batch  76/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 250/300 batch  77/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 250/300 batch  78/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 250/300 batch  79/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 250/300 batch  80/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 250/300 batch  81/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 250/300 batch  82/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 250/300 batch  83/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 250/300 batch  84/188  Train Loss: 0.063, Acc: 0.984\n",
      "epoch: 250/300 batch  85/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 250/300 batch  86/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 250/300 batch  87/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 250/300 batch  88/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 250/300 batch  89/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 250/300 batch  90/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 250/300 batch  91/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 250/300 batch  92/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 250/300 batch  93/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 250/300 batch  94/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 250/300 batch  95/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 250/300 batch  96/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 250/300 batch  97/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 250/300 batch  98/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 250/300 batch  99/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 250/300 batch 100/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 250/300 batch 101/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 250/300 batch 102/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 250/300 batch 103/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 250/300 batch 104/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 250/300 batch 105/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 250/300 batch 106/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 250/300 batch 107/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 250/300 batch 108/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 250/300 batch 109/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 250/300 batch 110/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 250/300 batch 111/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 250/300 batch 112/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 250/300 batch 113/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 250/300 batch 114/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 250/300 batch 115/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 250/300 batch 116/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 250/300 batch 117/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 250/300 batch 118/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 250/300 batch 119/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 250/300 batch 120/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 250/300 batch 121/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 250/300 batch 122/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 250/300 batch 123/188  Train Loss: 0.061, Acc: 0.973\n",
      "epoch: 250/300 batch 124/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 250/300 batch 125/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 250/300 batch 126/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 250/300 batch 127/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 250/300 batch 128/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 250/300 batch 129/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 250/300 batch 130/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 250/300 batch 131/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 250/300 batch 132/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 250/300 batch 133/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 250/300 batch 134/188  Train Loss: 0.074, Acc: 0.984\n",
      "epoch: 250/300 batch 135/188  Train Loss: 0.048, Acc: 0.980\n",
      "epoch: 250/300 batch 136/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 250/300 batch 137/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 250/300 batch 138/188  Train Loss: 0.066, Acc: 0.988\n",
      "epoch: 250/300 batch 139/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 250/300 batch 140/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 250/300 batch 141/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 250/300 batch 142/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 250/300 batch 143/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 250/300 batch 144/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 250/300 batch 145/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 250/300 batch 146/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 250/300 batch 147/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 250/300 batch 148/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 250/300 batch 149/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 250/300 batch 150/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 250/300 batch 151/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 250/300 batch 152/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 250/300 batch 153/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 250/300 batch 154/188  Train Loss: 0.030, Acc: 0.984\n",
      "epoch: 250/300 batch 155/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 250/300 batch 156/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 250/300 batch 157/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 250/300 batch 158/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 250/300 batch 159/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 250/300 batch 160/188  Train Loss: 0.047, Acc: 0.980\n",
      "epoch: 250/300 batch 161/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 250/300 batch 162/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 250/300 batch 163/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 250/300 batch 164/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 250/300 batch 165/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 250/300 batch 166/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 250/300 batch 167/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 250/300 batch 168/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 250/300 batch 169/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 250/300 batch 170/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 250/300 batch 171/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 250/300 batch 172/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 250/300 batch 173/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 250/300 batch 174/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 250/300 batch 175/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 250/300 batch 176/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 250/300 batch 177/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 250/300 batch 178/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 250/300 batch 179/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 250/300 batch 180/188  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 250/300 batch 181/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 250/300 batch 182/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 250/300 batch 183/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 250/300 batch 184/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 250/300 batch 185/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 250/300 batch 186/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 250/300 batch 187/188  Train Loss: 0.023, Acc: 1.000\n",
      "Train Loss: 0.032832, Acc: 0.993\n",
      "Val Loss: 0.057461, Acc: 0.983\n",
      "epoch: 251/300 batch   0/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 251/300 batch   1/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 251/300 batch   2/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 251/300 batch   3/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 251/300 batch   4/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 251/300 batch   5/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 251/300 batch   6/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 251/300 batch   7/188  Train Loss: 0.027, Acc: 0.988\n",
      "epoch: 251/300 batch   8/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 251/300 batch   9/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 251/300 batch  10/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 251/300 batch  11/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 251/300 batch  12/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 251/300 batch  13/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 251/300 batch  14/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 251/300 batch  15/188  Train Loss: 0.061, Acc: 0.984\n",
      "epoch: 251/300 batch  16/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 251/300 batch  17/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 251/300 batch  18/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 251/300 batch  19/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 251/300 batch  20/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 251/300 batch  21/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 251/300 batch  22/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 251/300 batch  23/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 251/300 batch  24/188  Train Loss: 0.016, Acc: 0.996\n",
      "epoch: 251/300 batch  25/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 251/300 batch  26/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 251/300 batch  27/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 251/300 batch  28/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 251/300 batch  29/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 251/300 batch  30/188  Train Loss: 0.032, Acc: 0.984\n",
      "epoch: 251/300 batch  31/188  Train Loss: 0.026, Acc: 0.988\n",
      "epoch: 251/300 batch  32/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 251/300 batch  33/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 251/300 batch  34/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 251/300 batch  35/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 251/300 batch  36/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 251/300 batch  37/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 251/300 batch  38/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 251/300 batch  39/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 251/300 batch  40/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 251/300 batch  41/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 251/300 batch  42/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 251/300 batch  43/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 251/300 batch  44/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 251/300 batch  45/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 251/300 batch  46/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 251/300 batch  47/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 251/300 batch  48/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 251/300 batch  49/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 251/300 batch  50/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 251/300 batch  51/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 251/300 batch  52/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 251/300 batch  53/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 251/300 batch  54/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 251/300 batch  55/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 251/300 batch  56/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 251/300 batch  57/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 251/300 batch  58/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 251/300 batch  59/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 251/300 batch  60/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 251/300 batch  61/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 251/300 batch  62/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 251/300 batch  63/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 251/300 batch  64/188  Train Loss: 0.032, Acc: 1.000\n",
      "epoch: 251/300 batch  65/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 251/300 batch  66/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 251/300 batch  67/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 251/300 batch  68/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 251/300 batch  69/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 251/300 batch  70/188  Train Loss: 0.071, Acc: 0.988\n",
      "epoch: 251/300 batch  71/188  Train Loss: 0.053, Acc: 0.980\n",
      "epoch: 251/300 batch  72/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 251/300 batch  73/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 251/300 batch  74/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 251/300 batch  75/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 251/300 batch  76/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 251/300 batch  77/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 251/300 batch  78/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 251/300 batch  79/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 251/300 batch  80/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 251/300 batch  81/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 251/300 batch  82/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 251/300 batch  83/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 251/300 batch  84/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 251/300 batch  85/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 251/300 batch  86/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 251/300 batch  87/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 251/300 batch  88/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 251/300 batch  89/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 251/300 batch  90/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 251/300 batch  91/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 251/300 batch  92/188  Train Loss: 0.058, Acc: 0.988\n",
      "epoch: 251/300 batch  93/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 251/300 batch  94/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 251/300 batch  95/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 251/300 batch  96/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 251/300 batch  97/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 251/300 batch  98/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 251/300 batch  99/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 251/300 batch 100/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 251/300 batch 101/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 251/300 batch 102/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 251/300 batch 103/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 251/300 batch 104/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 251/300 batch 105/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 251/300 batch 106/188  Train Loss: 0.033, Acc: 1.000\n",
      "epoch: 251/300 batch 107/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 251/300 batch 108/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 251/300 batch 109/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 251/300 batch 110/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 251/300 batch 111/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 251/300 batch 112/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 251/300 batch 113/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 251/300 batch 114/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 251/300 batch 115/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 251/300 batch 116/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 251/300 batch 117/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 251/300 batch 118/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 251/300 batch 119/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 251/300 batch 120/188  Train Loss: 0.061, Acc: 0.988\n",
      "epoch: 251/300 batch 121/188  Train Loss: 0.065, Acc: 0.980\n",
      "epoch: 251/300 batch 122/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 251/300 batch 123/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 251/300 batch 124/188  Train Loss: 0.051, Acc: 0.992\n",
      "epoch: 251/300 batch 125/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 251/300 batch 126/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 251/300 batch 127/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 251/300 batch 128/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 251/300 batch 129/188  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 251/300 batch 130/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 251/300 batch 131/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 251/300 batch 132/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 251/300 batch 133/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 251/300 batch 134/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 251/300 batch 135/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 251/300 batch 136/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 251/300 batch 137/188  Train Loss: 0.032, Acc: 1.000\n",
      "epoch: 251/300 batch 138/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 251/300 batch 139/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 251/300 batch 140/188  Train Loss: 0.068, Acc: 0.980\n",
      "epoch: 251/300 batch 141/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 251/300 batch 142/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 251/300 batch 143/188  Train Loss: 0.044, Acc: 0.980\n",
      "epoch: 251/300 batch 144/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 251/300 batch 145/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 251/300 batch 146/188  Train Loss: 0.064, Acc: 0.977\n",
      "epoch: 251/300 batch 147/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 251/300 batch 148/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 251/300 batch 149/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 251/300 batch 150/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 251/300 batch 151/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 251/300 batch 152/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 251/300 batch 153/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 251/300 batch 154/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 251/300 batch 155/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 251/300 batch 156/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 251/300 batch 157/188  Train Loss: 0.053, Acc: 0.980\n",
      "epoch: 251/300 batch 158/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 251/300 batch 159/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 251/300 batch 160/188  Train Loss: 0.053, Acc: 0.980\n",
      "epoch: 251/300 batch 161/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 251/300 batch 162/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 251/300 batch 163/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 251/300 batch 164/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 251/300 batch 165/188  Train Loss: 0.025, Acc: 0.984\n",
      "epoch: 251/300 batch 166/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 251/300 batch 167/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 251/300 batch 168/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 251/300 batch 169/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 251/300 batch 170/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 251/300 batch 171/188  Train Loss: 0.026, Acc: 0.988\n",
      "epoch: 251/300 batch 172/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 251/300 batch 173/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 251/300 batch 174/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 251/300 batch 175/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 251/300 batch 176/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 251/300 batch 177/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 251/300 batch 178/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 251/300 batch 179/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 251/300 batch 180/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 251/300 batch 181/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 251/300 batch 182/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 251/300 batch 183/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 251/300 batch 184/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 251/300 batch 185/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 251/300 batch 186/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 251/300 batch 187/188  Train Loss: 0.024, Acc: 0.992\n",
      "Train Loss: 0.032833, Acc: 0.993\n",
      "Val Loss: 0.057477, Acc: 0.983\n",
      "epoch: 252/300 batch   0/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 252/300 batch   1/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 252/300 batch   2/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 252/300 batch   3/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 252/300 batch   4/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 252/300 batch   5/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 252/300 batch   6/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 252/300 batch   7/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 252/300 batch   8/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 252/300 batch   9/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 252/300 batch  10/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 252/300 batch  11/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 252/300 batch  12/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 252/300 batch  13/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 252/300 batch  14/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 252/300 batch  15/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 252/300 batch  16/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 252/300 batch  17/188  Train Loss: 0.068, Acc: 0.984\n",
      "epoch: 252/300 batch  18/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 252/300 batch  19/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 252/300 batch  20/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 252/300 batch  21/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 252/300 batch  22/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 252/300 batch  23/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 252/300 batch  24/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 252/300 batch  25/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 252/300 batch  26/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 252/300 batch  27/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 252/300 batch  28/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 252/300 batch  29/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 252/300 batch  30/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 252/300 batch  31/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 252/300 batch  32/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 252/300 batch  33/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 252/300 batch  34/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 252/300 batch  35/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 252/300 batch  36/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 252/300 batch  37/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 252/300 batch  38/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 252/300 batch  39/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 252/300 batch  40/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 252/300 batch  41/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 252/300 batch  42/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 252/300 batch  43/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 252/300 batch  44/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 252/300 batch  45/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 252/300 batch  46/188  Train Loss: 0.016, Acc: 0.996\n",
      "epoch: 252/300 batch  47/188  Train Loss: 0.047, Acc: 0.996\n",
      "epoch: 252/300 batch  48/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 252/300 batch  49/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 252/300 batch  50/188  Train Loss: 0.039, Acc: 0.980\n",
      "epoch: 252/300 batch  51/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 252/300 batch  52/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 252/300 batch  53/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 252/300 batch  54/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 252/300 batch  55/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 252/300 batch  56/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 252/300 batch  57/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 252/300 batch  58/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 252/300 batch  59/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 252/300 batch  60/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 252/300 batch  61/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 252/300 batch  62/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 252/300 batch  63/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 252/300 batch  64/188  Train Loss: 0.033, Acc: 1.000\n",
      "epoch: 252/300 batch  65/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 252/300 batch  66/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 252/300 batch  67/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 252/300 batch  68/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 252/300 batch  69/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 252/300 batch  70/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 252/300 batch  71/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 252/300 batch  72/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 252/300 batch  73/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 252/300 batch  74/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 252/300 batch  75/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 252/300 batch  76/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 252/300 batch  77/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 252/300 batch  78/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 252/300 batch  79/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 252/300 batch  80/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 252/300 batch  81/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 252/300 batch  82/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 252/300 batch  83/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 252/300 batch  84/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 252/300 batch  85/188  Train Loss: 0.051, Acc: 0.980\n",
      "epoch: 252/300 batch  86/188  Train Loss: 0.081, Acc: 0.984\n",
      "epoch: 252/300 batch  87/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 252/300 batch  88/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 252/300 batch  89/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 252/300 batch  90/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 252/300 batch  91/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 252/300 batch  92/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 252/300 batch  93/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 252/300 batch  94/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 252/300 batch  95/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 252/300 batch  96/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 252/300 batch  97/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 252/300 batch  98/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 252/300 batch  99/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 252/300 batch 100/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 252/300 batch 101/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 252/300 batch 102/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 252/300 batch 103/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 252/300 batch 104/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 252/300 batch 105/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 252/300 batch 106/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 252/300 batch 107/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 252/300 batch 108/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 252/300 batch 109/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 252/300 batch 110/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 252/300 batch 111/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 252/300 batch 112/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 252/300 batch 113/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 252/300 batch 114/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 252/300 batch 115/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 252/300 batch 116/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 252/300 batch 117/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 252/300 batch 118/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 252/300 batch 119/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 252/300 batch 120/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 252/300 batch 121/188  Train Loss: 0.059, Acc: 0.984\n",
      "epoch: 252/300 batch 122/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 252/300 batch 123/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 252/300 batch 124/188  Train Loss: 0.066, Acc: 0.984\n",
      "epoch: 252/300 batch 125/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 252/300 batch 126/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 252/300 batch 127/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 252/300 batch 128/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 252/300 batch 129/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 252/300 batch 130/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 252/300 batch 131/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 252/300 batch 132/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 252/300 batch 133/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 252/300 batch 134/188  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 252/300 batch 135/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 252/300 batch 136/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 252/300 batch 137/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 252/300 batch 138/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 252/300 batch 139/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 252/300 batch 140/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 252/300 batch 141/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 252/300 batch 142/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 252/300 batch 143/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 252/300 batch 144/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 252/300 batch 145/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 252/300 batch 146/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 252/300 batch 147/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 252/300 batch 148/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 252/300 batch 149/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 252/300 batch 150/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 252/300 batch 151/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 252/300 batch 152/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 252/300 batch 153/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 252/300 batch 154/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 252/300 batch 155/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 252/300 batch 156/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 252/300 batch 157/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 252/300 batch 158/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 252/300 batch 159/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 252/300 batch 160/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 252/300 batch 161/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 252/300 batch 162/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 252/300 batch 163/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 252/300 batch 164/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 252/300 batch 165/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 252/300 batch 166/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 252/300 batch 167/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 252/300 batch 168/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 252/300 batch 169/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 252/300 batch 170/188  Train Loss: 0.056, Acc: 0.977\n",
      "epoch: 252/300 batch 171/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 252/300 batch 172/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 252/300 batch 173/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 252/300 batch 174/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 252/300 batch 175/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 252/300 batch 176/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 252/300 batch 177/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 252/300 batch 178/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 252/300 batch 179/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 252/300 batch 180/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 252/300 batch 181/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 252/300 batch 182/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 252/300 batch 183/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 252/300 batch 184/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 252/300 batch 185/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 252/300 batch 186/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 252/300 batch 187/188  Train Loss: 0.029, Acc: 1.000\n",
      "Train Loss: 0.032814, Acc: 0.993\n",
      "Val Loss: 0.057693, Acc: 0.983\n",
      "epoch: 253/300 batch   0/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 253/300 batch   1/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 253/300 batch   2/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 253/300 batch   3/188  Train Loss: 0.043, Acc: 0.996\n",
      "epoch: 253/300 batch   4/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 253/300 batch   5/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 253/300 batch   6/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 253/300 batch   7/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 253/300 batch   8/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 253/300 batch   9/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 253/300 batch  10/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 253/300 batch  11/188  Train Loss: 0.067, Acc: 0.984\n",
      "epoch: 253/300 batch  12/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 253/300 batch  13/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 253/300 batch  14/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 253/300 batch  15/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 253/300 batch  16/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 253/300 batch  17/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 253/300 batch  18/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 253/300 batch  19/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 253/300 batch  20/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 253/300 batch  21/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 253/300 batch  22/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 253/300 batch  23/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 253/300 batch  24/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 253/300 batch  25/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 253/300 batch  26/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 253/300 batch  27/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 253/300 batch  28/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 253/300 batch  29/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 253/300 batch  30/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 253/300 batch  31/188  Train Loss: 0.049, Acc: 0.977\n",
      "epoch: 253/300 batch  32/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 253/300 batch  33/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 253/300 batch  34/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 253/300 batch  35/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 253/300 batch  36/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 253/300 batch  37/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 253/300 batch  38/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 253/300 batch  39/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 253/300 batch  40/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 253/300 batch  41/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 253/300 batch  42/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 253/300 batch  43/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 253/300 batch  44/188  Train Loss: 0.015, Acc: 0.996\n",
      "epoch: 253/300 batch  45/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 253/300 batch  46/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 253/300 batch  47/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 253/300 batch  48/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 253/300 batch  49/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 253/300 batch  50/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 253/300 batch  51/188  Train Loss: 0.084, Acc: 0.980\n",
      "epoch: 253/300 batch  52/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 253/300 batch  53/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 253/300 batch  54/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 253/300 batch  55/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 253/300 batch  56/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 253/300 batch  57/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 253/300 batch  58/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 253/300 batch  59/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 253/300 batch  60/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 253/300 batch  61/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 253/300 batch  62/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 253/300 batch  63/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 253/300 batch  64/188  Train Loss: 0.042, Acc: 0.996\n",
      "epoch: 253/300 batch  65/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 253/300 batch  66/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 253/300 batch  67/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 253/300 batch  68/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 253/300 batch  69/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 253/300 batch  70/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 253/300 batch  71/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 253/300 batch  72/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 253/300 batch  73/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 253/300 batch  74/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 253/300 batch  75/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 253/300 batch  76/188  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 253/300 batch  77/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 253/300 batch  78/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 253/300 batch  79/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 253/300 batch  80/188  Train Loss: 0.031, Acc: 1.000\n",
      "epoch: 253/300 batch  81/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 253/300 batch  82/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 253/300 batch  83/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 253/300 batch  84/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 253/300 batch  85/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 253/300 batch  86/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 253/300 batch  87/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 253/300 batch  88/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 253/300 batch  89/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 253/300 batch  90/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 253/300 batch  91/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 253/300 batch  92/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 253/300 batch  93/188  Train Loss: 0.058, Acc: 0.980\n",
      "epoch: 253/300 batch  94/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 253/300 batch  95/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 253/300 batch  96/188  Train Loss: 0.061, Acc: 0.977\n",
      "epoch: 253/300 batch  97/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 253/300 batch  98/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 253/300 batch  99/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 253/300 batch 100/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 253/300 batch 101/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 253/300 batch 102/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 253/300 batch 103/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 253/300 batch 104/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 253/300 batch 105/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 253/300 batch 106/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 253/300 batch 107/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 253/300 batch 108/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 253/300 batch 109/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 253/300 batch 110/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 253/300 batch 111/188  Train Loss: 0.034, Acc: 0.984\n",
      "epoch: 253/300 batch 112/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 253/300 batch 113/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 253/300 batch 114/188  Train Loss: 0.068, Acc: 0.980\n",
      "epoch: 253/300 batch 115/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 253/300 batch 116/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 253/300 batch 117/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 253/300 batch 118/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 253/300 batch 119/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 253/300 batch 120/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 253/300 batch 121/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 253/300 batch 122/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 253/300 batch 123/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 253/300 batch 124/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 253/300 batch 125/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 253/300 batch 126/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 253/300 batch 127/188  Train Loss: 0.031, Acc: 1.000\n",
      "epoch: 253/300 batch 128/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 253/300 batch 129/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 253/300 batch 130/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 253/300 batch 131/188  Train Loss: 0.045, Acc: 0.996\n",
      "epoch: 253/300 batch 132/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 253/300 batch 133/188  Train Loss: 0.060, Acc: 0.984\n",
      "epoch: 253/300 batch 134/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 253/300 batch 135/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 253/300 batch 136/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 253/300 batch 137/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 253/300 batch 138/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 253/300 batch 139/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 253/300 batch 140/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 253/300 batch 141/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 253/300 batch 142/188  Train Loss: 0.016, Acc: 0.996\n",
      "epoch: 253/300 batch 143/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 253/300 batch 144/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 253/300 batch 145/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 253/300 batch 146/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 253/300 batch 147/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 253/300 batch 148/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 253/300 batch 149/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 253/300 batch 150/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 253/300 batch 151/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 253/300 batch 152/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 253/300 batch 153/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 253/300 batch 154/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 253/300 batch 155/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 253/300 batch 156/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 253/300 batch 157/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 253/300 batch 158/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 253/300 batch 159/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 253/300 batch 160/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 253/300 batch 161/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 253/300 batch 162/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 253/300 batch 163/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 253/300 batch 164/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 253/300 batch 165/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 253/300 batch 166/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 253/300 batch 167/188  Train Loss: 0.036, Acc: 0.980\n",
      "epoch: 253/300 batch 168/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 253/300 batch 169/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 253/300 batch 170/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 253/300 batch 171/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 253/300 batch 172/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 253/300 batch 173/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 253/300 batch 174/188  Train Loss: 0.042, Acc: 0.996\n",
      "epoch: 253/300 batch 175/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 253/300 batch 176/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 253/300 batch 177/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 253/300 batch 178/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 253/300 batch 179/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 253/300 batch 180/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 253/300 batch 181/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 253/300 batch 182/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 253/300 batch 183/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 253/300 batch 184/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 253/300 batch 185/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 253/300 batch 186/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 253/300 batch 187/188  Train Loss: 0.020, Acc: 1.000\n",
      "Train Loss: 0.032753, Acc: 0.993\n",
      "Val Loss: 0.057575, Acc: 0.983\n",
      "epoch: 254/300 batch   0/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 254/300 batch   1/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 254/300 batch   2/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 254/300 batch   3/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 254/300 batch   4/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 254/300 batch   5/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 254/300 batch   6/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 254/300 batch   7/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 254/300 batch   8/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 254/300 batch   9/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 254/300 batch  10/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 254/300 batch  11/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 254/300 batch  12/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 254/300 batch  13/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 254/300 batch  14/188  Train Loss: 0.043, Acc: 0.996\n",
      "epoch: 254/300 batch  15/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 254/300 batch  16/188  Train Loss: 0.059, Acc: 0.984\n",
      "epoch: 254/300 batch  17/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 254/300 batch  18/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 254/300 batch  19/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 254/300 batch  20/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 254/300 batch  21/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 254/300 batch  22/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 254/300 batch  23/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 254/300 batch  24/188  Train Loss: 0.064, Acc: 0.996\n",
      "epoch: 254/300 batch  25/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 254/300 batch  26/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 254/300 batch  27/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 254/300 batch  28/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 254/300 batch  29/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 254/300 batch  30/188  Train Loss: 0.016, Acc: 0.996\n",
      "epoch: 254/300 batch  31/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 254/300 batch  32/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 254/300 batch  33/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 254/300 batch  34/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 254/300 batch  35/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 254/300 batch  36/188  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 254/300 batch  37/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 254/300 batch  38/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 254/300 batch  39/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 254/300 batch  40/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 254/300 batch  41/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 254/300 batch  42/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 254/300 batch  43/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 254/300 batch  44/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 254/300 batch  45/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 254/300 batch  46/188  Train Loss: 0.063, Acc: 0.980\n",
      "epoch: 254/300 batch  47/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 254/300 batch  48/188  Train Loss: 0.057, Acc: 0.977\n",
      "epoch: 254/300 batch  49/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 254/300 batch  50/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 254/300 batch  51/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 254/300 batch  52/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 254/300 batch  53/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 254/300 batch  54/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 254/300 batch  55/188  Train Loss: 0.058, Acc: 0.980\n",
      "epoch: 254/300 batch  56/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 254/300 batch  57/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 254/300 batch  58/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 254/300 batch  59/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 254/300 batch  60/188  Train Loss: 0.068, Acc: 0.988\n",
      "epoch: 254/300 batch  61/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 254/300 batch  62/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 254/300 batch  63/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 254/300 batch  64/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 254/300 batch  65/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 254/300 batch  66/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 254/300 batch  67/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 254/300 batch  68/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 254/300 batch  69/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 254/300 batch  70/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 254/300 batch  71/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 254/300 batch  72/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 254/300 batch  73/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 254/300 batch  74/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 254/300 batch  75/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 254/300 batch  76/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 254/300 batch  77/188  Train Loss: 0.027, Acc: 0.988\n",
      "epoch: 254/300 batch  78/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 254/300 batch  79/188  Train Loss: 0.066, Acc: 0.984\n",
      "epoch: 254/300 batch  80/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 254/300 batch  81/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 254/300 batch  82/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 254/300 batch  83/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 254/300 batch  84/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 254/300 batch  85/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 254/300 batch  86/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 254/300 batch  87/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 254/300 batch  88/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 254/300 batch  89/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 254/300 batch  90/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 254/300 batch  91/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 254/300 batch  92/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 254/300 batch  93/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 254/300 batch  94/188  Train Loss: 0.047, Acc: 0.980\n",
      "epoch: 254/300 batch  95/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 254/300 batch  96/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 254/300 batch  97/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 254/300 batch  98/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 254/300 batch  99/188  Train Loss: 0.032, Acc: 0.984\n",
      "epoch: 254/300 batch 100/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 254/300 batch 101/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 254/300 batch 102/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 254/300 batch 103/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 254/300 batch 104/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 254/300 batch 105/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 254/300 batch 106/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 254/300 batch 107/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 254/300 batch 108/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 254/300 batch 109/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 254/300 batch 110/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 254/300 batch 111/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 254/300 batch 112/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 254/300 batch 113/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 254/300 batch 114/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 254/300 batch 115/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 254/300 batch 116/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 254/300 batch 117/188  Train Loss: 0.046, Acc: 0.980\n",
      "epoch: 254/300 batch 118/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 254/300 batch 119/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 254/300 batch 120/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 254/300 batch 121/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 254/300 batch 122/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 254/300 batch 123/188  Train Loss: 0.078, Acc: 0.980\n",
      "epoch: 254/300 batch 124/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 254/300 batch 125/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 254/300 batch 126/188  Train Loss: 0.072, Acc: 0.980\n",
      "epoch: 254/300 batch 127/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 254/300 batch 128/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 254/300 batch 129/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 254/300 batch 130/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 254/300 batch 131/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 254/300 batch 132/188  Train Loss: 0.062, Acc: 0.980\n",
      "epoch: 254/300 batch 133/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 254/300 batch 134/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 254/300 batch 135/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 254/300 batch 136/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 254/300 batch 137/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 254/300 batch 138/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 254/300 batch 139/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 254/300 batch 140/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 254/300 batch 141/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 254/300 batch 142/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 254/300 batch 143/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 254/300 batch 144/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 254/300 batch 145/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 254/300 batch 146/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 254/300 batch 147/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 254/300 batch 148/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 254/300 batch 149/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 254/300 batch 150/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 254/300 batch 151/188  Train Loss: 0.032, Acc: 0.984\n",
      "epoch: 254/300 batch 152/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 254/300 batch 153/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 254/300 batch 154/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 254/300 batch 155/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 254/300 batch 156/188  Train Loss: 0.043, Acc: 0.980\n",
      "epoch: 254/300 batch 157/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 254/300 batch 158/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 254/300 batch 159/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 254/300 batch 160/188  Train Loss: 0.051, Acc: 0.996\n",
      "epoch: 254/300 batch 161/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 254/300 batch 162/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 254/300 batch 163/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 254/300 batch 164/188  Train Loss: 0.043, Acc: 0.996\n",
      "epoch: 254/300 batch 165/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 254/300 batch 166/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 254/300 batch 167/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 254/300 batch 168/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 254/300 batch 169/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 254/300 batch 170/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 254/300 batch 171/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 254/300 batch 172/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 254/300 batch 173/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 254/300 batch 174/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 254/300 batch 175/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 254/300 batch 176/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 254/300 batch 177/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 254/300 batch 178/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 254/300 batch 179/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 254/300 batch 180/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 254/300 batch 181/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 254/300 batch 182/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 254/300 batch 183/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 254/300 batch 184/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 254/300 batch 185/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 254/300 batch 186/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 254/300 batch 187/188  Train Loss: 0.042, Acc: 0.992\n",
      "Train Loss: 0.032761, Acc: 0.993\n",
      "Val Loss: 0.057146, Acc: 0.983\n",
      "epoch: 255/300 batch   0/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 255/300 batch   1/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 255/300 batch   2/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 255/300 batch   3/188  Train Loss: 0.016, Acc: 0.996\n",
      "epoch: 255/300 batch   4/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 255/300 batch   5/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 255/300 batch   6/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 255/300 batch   7/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 255/300 batch   8/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 255/300 batch   9/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 255/300 batch  10/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 255/300 batch  11/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 255/300 batch  12/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 255/300 batch  13/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 255/300 batch  14/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 255/300 batch  15/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 255/300 batch  16/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 255/300 batch  17/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 255/300 batch  18/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 255/300 batch  19/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 255/300 batch  20/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 255/300 batch  21/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 255/300 batch  22/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 255/300 batch  23/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 255/300 batch  24/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 255/300 batch  25/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 255/300 batch  26/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 255/300 batch  27/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 255/300 batch  28/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 255/300 batch  29/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 255/300 batch  30/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 255/300 batch  31/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 255/300 batch  32/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 255/300 batch  33/188  Train Loss: 0.067, Acc: 0.988\n",
      "epoch: 255/300 batch  34/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 255/300 batch  35/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 255/300 batch  36/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 255/300 batch  37/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 255/300 batch  38/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 255/300 batch  39/188  Train Loss: 0.048, Acc: 0.980\n",
      "epoch: 255/300 batch  40/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 255/300 batch  41/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 255/300 batch  42/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 255/300 batch  43/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 255/300 batch  44/188  Train Loss: 0.016, Acc: 0.996\n",
      "epoch: 255/300 batch  45/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 255/300 batch  46/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 255/300 batch  47/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 255/300 batch  48/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 255/300 batch  49/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 255/300 batch  50/188  Train Loss: 0.052, Acc: 0.977\n",
      "epoch: 255/300 batch  51/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 255/300 batch  52/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 255/300 batch  53/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 255/300 batch  54/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 255/300 batch  55/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 255/300 batch  56/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 255/300 batch  57/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 255/300 batch  58/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 255/300 batch  59/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 255/300 batch  60/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 255/300 batch  61/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 255/300 batch  62/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 255/300 batch  63/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 255/300 batch  64/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 255/300 batch  65/188  Train Loss: 0.068, Acc: 0.984\n",
      "epoch: 255/300 batch  66/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 255/300 batch  67/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 255/300 batch  68/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 255/300 batch  69/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 255/300 batch  70/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 255/300 batch  71/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 255/300 batch  72/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 255/300 batch  73/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 255/300 batch  74/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 255/300 batch  75/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 255/300 batch  76/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 255/300 batch  77/188  Train Loss: 0.057, Acc: 0.980\n",
      "epoch: 255/300 batch  78/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 255/300 batch  79/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 255/300 batch  80/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 255/300 batch  81/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 255/300 batch  82/188  Train Loss: 0.058, Acc: 0.977\n",
      "epoch: 255/300 batch  83/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 255/300 batch  84/188  Train Loss: 0.053, Acc: 0.980\n",
      "epoch: 255/300 batch  85/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 255/300 batch  86/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 255/300 batch  87/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 255/300 batch  88/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 255/300 batch  89/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 255/300 batch  90/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 255/300 batch  91/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 255/300 batch  92/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 255/300 batch  93/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 255/300 batch  94/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 255/300 batch  95/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 255/300 batch  96/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 255/300 batch  97/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 255/300 batch  98/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 255/300 batch  99/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 255/300 batch 100/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 255/300 batch 101/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 255/300 batch 102/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 255/300 batch 103/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 255/300 batch 104/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 255/300 batch 105/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 255/300 batch 106/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 255/300 batch 107/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 255/300 batch 108/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 255/300 batch 109/188  Train Loss: 0.015, Acc: 0.996\n",
      "epoch: 255/300 batch 110/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 255/300 batch 111/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 255/300 batch 112/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 255/300 batch 113/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 255/300 batch 114/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 255/300 batch 115/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 255/300 batch 116/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 255/300 batch 117/188  Train Loss: 0.046, Acc: 0.980\n",
      "epoch: 255/300 batch 118/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 255/300 batch 119/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 255/300 batch 120/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 255/300 batch 121/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 255/300 batch 122/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 255/300 batch 123/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 255/300 batch 124/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 255/300 batch 125/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 255/300 batch 126/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 255/300 batch 127/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 255/300 batch 128/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 255/300 batch 129/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 255/300 batch 130/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 255/300 batch 131/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 255/300 batch 132/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 255/300 batch 133/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 255/300 batch 134/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 255/300 batch 135/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 255/300 batch 136/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 255/300 batch 137/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 255/300 batch 138/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 255/300 batch 139/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 255/300 batch 140/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 255/300 batch 141/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 255/300 batch 142/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 255/300 batch 143/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 255/300 batch 144/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 255/300 batch 145/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 255/300 batch 146/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 255/300 batch 147/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 255/300 batch 148/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 255/300 batch 149/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 255/300 batch 150/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 255/300 batch 151/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 255/300 batch 152/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 255/300 batch 153/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 255/300 batch 154/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 255/300 batch 155/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 255/300 batch 156/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 255/300 batch 157/188  Train Loss: 0.064, Acc: 0.988\n",
      "epoch: 255/300 batch 158/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 255/300 batch 159/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 255/300 batch 160/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 255/300 batch 161/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 255/300 batch 162/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 255/300 batch 163/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 255/300 batch 164/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 255/300 batch 165/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 255/300 batch 166/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 255/300 batch 167/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 255/300 batch 168/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 255/300 batch 169/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 255/300 batch 170/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 255/300 batch 171/188  Train Loss: 0.060, Acc: 0.980\n",
      "epoch: 255/300 batch 172/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 255/300 batch 173/188  Train Loss: 0.065, Acc: 0.980\n",
      "epoch: 255/300 batch 174/188  Train Loss: 0.014, Acc: 0.996\n",
      "epoch: 255/300 batch 175/188  Train Loss: 0.037, Acc: 0.980\n",
      "epoch: 255/300 batch 176/188  Train Loss: 0.045, Acc: 0.980\n",
      "epoch: 255/300 batch 177/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 255/300 batch 178/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 255/300 batch 179/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 255/300 batch 180/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 255/300 batch 181/188  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 255/300 batch 182/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 255/300 batch 183/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 255/300 batch 184/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 255/300 batch 185/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 255/300 batch 186/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 255/300 batch 187/188  Train Loss: 0.024, Acc: 0.992\n",
      "Train Loss: 0.032718, Acc: 0.993\n",
      "Val Loss: 0.057476, Acc: 0.983\n",
      "epoch: 256/300 batch   0/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 256/300 batch   1/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 256/300 batch   2/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 256/300 batch   3/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 256/300 batch   4/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 256/300 batch   5/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 256/300 batch   6/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 256/300 batch   7/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 256/300 batch   8/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 256/300 batch   9/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 256/300 batch  10/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 256/300 batch  11/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 256/300 batch  12/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 256/300 batch  13/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 256/300 batch  14/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 256/300 batch  15/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 256/300 batch  16/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 256/300 batch  17/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 256/300 batch  18/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 256/300 batch  19/188  Train Loss: 0.056, Acc: 0.992\n",
      "epoch: 256/300 batch  20/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 256/300 batch  21/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 256/300 batch  22/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 256/300 batch  23/188  Train Loss: 0.049, Acc: 0.980\n",
      "epoch: 256/300 batch  24/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 256/300 batch  25/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 256/300 batch  26/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 256/300 batch  27/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 256/300 batch  28/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 256/300 batch  29/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 256/300 batch  30/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 256/300 batch  31/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 256/300 batch  32/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 256/300 batch  33/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 256/300 batch  34/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 256/300 batch  35/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 256/300 batch  36/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 256/300 batch  37/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 256/300 batch  38/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 256/300 batch  39/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 256/300 batch  40/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 256/300 batch  41/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 256/300 batch  42/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 256/300 batch  43/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 256/300 batch  44/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 256/300 batch  45/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 256/300 batch  46/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 256/300 batch  47/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 256/300 batch  48/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 256/300 batch  49/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 256/300 batch  50/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 256/300 batch  51/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 256/300 batch  52/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 256/300 batch  53/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 256/300 batch  54/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 256/300 batch  55/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 256/300 batch  56/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 256/300 batch  57/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 256/300 batch  58/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 256/300 batch  59/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 256/300 batch  60/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 256/300 batch  61/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 256/300 batch  62/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 256/300 batch  63/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 256/300 batch  64/188  Train Loss: 0.065, Acc: 0.984\n",
      "epoch: 256/300 batch  65/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 256/300 batch  66/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 256/300 batch  67/188  Train Loss: 0.043, Acc: 0.980\n",
      "epoch: 256/300 batch  68/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 256/300 batch  69/188  Train Loss: 0.066, Acc: 0.984\n",
      "epoch: 256/300 batch  70/188  Train Loss: 0.056, Acc: 0.980\n",
      "epoch: 256/300 batch  71/188  Train Loss: 0.069, Acc: 0.980\n",
      "epoch: 256/300 batch  72/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 256/300 batch  73/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 256/300 batch  74/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 256/300 batch  75/188  Train Loss: 0.047, Acc: 0.980\n",
      "epoch: 256/300 batch  76/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 256/300 batch  77/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 256/300 batch  78/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 256/300 batch  79/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 256/300 batch  80/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 256/300 batch  81/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 256/300 batch  82/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 256/300 batch  83/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 256/300 batch  84/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 256/300 batch  85/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 256/300 batch  86/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 256/300 batch  87/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 256/300 batch  88/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 256/300 batch  89/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 256/300 batch  90/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 256/300 batch  91/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 256/300 batch  92/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 256/300 batch  93/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 256/300 batch  94/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 256/300 batch  95/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 256/300 batch  96/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 256/300 batch  97/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 256/300 batch  98/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 256/300 batch  99/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 256/300 batch 100/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 256/300 batch 101/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 256/300 batch 102/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 256/300 batch 103/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 256/300 batch 104/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 256/300 batch 105/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 256/300 batch 106/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 256/300 batch 107/188  Train Loss: 0.075, Acc: 0.973\n",
      "epoch: 256/300 batch 108/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 256/300 batch 109/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 256/300 batch 110/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 256/300 batch 111/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 256/300 batch 112/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 256/300 batch 113/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 256/300 batch 114/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 256/300 batch 115/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 256/300 batch 116/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 256/300 batch 117/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 256/300 batch 118/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 256/300 batch 119/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 256/300 batch 120/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 256/300 batch 121/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 256/300 batch 122/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 256/300 batch 123/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 256/300 batch 124/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 256/300 batch 125/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 256/300 batch 126/188  Train Loss: 0.042, Acc: 0.996\n",
      "epoch: 256/300 batch 127/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 256/300 batch 128/188  Train Loss: 0.014, Acc: 0.996\n",
      "epoch: 256/300 batch 129/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 256/300 batch 130/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 256/300 batch 131/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 256/300 batch 132/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 256/300 batch 133/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 256/300 batch 134/188  Train Loss: 0.053, Acc: 0.992\n",
      "epoch: 256/300 batch 135/188  Train Loss: 0.056, Acc: 0.988\n",
      "epoch: 256/300 batch 136/188  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 256/300 batch 137/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 256/300 batch 138/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 256/300 batch 139/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 256/300 batch 140/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 256/300 batch 141/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 256/300 batch 142/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 256/300 batch 143/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 256/300 batch 144/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 256/300 batch 145/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 256/300 batch 146/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 256/300 batch 147/188  Train Loss: 0.066, Acc: 0.992\n",
      "epoch: 256/300 batch 148/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 256/300 batch 149/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 256/300 batch 150/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 256/300 batch 151/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 256/300 batch 152/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 256/300 batch 153/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 256/300 batch 154/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 256/300 batch 155/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 256/300 batch 156/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 256/300 batch 157/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 256/300 batch 158/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 256/300 batch 159/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 256/300 batch 160/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 256/300 batch 161/188  Train Loss: 0.027, Acc: 0.988\n",
      "epoch: 256/300 batch 162/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 256/300 batch 163/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 256/300 batch 164/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 256/300 batch 165/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 256/300 batch 166/188  Train Loss: 0.059, Acc: 0.977\n",
      "epoch: 256/300 batch 167/188  Train Loss: 0.045, Acc: 0.980\n",
      "epoch: 256/300 batch 168/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 256/300 batch 169/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 256/300 batch 170/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 256/300 batch 171/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 256/300 batch 172/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 256/300 batch 173/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 256/300 batch 174/188  Train Loss: 0.045, Acc: 0.980\n",
      "epoch: 256/300 batch 175/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 256/300 batch 176/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 256/300 batch 177/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 256/300 batch 178/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 256/300 batch 179/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 256/300 batch 180/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 256/300 batch 181/188  Train Loss: 0.076, Acc: 0.977\n",
      "epoch: 256/300 batch 182/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 256/300 batch 183/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 256/300 batch 184/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 256/300 batch 185/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 256/300 batch 186/188  Train Loss: 0.060, Acc: 0.980\n",
      "epoch: 256/300 batch 187/188  Train Loss: 0.013, Acc: 1.000\n",
      "Train Loss: 0.032703, Acc: 0.993\n",
      "Val Loss: 0.057506, Acc: 0.983\n",
      "epoch: 257/300 batch   0/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 257/300 batch   1/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 257/300 batch   2/188  Train Loss: 0.014, Acc: 0.996\n",
      "epoch: 257/300 batch   3/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 257/300 batch   4/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 257/300 batch   5/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 257/300 batch   6/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 257/300 batch   7/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 257/300 batch   8/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 257/300 batch   9/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 257/300 batch  10/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 257/300 batch  11/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 257/300 batch  12/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 257/300 batch  13/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 257/300 batch  14/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 257/300 batch  15/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 257/300 batch  16/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 257/300 batch  17/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 257/300 batch  18/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 257/300 batch  19/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 257/300 batch  20/188  Train Loss: 0.054, Acc: 0.992\n",
      "epoch: 257/300 batch  21/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 257/300 batch  22/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 257/300 batch  23/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 257/300 batch  24/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 257/300 batch  25/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 257/300 batch  26/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 257/300 batch  27/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 257/300 batch  28/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 257/300 batch  29/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 257/300 batch  30/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 257/300 batch  31/188  Train Loss: 0.079, Acc: 0.980\n",
      "epoch: 257/300 batch  32/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 257/300 batch  33/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 257/300 batch  34/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 257/300 batch  35/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 257/300 batch  36/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 257/300 batch  37/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 257/300 batch  38/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 257/300 batch  39/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 257/300 batch  40/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 257/300 batch  41/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 257/300 batch  42/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 257/300 batch  43/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 257/300 batch  44/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 257/300 batch  45/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 257/300 batch  46/188  Train Loss: 0.049, Acc: 0.973\n",
      "epoch: 257/300 batch  47/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 257/300 batch  48/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 257/300 batch  49/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 257/300 batch  50/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 257/300 batch  51/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 257/300 batch  52/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 257/300 batch  53/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 257/300 batch  54/188  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 257/300 batch  55/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 257/300 batch  56/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 257/300 batch  57/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 257/300 batch  58/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 257/300 batch  59/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 257/300 batch  60/188  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 257/300 batch  61/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 257/300 batch  62/188  Train Loss: 0.059, Acc: 0.984\n",
      "epoch: 257/300 batch  63/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 257/300 batch  64/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 257/300 batch  65/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 257/300 batch  66/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 257/300 batch  67/188  Train Loss: 0.032, Acc: 1.000\n",
      "epoch: 257/300 batch  68/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 257/300 batch  69/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 257/300 batch  70/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 257/300 batch  71/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 257/300 batch  72/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 257/300 batch  73/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 257/300 batch  74/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 257/300 batch  75/188  Train Loss: 0.032, Acc: 1.000\n",
      "epoch: 257/300 batch  76/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 257/300 batch  77/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 257/300 batch  78/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 257/300 batch  79/188  Train Loss: 0.070, Acc: 0.980\n",
      "epoch: 257/300 batch  80/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 257/300 batch  81/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 257/300 batch  82/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 257/300 batch  83/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 257/300 batch  84/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 257/300 batch  85/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 257/300 batch  86/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 257/300 batch  87/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 257/300 batch  88/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 257/300 batch  89/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 257/300 batch  90/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 257/300 batch  91/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 257/300 batch  92/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 257/300 batch  93/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 257/300 batch  94/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 257/300 batch  95/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 257/300 batch  96/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 257/300 batch  97/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 257/300 batch  98/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 257/300 batch  99/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 257/300 batch 100/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 257/300 batch 101/188  Train Loss: 0.060, Acc: 0.984\n",
      "epoch: 257/300 batch 102/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 257/300 batch 103/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 257/300 batch 104/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 257/300 batch 105/188  Train Loss: 0.045, Acc: 0.980\n",
      "epoch: 257/300 batch 106/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 257/300 batch 107/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 257/300 batch 108/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 257/300 batch 109/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 257/300 batch 110/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 257/300 batch 111/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 257/300 batch 112/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 257/300 batch 113/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 257/300 batch 114/188  Train Loss: 0.052, Acc: 0.980\n",
      "epoch: 257/300 batch 115/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 257/300 batch 116/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 257/300 batch 117/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 257/300 batch 118/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 257/300 batch 119/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 257/300 batch 120/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 257/300 batch 121/188  Train Loss: 0.025, Acc: 0.984\n",
      "epoch: 257/300 batch 122/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 257/300 batch 123/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 257/300 batch 124/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 257/300 batch 125/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 257/300 batch 126/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 257/300 batch 127/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 257/300 batch 128/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 257/300 batch 129/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 257/300 batch 130/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 257/300 batch 131/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 257/300 batch 132/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 257/300 batch 133/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 257/300 batch 134/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 257/300 batch 135/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 257/300 batch 136/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 257/300 batch 137/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 257/300 batch 138/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 257/300 batch 139/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 257/300 batch 140/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 257/300 batch 141/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 257/300 batch 142/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 257/300 batch 143/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 257/300 batch 144/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 257/300 batch 145/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 257/300 batch 146/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 257/300 batch 147/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 257/300 batch 148/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 257/300 batch 149/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 257/300 batch 150/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 257/300 batch 151/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 257/300 batch 152/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 257/300 batch 153/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 257/300 batch 154/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 257/300 batch 155/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 257/300 batch 156/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 257/300 batch 157/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 257/300 batch 158/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 257/300 batch 159/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 257/300 batch 160/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 257/300 batch 161/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 257/300 batch 162/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 257/300 batch 163/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 257/300 batch 164/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 257/300 batch 165/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 257/300 batch 166/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 257/300 batch 167/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 257/300 batch 168/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 257/300 batch 169/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 257/300 batch 170/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 257/300 batch 171/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 257/300 batch 172/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 257/300 batch 173/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 257/300 batch 174/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 257/300 batch 175/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 257/300 batch 176/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 257/300 batch 177/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 257/300 batch 178/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 257/300 batch 179/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 257/300 batch 180/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 257/300 batch 181/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 257/300 batch 182/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 257/300 batch 183/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 257/300 batch 184/188  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 257/300 batch 185/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 257/300 batch 186/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 257/300 batch 187/188  Train Loss: 0.067, Acc: 0.977\n",
      "Train Loss: 0.032812, Acc: 0.993\n",
      "Val Loss: 0.057339, Acc: 0.983\n",
      "epoch: 258/300 batch   0/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 258/300 batch   1/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 258/300 batch   2/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 258/300 batch   3/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 258/300 batch   4/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 258/300 batch   5/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 258/300 batch   6/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 258/300 batch   7/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 258/300 batch   8/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 258/300 batch   9/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 258/300 batch  10/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 258/300 batch  11/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 258/300 batch  12/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 258/300 batch  13/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 258/300 batch  14/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 258/300 batch  15/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 258/300 batch  16/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 258/300 batch  17/188  Train Loss: 0.064, Acc: 0.973\n",
      "epoch: 258/300 batch  18/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 258/300 batch  19/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 258/300 batch  20/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 258/300 batch  21/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 258/300 batch  22/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 258/300 batch  23/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 258/300 batch  24/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 258/300 batch  25/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 258/300 batch  26/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 258/300 batch  27/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 258/300 batch  28/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 258/300 batch  29/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 258/300 batch  30/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 258/300 batch  31/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 258/300 batch  32/188  Train Loss: 0.032, Acc: 1.000\n",
      "epoch: 258/300 batch  33/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 258/300 batch  34/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 258/300 batch  35/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 258/300 batch  36/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 258/300 batch  37/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 258/300 batch  38/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 258/300 batch  39/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 258/300 batch  40/188  Train Loss: 0.027, Acc: 0.984\n",
      "epoch: 258/300 batch  41/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 258/300 batch  42/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 258/300 batch  43/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 258/300 batch  44/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 258/300 batch  45/188  Train Loss: 0.032, Acc: 1.000\n",
      "epoch: 258/300 batch  46/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 258/300 batch  47/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 258/300 batch  48/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 258/300 batch  49/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 258/300 batch  50/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 258/300 batch  51/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 258/300 batch  52/188  Train Loss: 0.064, Acc: 0.984\n",
      "epoch: 258/300 batch  53/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 258/300 batch  54/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 258/300 batch  55/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 258/300 batch  56/188  Train Loss: 0.059, Acc: 0.984\n",
      "epoch: 258/300 batch  57/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 258/300 batch  58/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 258/300 batch  59/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 258/300 batch  60/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 258/300 batch  61/188  Train Loss: 0.042, Acc: 0.996\n",
      "epoch: 258/300 batch  62/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 258/300 batch  63/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 258/300 batch  64/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 258/300 batch  65/188  Train Loss: 0.058, Acc: 0.977\n",
      "epoch: 258/300 batch  66/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 258/300 batch  67/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 258/300 batch  68/188  Train Loss: 0.069, Acc: 0.980\n",
      "epoch: 258/300 batch  69/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 258/300 batch  70/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 258/300 batch  71/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 258/300 batch  72/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 258/300 batch  73/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 258/300 batch  74/188  Train Loss: 0.062, Acc: 0.980\n",
      "epoch: 258/300 batch  75/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 258/300 batch  76/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 258/300 batch  77/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 258/300 batch  78/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 258/300 batch  79/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 258/300 batch  80/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 258/300 batch  81/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 258/300 batch  82/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 258/300 batch  83/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 258/300 batch  84/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 258/300 batch  85/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 258/300 batch  86/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 258/300 batch  87/188  Train Loss: 0.031, Acc: 0.984\n",
      "epoch: 258/300 batch  88/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 258/300 batch  89/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 258/300 batch  90/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 258/300 batch  91/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 258/300 batch  92/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 258/300 batch  93/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 258/300 batch  94/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 258/300 batch  95/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 258/300 batch  96/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 258/300 batch  97/188  Train Loss: 0.033, Acc: 0.984\n",
      "epoch: 258/300 batch  98/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 258/300 batch  99/188  Train Loss: 0.043, Acc: 0.980\n",
      "epoch: 258/300 batch 100/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 258/300 batch 101/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 258/300 batch 102/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 258/300 batch 103/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 258/300 batch 104/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 258/300 batch 105/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 258/300 batch 106/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 258/300 batch 107/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 258/300 batch 108/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 258/300 batch 109/188  Train Loss: 0.074, Acc: 0.984\n",
      "epoch: 258/300 batch 110/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 258/300 batch 111/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 258/300 batch 112/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 258/300 batch 113/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 258/300 batch 114/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 258/300 batch 115/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 258/300 batch 116/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 258/300 batch 117/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 258/300 batch 118/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 258/300 batch 119/188  Train Loss: 0.062, Acc: 0.988\n",
      "epoch: 258/300 batch 120/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 258/300 batch 121/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 258/300 batch 122/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 258/300 batch 123/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 258/300 batch 124/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 258/300 batch 125/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 258/300 batch 126/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 258/300 batch 127/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 258/300 batch 128/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 258/300 batch 129/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 258/300 batch 130/188  Train Loss: 0.057, Acc: 0.988\n",
      "epoch: 258/300 batch 131/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 258/300 batch 132/188  Train Loss: 0.016, Acc: 0.996\n",
      "epoch: 258/300 batch 133/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 258/300 batch 134/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 258/300 batch 135/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 258/300 batch 136/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 258/300 batch 137/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 258/300 batch 138/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 258/300 batch 139/188  Train Loss: 0.045, Acc: 0.980\n",
      "epoch: 258/300 batch 140/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 258/300 batch 141/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 258/300 batch 142/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 258/300 batch 143/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 258/300 batch 144/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 258/300 batch 145/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 258/300 batch 146/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 258/300 batch 147/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 258/300 batch 148/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 258/300 batch 149/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 258/300 batch 150/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 258/300 batch 151/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 258/300 batch 152/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 258/300 batch 153/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 258/300 batch 154/188  Train Loss: 0.050, Acc: 0.980\n",
      "epoch: 258/300 batch 155/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 258/300 batch 156/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 258/300 batch 157/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 258/300 batch 158/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 258/300 batch 159/188  Train Loss: 0.058, Acc: 0.980\n",
      "epoch: 258/300 batch 160/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 258/300 batch 161/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 258/300 batch 162/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 258/300 batch 163/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 258/300 batch 164/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 258/300 batch 165/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 258/300 batch 166/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 258/300 batch 167/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 258/300 batch 168/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 258/300 batch 169/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 258/300 batch 170/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 258/300 batch 171/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 258/300 batch 172/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 258/300 batch 173/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 258/300 batch 174/188  Train Loss: 0.026, Acc: 0.988\n",
      "epoch: 258/300 batch 175/188  Train Loss: 0.047, Acc: 0.977\n",
      "epoch: 258/300 batch 176/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 258/300 batch 177/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 258/300 batch 178/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 258/300 batch 179/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 258/300 batch 180/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 258/300 batch 181/188  Train Loss: 0.049, Acc: 0.980\n",
      "epoch: 258/300 batch 182/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 258/300 batch 183/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 258/300 batch 184/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 258/300 batch 185/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 258/300 batch 186/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 258/300 batch 187/188  Train Loss: 0.019, Acc: 1.000\n",
      "Train Loss: 0.032652, Acc: 0.993\n",
      "Val Loss: 0.057522, Acc: 0.983\n",
      "epoch: 259/300 batch   0/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 259/300 batch   1/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 259/300 batch   2/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 259/300 batch   3/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 259/300 batch   4/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 259/300 batch   5/188  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 259/300 batch   6/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 259/300 batch   7/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 259/300 batch   8/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 259/300 batch   9/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 259/300 batch  10/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 259/300 batch  11/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 259/300 batch  12/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 259/300 batch  13/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 259/300 batch  14/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 259/300 batch  15/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 259/300 batch  16/188  Train Loss: 0.056, Acc: 0.996\n",
      "epoch: 259/300 batch  17/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 259/300 batch  18/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 259/300 batch  19/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 259/300 batch  20/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 259/300 batch  21/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 259/300 batch  22/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 259/300 batch  23/188  Train Loss: 0.051, Acc: 0.980\n",
      "epoch: 259/300 batch  24/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 259/300 batch  25/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 259/300 batch  26/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 259/300 batch  27/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 259/300 batch  28/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 259/300 batch  29/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 259/300 batch  30/188  Train Loss: 0.057, Acc: 0.980\n",
      "epoch: 259/300 batch  31/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 259/300 batch  32/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 259/300 batch  33/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 259/300 batch  34/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 259/300 batch  35/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 259/300 batch  36/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 259/300 batch  37/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 259/300 batch  38/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 259/300 batch  39/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 259/300 batch  40/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 259/300 batch  41/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 259/300 batch  42/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 259/300 batch  43/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 259/300 batch  44/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 259/300 batch  45/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 259/300 batch  46/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 259/300 batch  47/188  Train Loss: 0.060, Acc: 0.984\n",
      "epoch: 259/300 batch  48/188  Train Loss: 0.043, Acc: 0.996\n",
      "epoch: 259/300 batch  49/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 259/300 batch  50/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 259/300 batch  51/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 259/300 batch  52/188  Train Loss: 0.047, Acc: 0.980\n",
      "epoch: 259/300 batch  53/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 259/300 batch  54/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 259/300 batch  55/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 259/300 batch  56/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 259/300 batch  57/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 259/300 batch  58/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 259/300 batch  59/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 259/300 batch  60/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 259/300 batch  61/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 259/300 batch  62/188  Train Loss: 0.033, Acc: 0.984\n",
      "epoch: 259/300 batch  63/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 259/300 batch  64/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 259/300 batch  65/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 259/300 batch  66/188  Train Loss: 0.045, Acc: 0.980\n",
      "epoch: 259/300 batch  67/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 259/300 batch  68/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 259/300 batch  69/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 259/300 batch  70/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 259/300 batch  71/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 259/300 batch  72/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 259/300 batch  73/188  Train Loss: 0.059, Acc: 0.988\n",
      "epoch: 259/300 batch  74/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 259/300 batch  75/188  Train Loss: 0.024, Acc: 0.988\n",
      "epoch: 259/300 batch  76/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 259/300 batch  77/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 259/300 batch  78/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 259/300 batch  79/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 259/300 batch  80/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 259/300 batch  81/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 259/300 batch  82/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 259/300 batch  83/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 259/300 batch  84/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 259/300 batch  85/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 259/300 batch  86/188  Train Loss: 0.033, Acc: 0.984\n",
      "epoch: 259/300 batch  87/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 259/300 batch  88/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 259/300 batch  89/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 259/300 batch  90/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 259/300 batch  91/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 259/300 batch  92/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 259/300 batch  93/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 259/300 batch  94/188  Train Loss: 0.069, Acc: 0.980\n",
      "epoch: 259/300 batch  95/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 259/300 batch  96/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 259/300 batch  97/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 259/300 batch  98/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 259/300 batch  99/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 259/300 batch 100/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 259/300 batch 101/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 259/300 batch 102/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 259/300 batch 103/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 259/300 batch 104/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 259/300 batch 105/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 259/300 batch 106/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 259/300 batch 107/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 259/300 batch 108/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 259/300 batch 109/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 259/300 batch 110/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 259/300 batch 111/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 259/300 batch 112/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 259/300 batch 113/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 259/300 batch 114/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 259/300 batch 115/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 259/300 batch 116/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 259/300 batch 117/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 259/300 batch 118/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 259/300 batch 119/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 259/300 batch 120/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 259/300 batch 121/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 259/300 batch 122/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 259/300 batch 123/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 259/300 batch 124/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 259/300 batch 125/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 259/300 batch 126/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 259/300 batch 127/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 259/300 batch 128/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 259/300 batch 129/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 259/300 batch 130/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 259/300 batch 131/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 259/300 batch 132/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 259/300 batch 133/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 259/300 batch 134/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 259/300 batch 135/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 259/300 batch 136/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 259/300 batch 137/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 259/300 batch 138/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 259/300 batch 139/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 259/300 batch 140/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 259/300 batch 141/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 259/300 batch 142/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 259/300 batch 143/188  Train Loss: 0.065, Acc: 0.984\n",
      "epoch: 259/300 batch 144/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 259/300 batch 145/188  Train Loss: 0.051, Acc: 0.980\n",
      "epoch: 259/300 batch 146/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 259/300 batch 147/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 259/300 batch 148/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 259/300 batch 149/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 259/300 batch 150/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 259/300 batch 151/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 259/300 batch 152/188  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 259/300 batch 153/188  Train Loss: 0.052, Acc: 0.980\n",
      "epoch: 259/300 batch 154/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 259/300 batch 155/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 259/300 batch 156/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 259/300 batch 157/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 259/300 batch 158/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 259/300 batch 159/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 259/300 batch 160/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 259/300 batch 161/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 259/300 batch 162/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 259/300 batch 163/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 259/300 batch 164/188  Train Loss: 0.031, Acc: 1.000\n",
      "epoch: 259/300 batch 165/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 259/300 batch 166/188  Train Loss: 0.046, Acc: 0.980\n",
      "epoch: 259/300 batch 167/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 259/300 batch 168/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 259/300 batch 169/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 259/300 batch 170/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 259/300 batch 171/188  Train Loss: 0.044, Acc: 0.977\n",
      "epoch: 259/300 batch 172/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 259/300 batch 173/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 259/300 batch 174/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 259/300 batch 175/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 259/300 batch 176/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 259/300 batch 177/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 259/300 batch 178/188  Train Loss: 0.045, Acc: 0.996\n",
      "epoch: 259/300 batch 179/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 259/300 batch 180/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 259/300 batch 181/188  Train Loss: 0.053, Acc: 0.977\n",
      "epoch: 259/300 batch 182/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 259/300 batch 183/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 259/300 batch 184/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 259/300 batch 185/188  Train Loss: 0.085, Acc: 0.973\n",
      "epoch: 259/300 batch 186/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 259/300 batch 187/188  Train Loss: 0.026, Acc: 0.992\n",
      "Train Loss: 0.032644, Acc: 0.993\n",
      "Val Loss: 0.057894, Acc: 0.983\n",
      "epoch: 260/300 batch   0/188  Train Loss: 0.062, Acc: 0.980\n",
      "epoch: 260/300 batch   1/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 260/300 batch   2/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 260/300 batch   3/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 260/300 batch   4/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 260/300 batch   5/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 260/300 batch   6/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 260/300 batch   7/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 260/300 batch   8/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 260/300 batch   9/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 260/300 batch  10/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 260/300 batch  11/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 260/300 batch  12/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 260/300 batch  13/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 260/300 batch  14/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 260/300 batch  15/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 260/300 batch  16/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 260/300 batch  17/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 260/300 batch  18/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 260/300 batch  19/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 260/300 batch  20/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 260/300 batch  21/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 260/300 batch  22/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 260/300 batch  23/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 260/300 batch  24/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 260/300 batch  25/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 260/300 batch  26/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 260/300 batch  27/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 260/300 batch  28/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 260/300 batch  29/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 260/300 batch  30/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 260/300 batch  31/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 260/300 batch  32/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 260/300 batch  33/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 260/300 batch  34/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 260/300 batch  35/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 260/300 batch  36/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 260/300 batch  37/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 260/300 batch  38/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 260/300 batch  39/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 260/300 batch  40/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 260/300 batch  41/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 260/300 batch  42/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 260/300 batch  43/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 260/300 batch  44/188  Train Loss: 0.060, Acc: 0.984\n",
      "epoch: 260/300 batch  45/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 260/300 batch  46/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 260/300 batch  47/188  Train Loss: 0.056, Acc: 0.977\n",
      "epoch: 260/300 batch  48/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 260/300 batch  49/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 260/300 batch  50/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 260/300 batch  51/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 260/300 batch  52/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 260/300 batch  53/188  Train Loss: 0.024, Acc: 0.988\n",
      "epoch: 260/300 batch  54/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 260/300 batch  55/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 260/300 batch  56/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 260/300 batch  57/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 260/300 batch  58/188  Train Loss: 0.080, Acc: 0.988\n",
      "epoch: 260/300 batch  59/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 260/300 batch  60/188  Train Loss: 0.041, Acc: 0.980\n",
      "epoch: 260/300 batch  61/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 260/300 batch  62/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 260/300 batch  63/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 260/300 batch  64/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 260/300 batch  65/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 260/300 batch  66/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 260/300 batch  67/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 260/300 batch  68/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 260/300 batch  69/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 260/300 batch  70/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 260/300 batch  71/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 260/300 batch  72/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 260/300 batch  73/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 260/300 batch  74/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 260/300 batch  75/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 260/300 batch  76/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 260/300 batch  77/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 260/300 batch  78/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 260/300 batch  79/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 260/300 batch  80/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 260/300 batch  81/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 260/300 batch  82/188  Train Loss: 0.048, Acc: 0.980\n",
      "epoch: 260/300 batch  83/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 260/300 batch  84/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 260/300 batch  85/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 260/300 batch  86/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 260/300 batch  87/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 260/300 batch  88/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 260/300 batch  89/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 260/300 batch  90/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 260/300 batch  91/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 260/300 batch  92/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 260/300 batch  93/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 260/300 batch  94/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 260/300 batch  95/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 260/300 batch  96/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 260/300 batch  97/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 260/300 batch  98/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 260/300 batch  99/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 260/300 batch 100/188  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 260/300 batch 101/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 260/300 batch 102/188  Train Loss: 0.059, Acc: 0.984\n",
      "epoch: 260/300 batch 103/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 260/300 batch 104/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 260/300 batch 105/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 260/300 batch 106/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 260/300 batch 107/188  Train Loss: 0.043, Acc: 0.980\n",
      "epoch: 260/300 batch 108/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 260/300 batch 109/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 260/300 batch 110/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 260/300 batch 111/188  Train Loss: 0.056, Acc: 0.980\n",
      "epoch: 260/300 batch 112/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 260/300 batch 113/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 260/300 batch 114/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 260/300 batch 115/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 260/300 batch 116/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 260/300 batch 117/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 260/300 batch 118/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 260/300 batch 119/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 260/300 batch 120/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 260/300 batch 121/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 260/300 batch 122/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 260/300 batch 123/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 260/300 batch 124/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 260/300 batch 125/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 260/300 batch 126/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 260/300 batch 127/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 260/300 batch 128/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 260/300 batch 129/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 260/300 batch 130/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 260/300 batch 131/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 260/300 batch 132/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 260/300 batch 133/188  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 260/300 batch 134/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 260/300 batch 135/188  Train Loss: 0.033, Acc: 0.984\n",
      "epoch: 260/300 batch 136/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 260/300 batch 137/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 260/300 batch 138/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 260/300 batch 139/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 260/300 batch 140/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 260/300 batch 141/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 260/300 batch 142/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 260/300 batch 143/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 260/300 batch 144/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 260/300 batch 145/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 260/300 batch 146/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 260/300 batch 147/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 260/300 batch 148/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 260/300 batch 149/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 260/300 batch 150/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 260/300 batch 151/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 260/300 batch 152/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 260/300 batch 153/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 260/300 batch 154/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 260/300 batch 155/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 260/300 batch 156/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 260/300 batch 157/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 260/300 batch 158/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 260/300 batch 159/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 260/300 batch 160/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 260/300 batch 161/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 260/300 batch 162/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 260/300 batch 163/188  Train Loss: 0.063, Acc: 0.984\n",
      "epoch: 260/300 batch 164/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 260/300 batch 165/188  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 260/300 batch 166/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 260/300 batch 167/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 260/300 batch 168/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 260/300 batch 169/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 260/300 batch 170/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 260/300 batch 171/188  Train Loss: 0.064, Acc: 0.973\n",
      "epoch: 260/300 batch 172/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 260/300 batch 173/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 260/300 batch 174/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 260/300 batch 175/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 260/300 batch 176/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 260/300 batch 177/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 260/300 batch 178/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 260/300 batch 179/188  Train Loss: 0.083, Acc: 0.980\n",
      "epoch: 260/300 batch 180/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 260/300 batch 181/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 260/300 batch 182/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 260/300 batch 183/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 260/300 batch 184/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 260/300 batch 185/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 260/300 batch 186/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 260/300 batch 187/188  Train Loss: 0.042, Acc: 0.984\n",
      "Train Loss: 0.032870, Acc: 0.993\n",
      "Val Loss: 0.057742, Acc: 0.983\n",
      "epoch: 261/300 batch   0/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 261/300 batch   1/188  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 261/300 batch   2/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 261/300 batch   3/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 261/300 batch   4/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 261/300 batch   5/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 261/300 batch   6/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 261/300 batch   7/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 261/300 batch   8/188  Train Loss: 0.062, Acc: 0.977\n",
      "epoch: 261/300 batch   9/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 261/300 batch  10/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 261/300 batch  11/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 261/300 batch  12/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 261/300 batch  13/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 261/300 batch  14/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 261/300 batch  15/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 261/300 batch  16/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 261/300 batch  17/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 261/300 batch  18/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 261/300 batch  19/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 261/300 batch  20/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 261/300 batch  21/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 261/300 batch  22/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 261/300 batch  23/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 261/300 batch  24/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 261/300 batch  25/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 261/300 batch  26/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 261/300 batch  27/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 261/300 batch  28/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 261/300 batch  29/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 261/300 batch  30/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 261/300 batch  31/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 261/300 batch  32/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 261/300 batch  33/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 261/300 batch  34/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 261/300 batch  35/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 261/300 batch  36/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 261/300 batch  37/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 261/300 batch  38/188  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 261/300 batch  39/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 261/300 batch  40/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 261/300 batch  41/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 261/300 batch  42/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 261/300 batch  43/188  Train Loss: 0.044, Acc: 0.996\n",
      "epoch: 261/300 batch  44/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 261/300 batch  45/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 261/300 batch  46/188  Train Loss: 0.061, Acc: 0.988\n",
      "epoch: 261/300 batch  47/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 261/300 batch  48/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 261/300 batch  49/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 261/300 batch  50/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 261/300 batch  51/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 261/300 batch  52/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 261/300 batch  53/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 261/300 batch  54/188  Train Loss: 0.024, Acc: 0.988\n",
      "epoch: 261/300 batch  55/188  Train Loss: 0.031, Acc: 1.000\n",
      "epoch: 261/300 batch  56/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 261/300 batch  57/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 261/300 batch  58/188  Train Loss: 0.048, Acc: 0.977\n",
      "epoch: 261/300 batch  59/188  Train Loss: 0.044, Acc: 0.980\n",
      "epoch: 261/300 batch  60/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 261/300 batch  61/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 261/300 batch  62/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 261/300 batch  63/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 261/300 batch  64/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 261/300 batch  65/188  Train Loss: 0.041, Acc: 1.000\n",
      "epoch: 261/300 batch  66/188  Train Loss: 0.053, Acc: 0.980\n",
      "epoch: 261/300 batch  67/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 261/300 batch  68/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 261/300 batch  69/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 261/300 batch  70/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 261/300 batch  71/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 261/300 batch  72/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 261/300 batch  73/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 261/300 batch  74/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 261/300 batch  75/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 261/300 batch  76/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 261/300 batch  77/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 261/300 batch  78/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 261/300 batch  79/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 261/300 batch  80/188  Train Loss: 0.062, Acc: 0.984\n",
      "epoch: 261/300 batch  81/188  Train Loss: 0.055, Acc: 0.992\n",
      "epoch: 261/300 batch  82/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 261/300 batch  83/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 261/300 batch  84/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 261/300 batch  85/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 261/300 batch  86/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 261/300 batch  87/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 261/300 batch  88/188  Train Loss: 0.083, Acc: 0.973\n",
      "epoch: 261/300 batch  89/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 261/300 batch  90/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 261/300 batch  91/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 261/300 batch  92/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 261/300 batch  93/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 261/300 batch  94/188  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 261/300 batch  95/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 261/300 batch  96/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 261/300 batch  97/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 261/300 batch  98/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 261/300 batch  99/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 261/300 batch 100/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 261/300 batch 101/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 261/300 batch 102/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 261/300 batch 103/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 261/300 batch 104/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 261/300 batch 105/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 261/300 batch 106/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 261/300 batch 107/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 261/300 batch 108/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 261/300 batch 109/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 261/300 batch 110/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 261/300 batch 111/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 261/300 batch 112/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 261/300 batch 113/188  Train Loss: 0.053, Acc: 0.977\n",
      "epoch: 261/300 batch 114/188  Train Loss: 0.045, Acc: 0.980\n",
      "epoch: 261/300 batch 115/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 261/300 batch 116/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 261/300 batch 117/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 261/300 batch 118/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 261/300 batch 119/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 261/300 batch 120/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 261/300 batch 121/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 261/300 batch 122/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 261/300 batch 123/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 261/300 batch 124/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 261/300 batch 125/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 261/300 batch 126/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 261/300 batch 127/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 261/300 batch 128/188  Train Loss: 0.062, Acc: 0.977\n",
      "epoch: 261/300 batch 129/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 261/300 batch 130/188  Train Loss: 0.063, Acc: 0.988\n",
      "epoch: 261/300 batch 131/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 261/300 batch 132/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 261/300 batch 133/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 261/300 batch 134/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 261/300 batch 135/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 261/300 batch 136/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 261/300 batch 137/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 261/300 batch 138/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 261/300 batch 139/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 261/300 batch 140/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 261/300 batch 141/188  Train Loss: 0.056, Acc: 0.988\n",
      "epoch: 261/300 batch 142/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 261/300 batch 143/188  Train Loss: 0.040, Acc: 0.980\n",
      "epoch: 261/300 batch 144/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 261/300 batch 145/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 261/300 batch 146/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 261/300 batch 147/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 261/300 batch 148/188  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 261/300 batch 149/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 261/300 batch 150/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 261/300 batch 151/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 261/300 batch 152/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 261/300 batch 153/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 261/300 batch 154/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 261/300 batch 155/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 261/300 batch 156/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 261/300 batch 157/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 261/300 batch 158/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 261/300 batch 159/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 261/300 batch 160/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 261/300 batch 161/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 261/300 batch 162/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 261/300 batch 163/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 261/300 batch 164/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 261/300 batch 165/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 261/300 batch 166/188  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 261/300 batch 167/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 261/300 batch 168/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 261/300 batch 169/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 261/300 batch 170/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 261/300 batch 171/188  Train Loss: 0.053, Acc: 0.980\n",
      "epoch: 261/300 batch 172/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 261/300 batch 173/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 261/300 batch 174/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 261/300 batch 175/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 261/300 batch 176/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 261/300 batch 177/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 261/300 batch 178/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 261/300 batch 179/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 261/300 batch 180/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 261/300 batch 181/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 261/300 batch 182/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 261/300 batch 183/188  Train Loss: 0.067, Acc: 0.980\n",
      "epoch: 261/300 batch 184/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 261/300 batch 185/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 261/300 batch 186/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 261/300 batch 187/188  Train Loss: 0.019, Acc: 1.000\n",
      "Train Loss: 0.032752, Acc: 0.993\n",
      "Val Loss: 0.057446, Acc: 0.983\n",
      "epoch: 262/300 batch   0/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 262/300 batch   1/188  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 262/300 batch   2/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 262/300 batch   3/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 262/300 batch   4/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 262/300 batch   5/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 262/300 batch   6/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 262/300 batch   7/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 262/300 batch   8/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 262/300 batch   9/188  Train Loss: 0.016, Acc: 0.996\n",
      "epoch: 262/300 batch  10/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 262/300 batch  11/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 262/300 batch  12/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 262/300 batch  13/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 262/300 batch  14/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 262/300 batch  15/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 262/300 batch  16/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 262/300 batch  17/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 262/300 batch  18/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 262/300 batch  19/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 262/300 batch  20/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 262/300 batch  21/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 262/300 batch  22/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 262/300 batch  23/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 262/300 batch  24/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 262/300 batch  25/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 262/300 batch  26/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 262/300 batch  27/188  Train Loss: 0.045, Acc: 0.980\n",
      "epoch: 262/300 batch  28/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 262/300 batch  29/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 262/300 batch  30/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 262/300 batch  31/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 262/300 batch  32/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 262/300 batch  33/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 262/300 batch  34/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 262/300 batch  35/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 262/300 batch  36/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 262/300 batch  37/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 262/300 batch  38/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 262/300 batch  39/188  Train Loss: 0.055, Acc: 0.992\n",
      "epoch: 262/300 batch  40/188  Train Loss: 0.042, Acc: 0.996\n",
      "epoch: 262/300 batch  41/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 262/300 batch  42/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 262/300 batch  43/188  Train Loss: 0.031, Acc: 0.984\n",
      "epoch: 262/300 batch  44/188  Train Loss: 0.056, Acc: 0.992\n",
      "epoch: 262/300 batch  45/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 262/300 batch  46/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 262/300 batch  47/188  Train Loss: 0.044, Acc: 0.980\n",
      "epoch: 262/300 batch  48/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 262/300 batch  49/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 262/300 batch  50/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 262/300 batch  51/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 262/300 batch  52/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 262/300 batch  53/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 262/300 batch  54/188  Train Loss: 0.032, Acc: 0.984\n",
      "epoch: 262/300 batch  55/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 262/300 batch  56/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 262/300 batch  57/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 262/300 batch  58/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 262/300 batch  59/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 262/300 batch  60/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 262/300 batch  61/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 262/300 batch  62/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 262/300 batch  63/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 262/300 batch  64/188  Train Loss: 0.078, Acc: 0.973\n",
      "epoch: 262/300 batch  65/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 262/300 batch  66/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 262/300 batch  67/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 262/300 batch  68/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 262/300 batch  69/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 262/300 batch  70/188  Train Loss: 0.079, Acc: 0.973\n",
      "epoch: 262/300 batch  71/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 262/300 batch  72/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 262/300 batch  73/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 262/300 batch  74/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 262/300 batch  75/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 262/300 batch  76/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 262/300 batch  77/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 262/300 batch  78/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 262/300 batch  79/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 262/300 batch  80/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 262/300 batch  81/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 262/300 batch  82/188  Train Loss: 0.050, Acc: 0.980\n",
      "epoch: 262/300 batch  83/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 262/300 batch  84/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 262/300 batch  85/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 262/300 batch  86/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 262/300 batch  87/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 262/300 batch  88/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 262/300 batch  89/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 262/300 batch  90/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 262/300 batch  91/188  Train Loss: 0.077, Acc: 0.984\n",
      "epoch: 262/300 batch  92/188  Train Loss: 0.052, Acc: 0.980\n",
      "epoch: 262/300 batch  93/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 262/300 batch  94/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 262/300 batch  95/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 262/300 batch  96/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 262/300 batch  97/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 262/300 batch  98/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 262/300 batch  99/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 262/300 batch 100/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 262/300 batch 101/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 262/300 batch 102/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 262/300 batch 103/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 262/300 batch 104/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 262/300 batch 105/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 262/300 batch 106/188  Train Loss: 0.042, Acc: 0.980\n",
      "epoch: 262/300 batch 107/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 262/300 batch 108/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 262/300 batch 109/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 262/300 batch 110/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 262/300 batch 111/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 262/300 batch 112/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 262/300 batch 113/188  Train Loss: 0.057, Acc: 0.980\n",
      "epoch: 262/300 batch 114/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 262/300 batch 115/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 262/300 batch 116/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 262/300 batch 117/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 262/300 batch 118/188  Train Loss: 0.072, Acc: 0.980\n",
      "epoch: 262/300 batch 119/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 262/300 batch 120/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 262/300 batch 121/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 262/300 batch 122/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 262/300 batch 123/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 262/300 batch 124/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 262/300 batch 125/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 262/300 batch 126/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 262/300 batch 127/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 262/300 batch 128/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 262/300 batch 129/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 262/300 batch 130/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 262/300 batch 131/188  Train Loss: 0.054, Acc: 0.977\n",
      "epoch: 262/300 batch 132/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 262/300 batch 133/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 262/300 batch 134/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 262/300 batch 135/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 262/300 batch 136/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 262/300 batch 137/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 262/300 batch 138/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 262/300 batch 139/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 262/300 batch 140/188  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 262/300 batch 141/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 262/300 batch 142/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 262/300 batch 143/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 262/300 batch 144/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 262/300 batch 145/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 262/300 batch 146/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 262/300 batch 147/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 262/300 batch 148/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 262/300 batch 149/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 262/300 batch 150/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 262/300 batch 151/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 262/300 batch 152/188  Train Loss: 0.055, Acc: 0.977\n",
      "epoch: 262/300 batch 153/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 262/300 batch 154/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 262/300 batch 155/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 262/300 batch 156/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 262/300 batch 157/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 262/300 batch 158/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 262/300 batch 159/188  Train Loss: 0.057, Acc: 0.988\n",
      "epoch: 262/300 batch 160/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 262/300 batch 161/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 262/300 batch 162/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 262/300 batch 163/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 262/300 batch 164/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 262/300 batch 165/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 262/300 batch 166/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 262/300 batch 167/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 262/300 batch 168/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 262/300 batch 169/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 262/300 batch 170/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 262/300 batch 171/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 262/300 batch 172/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 262/300 batch 173/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 262/300 batch 174/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 262/300 batch 175/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 262/300 batch 176/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 262/300 batch 177/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 262/300 batch 178/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 262/300 batch 179/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 262/300 batch 180/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 262/300 batch 181/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 262/300 batch 182/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 262/300 batch 183/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 262/300 batch 184/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 262/300 batch 185/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 262/300 batch 186/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 262/300 batch 187/188  Train Loss: 0.021, Acc: 1.000\n",
      "Train Loss: 0.032676, Acc: 0.993\n",
      "Val Loss: 0.057300, Acc: 0.983\n",
      "epoch: 263/300 batch   0/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 263/300 batch   1/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 263/300 batch   2/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 263/300 batch   3/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 263/300 batch   4/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 263/300 batch   5/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 263/300 batch   6/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 263/300 batch   7/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 263/300 batch   8/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 263/300 batch   9/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 263/300 batch  10/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 263/300 batch  11/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 263/300 batch  12/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 263/300 batch  13/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 263/300 batch  14/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 263/300 batch  15/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 263/300 batch  16/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 263/300 batch  17/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 263/300 batch  18/188  Train Loss: 0.052, Acc: 0.980\n",
      "epoch: 263/300 batch  19/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 263/300 batch  20/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 263/300 batch  21/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 263/300 batch  22/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 263/300 batch  23/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 263/300 batch  24/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 263/300 batch  25/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 263/300 batch  26/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 263/300 batch  27/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 263/300 batch  28/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 263/300 batch  29/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 263/300 batch  30/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 263/300 batch  31/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 263/300 batch  32/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 263/300 batch  33/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 263/300 batch  34/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 263/300 batch  35/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 263/300 batch  36/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 263/300 batch  37/188  Train Loss: 0.059, Acc: 0.977\n",
      "epoch: 263/300 batch  38/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 263/300 batch  39/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 263/300 batch  40/188  Train Loss: 0.075, Acc: 0.980\n",
      "epoch: 263/300 batch  41/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 263/300 batch  42/188  Train Loss: 0.051, Acc: 0.992\n",
      "epoch: 263/300 batch  43/188  Train Loss: 0.053, Acc: 0.980\n",
      "epoch: 263/300 batch  44/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 263/300 batch  45/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 263/300 batch  46/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 263/300 batch  47/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 263/300 batch  48/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 263/300 batch  49/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 263/300 batch  50/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 263/300 batch  51/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 263/300 batch  52/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 263/300 batch  53/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 263/300 batch  54/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 263/300 batch  55/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 263/300 batch  56/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 263/300 batch  57/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 263/300 batch  58/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 263/300 batch  59/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 263/300 batch  60/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 263/300 batch  61/188  Train Loss: 0.031, Acc: 1.000\n",
      "epoch: 263/300 batch  62/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 263/300 batch  63/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 263/300 batch  64/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 263/300 batch  65/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 263/300 batch  66/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 263/300 batch  67/188  Train Loss: 0.072, Acc: 0.984\n",
      "epoch: 263/300 batch  68/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 263/300 batch  69/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 263/300 batch  70/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 263/300 batch  71/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 263/300 batch  72/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 263/300 batch  73/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 263/300 batch  74/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 263/300 batch  75/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 263/300 batch  76/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 263/300 batch  77/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 263/300 batch  78/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 263/300 batch  79/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 263/300 batch  80/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 263/300 batch  81/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 263/300 batch  82/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 263/300 batch  83/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 263/300 batch  84/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 263/300 batch  85/188  Train Loss: 0.068, Acc: 0.980\n",
      "epoch: 263/300 batch  86/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 263/300 batch  87/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 263/300 batch  88/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 263/300 batch  89/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 263/300 batch  90/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 263/300 batch  91/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 263/300 batch  92/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 263/300 batch  93/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 263/300 batch  94/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 263/300 batch  95/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 263/300 batch  96/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 263/300 batch  97/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 263/300 batch  98/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 263/300 batch  99/188  Train Loss: 0.032, Acc: 1.000\n",
      "epoch: 263/300 batch 100/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 263/300 batch 101/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 263/300 batch 102/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 263/300 batch 103/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 263/300 batch 104/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 263/300 batch 105/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 263/300 batch 106/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 263/300 batch 107/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 263/300 batch 108/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 263/300 batch 109/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 263/300 batch 110/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 263/300 batch 111/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 263/300 batch 112/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 263/300 batch 113/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 263/300 batch 114/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 263/300 batch 115/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 263/300 batch 116/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 263/300 batch 117/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 263/300 batch 118/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 263/300 batch 119/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 263/300 batch 120/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 263/300 batch 121/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 263/300 batch 122/188  Train Loss: 0.067, Acc: 0.977\n",
      "epoch: 263/300 batch 123/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 263/300 batch 124/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 263/300 batch 125/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 263/300 batch 126/188  Train Loss: 0.032, Acc: 0.984\n",
      "epoch: 263/300 batch 127/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 263/300 batch 128/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 263/300 batch 129/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 263/300 batch 130/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 263/300 batch 131/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 263/300 batch 132/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 263/300 batch 133/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 263/300 batch 134/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 263/300 batch 135/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 263/300 batch 136/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 263/300 batch 137/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 263/300 batch 138/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 263/300 batch 139/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 263/300 batch 140/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 263/300 batch 141/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 263/300 batch 142/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 263/300 batch 143/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 263/300 batch 144/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 263/300 batch 145/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 263/300 batch 146/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 263/300 batch 147/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 263/300 batch 148/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 263/300 batch 149/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 263/300 batch 150/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 263/300 batch 151/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 263/300 batch 152/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 263/300 batch 153/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 263/300 batch 154/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 263/300 batch 155/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 263/300 batch 156/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 263/300 batch 157/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 263/300 batch 158/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 263/300 batch 159/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 263/300 batch 160/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 263/300 batch 161/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 263/300 batch 162/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 263/300 batch 163/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 263/300 batch 164/188  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 263/300 batch 165/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 263/300 batch 166/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 263/300 batch 167/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 263/300 batch 168/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 263/300 batch 169/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 263/300 batch 170/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 263/300 batch 171/188  Train Loss: 0.059, Acc: 0.984\n",
      "epoch: 263/300 batch 172/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 263/300 batch 173/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 263/300 batch 174/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 263/300 batch 175/188  Train Loss: 0.057, Acc: 0.988\n",
      "epoch: 263/300 batch 176/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 263/300 batch 177/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 263/300 batch 178/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 263/300 batch 179/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 263/300 batch 180/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 263/300 batch 181/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 263/300 batch 182/188  Train Loss: 0.058, Acc: 0.977\n",
      "epoch: 263/300 batch 183/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 263/300 batch 184/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 263/300 batch 185/188  Train Loss: 0.040, Acc: 0.980\n",
      "epoch: 263/300 batch 186/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 263/300 batch 187/188  Train Loss: 0.036, Acc: 0.984\n",
      "Train Loss: 0.032652, Acc: 0.993\n",
      "Val Loss: 0.057426, Acc: 0.983\n",
      "epoch: 264/300 batch   0/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 264/300 batch   1/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 264/300 batch   2/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 264/300 batch   3/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 264/300 batch   4/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 264/300 batch   5/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 264/300 batch   6/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 264/300 batch   7/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 264/300 batch   8/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 264/300 batch   9/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 264/300 batch  10/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 264/300 batch  11/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 264/300 batch  12/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 264/300 batch  13/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 264/300 batch  14/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 264/300 batch  15/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 264/300 batch  16/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 264/300 batch  17/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 264/300 batch  18/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 264/300 batch  19/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 264/300 batch  20/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 264/300 batch  21/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 264/300 batch  22/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 264/300 batch  23/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 264/300 batch  24/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 264/300 batch  25/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 264/300 batch  26/188  Train Loss: 0.055, Acc: 0.977\n",
      "epoch: 264/300 batch  27/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 264/300 batch  28/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 264/300 batch  29/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 264/300 batch  30/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 264/300 batch  31/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 264/300 batch  32/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 264/300 batch  33/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 264/300 batch  34/188  Train Loss: 0.059, Acc: 0.992\n",
      "epoch: 264/300 batch  35/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 264/300 batch  36/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 264/300 batch  37/188  Train Loss: 0.053, Acc: 0.973\n",
      "epoch: 264/300 batch  38/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 264/300 batch  39/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 264/300 batch  40/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 264/300 batch  41/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 264/300 batch  42/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 264/300 batch  43/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 264/300 batch  44/188  Train Loss: 0.034, Acc: 0.984\n",
      "epoch: 264/300 batch  45/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 264/300 batch  46/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 264/300 batch  47/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 264/300 batch  48/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 264/300 batch  49/188  Train Loss: 0.057, Acc: 0.980\n",
      "epoch: 264/300 batch  50/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 264/300 batch  51/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 264/300 batch  52/188  Train Loss: 0.031, Acc: 1.000\n",
      "epoch: 264/300 batch  53/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 264/300 batch  54/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 264/300 batch  55/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 264/300 batch  56/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 264/300 batch  57/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 264/300 batch  58/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 264/300 batch  59/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 264/300 batch  60/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 264/300 batch  61/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 264/300 batch  62/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 264/300 batch  63/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 264/300 batch  64/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 264/300 batch  65/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 264/300 batch  66/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 264/300 batch  67/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 264/300 batch  68/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 264/300 batch  69/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 264/300 batch  70/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 264/300 batch  71/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 264/300 batch  72/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 264/300 batch  73/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 264/300 batch  74/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 264/300 batch  75/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 264/300 batch  76/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 264/300 batch  77/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 264/300 batch  78/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 264/300 batch  79/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 264/300 batch  80/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 264/300 batch  81/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 264/300 batch  82/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 264/300 batch  83/188  Train Loss: 0.070, Acc: 0.984\n",
      "epoch: 264/300 batch  84/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 264/300 batch  85/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 264/300 batch  86/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 264/300 batch  87/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 264/300 batch  88/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 264/300 batch  89/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 264/300 batch  90/188  Train Loss: 0.078, Acc: 0.984\n",
      "epoch: 264/300 batch  91/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 264/300 batch  92/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 264/300 batch  93/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 264/300 batch  94/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 264/300 batch  95/188  Train Loss: 0.061, Acc: 0.980\n",
      "epoch: 264/300 batch  96/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 264/300 batch  97/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 264/300 batch  98/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 264/300 batch  99/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 264/300 batch 100/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 264/300 batch 101/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 264/300 batch 102/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 264/300 batch 103/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 264/300 batch 104/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 264/300 batch 105/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 264/300 batch 106/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 264/300 batch 107/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 264/300 batch 108/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 264/300 batch 109/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 264/300 batch 110/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 264/300 batch 111/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 264/300 batch 112/188  Train Loss: 0.057, Acc: 0.992\n",
      "epoch: 264/300 batch 113/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 264/300 batch 114/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 264/300 batch 115/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 264/300 batch 116/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 264/300 batch 117/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 264/300 batch 118/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 264/300 batch 119/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 264/300 batch 120/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 264/300 batch 121/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 264/300 batch 122/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 264/300 batch 123/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 264/300 batch 124/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 264/300 batch 125/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 264/300 batch 126/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 264/300 batch 127/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 264/300 batch 128/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 264/300 batch 129/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 264/300 batch 130/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 264/300 batch 131/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 264/300 batch 132/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 264/300 batch 133/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 264/300 batch 134/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 264/300 batch 135/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 264/300 batch 136/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 264/300 batch 137/188  Train Loss: 0.016, Acc: 0.996\n",
      "epoch: 264/300 batch 138/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 264/300 batch 139/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 264/300 batch 140/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 264/300 batch 141/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 264/300 batch 142/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 264/300 batch 143/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 264/300 batch 144/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 264/300 batch 145/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 264/300 batch 146/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 264/300 batch 147/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 264/300 batch 148/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 264/300 batch 149/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 264/300 batch 150/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 264/300 batch 151/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 264/300 batch 152/188  Train Loss: 0.048, Acc: 0.977\n",
      "epoch: 264/300 batch 153/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 264/300 batch 154/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 264/300 batch 155/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 264/300 batch 156/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 264/300 batch 157/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 264/300 batch 158/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 264/300 batch 159/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 264/300 batch 160/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 264/300 batch 161/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 264/300 batch 162/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 264/300 batch 163/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 264/300 batch 164/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 264/300 batch 165/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 264/300 batch 166/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 264/300 batch 167/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 264/300 batch 168/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 264/300 batch 169/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 264/300 batch 170/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 264/300 batch 171/188  Train Loss: 0.066, Acc: 0.977\n",
      "epoch: 264/300 batch 172/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 264/300 batch 173/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 264/300 batch 174/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 264/300 batch 175/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 264/300 batch 176/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 264/300 batch 177/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 264/300 batch 178/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 264/300 batch 179/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 264/300 batch 180/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 264/300 batch 181/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 264/300 batch 182/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 264/300 batch 183/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 264/300 batch 184/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 264/300 batch 185/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 264/300 batch 186/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 264/300 batch 187/188  Train Loss: 0.057, Acc: 0.984\n",
      "Train Loss: 0.032830, Acc: 0.993\n",
      "Val Loss: 0.057200, Acc: 0.983\n",
      "epoch: 265/300 batch   0/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 265/300 batch   1/188  Train Loss: 0.063, Acc: 0.984\n",
      "epoch: 265/300 batch   2/188  Train Loss: 0.055, Acc: 0.992\n",
      "epoch: 265/300 batch   3/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 265/300 batch   4/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 265/300 batch   5/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 265/300 batch   6/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 265/300 batch   7/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 265/300 batch   8/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 265/300 batch   9/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 265/300 batch  10/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 265/300 batch  11/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 265/300 batch  12/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 265/300 batch  13/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 265/300 batch  14/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 265/300 batch  15/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 265/300 batch  16/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 265/300 batch  17/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 265/300 batch  18/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 265/300 batch  19/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 265/300 batch  20/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 265/300 batch  21/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 265/300 batch  22/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 265/300 batch  23/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 265/300 batch  24/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 265/300 batch  25/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 265/300 batch  26/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 265/300 batch  27/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 265/300 batch  28/188  Train Loss: 0.033, Acc: 0.984\n",
      "epoch: 265/300 batch  29/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 265/300 batch  30/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 265/300 batch  31/188  Train Loss: 0.016, Acc: 0.996\n",
      "epoch: 265/300 batch  32/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 265/300 batch  33/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 265/300 batch  34/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 265/300 batch  35/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 265/300 batch  36/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 265/300 batch  37/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 265/300 batch  38/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 265/300 batch  39/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 265/300 batch  40/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 265/300 batch  41/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 265/300 batch  42/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 265/300 batch  43/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 265/300 batch  44/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 265/300 batch  45/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 265/300 batch  46/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 265/300 batch  47/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 265/300 batch  48/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 265/300 batch  49/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 265/300 batch  50/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 265/300 batch  51/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 265/300 batch  52/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 265/300 batch  53/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 265/300 batch  54/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 265/300 batch  55/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 265/300 batch  56/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 265/300 batch  57/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 265/300 batch  58/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 265/300 batch  59/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 265/300 batch  60/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 265/300 batch  61/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 265/300 batch  62/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 265/300 batch  63/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 265/300 batch  64/188  Train Loss: 0.027, Acc: 0.988\n",
      "epoch: 265/300 batch  65/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 265/300 batch  66/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 265/300 batch  67/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 265/300 batch  68/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 265/300 batch  69/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 265/300 batch  70/188  Train Loss: 0.064, Acc: 0.992\n",
      "epoch: 265/300 batch  71/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 265/300 batch  72/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 265/300 batch  73/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 265/300 batch  74/188  Train Loss: 0.062, Acc: 0.980\n",
      "epoch: 265/300 batch  75/188  Train Loss: 0.049, Acc: 0.980\n",
      "epoch: 265/300 batch  76/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 265/300 batch  77/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 265/300 batch  78/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 265/300 batch  79/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 265/300 batch  80/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 265/300 batch  81/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 265/300 batch  82/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 265/300 batch  83/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 265/300 batch  84/188  Train Loss: 0.049, Acc: 0.980\n",
      "epoch: 265/300 batch  85/188  Train Loss: 0.064, Acc: 0.988\n",
      "epoch: 265/300 batch  86/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 265/300 batch  87/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 265/300 batch  88/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 265/300 batch  89/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 265/300 batch  90/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 265/300 batch  91/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 265/300 batch  92/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 265/300 batch  93/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 265/300 batch  94/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 265/300 batch  95/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 265/300 batch  96/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 265/300 batch  97/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 265/300 batch  98/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 265/300 batch  99/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 265/300 batch 100/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 265/300 batch 101/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 265/300 batch 102/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 265/300 batch 103/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 265/300 batch 104/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 265/300 batch 105/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 265/300 batch 106/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 265/300 batch 107/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 265/300 batch 108/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 265/300 batch 109/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 265/300 batch 110/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 265/300 batch 111/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 265/300 batch 112/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 265/300 batch 113/188  Train Loss: 0.073, Acc: 0.980\n",
      "epoch: 265/300 batch 114/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 265/300 batch 115/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 265/300 batch 116/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 265/300 batch 117/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 265/300 batch 118/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 265/300 batch 119/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 265/300 batch 120/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 265/300 batch 121/188  Train Loss: 0.059, Acc: 0.980\n",
      "epoch: 265/300 batch 122/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 265/300 batch 123/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 265/300 batch 124/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 265/300 batch 125/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 265/300 batch 126/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 265/300 batch 127/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 265/300 batch 128/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 265/300 batch 129/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 265/300 batch 130/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 265/300 batch 131/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 265/300 batch 132/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 265/300 batch 133/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 265/300 batch 134/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 265/300 batch 135/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 265/300 batch 136/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 265/300 batch 137/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 265/300 batch 138/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 265/300 batch 139/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 265/300 batch 140/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 265/300 batch 141/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 265/300 batch 142/188  Train Loss: 0.031, Acc: 1.000\n",
      "epoch: 265/300 batch 143/188  Train Loss: 0.057, Acc: 0.992\n",
      "epoch: 265/300 batch 144/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 265/300 batch 145/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 265/300 batch 146/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 265/300 batch 147/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 265/300 batch 148/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 265/300 batch 149/188  Train Loss: 0.052, Acc: 0.980\n",
      "epoch: 265/300 batch 150/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 265/300 batch 151/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 265/300 batch 152/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 265/300 batch 153/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 265/300 batch 154/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 265/300 batch 155/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 265/300 batch 156/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 265/300 batch 157/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 265/300 batch 158/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 265/300 batch 159/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 265/300 batch 160/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 265/300 batch 161/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 265/300 batch 162/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 265/300 batch 163/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 265/300 batch 164/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 265/300 batch 165/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 265/300 batch 166/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 265/300 batch 167/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 265/300 batch 168/188  Train Loss: 0.057, Acc: 0.980\n",
      "epoch: 265/300 batch 169/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 265/300 batch 170/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 265/300 batch 171/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 265/300 batch 172/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 265/300 batch 173/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 265/300 batch 174/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 265/300 batch 175/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 265/300 batch 176/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 265/300 batch 177/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 265/300 batch 178/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 265/300 batch 179/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 265/300 batch 180/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 265/300 batch 181/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 265/300 batch 182/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 265/300 batch 183/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 265/300 batch 184/188  Train Loss: 0.034, Acc: 0.984\n",
      "epoch: 265/300 batch 185/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 265/300 batch 186/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 265/300 batch 187/188  Train Loss: 0.026, Acc: 1.000\n",
      "Train Loss: 0.032692, Acc: 0.993\n",
      "Val Loss: 0.057396, Acc: 0.983\n",
      "epoch: 266/300 batch   0/188  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 266/300 batch   1/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 266/300 batch   2/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 266/300 batch   3/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 266/300 batch   4/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 266/300 batch   5/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 266/300 batch   6/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 266/300 batch   7/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 266/300 batch   8/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 266/300 batch   9/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 266/300 batch  10/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 266/300 batch  11/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 266/300 batch  12/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 266/300 batch  13/188  Train Loss: 0.029, Acc: 0.984\n",
      "epoch: 266/300 batch  14/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 266/300 batch  15/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 266/300 batch  16/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 266/300 batch  17/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 266/300 batch  18/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 266/300 batch  19/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 266/300 batch  20/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 266/300 batch  21/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 266/300 batch  22/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 266/300 batch  23/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 266/300 batch  24/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 266/300 batch  25/188  Train Loss: 0.038, Acc: 0.980\n",
      "epoch: 266/300 batch  26/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 266/300 batch  27/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 266/300 batch  28/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 266/300 batch  29/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 266/300 batch  30/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 266/300 batch  31/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 266/300 batch  32/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 266/300 batch  33/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 266/300 batch  34/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 266/300 batch  35/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 266/300 batch  36/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 266/300 batch  37/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 266/300 batch  38/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 266/300 batch  39/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 266/300 batch  40/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 266/300 batch  41/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 266/300 batch  42/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 266/300 batch  43/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 266/300 batch  44/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 266/300 batch  45/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 266/300 batch  46/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 266/300 batch  47/188  Train Loss: 0.049, Acc: 0.996\n",
      "epoch: 266/300 batch  48/188  Train Loss: 0.062, Acc: 0.988\n",
      "epoch: 266/300 batch  49/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 266/300 batch  50/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 266/300 batch  51/188  Train Loss: 0.049, Acc: 0.980\n",
      "epoch: 266/300 batch  52/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 266/300 batch  53/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 266/300 batch  54/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 266/300 batch  55/188  Train Loss: 0.012, Acc: 0.996\n",
      "epoch: 266/300 batch  56/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 266/300 batch  57/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 266/300 batch  58/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 266/300 batch  59/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 266/300 batch  60/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 266/300 batch  61/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 266/300 batch  62/188  Train Loss: 0.026, Acc: 0.988\n",
      "epoch: 266/300 batch  63/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 266/300 batch  64/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 266/300 batch  65/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 266/300 batch  66/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 266/300 batch  67/188  Train Loss: 0.062, Acc: 0.980\n",
      "epoch: 266/300 batch  68/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 266/300 batch  69/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 266/300 batch  70/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 266/300 batch  71/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 266/300 batch  72/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 266/300 batch  73/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 266/300 batch  74/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 266/300 batch  75/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 266/300 batch  76/188  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 266/300 batch  77/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 266/300 batch  78/188  Train Loss: 0.054, Acc: 0.992\n",
      "epoch: 266/300 batch  79/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 266/300 batch  80/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 266/300 batch  81/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 266/300 batch  82/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 266/300 batch  83/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 266/300 batch  84/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 266/300 batch  85/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 266/300 batch  86/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 266/300 batch  87/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 266/300 batch  88/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 266/300 batch  89/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 266/300 batch  90/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 266/300 batch  91/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 266/300 batch  92/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 266/300 batch  93/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 266/300 batch  94/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 266/300 batch  95/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 266/300 batch  96/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 266/300 batch  97/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 266/300 batch  98/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 266/300 batch  99/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 266/300 batch 100/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 266/300 batch 101/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 266/300 batch 102/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 266/300 batch 103/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 266/300 batch 104/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 266/300 batch 105/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 266/300 batch 106/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 266/300 batch 107/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 266/300 batch 108/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 266/300 batch 109/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 266/300 batch 110/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 266/300 batch 111/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 266/300 batch 112/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 266/300 batch 113/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 266/300 batch 114/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 266/300 batch 115/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 266/300 batch 116/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 266/300 batch 117/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 266/300 batch 118/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 266/300 batch 119/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 266/300 batch 120/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 266/300 batch 121/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 266/300 batch 122/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 266/300 batch 123/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 266/300 batch 124/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 266/300 batch 125/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 266/300 batch 126/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 266/300 batch 127/188  Train Loss: 0.087, Acc: 0.984\n",
      "epoch: 266/300 batch 128/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 266/300 batch 129/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 266/300 batch 130/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 266/300 batch 131/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 266/300 batch 132/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 266/300 batch 133/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 266/300 batch 134/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 266/300 batch 135/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 266/300 batch 136/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 266/300 batch 137/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 266/300 batch 138/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 266/300 batch 139/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 266/300 batch 140/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 266/300 batch 141/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 266/300 batch 142/188  Train Loss: 0.047, Acc: 0.980\n",
      "epoch: 266/300 batch 143/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 266/300 batch 144/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 266/300 batch 145/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 266/300 batch 146/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 266/300 batch 147/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 266/300 batch 148/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 266/300 batch 149/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 266/300 batch 150/188  Train Loss: 0.030, Acc: 0.984\n",
      "epoch: 266/300 batch 151/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 266/300 batch 152/188  Train Loss: 0.046, Acc: 0.977\n",
      "epoch: 266/300 batch 153/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 266/300 batch 154/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 266/300 batch 155/188  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 266/300 batch 156/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 266/300 batch 157/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 266/300 batch 158/188  Train Loss: 0.054, Acc: 0.992\n",
      "epoch: 266/300 batch 159/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 266/300 batch 160/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 266/300 batch 161/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 266/300 batch 162/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 266/300 batch 163/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 266/300 batch 164/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 266/300 batch 165/188  Train Loss: 0.046, Acc: 0.977\n",
      "epoch: 266/300 batch 166/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 266/300 batch 167/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 266/300 batch 168/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 266/300 batch 169/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 266/300 batch 170/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 266/300 batch 171/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 266/300 batch 172/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 266/300 batch 173/188  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 266/300 batch 174/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 266/300 batch 175/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 266/300 batch 176/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 266/300 batch 177/188  Train Loss: 0.051, Acc: 0.992\n",
      "epoch: 266/300 batch 178/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 266/300 batch 179/188  Train Loss: 0.032, Acc: 1.000\n",
      "epoch: 266/300 batch 180/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 266/300 batch 181/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 266/300 batch 182/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 266/300 batch 183/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 266/300 batch 184/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 266/300 batch 185/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 266/300 batch 186/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 266/300 batch 187/188  Train Loss: 0.024, Acc: 0.992\n",
      "Train Loss: 0.032630, Acc: 0.993\n",
      "Val Loss: 0.057476, Acc: 0.983\n",
      "epoch: 267/300 batch   0/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 267/300 batch   1/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 267/300 batch   2/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 267/300 batch   3/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 267/300 batch   4/188  Train Loss: 0.053, Acc: 0.992\n",
      "epoch: 267/300 batch   5/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 267/300 batch   6/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 267/300 batch   7/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 267/300 batch   8/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 267/300 batch   9/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 267/300 batch  10/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 267/300 batch  11/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 267/300 batch  12/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 267/300 batch  13/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 267/300 batch  14/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 267/300 batch  15/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 267/300 batch  16/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 267/300 batch  17/188  Train Loss: 0.042, Acc: 0.996\n",
      "epoch: 267/300 batch  18/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 267/300 batch  19/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 267/300 batch  20/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 267/300 batch  21/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 267/300 batch  22/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 267/300 batch  23/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 267/300 batch  24/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 267/300 batch  25/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 267/300 batch  26/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 267/300 batch  27/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 267/300 batch  28/188  Train Loss: 0.031, Acc: 1.000\n",
      "epoch: 267/300 batch  29/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 267/300 batch  30/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 267/300 batch  31/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 267/300 batch  32/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 267/300 batch  33/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 267/300 batch  34/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 267/300 batch  35/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 267/300 batch  36/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 267/300 batch  37/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 267/300 batch  38/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 267/300 batch  39/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 267/300 batch  40/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 267/300 batch  41/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 267/300 batch  42/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 267/300 batch  43/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 267/300 batch  44/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 267/300 batch  45/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 267/300 batch  46/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 267/300 batch  47/188  Train Loss: 0.086, Acc: 0.984\n",
      "epoch: 267/300 batch  48/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 267/300 batch  49/188  Train Loss: 0.059, Acc: 0.984\n",
      "epoch: 267/300 batch  50/188  Train Loss: 0.043, Acc: 0.980\n",
      "epoch: 267/300 batch  51/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 267/300 batch  52/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 267/300 batch  53/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 267/300 batch  54/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 267/300 batch  55/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 267/300 batch  56/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 267/300 batch  57/188  Train Loss: 0.021, Acc: 0.988\n",
      "epoch: 267/300 batch  58/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 267/300 batch  59/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 267/300 batch  60/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 267/300 batch  61/188  Train Loss: 0.059, Acc: 0.980\n",
      "epoch: 267/300 batch  62/188  Train Loss: 0.053, Acc: 0.980\n",
      "epoch: 267/300 batch  63/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 267/300 batch  64/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 267/300 batch  65/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 267/300 batch  66/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 267/300 batch  67/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 267/300 batch  68/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 267/300 batch  69/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 267/300 batch  70/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 267/300 batch  71/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 267/300 batch  72/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 267/300 batch  73/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 267/300 batch  74/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 267/300 batch  75/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 267/300 batch  76/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 267/300 batch  77/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 267/300 batch  78/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 267/300 batch  79/188  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 267/300 batch  80/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 267/300 batch  81/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 267/300 batch  82/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 267/300 batch  83/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 267/300 batch  84/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 267/300 batch  85/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 267/300 batch  86/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 267/300 batch  87/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 267/300 batch  88/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 267/300 batch  89/188  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 267/300 batch  90/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 267/300 batch  91/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 267/300 batch  92/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 267/300 batch  93/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 267/300 batch  94/188  Train Loss: 0.061, Acc: 0.984\n",
      "epoch: 267/300 batch  95/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 267/300 batch  96/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 267/300 batch  97/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 267/300 batch  98/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 267/300 batch  99/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 267/300 batch 100/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 267/300 batch 101/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 267/300 batch 102/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 267/300 batch 103/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 267/300 batch 104/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 267/300 batch 105/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 267/300 batch 106/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 267/300 batch 107/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 267/300 batch 108/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 267/300 batch 109/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 267/300 batch 110/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 267/300 batch 111/188  Train Loss: 0.071, Acc: 0.980\n",
      "epoch: 267/300 batch 112/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 267/300 batch 113/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 267/300 batch 114/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 267/300 batch 115/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 267/300 batch 116/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 267/300 batch 117/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 267/300 batch 118/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 267/300 batch 119/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 267/300 batch 120/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 267/300 batch 121/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 267/300 batch 122/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 267/300 batch 123/188  Train Loss: 0.065, Acc: 0.988\n",
      "epoch: 267/300 batch 124/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 267/300 batch 125/188  Train Loss: 0.057, Acc: 0.988\n",
      "epoch: 267/300 batch 126/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 267/300 batch 127/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 267/300 batch 128/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 267/300 batch 129/188  Train Loss: 0.046, Acc: 0.996\n",
      "epoch: 267/300 batch 130/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 267/300 batch 131/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 267/300 batch 132/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 267/300 batch 133/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 267/300 batch 134/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 267/300 batch 135/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 267/300 batch 136/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 267/300 batch 137/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 267/300 batch 138/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 267/300 batch 139/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 267/300 batch 140/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 267/300 batch 141/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 267/300 batch 142/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 267/300 batch 143/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 267/300 batch 144/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 267/300 batch 145/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 267/300 batch 146/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 267/300 batch 147/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 267/300 batch 148/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 267/300 batch 149/188  Train Loss: 0.069, Acc: 0.977\n",
      "epoch: 267/300 batch 150/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 267/300 batch 151/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 267/300 batch 152/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 267/300 batch 153/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 267/300 batch 154/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 267/300 batch 155/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 267/300 batch 156/188  Train Loss: 0.051, Acc: 0.980\n",
      "epoch: 267/300 batch 157/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 267/300 batch 158/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 267/300 batch 159/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 267/300 batch 160/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 267/300 batch 161/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 267/300 batch 162/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 267/300 batch 163/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 267/300 batch 164/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 267/300 batch 165/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 267/300 batch 166/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 267/300 batch 167/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 267/300 batch 168/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 267/300 batch 169/188  Train Loss: 0.052, Acc: 0.980\n",
      "epoch: 267/300 batch 170/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 267/300 batch 171/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 267/300 batch 172/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 267/300 batch 173/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 267/300 batch 174/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 267/300 batch 175/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 267/300 batch 176/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 267/300 batch 177/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 267/300 batch 178/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 267/300 batch 179/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 267/300 batch 180/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 267/300 batch 181/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 267/300 batch 182/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 267/300 batch 183/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 267/300 batch 184/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 267/300 batch 185/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 267/300 batch 186/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 267/300 batch 187/188  Train Loss: 0.040, Acc: 0.992\n",
      "Train Loss: 0.032649, Acc: 0.993\n",
      "Val Loss: 0.058105, Acc: 0.983\n",
      "epoch: 268/300 batch   0/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 268/300 batch   1/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 268/300 batch   2/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 268/300 batch   3/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 268/300 batch   4/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 268/300 batch   5/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 268/300 batch   6/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 268/300 batch   7/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 268/300 batch   8/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 268/300 batch   9/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 268/300 batch  10/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 268/300 batch  11/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 268/300 batch  12/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 268/300 batch  13/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 268/300 batch  14/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 268/300 batch  15/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 268/300 batch  16/188  Train Loss: 0.044, Acc: 0.996\n",
      "epoch: 268/300 batch  17/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 268/300 batch  18/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 268/300 batch  19/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 268/300 batch  20/188  Train Loss: 0.036, Acc: 0.980\n",
      "epoch: 268/300 batch  21/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 268/300 batch  22/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 268/300 batch  23/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 268/300 batch  24/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 268/300 batch  25/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 268/300 batch  26/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 268/300 batch  27/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 268/300 batch  28/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 268/300 batch  29/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 268/300 batch  30/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 268/300 batch  31/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 268/300 batch  32/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 268/300 batch  33/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 268/300 batch  34/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 268/300 batch  35/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 268/300 batch  36/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 268/300 batch  37/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 268/300 batch  38/188  Train Loss: 0.042, Acc: 0.980\n",
      "epoch: 268/300 batch  39/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 268/300 batch  40/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 268/300 batch  41/188  Train Loss: 0.043, Acc: 0.980\n",
      "epoch: 268/300 batch  42/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 268/300 batch  43/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 268/300 batch  44/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 268/300 batch  45/188  Train Loss: 0.047, Acc: 0.980\n",
      "epoch: 268/300 batch  46/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 268/300 batch  47/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 268/300 batch  48/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 268/300 batch  49/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 268/300 batch  50/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 268/300 batch  51/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 268/300 batch  52/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 268/300 batch  53/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 268/300 batch  54/188  Train Loss: 0.027, Acc: 0.984\n",
      "epoch: 268/300 batch  55/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 268/300 batch  56/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 268/300 batch  57/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 268/300 batch  58/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 268/300 batch  59/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 268/300 batch  60/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 268/300 batch  61/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 268/300 batch  62/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 268/300 batch  63/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 268/300 batch  64/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 268/300 batch  65/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 268/300 batch  66/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 268/300 batch  67/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 268/300 batch  68/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 268/300 batch  69/188  Train Loss: 0.056, Acc: 0.988\n",
      "epoch: 268/300 batch  70/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 268/300 batch  71/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 268/300 batch  72/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 268/300 batch  73/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 268/300 batch  74/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 268/300 batch  75/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 268/300 batch  76/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 268/300 batch  77/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 268/300 batch  78/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 268/300 batch  79/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 268/300 batch  80/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 268/300 batch  81/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 268/300 batch  82/188  Train Loss: 0.059, Acc: 0.992\n",
      "epoch: 268/300 batch  83/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 268/300 batch  84/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 268/300 batch  85/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 268/300 batch  86/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 268/300 batch  87/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 268/300 batch  88/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 268/300 batch  89/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 268/300 batch  90/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 268/300 batch  91/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 268/300 batch  92/188  Train Loss: 0.059, Acc: 0.988\n",
      "epoch: 268/300 batch  93/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 268/300 batch  94/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 268/300 batch  95/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 268/300 batch  96/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 268/300 batch  97/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 268/300 batch  98/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 268/300 batch  99/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 268/300 batch 100/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 268/300 batch 101/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 268/300 batch 102/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 268/300 batch 103/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 268/300 batch 104/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 268/300 batch 105/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 268/300 batch 106/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 268/300 batch 107/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 268/300 batch 108/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 268/300 batch 109/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 268/300 batch 110/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 268/300 batch 111/188  Train Loss: 0.053, Acc: 0.977\n",
      "epoch: 268/300 batch 112/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 268/300 batch 113/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 268/300 batch 114/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 268/300 batch 115/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 268/300 batch 116/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 268/300 batch 117/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 268/300 batch 118/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 268/300 batch 119/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 268/300 batch 120/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 268/300 batch 121/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 268/300 batch 122/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 268/300 batch 123/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 268/300 batch 124/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 268/300 batch 125/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 268/300 batch 126/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 268/300 batch 127/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 268/300 batch 128/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 268/300 batch 129/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 268/300 batch 130/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 268/300 batch 131/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 268/300 batch 132/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 268/300 batch 133/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 268/300 batch 134/188  Train Loss: 0.060, Acc: 0.988\n",
      "epoch: 268/300 batch 135/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 268/300 batch 136/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 268/300 batch 137/188  Train Loss: 0.057, Acc: 0.988\n",
      "epoch: 268/300 batch 138/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 268/300 batch 139/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 268/300 batch 140/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 268/300 batch 141/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 268/300 batch 142/188  Train Loss: 0.046, Acc: 0.996\n",
      "epoch: 268/300 batch 143/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 268/300 batch 144/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 268/300 batch 145/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 268/300 batch 146/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 268/300 batch 147/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 268/300 batch 148/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 268/300 batch 149/188  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 268/300 batch 150/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 268/300 batch 151/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 268/300 batch 152/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 268/300 batch 153/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 268/300 batch 154/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 268/300 batch 155/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 268/300 batch 156/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 268/300 batch 157/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 268/300 batch 158/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 268/300 batch 159/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 268/300 batch 160/188  Train Loss: 0.057, Acc: 0.977\n",
      "epoch: 268/300 batch 161/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 268/300 batch 162/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 268/300 batch 163/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 268/300 batch 164/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 268/300 batch 165/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 268/300 batch 166/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 268/300 batch 167/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 268/300 batch 168/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 268/300 batch 169/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 268/300 batch 170/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 268/300 batch 171/188  Train Loss: 0.048, Acc: 0.980\n",
      "epoch: 268/300 batch 172/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 268/300 batch 173/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 268/300 batch 174/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 268/300 batch 175/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 268/300 batch 176/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 268/300 batch 177/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 268/300 batch 178/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 268/300 batch 179/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 268/300 batch 180/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 268/300 batch 181/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 268/300 batch 182/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 268/300 batch 183/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 268/300 batch 184/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 268/300 batch 185/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 268/300 batch 186/188  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 268/300 batch 187/188  Train Loss: 0.017, Acc: 1.000\n",
      "Train Loss: 0.032655, Acc: 0.993\n",
      "Val Loss: 0.057327, Acc: 0.983\n",
      "epoch: 269/300 batch   0/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 269/300 batch   1/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 269/300 batch   2/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 269/300 batch   3/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 269/300 batch   4/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 269/300 batch   5/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 269/300 batch   6/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 269/300 batch   7/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 269/300 batch   8/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 269/300 batch   9/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 269/300 batch  10/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 269/300 batch  11/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 269/300 batch  12/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 269/300 batch  13/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 269/300 batch  14/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 269/300 batch  15/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 269/300 batch  16/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 269/300 batch  17/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 269/300 batch  18/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 269/300 batch  19/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 269/300 batch  20/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 269/300 batch  21/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 269/300 batch  22/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 269/300 batch  23/188  Train Loss: 0.057, Acc: 0.992\n",
      "epoch: 269/300 batch  24/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 269/300 batch  25/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 269/300 batch  26/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 269/300 batch  27/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 269/300 batch  28/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 269/300 batch  29/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 269/300 batch  30/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 269/300 batch  31/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 269/300 batch  32/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 269/300 batch  33/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 269/300 batch  34/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 269/300 batch  35/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 269/300 batch  36/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 269/300 batch  37/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 269/300 batch  38/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 269/300 batch  39/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 269/300 batch  40/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 269/300 batch  41/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 269/300 batch  42/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 269/300 batch  43/188  Train Loss: 0.062, Acc: 0.988\n",
      "epoch: 269/300 batch  44/188  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 269/300 batch  45/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 269/300 batch  46/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 269/300 batch  47/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 269/300 batch  48/188  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 269/300 batch  49/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 269/300 batch  50/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 269/300 batch  51/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 269/300 batch  52/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 269/300 batch  53/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 269/300 batch  54/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 269/300 batch  55/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 269/300 batch  56/188  Train Loss: 0.051, Acc: 0.977\n",
      "epoch: 269/300 batch  57/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 269/300 batch  58/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 269/300 batch  59/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 269/300 batch  60/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 269/300 batch  61/188  Train Loss: 0.063, Acc: 0.984\n",
      "epoch: 269/300 batch  62/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 269/300 batch  63/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 269/300 batch  64/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 269/300 batch  65/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 269/300 batch  66/188  Train Loss: 0.037, Acc: 0.980\n",
      "epoch: 269/300 batch  67/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 269/300 batch  68/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 269/300 batch  69/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 269/300 batch  70/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 269/300 batch  71/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 269/300 batch  72/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 269/300 batch  73/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 269/300 batch  74/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 269/300 batch  75/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 269/300 batch  76/188  Train Loss: 0.015, Acc: 0.996\n",
      "epoch: 269/300 batch  77/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 269/300 batch  78/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 269/300 batch  79/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 269/300 batch  80/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 269/300 batch  81/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 269/300 batch  82/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 269/300 batch  83/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 269/300 batch  84/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 269/300 batch  85/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 269/300 batch  86/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 269/300 batch  87/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 269/300 batch  88/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 269/300 batch  89/188  Train Loss: 0.045, Acc: 0.980\n",
      "epoch: 269/300 batch  90/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 269/300 batch  91/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 269/300 batch  92/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 269/300 batch  93/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 269/300 batch  94/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 269/300 batch  95/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 269/300 batch  96/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 269/300 batch  97/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 269/300 batch  98/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 269/300 batch  99/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 269/300 batch 100/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 269/300 batch 101/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 269/300 batch 102/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 269/300 batch 103/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 269/300 batch 104/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 269/300 batch 105/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 269/300 batch 106/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 269/300 batch 107/188  Train Loss: 0.059, Acc: 0.992\n",
      "epoch: 269/300 batch 108/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 269/300 batch 109/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 269/300 batch 110/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 269/300 batch 111/188  Train Loss: 0.048, Acc: 0.980\n",
      "epoch: 269/300 batch 112/188  Train Loss: 0.060, Acc: 0.996\n",
      "epoch: 269/300 batch 113/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 269/300 batch 114/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 269/300 batch 115/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 269/300 batch 116/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 269/300 batch 117/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 269/300 batch 118/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 269/300 batch 119/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 269/300 batch 120/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 269/300 batch 121/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 269/300 batch 122/188  Train Loss: 0.079, Acc: 0.977\n",
      "epoch: 269/300 batch 123/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 269/300 batch 124/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 269/300 batch 125/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 269/300 batch 126/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 269/300 batch 127/188  Train Loss: 0.069, Acc: 0.977\n",
      "epoch: 269/300 batch 128/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 269/300 batch 129/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 269/300 batch 130/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 269/300 batch 131/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 269/300 batch 132/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 269/300 batch 133/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 269/300 batch 134/188  Train Loss: 0.016, Acc: 0.996\n",
      "epoch: 269/300 batch 135/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 269/300 batch 136/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 269/300 batch 137/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 269/300 batch 138/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 269/300 batch 139/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 269/300 batch 140/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 269/300 batch 141/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 269/300 batch 142/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 269/300 batch 143/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 269/300 batch 144/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 269/300 batch 145/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 269/300 batch 146/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 269/300 batch 147/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 269/300 batch 148/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 269/300 batch 149/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 269/300 batch 150/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 269/300 batch 151/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 269/300 batch 152/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 269/300 batch 153/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 269/300 batch 154/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 269/300 batch 155/188  Train Loss: 0.051, Acc: 0.973\n",
      "epoch: 269/300 batch 156/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 269/300 batch 157/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 269/300 batch 158/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 269/300 batch 159/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 269/300 batch 160/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 269/300 batch 161/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 269/300 batch 162/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 269/300 batch 163/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 269/300 batch 164/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 269/300 batch 165/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 269/300 batch 166/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 269/300 batch 167/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 269/300 batch 168/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 269/300 batch 169/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 269/300 batch 170/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 269/300 batch 171/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 269/300 batch 172/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 269/300 batch 173/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 269/300 batch 174/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 269/300 batch 175/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 269/300 batch 176/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 269/300 batch 177/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 269/300 batch 178/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 269/300 batch 179/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 269/300 batch 180/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 269/300 batch 181/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 269/300 batch 182/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 269/300 batch 183/188  Train Loss: 0.063, Acc: 0.977\n",
      "epoch: 269/300 batch 184/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 269/300 batch 185/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 269/300 batch 186/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 269/300 batch 187/188  Train Loss: 0.018, Acc: 0.992\n",
      "Train Loss: 0.032626, Acc: 0.993\n",
      "Val Loss: 0.057348, Acc: 0.983\n",
      "epoch: 270/300 batch   0/188  Train Loss: 0.039, Acc: 0.980\n",
      "epoch: 270/300 batch   1/188  Train Loss: 0.048, Acc: 0.980\n",
      "epoch: 270/300 batch   2/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 270/300 batch   3/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 270/300 batch   4/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 270/300 batch   5/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 270/300 batch   6/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 270/300 batch   7/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 270/300 batch   8/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 270/300 batch   9/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 270/300 batch  10/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 270/300 batch  11/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 270/300 batch  12/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 270/300 batch  13/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 270/300 batch  14/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 270/300 batch  15/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 270/300 batch  16/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 270/300 batch  17/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 270/300 batch  18/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 270/300 batch  19/188  Train Loss: 0.032, Acc: 1.000\n",
      "epoch: 270/300 batch  20/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 270/300 batch  21/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 270/300 batch  22/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 270/300 batch  23/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 270/300 batch  24/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 270/300 batch  25/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 270/300 batch  26/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 270/300 batch  27/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 270/300 batch  28/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 270/300 batch  29/188  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 270/300 batch  30/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 270/300 batch  31/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 270/300 batch  32/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 270/300 batch  33/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 270/300 batch  34/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 270/300 batch  35/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 270/300 batch  36/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 270/300 batch  37/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 270/300 batch  38/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 270/300 batch  39/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 270/300 batch  40/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 270/300 batch  41/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 270/300 batch  42/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 270/300 batch  43/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 270/300 batch  44/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 270/300 batch  45/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 270/300 batch  46/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 270/300 batch  47/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 270/300 batch  48/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 270/300 batch  49/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 270/300 batch  50/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 270/300 batch  51/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 270/300 batch  52/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 270/300 batch  53/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 270/300 batch  54/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 270/300 batch  55/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 270/300 batch  56/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 270/300 batch  57/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 270/300 batch  58/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 270/300 batch  59/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 270/300 batch  60/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 270/300 batch  61/188  Train Loss: 0.072, Acc: 0.984\n",
      "epoch: 270/300 batch  62/188  Train Loss: 0.074, Acc: 0.988\n",
      "epoch: 270/300 batch  63/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 270/300 batch  64/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 270/300 batch  65/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 270/300 batch  66/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 270/300 batch  67/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 270/300 batch  68/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 270/300 batch  69/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 270/300 batch  70/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 270/300 batch  71/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 270/300 batch  72/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 270/300 batch  73/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 270/300 batch  74/188  Train Loss: 0.052, Acc: 0.980\n",
      "epoch: 270/300 batch  75/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 270/300 batch  76/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 270/300 batch  77/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 270/300 batch  78/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 270/300 batch  79/188  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 270/300 batch  80/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 270/300 batch  81/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 270/300 batch  82/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 270/300 batch  83/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 270/300 batch  84/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 270/300 batch  85/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 270/300 batch  86/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 270/300 batch  87/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 270/300 batch  88/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 270/300 batch  89/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 270/300 batch  90/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 270/300 batch  91/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 270/300 batch  92/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 270/300 batch  93/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 270/300 batch  94/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 270/300 batch  95/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 270/300 batch  96/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 270/300 batch  97/188  Train Loss: 0.026, Acc: 0.988\n",
      "epoch: 270/300 batch  98/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 270/300 batch  99/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 270/300 batch 100/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 270/300 batch 101/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 270/300 batch 102/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 270/300 batch 103/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 270/300 batch 104/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 270/300 batch 105/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 270/300 batch 106/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 270/300 batch 107/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 270/300 batch 108/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 270/300 batch 109/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 270/300 batch 110/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 270/300 batch 111/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 270/300 batch 112/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 270/300 batch 113/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 270/300 batch 114/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 270/300 batch 115/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 270/300 batch 116/188  Train Loss: 0.051, Acc: 0.992\n",
      "epoch: 270/300 batch 117/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 270/300 batch 118/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 270/300 batch 119/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 270/300 batch 120/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 270/300 batch 121/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 270/300 batch 122/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 270/300 batch 123/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 270/300 batch 124/188  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 270/300 batch 125/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 270/300 batch 126/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 270/300 batch 127/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 270/300 batch 128/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 270/300 batch 129/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 270/300 batch 130/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 270/300 batch 131/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 270/300 batch 132/188  Train Loss: 0.059, Acc: 0.980\n",
      "epoch: 270/300 batch 133/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 270/300 batch 134/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 270/300 batch 135/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 270/300 batch 136/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 270/300 batch 137/188  Train Loss: 0.047, Acc: 0.980\n",
      "epoch: 270/300 batch 138/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 270/300 batch 139/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 270/300 batch 140/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 270/300 batch 141/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 270/300 batch 142/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 270/300 batch 143/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 270/300 batch 144/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 270/300 batch 145/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 270/300 batch 146/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 270/300 batch 147/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 270/300 batch 148/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 270/300 batch 149/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 270/300 batch 150/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 270/300 batch 151/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 270/300 batch 152/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 270/300 batch 153/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 270/300 batch 154/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 270/300 batch 155/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 270/300 batch 156/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 270/300 batch 157/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 270/300 batch 158/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 270/300 batch 159/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 270/300 batch 160/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 270/300 batch 161/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 270/300 batch 162/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 270/300 batch 163/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 270/300 batch 164/188  Train Loss: 0.065, Acc: 0.984\n",
      "epoch: 270/300 batch 165/188  Train Loss: 0.042, Acc: 0.996\n",
      "epoch: 270/300 batch 166/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 270/300 batch 167/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 270/300 batch 168/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 270/300 batch 169/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 270/300 batch 170/188  Train Loss: 0.050, Acc: 0.980\n",
      "epoch: 270/300 batch 171/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 270/300 batch 172/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 270/300 batch 173/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 270/300 batch 174/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 270/300 batch 175/188  Train Loss: 0.059, Acc: 0.980\n",
      "epoch: 270/300 batch 176/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 270/300 batch 177/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 270/300 batch 178/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 270/300 batch 179/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 270/300 batch 180/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 270/300 batch 181/188  Train Loss: 0.052, Acc: 0.992\n",
      "epoch: 270/300 batch 182/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 270/300 batch 183/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 270/300 batch 184/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 270/300 batch 185/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 270/300 batch 186/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 270/300 batch 187/188  Train Loss: 0.038, Acc: 1.000\n",
      "Train Loss: 0.032667, Acc: 0.993\n",
      "Val Loss: 0.057820, Acc: 0.983\n",
      "epoch: 271/300 batch   0/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 271/300 batch   1/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 271/300 batch   2/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 271/300 batch   3/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 271/300 batch   4/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 271/300 batch   5/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 271/300 batch   6/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 271/300 batch   7/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 271/300 batch   8/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 271/300 batch   9/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 271/300 batch  10/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 271/300 batch  11/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 271/300 batch  12/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 271/300 batch  13/188  Train Loss: 0.025, Acc: 0.988\n",
      "epoch: 271/300 batch  14/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 271/300 batch  15/188  Train Loss: 0.043, Acc: 0.996\n",
      "epoch: 271/300 batch  16/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 271/300 batch  17/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 271/300 batch  18/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 271/300 batch  19/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 271/300 batch  20/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 271/300 batch  21/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 271/300 batch  22/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 271/300 batch  23/188  Train Loss: 0.062, Acc: 0.988\n",
      "epoch: 271/300 batch  24/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 271/300 batch  25/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 271/300 batch  26/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 271/300 batch  27/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 271/300 batch  28/188  Train Loss: 0.048, Acc: 0.980\n",
      "epoch: 271/300 batch  29/188  Train Loss: 0.052, Acc: 0.980\n",
      "epoch: 271/300 batch  30/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 271/300 batch  31/188  Train Loss: 0.050, Acc: 0.977\n",
      "epoch: 271/300 batch  32/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 271/300 batch  33/188  Train Loss: 0.057, Acc: 0.980\n",
      "epoch: 271/300 batch  34/188  Train Loss: 0.079, Acc: 0.984\n",
      "epoch: 271/300 batch  35/188  Train Loss: 0.025, Acc: 0.988\n",
      "epoch: 271/300 batch  36/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 271/300 batch  37/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 271/300 batch  38/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 271/300 batch  39/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 271/300 batch  40/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 271/300 batch  41/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 271/300 batch  42/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 271/300 batch  43/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 271/300 batch  44/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 271/300 batch  45/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 271/300 batch  46/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 271/300 batch  47/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 271/300 batch  48/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 271/300 batch  49/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 271/300 batch  50/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 271/300 batch  51/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 271/300 batch  52/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 271/300 batch  53/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 271/300 batch  54/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 271/300 batch  55/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 271/300 batch  56/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 271/300 batch  57/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 271/300 batch  58/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 271/300 batch  59/188  Train Loss: 0.038, Acc: 1.000\n",
      "epoch: 271/300 batch  60/188  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 271/300 batch  61/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 271/300 batch  62/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 271/300 batch  63/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 271/300 batch  64/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 271/300 batch  65/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 271/300 batch  66/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 271/300 batch  67/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 271/300 batch  68/188  Train Loss: 0.030, Acc: 0.984\n",
      "epoch: 271/300 batch  69/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 271/300 batch  70/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 271/300 batch  71/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 271/300 batch  72/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 271/300 batch  73/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 271/300 batch  74/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 271/300 batch  75/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 271/300 batch  76/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 271/300 batch  77/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 271/300 batch  78/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 271/300 batch  79/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 271/300 batch  80/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 271/300 batch  81/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 271/300 batch  82/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 271/300 batch  83/188  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 271/300 batch  84/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 271/300 batch  85/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 271/300 batch  86/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 271/300 batch  87/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 271/300 batch  88/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 271/300 batch  89/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 271/300 batch  90/188  Train Loss: 0.070, Acc: 0.984\n",
      "epoch: 271/300 batch  91/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 271/300 batch  92/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 271/300 batch  93/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 271/300 batch  94/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 271/300 batch  95/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 271/300 batch  96/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 271/300 batch  97/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 271/300 batch  98/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 271/300 batch  99/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 271/300 batch 100/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 271/300 batch 101/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 271/300 batch 102/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 271/300 batch 103/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 271/300 batch 104/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 271/300 batch 105/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 271/300 batch 106/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 271/300 batch 107/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 271/300 batch 108/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 271/300 batch 109/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 271/300 batch 110/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 271/300 batch 111/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 271/300 batch 112/188  Train Loss: 0.032, Acc: 0.984\n",
      "epoch: 271/300 batch 113/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 271/300 batch 114/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 271/300 batch 115/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 271/300 batch 116/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 271/300 batch 117/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 271/300 batch 118/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 271/300 batch 119/188  Train Loss: 0.054, Acc: 0.977\n",
      "epoch: 271/300 batch 120/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 271/300 batch 121/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 271/300 batch 122/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 271/300 batch 123/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 271/300 batch 124/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 271/300 batch 125/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 271/300 batch 126/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 271/300 batch 127/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 271/300 batch 128/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 271/300 batch 129/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 271/300 batch 130/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 271/300 batch 131/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 271/300 batch 132/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 271/300 batch 133/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 271/300 batch 134/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 271/300 batch 135/188  Train Loss: 0.071, Acc: 0.988\n",
      "epoch: 271/300 batch 136/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 271/300 batch 137/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 271/300 batch 138/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 271/300 batch 139/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 271/300 batch 140/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 271/300 batch 141/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 271/300 batch 142/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 271/300 batch 143/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 271/300 batch 144/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 271/300 batch 145/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 271/300 batch 146/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 271/300 batch 147/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 271/300 batch 148/188  Train Loss: 0.033, Acc: 0.984\n",
      "epoch: 271/300 batch 149/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 271/300 batch 150/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 271/300 batch 151/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 271/300 batch 152/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 271/300 batch 153/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 271/300 batch 154/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 271/300 batch 155/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 271/300 batch 156/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 271/300 batch 157/188  Train Loss: 0.062, Acc: 0.988\n",
      "epoch: 271/300 batch 158/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 271/300 batch 159/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 271/300 batch 160/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 271/300 batch 161/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 271/300 batch 162/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 271/300 batch 163/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 271/300 batch 164/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 271/300 batch 165/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 271/300 batch 166/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 271/300 batch 167/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 271/300 batch 168/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 271/300 batch 169/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 271/300 batch 170/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 271/300 batch 171/188  Train Loss: 0.063, Acc: 0.984\n",
      "epoch: 271/300 batch 172/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 271/300 batch 173/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 271/300 batch 174/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 271/300 batch 175/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 271/300 batch 176/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 271/300 batch 177/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 271/300 batch 178/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 271/300 batch 179/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 271/300 batch 180/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 271/300 batch 181/188  Train Loss: 0.064, Acc: 0.984\n",
      "epoch: 271/300 batch 182/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 271/300 batch 183/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 271/300 batch 184/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 271/300 batch 185/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 271/300 batch 186/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 271/300 batch 187/188  Train Loss: 0.028, Acc: 0.992\n",
      "Train Loss: 0.032625, Acc: 0.993\n",
      "Val Loss: 0.057373, Acc: 0.984\n",
      "epoch: 272/300 batch   0/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 272/300 batch   1/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 272/300 batch   2/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 272/300 batch   3/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 272/300 batch   4/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 272/300 batch   5/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 272/300 batch   6/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 272/300 batch   7/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 272/300 batch   8/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 272/300 batch   9/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 272/300 batch  10/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 272/300 batch  11/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 272/300 batch  12/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 272/300 batch  13/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 272/300 batch  14/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 272/300 batch  15/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 272/300 batch  16/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 272/300 batch  17/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 272/300 batch  18/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 272/300 batch  19/188  Train Loss: 0.033, Acc: 0.984\n",
      "epoch: 272/300 batch  20/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 272/300 batch  21/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 272/300 batch  22/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 272/300 batch  23/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 272/300 batch  24/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 272/300 batch  25/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 272/300 batch  26/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 272/300 batch  27/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 272/300 batch  28/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 272/300 batch  29/188  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 272/300 batch  30/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 272/300 batch  31/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 272/300 batch  32/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 272/300 batch  33/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 272/300 batch  34/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 272/300 batch  35/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 272/300 batch  36/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 272/300 batch  37/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 272/300 batch  38/188  Train Loss: 0.027, Acc: 0.988\n",
      "epoch: 272/300 batch  39/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 272/300 batch  40/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 272/300 batch  41/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 272/300 batch  42/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 272/300 batch  43/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 272/300 batch  44/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 272/300 batch  45/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 272/300 batch  46/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 272/300 batch  47/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 272/300 batch  48/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 272/300 batch  49/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 272/300 batch  50/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 272/300 batch  51/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 272/300 batch  52/188  Train Loss: 0.034, Acc: 0.980\n",
      "epoch: 272/300 batch  53/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 272/300 batch  54/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 272/300 batch  55/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 272/300 batch  56/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 272/300 batch  57/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 272/300 batch  58/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 272/300 batch  59/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 272/300 batch  60/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 272/300 batch  61/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 272/300 batch  62/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 272/300 batch  63/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 272/300 batch  64/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 272/300 batch  65/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 272/300 batch  66/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 272/300 batch  67/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 272/300 batch  68/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 272/300 batch  69/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 272/300 batch  70/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 272/300 batch  71/188  Train Loss: 0.041, Acc: 0.980\n",
      "epoch: 272/300 batch  72/188  Train Loss: 0.047, Acc: 0.980\n",
      "epoch: 272/300 batch  73/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 272/300 batch  74/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 272/300 batch  75/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 272/300 batch  76/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 272/300 batch  77/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 272/300 batch  78/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 272/300 batch  79/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 272/300 batch  80/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 272/300 batch  81/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 272/300 batch  82/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 272/300 batch  83/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 272/300 batch  84/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 272/300 batch  85/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 272/300 batch  86/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 272/300 batch  87/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 272/300 batch  88/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 272/300 batch  89/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 272/300 batch  90/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 272/300 batch  91/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 272/300 batch  92/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 272/300 batch  93/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 272/300 batch  94/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 272/300 batch  95/188  Train Loss: 0.057, Acc: 0.980\n",
      "epoch: 272/300 batch  96/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 272/300 batch  97/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 272/300 batch  98/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 272/300 batch  99/188  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 272/300 batch 100/188  Train Loss: 0.043, Acc: 0.996\n",
      "epoch: 272/300 batch 101/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 272/300 batch 102/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 272/300 batch 103/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 272/300 batch 104/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 272/300 batch 105/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 272/300 batch 106/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 272/300 batch 107/188  Train Loss: 0.064, Acc: 0.984\n",
      "epoch: 272/300 batch 108/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 272/300 batch 109/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 272/300 batch 110/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 272/300 batch 111/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 272/300 batch 112/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 272/300 batch 113/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 272/300 batch 114/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 272/300 batch 115/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 272/300 batch 116/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 272/300 batch 117/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 272/300 batch 118/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 272/300 batch 119/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 272/300 batch 120/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 272/300 batch 121/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 272/300 batch 122/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 272/300 batch 123/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 272/300 batch 124/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 272/300 batch 125/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 272/300 batch 126/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 272/300 batch 127/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 272/300 batch 128/188  Train Loss: 0.066, Acc: 0.984\n",
      "epoch: 272/300 batch 129/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 272/300 batch 130/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 272/300 batch 131/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 272/300 batch 132/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 272/300 batch 133/188  Train Loss: 0.047, Acc: 0.980\n",
      "epoch: 272/300 batch 134/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 272/300 batch 135/188  Train Loss: 0.055, Acc: 0.992\n",
      "epoch: 272/300 batch 136/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 272/300 batch 137/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 272/300 batch 138/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 272/300 batch 139/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 272/300 batch 140/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 272/300 batch 141/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 272/300 batch 142/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 272/300 batch 143/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 272/300 batch 144/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 272/300 batch 145/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 272/300 batch 146/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 272/300 batch 147/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 272/300 batch 148/188  Train Loss: 0.075, Acc: 0.980\n",
      "epoch: 272/300 batch 149/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 272/300 batch 150/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 272/300 batch 151/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 272/300 batch 152/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 272/300 batch 153/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 272/300 batch 154/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 272/300 batch 155/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 272/300 batch 156/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 272/300 batch 157/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 272/300 batch 158/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 272/300 batch 159/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 272/300 batch 160/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 272/300 batch 161/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 272/300 batch 162/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 272/300 batch 163/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 272/300 batch 164/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 272/300 batch 165/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 272/300 batch 166/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 272/300 batch 167/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 272/300 batch 168/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 272/300 batch 169/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 272/300 batch 170/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 272/300 batch 171/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 272/300 batch 172/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 272/300 batch 173/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 272/300 batch 174/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 272/300 batch 175/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 272/300 batch 176/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 272/300 batch 177/188  Train Loss: 0.016, Acc: 0.996\n",
      "epoch: 272/300 batch 178/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 272/300 batch 179/188  Train Loss: 0.071, Acc: 0.980\n",
      "epoch: 272/300 batch 180/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 272/300 batch 181/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 272/300 batch 182/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 272/300 batch 183/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 272/300 batch 184/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 272/300 batch 185/188  Train Loss: 0.065, Acc: 0.992\n",
      "epoch: 272/300 batch 186/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 272/300 batch 187/188  Train Loss: 0.045, Acc: 0.992\n",
      "Train Loss: 0.032711, Acc: 0.993\n",
      "Val Loss: 0.057104, Acc: 0.984\n",
      "epoch: 273/300 batch   0/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 273/300 batch   1/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 273/300 batch   2/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 273/300 batch   3/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 273/300 batch   4/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 273/300 batch   5/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 273/300 batch   6/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 273/300 batch   7/188  Train Loss: 0.041, Acc: 0.980\n",
      "epoch: 273/300 batch   8/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 273/300 batch   9/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 273/300 batch  10/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 273/300 batch  11/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 273/300 batch  12/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 273/300 batch  13/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 273/300 batch  14/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 273/300 batch  15/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 273/300 batch  16/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 273/300 batch  17/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 273/300 batch  18/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 273/300 batch  19/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 273/300 batch  20/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 273/300 batch  21/188  Train Loss: 0.046, Acc: 0.977\n",
      "epoch: 273/300 batch  22/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 273/300 batch  23/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 273/300 batch  24/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 273/300 batch  25/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 273/300 batch  26/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 273/300 batch  27/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 273/300 batch  28/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 273/300 batch  29/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 273/300 batch  30/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 273/300 batch  31/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 273/300 batch  32/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 273/300 batch  33/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 273/300 batch  34/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 273/300 batch  35/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 273/300 batch  36/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 273/300 batch  37/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 273/300 batch  38/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 273/300 batch  39/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 273/300 batch  40/188  Train Loss: 0.043, Acc: 0.980\n",
      "epoch: 273/300 batch  41/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 273/300 batch  42/188  Train Loss: 0.026, Acc: 0.988\n",
      "epoch: 273/300 batch  43/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 273/300 batch  44/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 273/300 batch  45/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 273/300 batch  46/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 273/300 batch  47/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 273/300 batch  48/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 273/300 batch  49/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 273/300 batch  50/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 273/300 batch  51/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 273/300 batch  52/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 273/300 batch  53/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 273/300 batch  54/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 273/300 batch  55/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 273/300 batch  56/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 273/300 batch  57/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 273/300 batch  58/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 273/300 batch  59/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 273/300 batch  60/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 273/300 batch  61/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 273/300 batch  62/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 273/300 batch  63/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 273/300 batch  64/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 273/300 batch  65/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 273/300 batch  66/188  Train Loss: 0.044, Acc: 0.996\n",
      "epoch: 273/300 batch  67/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 273/300 batch  68/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 273/300 batch  69/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 273/300 batch  70/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 273/300 batch  71/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 273/300 batch  72/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 273/300 batch  73/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 273/300 batch  74/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 273/300 batch  75/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 273/300 batch  76/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 273/300 batch  77/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 273/300 batch  78/188  Train Loss: 0.062, Acc: 0.988\n",
      "epoch: 273/300 batch  79/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 273/300 batch  80/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 273/300 batch  81/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 273/300 batch  82/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 273/300 batch  83/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 273/300 batch  84/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 273/300 batch  85/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 273/300 batch  86/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 273/300 batch  87/188  Train Loss: 0.056, Acc: 0.988\n",
      "epoch: 273/300 batch  88/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 273/300 batch  89/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 273/300 batch  90/188  Train Loss: 0.048, Acc: 0.973\n",
      "epoch: 273/300 batch  91/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 273/300 batch  92/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 273/300 batch  93/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 273/300 batch  94/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 273/300 batch  95/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 273/300 batch  96/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 273/300 batch  97/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 273/300 batch  98/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 273/300 batch  99/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 273/300 batch 100/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 273/300 batch 101/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 273/300 batch 102/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 273/300 batch 103/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 273/300 batch 104/188  Train Loss: 0.061, Acc: 0.984\n",
      "epoch: 273/300 batch 105/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 273/300 batch 106/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 273/300 batch 107/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 273/300 batch 108/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 273/300 batch 109/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 273/300 batch 110/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 273/300 batch 111/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 273/300 batch 112/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 273/300 batch 113/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 273/300 batch 114/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 273/300 batch 115/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 273/300 batch 116/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 273/300 batch 117/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 273/300 batch 118/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 273/300 batch 119/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 273/300 batch 120/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 273/300 batch 121/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 273/300 batch 122/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 273/300 batch 123/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 273/300 batch 124/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 273/300 batch 125/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 273/300 batch 126/188  Train Loss: 0.036, Acc: 0.980\n",
      "epoch: 273/300 batch 127/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 273/300 batch 128/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 273/300 batch 129/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 273/300 batch 130/188  Train Loss: 0.025, Acc: 0.988\n",
      "epoch: 273/300 batch 131/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 273/300 batch 132/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 273/300 batch 133/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 273/300 batch 134/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 273/300 batch 135/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 273/300 batch 136/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 273/300 batch 137/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 273/300 batch 138/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 273/300 batch 139/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 273/300 batch 140/188  Train Loss: 0.052, Acc: 0.992\n",
      "epoch: 273/300 batch 141/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 273/300 batch 142/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 273/300 batch 143/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 273/300 batch 144/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 273/300 batch 145/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 273/300 batch 146/188  Train Loss: 0.054, Acc: 0.977\n",
      "epoch: 273/300 batch 147/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 273/300 batch 148/188  Train Loss: 0.047, Acc: 0.980\n",
      "epoch: 273/300 batch 149/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 273/300 batch 150/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 273/300 batch 151/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 273/300 batch 152/188  Train Loss: 0.062, Acc: 0.988\n",
      "epoch: 273/300 batch 153/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 273/300 batch 154/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 273/300 batch 155/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 273/300 batch 156/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 273/300 batch 157/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 273/300 batch 158/188  Train Loss: 0.059, Acc: 0.980\n",
      "epoch: 273/300 batch 159/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 273/300 batch 160/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 273/300 batch 161/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 273/300 batch 162/188  Train Loss: 0.048, Acc: 0.980\n",
      "epoch: 273/300 batch 163/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 273/300 batch 164/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 273/300 batch 165/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 273/300 batch 166/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 273/300 batch 167/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 273/300 batch 168/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 273/300 batch 169/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 273/300 batch 170/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 273/300 batch 171/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 273/300 batch 172/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 273/300 batch 173/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 273/300 batch 174/188  Train Loss: 0.059, Acc: 0.980\n",
      "epoch: 273/300 batch 175/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 273/300 batch 176/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 273/300 batch 177/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 273/300 batch 178/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 273/300 batch 179/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 273/300 batch 180/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 273/300 batch 181/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 273/300 batch 182/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 273/300 batch 183/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 273/300 batch 184/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 273/300 batch 185/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 273/300 batch 186/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 273/300 batch 187/188  Train Loss: 0.018, Acc: 0.992\n",
      "Train Loss: 0.032534, Acc: 0.993\n",
      "Val Loss: 0.057325, Acc: 0.984\n",
      "epoch: 274/300 batch   0/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 274/300 batch   1/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 274/300 batch   2/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 274/300 batch   3/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 274/300 batch   4/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 274/300 batch   5/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 274/300 batch   6/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 274/300 batch   7/188  Train Loss: 0.034, Acc: 0.984\n",
      "epoch: 274/300 batch   8/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 274/300 batch   9/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 274/300 batch  10/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 274/300 batch  11/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 274/300 batch  12/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 274/300 batch  13/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 274/300 batch  14/188  Train Loss: 0.053, Acc: 0.980\n",
      "epoch: 274/300 batch  15/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 274/300 batch  16/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 274/300 batch  17/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 274/300 batch  18/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 274/300 batch  19/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 274/300 batch  20/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 274/300 batch  21/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 274/300 batch  22/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 274/300 batch  23/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 274/300 batch  24/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 274/300 batch  25/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 274/300 batch  26/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 274/300 batch  27/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 274/300 batch  28/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 274/300 batch  29/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 274/300 batch  30/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 274/300 batch  31/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 274/300 batch  32/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 274/300 batch  33/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 274/300 batch  34/188  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 274/300 batch  35/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 274/300 batch  36/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 274/300 batch  37/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 274/300 batch  38/188  Train Loss: 0.051, Acc: 0.992\n",
      "epoch: 274/300 batch  39/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 274/300 batch  40/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 274/300 batch  41/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 274/300 batch  42/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 274/300 batch  43/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 274/300 batch  44/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 274/300 batch  45/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 274/300 batch  46/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 274/300 batch  47/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 274/300 batch  48/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 274/300 batch  49/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 274/300 batch  50/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 274/300 batch  51/188  Train Loss: 0.042, Acc: 0.996\n",
      "epoch: 274/300 batch  52/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 274/300 batch  53/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 274/300 batch  54/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 274/300 batch  55/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 274/300 batch  56/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 274/300 batch  57/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 274/300 batch  58/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 274/300 batch  59/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 274/300 batch  60/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 274/300 batch  61/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 274/300 batch  62/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 274/300 batch  63/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 274/300 batch  64/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 274/300 batch  65/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 274/300 batch  66/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 274/300 batch  67/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 274/300 batch  68/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 274/300 batch  69/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 274/300 batch  70/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 274/300 batch  71/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 274/300 batch  72/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 274/300 batch  73/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 274/300 batch  74/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 274/300 batch  75/188  Train Loss: 0.033, Acc: 0.984\n",
      "epoch: 274/300 batch  76/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 274/300 batch  77/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 274/300 batch  78/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 274/300 batch  79/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 274/300 batch  80/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 274/300 batch  81/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 274/300 batch  82/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 274/300 batch  83/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 274/300 batch  84/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 274/300 batch  85/188  Train Loss: 0.043, Acc: 0.996\n",
      "epoch: 274/300 batch  86/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 274/300 batch  87/188  Train Loss: 0.044, Acc: 0.977\n",
      "epoch: 274/300 batch  88/188  Train Loss: 0.032, Acc: 0.984\n",
      "epoch: 274/300 batch  89/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 274/300 batch  90/188  Train Loss: 0.056, Acc: 0.988\n",
      "epoch: 274/300 batch  91/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 274/300 batch  92/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 274/300 batch  93/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 274/300 batch  94/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 274/300 batch  95/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 274/300 batch  96/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 274/300 batch  97/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 274/300 batch  98/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 274/300 batch  99/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 274/300 batch 100/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 274/300 batch 101/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 274/300 batch 102/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 274/300 batch 103/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 274/300 batch 104/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 274/300 batch 105/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 274/300 batch 106/188  Train Loss: 0.049, Acc: 0.980\n",
      "epoch: 274/300 batch 107/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 274/300 batch 108/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 274/300 batch 109/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 274/300 batch 110/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 274/300 batch 111/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 274/300 batch 112/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 274/300 batch 113/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 274/300 batch 114/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 274/300 batch 115/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 274/300 batch 116/188  Train Loss: 0.016, Acc: 0.996\n",
      "epoch: 274/300 batch 117/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 274/300 batch 118/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 274/300 batch 119/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 274/300 batch 120/188  Train Loss: 0.032, Acc: 0.984\n",
      "epoch: 274/300 batch 121/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 274/300 batch 122/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 274/300 batch 123/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 274/300 batch 124/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 274/300 batch 125/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 274/300 batch 126/188  Train Loss: 0.065, Acc: 0.977\n",
      "epoch: 274/300 batch 127/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 274/300 batch 128/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 274/300 batch 129/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 274/300 batch 130/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 274/300 batch 131/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 274/300 batch 132/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 274/300 batch 133/188  Train Loss: 0.076, Acc: 0.984\n",
      "epoch: 274/300 batch 134/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 274/300 batch 135/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 274/300 batch 136/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 274/300 batch 137/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 274/300 batch 138/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 274/300 batch 139/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 274/300 batch 140/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 274/300 batch 141/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 274/300 batch 142/188  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 274/300 batch 143/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 274/300 batch 144/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 274/300 batch 145/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 274/300 batch 146/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 274/300 batch 147/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 274/300 batch 148/188  Train Loss: 0.015, Acc: 0.996\n",
      "epoch: 274/300 batch 149/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 274/300 batch 150/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 274/300 batch 151/188  Train Loss: 0.034, Acc: 0.984\n",
      "epoch: 274/300 batch 152/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 274/300 batch 153/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 274/300 batch 154/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 274/300 batch 155/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 274/300 batch 156/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 274/300 batch 157/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 274/300 batch 158/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 274/300 batch 159/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 274/300 batch 160/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 274/300 batch 161/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 274/300 batch 162/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 274/300 batch 163/188  Train Loss: 0.051, Acc: 0.992\n",
      "epoch: 274/300 batch 164/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 274/300 batch 165/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 274/300 batch 166/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 274/300 batch 167/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 274/300 batch 168/188  Train Loss: 0.013, Acc: 0.996\n",
      "epoch: 274/300 batch 169/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 274/300 batch 170/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 274/300 batch 171/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 274/300 batch 172/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 274/300 batch 173/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 274/300 batch 174/188  Train Loss: 0.055, Acc: 0.973\n",
      "epoch: 274/300 batch 175/188  Train Loss: 0.057, Acc: 0.980\n",
      "epoch: 274/300 batch 176/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 274/300 batch 177/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 274/300 batch 178/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 274/300 batch 179/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 274/300 batch 180/188  Train Loss: 0.074, Acc: 0.992\n",
      "epoch: 274/300 batch 181/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 274/300 batch 182/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 274/300 batch 183/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 274/300 batch 184/188  Train Loss: 0.046, Acc: 0.980\n",
      "epoch: 274/300 batch 185/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 274/300 batch 186/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 274/300 batch 187/188  Train Loss: 0.029, Acc: 0.992\n",
      "Train Loss: 0.032576, Acc: 0.993\n",
      "Val Loss: 0.057654, Acc: 0.983\n",
      "epoch: 275/300 batch   0/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 275/300 batch   1/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 275/300 batch   2/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 275/300 batch   3/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 275/300 batch   4/188  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 275/300 batch   5/188  Train Loss: 0.016, Acc: 0.996\n",
      "epoch: 275/300 batch   6/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 275/300 batch   7/188  Train Loss: 0.065, Acc: 0.980\n",
      "epoch: 275/300 batch   8/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 275/300 batch   9/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 275/300 batch  10/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 275/300 batch  11/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 275/300 batch  12/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 275/300 batch  13/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 275/300 batch  14/188  Train Loss: 0.064, Acc: 0.992\n",
      "epoch: 275/300 batch  15/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 275/300 batch  16/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 275/300 batch  17/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 275/300 batch  18/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 275/300 batch  19/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 275/300 batch  20/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 275/300 batch  21/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 275/300 batch  22/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 275/300 batch  23/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 275/300 batch  24/188  Train Loss: 0.051, Acc: 0.980\n",
      "epoch: 275/300 batch  25/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 275/300 batch  26/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 275/300 batch  27/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 275/300 batch  28/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 275/300 batch  29/188  Train Loss: 0.077, Acc: 0.988\n",
      "epoch: 275/300 batch  30/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 275/300 batch  31/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 275/300 batch  32/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 275/300 batch  33/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 275/300 batch  34/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 275/300 batch  35/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 275/300 batch  36/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 275/300 batch  37/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 275/300 batch  38/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 275/300 batch  39/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 275/300 batch  40/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 275/300 batch  41/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 275/300 batch  42/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 275/300 batch  43/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 275/300 batch  44/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 275/300 batch  45/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 275/300 batch  46/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 275/300 batch  47/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 275/300 batch  48/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 275/300 batch  49/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 275/300 batch  50/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 275/300 batch  51/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 275/300 batch  52/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 275/300 batch  53/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 275/300 batch  54/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 275/300 batch  55/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 275/300 batch  56/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 275/300 batch  57/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 275/300 batch  58/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 275/300 batch  59/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 275/300 batch  60/188  Train Loss: 0.043, Acc: 0.980\n",
      "epoch: 275/300 batch  61/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 275/300 batch  62/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 275/300 batch  63/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 275/300 batch  64/188  Train Loss: 0.064, Acc: 0.984\n",
      "epoch: 275/300 batch  65/188  Train Loss: 0.046, Acc: 0.980\n",
      "epoch: 275/300 batch  66/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 275/300 batch  67/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 275/300 batch  68/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 275/300 batch  69/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 275/300 batch  70/188  Train Loss: 0.065, Acc: 0.980\n",
      "epoch: 275/300 batch  71/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 275/300 batch  72/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 275/300 batch  73/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 275/300 batch  74/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 275/300 batch  75/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 275/300 batch  76/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 275/300 batch  77/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 275/300 batch  78/188  Train Loss: 0.016, Acc: 0.996\n",
      "epoch: 275/300 batch  79/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 275/300 batch  80/188  Train Loss: 0.054, Acc: 0.996\n",
      "epoch: 275/300 batch  81/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 275/300 batch  82/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 275/300 batch  83/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 275/300 batch  84/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 275/300 batch  85/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 275/300 batch  86/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 275/300 batch  87/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 275/300 batch  88/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 275/300 batch  89/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 275/300 batch  90/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 275/300 batch  91/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 275/300 batch  92/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 275/300 batch  93/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 275/300 batch  94/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 275/300 batch  95/188  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 275/300 batch  96/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 275/300 batch  97/188  Train Loss: 0.065, Acc: 0.977\n",
      "epoch: 275/300 batch  98/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 275/300 batch  99/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 275/300 batch 100/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 275/300 batch 101/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 275/300 batch 102/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 275/300 batch 103/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 275/300 batch 104/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 275/300 batch 105/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 275/300 batch 106/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 275/300 batch 107/188  Train Loss: 0.015, Acc: 0.996\n",
      "epoch: 275/300 batch 108/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 275/300 batch 109/188  Train Loss: 0.043, Acc: 0.973\n",
      "epoch: 275/300 batch 110/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 275/300 batch 111/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 275/300 batch 112/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 275/300 batch 113/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 275/300 batch 114/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 275/300 batch 115/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 275/300 batch 116/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 275/300 batch 117/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 275/300 batch 118/188  Train Loss: 0.051, Acc: 0.980\n",
      "epoch: 275/300 batch 119/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 275/300 batch 120/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 275/300 batch 121/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 275/300 batch 122/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 275/300 batch 123/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 275/300 batch 124/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 275/300 batch 125/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 275/300 batch 126/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 275/300 batch 127/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 275/300 batch 128/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 275/300 batch 129/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 275/300 batch 130/188  Train Loss: 0.056, Acc: 0.992\n",
      "epoch: 275/300 batch 131/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 275/300 batch 132/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 275/300 batch 133/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 275/300 batch 134/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 275/300 batch 135/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 275/300 batch 136/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 275/300 batch 137/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 275/300 batch 138/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 275/300 batch 139/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 275/300 batch 140/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 275/300 batch 141/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 275/300 batch 142/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 275/300 batch 143/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 275/300 batch 144/188  Train Loss: 0.036, Acc: 0.980\n",
      "epoch: 275/300 batch 145/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 275/300 batch 146/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 275/300 batch 147/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 275/300 batch 148/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 275/300 batch 149/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 275/300 batch 150/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 275/300 batch 151/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 275/300 batch 152/188  Train Loss: 0.074, Acc: 0.980\n",
      "epoch: 275/300 batch 153/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 275/300 batch 154/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 275/300 batch 155/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 275/300 batch 156/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 275/300 batch 157/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 275/300 batch 158/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 275/300 batch 159/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 275/300 batch 160/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 275/300 batch 161/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 275/300 batch 162/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 275/300 batch 163/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 275/300 batch 164/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 275/300 batch 165/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 275/300 batch 166/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 275/300 batch 167/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 275/300 batch 168/188  Train Loss: 0.057, Acc: 0.992\n",
      "epoch: 275/300 batch 169/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 275/300 batch 170/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 275/300 batch 171/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 275/300 batch 172/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 275/300 batch 173/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 275/300 batch 174/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 275/300 batch 175/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 275/300 batch 176/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 275/300 batch 177/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 275/300 batch 178/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 275/300 batch 179/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 275/300 batch 180/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 275/300 batch 181/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 275/300 batch 182/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 275/300 batch 183/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 275/300 batch 184/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 275/300 batch 185/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 275/300 batch 186/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 275/300 batch 187/188  Train Loss: 0.025, Acc: 1.000\n",
      "Train Loss: 0.032680, Acc: 0.993\n",
      "Val Loss: 0.057365, Acc: 0.983\n",
      "epoch: 276/300 batch   0/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 276/300 batch   1/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 276/300 batch   2/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 276/300 batch   3/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 276/300 batch   4/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 276/300 batch   5/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 276/300 batch   6/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 276/300 batch   7/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 276/300 batch   8/188  Train Loss: 0.031, Acc: 1.000\n",
      "epoch: 276/300 batch   9/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 276/300 batch  10/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 276/300 batch  11/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 276/300 batch  12/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 276/300 batch  13/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 276/300 batch  14/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 276/300 batch  15/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 276/300 batch  16/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 276/300 batch  17/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 276/300 batch  18/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 276/300 batch  19/188  Train Loss: 0.057, Acc: 0.992\n",
      "epoch: 276/300 batch  20/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 276/300 batch  21/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 276/300 batch  22/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 276/300 batch  23/188  Train Loss: 0.058, Acc: 0.980\n",
      "epoch: 276/300 batch  24/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 276/300 batch  25/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 276/300 batch  26/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 276/300 batch  27/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 276/300 batch  28/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 276/300 batch  29/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 276/300 batch  30/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 276/300 batch  31/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 276/300 batch  32/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 276/300 batch  33/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 276/300 batch  34/188  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 276/300 batch  35/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 276/300 batch  36/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 276/300 batch  37/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 276/300 batch  38/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 276/300 batch  39/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 276/300 batch  40/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 276/300 batch  41/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 276/300 batch  42/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 276/300 batch  43/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 276/300 batch  44/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 276/300 batch  45/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 276/300 batch  46/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 276/300 batch  47/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 276/300 batch  48/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 276/300 batch  49/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 276/300 batch  50/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 276/300 batch  51/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 276/300 batch  52/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 276/300 batch  53/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 276/300 batch  54/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 276/300 batch  55/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 276/300 batch  56/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 276/300 batch  57/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 276/300 batch  58/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 276/300 batch  59/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 276/300 batch  60/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 276/300 batch  61/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 276/300 batch  62/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 276/300 batch  63/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 276/300 batch  64/188  Train Loss: 0.046, Acc: 0.996\n",
      "epoch: 276/300 batch  65/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 276/300 batch  66/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 276/300 batch  67/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 276/300 batch  68/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 276/300 batch  69/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 276/300 batch  70/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 276/300 batch  71/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 276/300 batch  72/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 276/300 batch  73/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 276/300 batch  74/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 276/300 batch  75/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 276/300 batch  76/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 276/300 batch  77/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 276/300 batch  78/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 276/300 batch  79/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 276/300 batch  80/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 276/300 batch  81/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 276/300 batch  82/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 276/300 batch  83/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 276/300 batch  84/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 276/300 batch  85/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 276/300 batch  86/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 276/300 batch  87/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 276/300 batch  88/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 276/300 batch  89/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 276/300 batch  90/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 276/300 batch  91/188  Train Loss: 0.033, Acc: 0.984\n",
      "epoch: 276/300 batch  92/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 276/300 batch  93/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 276/300 batch  94/188  Train Loss: 0.059, Acc: 0.984\n",
      "epoch: 276/300 batch  95/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 276/300 batch  96/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 276/300 batch  97/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 276/300 batch  98/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 276/300 batch  99/188  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 276/300 batch 100/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 276/300 batch 101/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 276/300 batch 102/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 276/300 batch 103/188  Train Loss: 0.059, Acc: 0.988\n",
      "epoch: 276/300 batch 104/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 276/300 batch 105/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 276/300 batch 106/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 276/300 batch 107/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 276/300 batch 108/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 276/300 batch 109/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 276/300 batch 110/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 276/300 batch 111/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 276/300 batch 112/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 276/300 batch 113/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 276/300 batch 114/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 276/300 batch 115/188  Train Loss: 0.050, Acc: 0.980\n",
      "epoch: 276/300 batch 116/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 276/300 batch 117/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 276/300 batch 118/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 276/300 batch 119/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 276/300 batch 120/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 276/300 batch 121/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 276/300 batch 122/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 276/300 batch 123/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 276/300 batch 124/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 276/300 batch 125/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 276/300 batch 126/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 276/300 batch 127/188  Train Loss: 0.033, Acc: 0.984\n",
      "epoch: 276/300 batch 128/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 276/300 batch 129/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 276/300 batch 130/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 276/300 batch 131/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 276/300 batch 132/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 276/300 batch 133/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 276/300 batch 134/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 276/300 batch 135/188  Train Loss: 0.052, Acc: 0.980\n",
      "epoch: 276/300 batch 136/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 276/300 batch 137/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 276/300 batch 138/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 276/300 batch 139/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 276/300 batch 140/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 276/300 batch 141/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 276/300 batch 142/188  Train Loss: 0.059, Acc: 0.977\n",
      "epoch: 276/300 batch 143/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 276/300 batch 144/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 276/300 batch 145/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 276/300 batch 146/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 276/300 batch 147/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 276/300 batch 148/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 276/300 batch 149/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 276/300 batch 150/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 276/300 batch 151/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 276/300 batch 152/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 276/300 batch 153/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 276/300 batch 154/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 276/300 batch 155/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 276/300 batch 156/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 276/300 batch 157/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 276/300 batch 158/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 276/300 batch 159/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 276/300 batch 160/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 276/300 batch 161/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 276/300 batch 162/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 276/300 batch 163/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 276/300 batch 164/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 276/300 batch 165/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 276/300 batch 166/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 276/300 batch 167/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 276/300 batch 168/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 276/300 batch 169/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 276/300 batch 170/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 276/300 batch 171/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 276/300 batch 172/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 276/300 batch 173/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 276/300 batch 174/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 276/300 batch 175/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 276/300 batch 176/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 276/300 batch 177/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 276/300 batch 178/188  Train Loss: 0.047, Acc: 0.980\n",
      "epoch: 276/300 batch 179/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 276/300 batch 180/188  Train Loss: 0.053, Acc: 0.980\n",
      "epoch: 276/300 batch 181/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 276/300 batch 182/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 276/300 batch 183/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 276/300 batch 184/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 276/300 batch 185/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 276/300 batch 186/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 276/300 batch 187/188  Train Loss: 0.048, Acc: 0.977\n",
      "Train Loss: 0.032600, Acc: 0.993\n",
      "Val Loss: 0.057823, Acc: 0.983\n",
      "epoch: 277/300 batch   0/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 277/300 batch   1/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 277/300 batch   2/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 277/300 batch   3/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 277/300 batch   4/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 277/300 batch   5/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 277/300 batch   6/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 277/300 batch   7/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 277/300 batch   8/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 277/300 batch   9/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 277/300 batch  10/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 277/300 batch  11/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 277/300 batch  12/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 277/300 batch  13/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 277/300 batch  14/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 277/300 batch  15/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 277/300 batch  16/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 277/300 batch  17/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 277/300 batch  18/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 277/300 batch  19/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 277/300 batch  20/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 277/300 batch  21/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 277/300 batch  22/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 277/300 batch  23/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 277/300 batch  24/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 277/300 batch  25/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 277/300 batch  26/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 277/300 batch  27/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 277/300 batch  28/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 277/300 batch  29/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 277/300 batch  30/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 277/300 batch  31/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 277/300 batch  32/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 277/300 batch  33/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 277/300 batch  34/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 277/300 batch  35/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 277/300 batch  36/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 277/300 batch  37/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 277/300 batch  38/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 277/300 batch  39/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 277/300 batch  40/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 277/300 batch  41/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 277/300 batch  42/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 277/300 batch  43/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 277/300 batch  44/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 277/300 batch  45/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 277/300 batch  46/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 277/300 batch  47/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 277/300 batch  48/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 277/300 batch  49/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 277/300 batch  50/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 277/300 batch  51/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 277/300 batch  52/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 277/300 batch  53/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 277/300 batch  54/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 277/300 batch  55/188  Train Loss: 0.047, Acc: 0.980\n",
      "epoch: 277/300 batch  56/188  Train Loss: 0.084, Acc: 0.980\n",
      "epoch: 277/300 batch  57/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 277/300 batch  58/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 277/300 batch  59/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 277/300 batch  60/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 277/300 batch  61/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 277/300 batch  62/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 277/300 batch  63/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 277/300 batch  64/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 277/300 batch  65/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 277/300 batch  66/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 277/300 batch  67/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 277/300 batch  68/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 277/300 batch  69/188  Train Loss: 0.053, Acc: 0.980\n",
      "epoch: 277/300 batch  70/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 277/300 batch  71/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 277/300 batch  72/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 277/300 batch  73/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 277/300 batch  74/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 277/300 batch  75/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 277/300 batch  76/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 277/300 batch  77/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 277/300 batch  78/188  Train Loss: 0.066, Acc: 0.973\n",
      "epoch: 277/300 batch  79/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 277/300 batch  80/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 277/300 batch  81/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 277/300 batch  82/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 277/300 batch  83/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 277/300 batch  84/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 277/300 batch  85/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 277/300 batch  86/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 277/300 batch  87/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 277/300 batch  88/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 277/300 batch  89/188  Train Loss: 0.034, Acc: 0.984\n",
      "epoch: 277/300 batch  90/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 277/300 batch  91/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 277/300 batch  92/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 277/300 batch  93/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 277/300 batch  94/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 277/300 batch  95/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 277/300 batch  96/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 277/300 batch  97/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 277/300 batch  98/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 277/300 batch  99/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 277/300 batch 100/188  Train Loss: 0.034, Acc: 0.984\n",
      "epoch: 277/300 batch 101/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 277/300 batch 102/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 277/300 batch 103/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 277/300 batch 104/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 277/300 batch 105/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 277/300 batch 106/188  Train Loss: 0.049, Acc: 0.980\n",
      "epoch: 277/300 batch 107/188  Train Loss: 0.062, Acc: 0.992\n",
      "epoch: 277/300 batch 108/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 277/300 batch 109/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 277/300 batch 110/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 277/300 batch 111/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 277/300 batch 112/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 277/300 batch 113/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 277/300 batch 114/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 277/300 batch 115/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 277/300 batch 116/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 277/300 batch 117/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 277/300 batch 118/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 277/300 batch 119/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 277/300 batch 120/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 277/300 batch 121/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 277/300 batch 122/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 277/300 batch 123/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 277/300 batch 124/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 277/300 batch 125/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 277/300 batch 126/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 277/300 batch 127/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 277/300 batch 128/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 277/300 batch 129/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 277/300 batch 130/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 277/300 batch 131/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 277/300 batch 132/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 277/300 batch 133/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 277/300 batch 134/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 277/300 batch 135/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 277/300 batch 136/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 277/300 batch 137/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 277/300 batch 138/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 277/300 batch 139/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 277/300 batch 140/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 277/300 batch 141/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 277/300 batch 142/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 277/300 batch 143/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 277/300 batch 144/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 277/300 batch 145/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 277/300 batch 146/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 277/300 batch 147/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 277/300 batch 148/188  Train Loss: 0.047, Acc: 0.996\n",
      "epoch: 277/300 batch 149/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 277/300 batch 150/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 277/300 batch 151/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 277/300 batch 152/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 277/300 batch 153/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 277/300 batch 154/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 277/300 batch 155/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 277/300 batch 156/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 277/300 batch 157/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 277/300 batch 158/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 277/300 batch 159/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 277/300 batch 160/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 277/300 batch 161/188  Train Loss: 0.061, Acc: 0.984\n",
      "epoch: 277/300 batch 162/188  Train Loss: 0.054, Acc: 0.980\n",
      "epoch: 277/300 batch 163/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 277/300 batch 164/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 277/300 batch 165/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 277/300 batch 166/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 277/300 batch 167/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 277/300 batch 168/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 277/300 batch 169/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 277/300 batch 170/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 277/300 batch 171/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 277/300 batch 172/188  Train Loss: 0.057, Acc: 0.988\n",
      "epoch: 277/300 batch 173/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 277/300 batch 174/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 277/300 batch 175/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 277/300 batch 176/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 277/300 batch 177/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 277/300 batch 178/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 277/300 batch 179/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 277/300 batch 180/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 277/300 batch 181/188  Train Loss: 0.060, Acc: 0.984\n",
      "epoch: 277/300 batch 182/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 277/300 batch 183/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 277/300 batch 184/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 277/300 batch 185/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 277/300 batch 186/188  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 277/300 batch 187/188  Train Loss: 0.051, Acc: 0.984\n",
      "Train Loss: 0.032676, Acc: 0.993\n",
      "Val Loss: 0.057115, Acc: 0.984\n",
      "epoch: 278/300 batch   0/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 278/300 batch   1/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 278/300 batch   2/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 278/300 batch   3/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 278/300 batch   4/188  Train Loss: 0.046, Acc: 0.973\n",
      "epoch: 278/300 batch   5/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 278/300 batch   6/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 278/300 batch   7/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 278/300 batch   8/188  Train Loss: 0.066, Acc: 0.980\n",
      "epoch: 278/300 batch   9/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 278/300 batch  10/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 278/300 batch  11/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 278/300 batch  12/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 278/300 batch  13/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 278/300 batch  14/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 278/300 batch  15/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 278/300 batch  16/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 278/300 batch  17/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 278/300 batch  18/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 278/300 batch  19/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 278/300 batch  20/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 278/300 batch  21/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 278/300 batch  22/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 278/300 batch  23/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 278/300 batch  24/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 278/300 batch  25/188  Train Loss: 0.043, Acc: 0.977\n",
      "epoch: 278/300 batch  26/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 278/300 batch  27/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 278/300 batch  28/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 278/300 batch  29/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 278/300 batch  30/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 278/300 batch  31/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 278/300 batch  32/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 278/300 batch  33/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 278/300 batch  34/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 278/300 batch  35/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 278/300 batch  36/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 278/300 batch  37/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 278/300 batch  38/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 278/300 batch  39/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 278/300 batch  40/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 278/300 batch  41/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 278/300 batch  42/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 278/300 batch  43/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 278/300 batch  44/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 278/300 batch  45/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 278/300 batch  46/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 278/300 batch  47/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 278/300 batch  48/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 278/300 batch  49/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 278/300 batch  50/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 278/300 batch  51/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 278/300 batch  52/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 278/300 batch  53/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 278/300 batch  54/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 278/300 batch  55/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 278/300 batch  56/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 278/300 batch  57/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 278/300 batch  58/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 278/300 batch  59/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 278/300 batch  60/188  Train Loss: 0.056, Acc: 0.992\n",
      "epoch: 278/300 batch  61/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 278/300 batch  62/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 278/300 batch  63/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 278/300 batch  64/188  Train Loss: 0.049, Acc: 0.980\n",
      "epoch: 278/300 batch  65/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 278/300 batch  66/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 278/300 batch  67/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 278/300 batch  68/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 278/300 batch  69/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 278/300 batch  70/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 278/300 batch  71/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 278/300 batch  72/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 278/300 batch  73/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 278/300 batch  74/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 278/300 batch  75/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 278/300 batch  76/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 278/300 batch  77/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 278/300 batch  78/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 278/300 batch  79/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 278/300 batch  80/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 278/300 batch  81/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 278/300 batch  82/188  Train Loss: 0.047, Acc: 0.980\n",
      "epoch: 278/300 batch  83/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 278/300 batch  84/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 278/300 batch  85/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 278/300 batch  86/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 278/300 batch  87/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 278/300 batch  88/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 278/300 batch  89/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 278/300 batch  90/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 278/300 batch  91/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 278/300 batch  92/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 278/300 batch  93/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 278/300 batch  94/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 278/300 batch  95/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 278/300 batch  96/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 278/300 batch  97/188  Train Loss: 0.048, Acc: 0.977\n",
      "epoch: 278/300 batch  98/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 278/300 batch  99/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 278/300 batch 100/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 278/300 batch 101/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 278/300 batch 102/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 278/300 batch 103/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 278/300 batch 104/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 278/300 batch 105/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 278/300 batch 106/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 278/300 batch 107/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 278/300 batch 108/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 278/300 batch 109/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 278/300 batch 110/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 278/300 batch 111/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 278/300 batch 112/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 278/300 batch 113/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 278/300 batch 114/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 278/300 batch 115/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 278/300 batch 116/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 278/300 batch 117/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 278/300 batch 118/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 278/300 batch 119/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 278/300 batch 120/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 278/300 batch 121/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 278/300 batch 122/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 278/300 batch 123/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 278/300 batch 124/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 278/300 batch 125/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 278/300 batch 126/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 278/300 batch 127/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 278/300 batch 128/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 278/300 batch 129/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 278/300 batch 130/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 278/300 batch 131/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 278/300 batch 132/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 278/300 batch 133/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 278/300 batch 134/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 278/300 batch 135/188  Train Loss: 0.057, Acc: 0.988\n",
      "epoch: 278/300 batch 136/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 278/300 batch 137/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 278/300 batch 138/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 278/300 batch 139/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 278/300 batch 140/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 278/300 batch 141/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 278/300 batch 142/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 278/300 batch 143/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 278/300 batch 144/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 278/300 batch 145/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 278/300 batch 146/188  Train Loss: 0.038, Acc: 0.980\n",
      "epoch: 278/300 batch 147/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 278/300 batch 148/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 278/300 batch 149/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 278/300 batch 150/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 278/300 batch 151/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 278/300 batch 152/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 278/300 batch 153/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 278/300 batch 154/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 278/300 batch 155/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 278/300 batch 156/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 278/300 batch 157/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 278/300 batch 158/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 278/300 batch 159/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 278/300 batch 160/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 278/300 batch 161/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 278/300 batch 162/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 278/300 batch 163/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 278/300 batch 164/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 278/300 batch 165/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 278/300 batch 166/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 278/300 batch 167/188  Train Loss: 0.064, Acc: 0.992\n",
      "epoch: 278/300 batch 168/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 278/300 batch 169/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 278/300 batch 170/188  Train Loss: 0.038, Acc: 0.980\n",
      "epoch: 278/300 batch 171/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 278/300 batch 172/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 278/300 batch 173/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 278/300 batch 174/188  Train Loss: 0.044, Acc: 0.980\n",
      "epoch: 278/300 batch 175/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 278/300 batch 176/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 278/300 batch 177/188  Train Loss: 0.066, Acc: 0.988\n",
      "epoch: 278/300 batch 178/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 278/300 batch 179/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 278/300 batch 180/188  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 278/300 batch 181/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 278/300 batch 182/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 278/300 batch 183/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 278/300 batch 184/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 278/300 batch 185/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 278/300 batch 186/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 278/300 batch 187/188  Train Loss: 0.033, Acc: 0.992\n",
      "Train Loss: 0.032567, Acc: 0.993\n",
      "Val Loss: 0.057475, Acc: 0.983\n",
      "epoch: 279/300 batch   0/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 279/300 batch   1/188  Train Loss: 0.068, Acc: 0.984\n",
      "epoch: 279/300 batch   2/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 279/300 batch   3/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 279/300 batch   4/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 279/300 batch   5/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 279/300 batch   6/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 279/300 batch   7/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 279/300 batch   8/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 279/300 batch   9/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 279/300 batch  10/188  Train Loss: 0.034, Acc: 0.984\n",
      "epoch: 279/300 batch  11/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 279/300 batch  12/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 279/300 batch  13/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 279/300 batch  14/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 279/300 batch  15/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 279/300 batch  16/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 279/300 batch  17/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 279/300 batch  18/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 279/300 batch  19/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 279/300 batch  20/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 279/300 batch  21/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 279/300 batch  22/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 279/300 batch  23/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 279/300 batch  24/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 279/300 batch  25/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 279/300 batch  26/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 279/300 batch  27/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 279/300 batch  28/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 279/300 batch  29/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 279/300 batch  30/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 279/300 batch  31/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 279/300 batch  32/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 279/300 batch  33/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 279/300 batch  34/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 279/300 batch  35/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 279/300 batch  36/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 279/300 batch  37/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 279/300 batch  38/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 279/300 batch  39/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 279/300 batch  40/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 279/300 batch  41/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 279/300 batch  42/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 279/300 batch  43/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 279/300 batch  44/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 279/300 batch  45/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 279/300 batch  46/188  Train Loss: 0.054, Acc: 0.996\n",
      "epoch: 279/300 batch  47/188  Train Loss: 0.036, Acc: 1.000\n",
      "epoch: 279/300 batch  48/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 279/300 batch  49/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 279/300 batch  50/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 279/300 batch  51/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 279/300 batch  52/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 279/300 batch  53/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 279/300 batch  54/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 279/300 batch  55/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 279/300 batch  56/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 279/300 batch  57/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 279/300 batch  58/188  Train Loss: 0.048, Acc: 0.977\n",
      "epoch: 279/300 batch  59/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 279/300 batch  60/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 279/300 batch  61/188  Train Loss: 0.050, Acc: 0.996\n",
      "epoch: 279/300 batch  62/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 279/300 batch  63/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 279/300 batch  64/188  Train Loss: 0.033, Acc: 1.000\n",
      "epoch: 279/300 batch  65/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 279/300 batch  66/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 279/300 batch  67/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 279/300 batch  68/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 279/300 batch  69/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 279/300 batch  70/188  Train Loss: 0.062, Acc: 0.980\n",
      "epoch: 279/300 batch  71/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 279/300 batch  72/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 279/300 batch  73/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 279/300 batch  74/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 279/300 batch  75/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 279/300 batch  76/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 279/300 batch  77/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 279/300 batch  78/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 279/300 batch  79/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 279/300 batch  80/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 279/300 batch  81/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 279/300 batch  82/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 279/300 batch  83/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 279/300 batch  84/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 279/300 batch  85/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 279/300 batch  86/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 279/300 batch  87/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 279/300 batch  88/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 279/300 batch  89/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 279/300 batch  90/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 279/300 batch  91/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 279/300 batch  92/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 279/300 batch  93/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 279/300 batch  94/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 279/300 batch  95/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 279/300 batch  96/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 279/300 batch  97/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 279/300 batch  98/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 279/300 batch  99/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 279/300 batch 100/188  Train Loss: 0.038, Acc: 0.980\n",
      "epoch: 279/300 batch 101/188  Train Loss: 0.042, Acc: 0.980\n",
      "epoch: 279/300 batch 102/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 279/300 batch 103/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 279/300 batch 104/188  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 279/300 batch 105/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 279/300 batch 106/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 279/300 batch 107/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 279/300 batch 108/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 279/300 batch 109/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 279/300 batch 110/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 279/300 batch 111/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 279/300 batch 112/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 279/300 batch 113/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 279/300 batch 114/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 279/300 batch 115/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 279/300 batch 116/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 279/300 batch 117/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 279/300 batch 118/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 279/300 batch 119/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 279/300 batch 120/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 279/300 batch 121/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 279/300 batch 122/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 279/300 batch 123/188  Train Loss: 0.027, Acc: 0.988\n",
      "epoch: 279/300 batch 124/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 279/300 batch 125/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 279/300 batch 126/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 279/300 batch 127/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 279/300 batch 128/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 279/300 batch 129/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 279/300 batch 130/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 279/300 batch 131/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 279/300 batch 132/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 279/300 batch 133/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 279/300 batch 134/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 279/300 batch 135/188  Train Loss: 0.042, Acc: 0.996\n",
      "epoch: 279/300 batch 136/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 279/300 batch 137/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 279/300 batch 138/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 279/300 batch 139/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 279/300 batch 140/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 279/300 batch 141/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 279/300 batch 142/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 279/300 batch 143/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 279/300 batch 144/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 279/300 batch 145/188  Train Loss: 0.056, Acc: 0.980\n",
      "epoch: 279/300 batch 146/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 279/300 batch 147/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 279/300 batch 148/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 279/300 batch 149/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 279/300 batch 150/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 279/300 batch 151/188  Train Loss: 0.057, Acc: 0.988\n",
      "epoch: 279/300 batch 152/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 279/300 batch 153/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 279/300 batch 154/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 279/300 batch 155/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 279/300 batch 156/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 279/300 batch 157/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 279/300 batch 158/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 279/300 batch 159/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 279/300 batch 160/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 279/300 batch 161/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 279/300 batch 162/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 279/300 batch 163/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 279/300 batch 164/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 279/300 batch 165/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 279/300 batch 166/188  Train Loss: 0.053, Acc: 0.980\n",
      "epoch: 279/300 batch 167/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 279/300 batch 168/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 279/300 batch 169/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 279/300 batch 170/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 279/300 batch 171/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 279/300 batch 172/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 279/300 batch 173/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 279/300 batch 174/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 279/300 batch 175/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 279/300 batch 176/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 279/300 batch 177/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 279/300 batch 178/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 279/300 batch 179/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 279/300 batch 180/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 279/300 batch 181/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 279/300 batch 182/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 279/300 batch 183/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 279/300 batch 184/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 279/300 batch 185/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 279/300 batch 186/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 279/300 batch 187/188  Train Loss: 0.033, Acc: 0.984\n",
      "Train Loss: 0.032560, Acc: 0.993\n",
      "Val Loss: 0.057600, Acc: 0.983\n",
      "epoch: 280/300 batch   0/188  Train Loss: 0.048, Acc: 0.973\n",
      "epoch: 280/300 batch   1/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 280/300 batch   2/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 280/300 batch   3/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 280/300 batch   4/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 280/300 batch   5/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 280/300 batch   6/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 280/300 batch   7/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 280/300 batch   8/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 280/300 batch   9/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 280/300 batch  10/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 280/300 batch  11/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 280/300 batch  12/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 280/300 batch  13/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 280/300 batch  14/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 280/300 batch  15/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 280/300 batch  16/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 280/300 batch  17/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 280/300 batch  18/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 280/300 batch  19/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 280/300 batch  20/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 280/300 batch  21/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 280/300 batch  22/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 280/300 batch  23/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 280/300 batch  24/188  Train Loss: 0.052, Acc: 0.992\n",
      "epoch: 280/300 batch  25/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 280/300 batch  26/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 280/300 batch  27/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 280/300 batch  28/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 280/300 batch  29/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 280/300 batch  30/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 280/300 batch  31/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 280/300 batch  32/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 280/300 batch  33/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 280/300 batch  34/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 280/300 batch  35/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 280/300 batch  36/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 280/300 batch  37/188  Train Loss: 0.033, Acc: 0.984\n",
      "epoch: 280/300 batch  38/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 280/300 batch  39/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 280/300 batch  40/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 280/300 batch  41/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 280/300 batch  42/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 280/300 batch  43/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 280/300 batch  44/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 280/300 batch  45/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 280/300 batch  46/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 280/300 batch  47/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 280/300 batch  48/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 280/300 batch  49/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 280/300 batch  50/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 280/300 batch  51/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 280/300 batch  52/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 280/300 batch  53/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 280/300 batch  54/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 280/300 batch  55/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 280/300 batch  56/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 280/300 batch  57/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 280/300 batch  58/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 280/300 batch  59/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 280/300 batch  60/188  Train Loss: 0.053, Acc: 0.980\n",
      "epoch: 280/300 batch  61/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 280/300 batch  62/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 280/300 batch  63/188  Train Loss: 0.064, Acc: 0.980\n",
      "epoch: 280/300 batch  64/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 280/300 batch  65/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 280/300 batch  66/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 280/300 batch  67/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 280/300 batch  68/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 280/300 batch  69/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 280/300 batch  70/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 280/300 batch  71/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 280/300 batch  72/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 280/300 batch  73/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 280/300 batch  74/188  Train Loss: 0.026, Acc: 0.988\n",
      "epoch: 280/300 batch  75/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 280/300 batch  76/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 280/300 batch  77/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 280/300 batch  78/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 280/300 batch  79/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 280/300 batch  80/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 280/300 batch  81/188  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 280/300 batch  82/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 280/300 batch  83/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 280/300 batch  84/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 280/300 batch  85/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 280/300 batch  86/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 280/300 batch  87/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 280/300 batch  88/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 280/300 batch  89/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 280/300 batch  90/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 280/300 batch  91/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 280/300 batch  92/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 280/300 batch  93/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 280/300 batch  94/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 280/300 batch  95/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 280/300 batch  96/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 280/300 batch  97/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 280/300 batch  98/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 280/300 batch  99/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 280/300 batch 100/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 280/300 batch 101/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 280/300 batch 102/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 280/300 batch 103/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 280/300 batch 104/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 280/300 batch 105/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 280/300 batch 106/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 280/300 batch 107/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 280/300 batch 108/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 280/300 batch 109/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 280/300 batch 110/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 280/300 batch 111/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 280/300 batch 112/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 280/300 batch 113/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 280/300 batch 114/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 280/300 batch 115/188  Train Loss: 0.013, Acc: 0.996\n",
      "epoch: 280/300 batch 116/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 280/300 batch 117/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 280/300 batch 118/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 280/300 batch 119/188  Train Loss: 0.046, Acc: 0.980\n",
      "epoch: 280/300 batch 120/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 280/300 batch 121/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 280/300 batch 122/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 280/300 batch 123/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 280/300 batch 124/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 280/300 batch 125/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 280/300 batch 126/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 280/300 batch 127/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 280/300 batch 128/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 280/300 batch 129/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 280/300 batch 130/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 280/300 batch 131/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 280/300 batch 132/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 280/300 batch 133/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 280/300 batch 134/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 280/300 batch 135/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 280/300 batch 136/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 280/300 batch 137/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 280/300 batch 138/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 280/300 batch 139/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 280/300 batch 140/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 280/300 batch 141/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 280/300 batch 142/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 280/300 batch 143/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 280/300 batch 144/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 280/300 batch 145/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 280/300 batch 146/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 280/300 batch 147/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 280/300 batch 148/188  Train Loss: 0.059, Acc: 0.973\n",
      "epoch: 280/300 batch 149/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 280/300 batch 150/188  Train Loss: 0.076, Acc: 0.988\n",
      "epoch: 280/300 batch 151/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 280/300 batch 152/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 280/300 batch 153/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 280/300 batch 154/188  Train Loss: 0.032, Acc: 0.984\n",
      "epoch: 280/300 batch 155/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 280/300 batch 156/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 280/300 batch 157/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 280/300 batch 158/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 280/300 batch 159/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 280/300 batch 160/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 280/300 batch 161/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 280/300 batch 162/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 280/300 batch 163/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 280/300 batch 164/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 280/300 batch 165/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 280/300 batch 166/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 280/300 batch 167/188  Train Loss: 0.050, Acc: 0.980\n",
      "epoch: 280/300 batch 168/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 280/300 batch 169/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 280/300 batch 170/188  Train Loss: 0.032, Acc: 0.984\n",
      "epoch: 280/300 batch 171/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 280/300 batch 172/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 280/300 batch 173/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 280/300 batch 174/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 280/300 batch 175/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 280/300 batch 176/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 280/300 batch 177/188  Train Loss: 0.045, Acc: 0.980\n",
      "epoch: 280/300 batch 178/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 280/300 batch 179/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 280/300 batch 180/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 280/300 batch 181/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 280/300 batch 182/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 280/300 batch 183/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 280/300 batch 184/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 280/300 batch 185/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 280/300 batch 186/188  Train Loss: 0.032, Acc: 1.000\n",
      "epoch: 280/300 batch 187/188  Train Loss: 0.080, Acc: 0.961\n",
      "Train Loss: 0.032686, Acc: 0.993\n",
      "Val Loss: 0.057323, Acc: 0.984\n",
      "epoch: 281/300 batch   0/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 281/300 batch   1/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 281/300 batch   2/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 281/300 batch   3/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 281/300 batch   4/188  Train Loss: 0.067, Acc: 0.988\n",
      "epoch: 281/300 batch   5/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 281/300 batch   6/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 281/300 batch   7/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 281/300 batch   8/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 281/300 batch   9/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 281/300 batch  10/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 281/300 batch  11/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 281/300 batch  12/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 281/300 batch  13/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 281/300 batch  14/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 281/300 batch  15/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 281/300 batch  16/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 281/300 batch  17/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 281/300 batch  18/188  Train Loss: 0.026, Acc: 0.988\n",
      "epoch: 281/300 batch  19/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 281/300 batch  20/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 281/300 batch  21/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 281/300 batch  22/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 281/300 batch  23/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 281/300 batch  24/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 281/300 batch  25/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 281/300 batch  26/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 281/300 batch  27/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 281/300 batch  28/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 281/300 batch  29/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 281/300 batch  30/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 281/300 batch  31/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 281/300 batch  32/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 281/300 batch  33/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 281/300 batch  34/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 281/300 batch  35/188  Train Loss: 0.015, Acc: 0.996\n",
      "epoch: 281/300 batch  36/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 281/300 batch  37/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 281/300 batch  38/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 281/300 batch  39/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 281/300 batch  40/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 281/300 batch  41/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 281/300 batch  42/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 281/300 batch  43/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 281/300 batch  44/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 281/300 batch  45/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 281/300 batch  46/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 281/300 batch  47/188  Train Loss: 0.052, Acc: 0.980\n",
      "epoch: 281/300 batch  48/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 281/300 batch  49/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 281/300 batch  50/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 281/300 batch  51/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 281/300 batch  52/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 281/300 batch  53/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 281/300 batch  54/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 281/300 batch  55/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 281/300 batch  56/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 281/300 batch  57/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 281/300 batch  58/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 281/300 batch  59/188  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 281/300 batch  60/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 281/300 batch  61/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 281/300 batch  62/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 281/300 batch  63/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 281/300 batch  64/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 281/300 batch  65/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 281/300 batch  66/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 281/300 batch  67/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 281/300 batch  68/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 281/300 batch  69/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 281/300 batch  70/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 281/300 batch  71/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 281/300 batch  72/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 281/300 batch  73/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 281/300 batch  74/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 281/300 batch  75/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 281/300 batch  76/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 281/300 batch  77/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 281/300 batch  78/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 281/300 batch  79/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 281/300 batch  80/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 281/300 batch  81/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 281/300 batch  82/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 281/300 batch  83/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 281/300 batch  84/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 281/300 batch  85/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 281/300 batch  86/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 281/300 batch  87/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 281/300 batch  88/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 281/300 batch  89/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 281/300 batch  90/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 281/300 batch  91/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 281/300 batch  92/188  Train Loss: 0.067, Acc: 0.984\n",
      "epoch: 281/300 batch  93/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 281/300 batch  94/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 281/300 batch  95/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 281/300 batch  96/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 281/300 batch  97/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 281/300 batch  98/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 281/300 batch  99/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 281/300 batch 100/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 281/300 batch 101/188  Train Loss: 0.058, Acc: 0.988\n",
      "epoch: 281/300 batch 102/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 281/300 batch 103/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 281/300 batch 104/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 281/300 batch 105/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 281/300 batch 106/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 281/300 batch 107/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 281/300 batch 108/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 281/300 batch 109/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 281/300 batch 110/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 281/300 batch 111/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 281/300 batch 112/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 281/300 batch 113/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 281/300 batch 114/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 281/300 batch 115/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 281/300 batch 116/188  Train Loss: 0.059, Acc: 0.988\n",
      "epoch: 281/300 batch 117/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 281/300 batch 118/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 281/300 batch 119/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 281/300 batch 120/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 281/300 batch 121/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 281/300 batch 122/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 281/300 batch 123/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 281/300 batch 124/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 281/300 batch 125/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 281/300 batch 126/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 281/300 batch 127/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 281/300 batch 128/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 281/300 batch 129/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 281/300 batch 130/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 281/300 batch 131/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 281/300 batch 132/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 281/300 batch 133/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 281/300 batch 134/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 281/300 batch 135/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 281/300 batch 136/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 281/300 batch 137/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 281/300 batch 138/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 281/300 batch 139/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 281/300 batch 140/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 281/300 batch 141/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 281/300 batch 142/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 281/300 batch 143/188  Train Loss: 0.048, Acc: 0.996\n",
      "epoch: 281/300 batch 144/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 281/300 batch 145/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 281/300 batch 146/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 281/300 batch 147/188  Train Loss: 0.046, Acc: 0.996\n",
      "epoch: 281/300 batch 148/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 281/300 batch 149/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 281/300 batch 150/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 281/300 batch 151/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 281/300 batch 152/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 281/300 batch 153/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 281/300 batch 154/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 281/300 batch 155/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 281/300 batch 156/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 281/300 batch 157/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 281/300 batch 158/188  Train Loss: 0.046, Acc: 0.980\n",
      "epoch: 281/300 batch 159/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 281/300 batch 160/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 281/300 batch 161/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 281/300 batch 162/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 281/300 batch 163/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 281/300 batch 164/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 281/300 batch 165/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 281/300 batch 166/188  Train Loss: 0.052, Acc: 0.973\n",
      "epoch: 281/300 batch 167/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 281/300 batch 168/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 281/300 batch 169/188  Train Loss: 0.050, Acc: 0.977\n",
      "epoch: 281/300 batch 170/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 281/300 batch 171/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 281/300 batch 172/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 281/300 batch 173/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 281/300 batch 174/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 281/300 batch 175/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 281/300 batch 176/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 281/300 batch 177/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 281/300 batch 178/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 281/300 batch 179/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 281/300 batch 180/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 281/300 batch 181/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 281/300 batch 182/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 281/300 batch 183/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 281/300 batch 184/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 281/300 batch 185/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 281/300 batch 186/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 281/300 batch 187/188  Train Loss: 0.025, Acc: 0.992\n",
      "Train Loss: 0.032495, Acc: 0.993\n",
      "Val Loss: 0.057342, Acc: 0.983\n",
      "epoch: 282/300 batch   0/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 282/300 batch   1/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 282/300 batch   2/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 282/300 batch   3/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 282/300 batch   4/188  Train Loss: 0.047, Acc: 0.980\n",
      "epoch: 282/300 batch   5/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 282/300 batch   6/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 282/300 batch   7/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 282/300 batch   8/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 282/300 batch   9/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 282/300 batch  10/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 282/300 batch  11/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 282/300 batch  12/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 282/300 batch  13/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 282/300 batch  14/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 282/300 batch  15/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 282/300 batch  16/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 282/300 batch  17/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 282/300 batch  18/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 282/300 batch  19/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 282/300 batch  20/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 282/300 batch  21/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 282/300 batch  22/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 282/300 batch  23/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 282/300 batch  24/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 282/300 batch  25/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 282/300 batch  26/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 282/300 batch  27/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 282/300 batch  28/188  Train Loss: 0.060, Acc: 0.977\n",
      "epoch: 282/300 batch  29/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 282/300 batch  30/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 282/300 batch  31/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 282/300 batch  32/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 282/300 batch  33/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 282/300 batch  34/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 282/300 batch  35/188  Train Loss: 0.036, Acc: 1.000\n",
      "epoch: 282/300 batch  36/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 282/300 batch  37/188  Train Loss: 0.054, Acc: 0.992\n",
      "epoch: 282/300 batch  38/188  Train Loss: 0.042, Acc: 0.996\n",
      "epoch: 282/300 batch  39/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 282/300 batch  40/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 282/300 batch  41/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 282/300 batch  42/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 282/300 batch  43/188  Train Loss: 0.069, Acc: 0.988\n",
      "epoch: 282/300 batch  44/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 282/300 batch  45/188  Train Loss: 0.015, Acc: 0.996\n",
      "epoch: 282/300 batch  46/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 282/300 batch  47/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 282/300 batch  48/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 282/300 batch  49/188  Train Loss: 0.026, Acc: 0.988\n",
      "epoch: 282/300 batch  50/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 282/300 batch  51/188  Train Loss: 0.058, Acc: 0.988\n",
      "epoch: 282/300 batch  52/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 282/300 batch  53/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 282/300 batch  54/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 282/300 batch  55/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 282/300 batch  56/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 282/300 batch  57/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 282/300 batch  58/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 282/300 batch  59/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 282/300 batch  60/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 282/300 batch  61/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 282/300 batch  62/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 282/300 batch  63/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 282/300 batch  64/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 282/300 batch  65/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 282/300 batch  66/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 282/300 batch  67/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 282/300 batch  68/188  Train Loss: 0.054, Acc: 0.980\n",
      "epoch: 282/300 batch  69/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 282/300 batch  70/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 282/300 batch  71/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 282/300 batch  72/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 282/300 batch  73/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 282/300 batch  74/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 282/300 batch  75/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 282/300 batch  76/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 282/300 batch  77/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 282/300 batch  78/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 282/300 batch  79/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 282/300 batch  80/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 282/300 batch  81/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 282/300 batch  82/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 282/300 batch  83/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 282/300 batch  84/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 282/300 batch  85/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 282/300 batch  86/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 282/300 batch  87/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 282/300 batch  88/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 282/300 batch  89/188  Train Loss: 0.045, Acc: 0.980\n",
      "epoch: 282/300 batch  90/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 282/300 batch  91/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 282/300 batch  92/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 282/300 batch  93/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 282/300 batch  94/188  Train Loss: 0.081, Acc: 0.984\n",
      "epoch: 282/300 batch  95/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 282/300 batch  96/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 282/300 batch  97/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 282/300 batch  98/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 282/300 batch  99/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 282/300 batch 100/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 282/300 batch 101/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 282/300 batch 102/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 282/300 batch 103/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 282/300 batch 104/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 282/300 batch 105/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 282/300 batch 106/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 282/300 batch 107/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 282/300 batch 108/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 282/300 batch 109/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 282/300 batch 110/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 282/300 batch 111/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 282/300 batch 112/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 282/300 batch 113/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 282/300 batch 114/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 282/300 batch 115/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 282/300 batch 116/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 282/300 batch 117/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 282/300 batch 118/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 282/300 batch 119/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 282/300 batch 120/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 282/300 batch 121/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 282/300 batch 122/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 282/300 batch 123/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 282/300 batch 124/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 282/300 batch 125/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 282/300 batch 126/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 282/300 batch 127/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 282/300 batch 128/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 282/300 batch 129/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 282/300 batch 130/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 282/300 batch 131/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 282/300 batch 132/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 282/300 batch 133/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 282/300 batch 134/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 282/300 batch 135/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 282/300 batch 136/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 282/300 batch 137/188  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 282/300 batch 138/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 282/300 batch 139/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 282/300 batch 140/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 282/300 batch 141/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 282/300 batch 142/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 282/300 batch 143/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 282/300 batch 144/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 282/300 batch 145/188  Train Loss: 0.023, Acc: 0.988\n",
      "epoch: 282/300 batch 146/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 282/300 batch 147/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 282/300 batch 148/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 282/300 batch 149/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 282/300 batch 150/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 282/300 batch 151/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 282/300 batch 152/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 282/300 batch 153/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 282/300 batch 154/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 282/300 batch 155/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 282/300 batch 156/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 282/300 batch 157/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 282/300 batch 158/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 282/300 batch 159/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 282/300 batch 160/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 282/300 batch 161/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 282/300 batch 162/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 282/300 batch 163/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 282/300 batch 164/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 282/300 batch 165/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 282/300 batch 166/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 282/300 batch 167/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 282/300 batch 168/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 282/300 batch 169/188  Train Loss: 0.049, Acc: 0.980\n",
      "epoch: 282/300 batch 170/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 282/300 batch 171/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 282/300 batch 172/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 282/300 batch 173/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 282/300 batch 174/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 282/300 batch 175/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 282/300 batch 176/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 282/300 batch 177/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 282/300 batch 178/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 282/300 batch 179/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 282/300 batch 180/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 282/300 batch 181/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 282/300 batch 182/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 282/300 batch 183/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 282/300 batch 184/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 282/300 batch 185/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 282/300 batch 186/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 282/300 batch 187/188  Train Loss: 0.020, Acc: 1.000\n",
      "Train Loss: 0.032524, Acc: 0.993\n",
      "Val Loss: 0.057544, Acc: 0.984\n",
      "epoch: 283/300 batch   0/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 283/300 batch   1/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 283/300 batch   2/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 283/300 batch   3/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 283/300 batch   4/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 283/300 batch   5/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 283/300 batch   6/188  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 283/300 batch   7/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 283/300 batch   8/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 283/300 batch   9/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 283/300 batch  10/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 283/300 batch  11/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 283/300 batch  12/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 283/300 batch  13/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 283/300 batch  14/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 283/300 batch  15/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 283/300 batch  16/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 283/300 batch  17/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 283/300 batch  18/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 283/300 batch  19/188  Train Loss: 0.031, Acc: 0.984\n",
      "epoch: 283/300 batch  20/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 283/300 batch  21/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 283/300 batch  22/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 283/300 batch  23/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 283/300 batch  24/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 283/300 batch  25/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 283/300 batch  26/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 283/300 batch  27/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 283/300 batch  28/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 283/300 batch  29/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 283/300 batch  30/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 283/300 batch  31/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 283/300 batch  32/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 283/300 batch  33/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 283/300 batch  34/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 283/300 batch  35/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 283/300 batch  36/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 283/300 batch  37/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 283/300 batch  38/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 283/300 batch  39/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 283/300 batch  40/188  Train Loss: 0.065, Acc: 0.988\n",
      "epoch: 283/300 batch  41/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 283/300 batch  42/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 283/300 batch  43/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 283/300 batch  44/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 283/300 batch  45/188  Train Loss: 0.045, Acc: 0.980\n",
      "epoch: 283/300 batch  46/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 283/300 batch  47/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 283/300 batch  48/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 283/300 batch  49/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 283/300 batch  50/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 283/300 batch  51/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 283/300 batch  52/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 283/300 batch  53/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 283/300 batch  54/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 283/300 batch  55/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 283/300 batch  56/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 283/300 batch  57/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 283/300 batch  58/188  Train Loss: 0.064, Acc: 0.996\n",
      "epoch: 283/300 batch  59/188  Train Loss: 0.062, Acc: 0.988\n",
      "epoch: 283/300 batch  60/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 283/300 batch  61/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 283/300 batch  62/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 283/300 batch  63/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 283/300 batch  64/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 283/300 batch  65/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 283/300 batch  66/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 283/300 batch  67/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 283/300 batch  68/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 283/300 batch  69/188  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 283/300 batch  70/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 283/300 batch  71/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 283/300 batch  72/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 283/300 batch  73/188  Train Loss: 0.089, Acc: 0.961\n",
      "epoch: 283/300 batch  74/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 283/300 batch  75/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 283/300 batch  76/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 283/300 batch  77/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 283/300 batch  78/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 283/300 batch  79/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 283/300 batch  80/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 283/300 batch  81/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 283/300 batch  82/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 283/300 batch  83/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 283/300 batch  84/188  Train Loss: 0.022, Acc: 0.988\n",
      "epoch: 283/300 batch  85/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 283/300 batch  86/188  Train Loss: 0.066, Acc: 0.988\n",
      "epoch: 283/300 batch  87/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 283/300 batch  88/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 283/300 batch  89/188  Train Loss: 0.045, Acc: 0.980\n",
      "epoch: 283/300 batch  90/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 283/300 batch  91/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 283/300 batch  92/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 283/300 batch  93/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 283/300 batch  94/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 283/300 batch  95/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 283/300 batch  96/188  Train Loss: 0.060, Acc: 0.988\n",
      "epoch: 283/300 batch  97/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 283/300 batch  98/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 283/300 batch  99/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 283/300 batch 100/188  Train Loss: 0.016, Acc: 0.996\n",
      "epoch: 283/300 batch 101/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 283/300 batch 102/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 283/300 batch 103/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 283/300 batch 104/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 283/300 batch 105/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 283/300 batch 106/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 283/300 batch 107/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 283/300 batch 108/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 283/300 batch 109/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 283/300 batch 110/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 283/300 batch 111/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 283/300 batch 112/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 283/300 batch 113/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 283/300 batch 114/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 283/300 batch 115/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 283/300 batch 116/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 283/300 batch 117/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 283/300 batch 118/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 283/300 batch 119/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 283/300 batch 120/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 283/300 batch 121/188  Train Loss: 0.026, Acc: 0.988\n",
      "epoch: 283/300 batch 122/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 283/300 batch 123/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 283/300 batch 124/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 283/300 batch 125/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 283/300 batch 126/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 283/300 batch 127/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 283/300 batch 128/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 283/300 batch 129/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 283/300 batch 130/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 283/300 batch 131/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 283/300 batch 132/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 283/300 batch 133/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 283/300 batch 134/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 283/300 batch 135/188  Train Loss: 0.044, Acc: 0.996\n",
      "epoch: 283/300 batch 136/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 283/300 batch 137/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 283/300 batch 138/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 283/300 batch 139/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 283/300 batch 140/188  Train Loss: 0.043, Acc: 0.996\n",
      "epoch: 283/300 batch 141/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 283/300 batch 142/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 283/300 batch 143/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 283/300 batch 144/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 283/300 batch 145/188  Train Loss: 0.036, Acc: 0.980\n",
      "epoch: 283/300 batch 146/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 283/300 batch 147/188  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 283/300 batch 148/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 283/300 batch 149/188  Train Loss: 0.016, Acc: 0.996\n",
      "epoch: 283/300 batch 150/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 283/300 batch 151/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 283/300 batch 152/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 283/300 batch 153/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 283/300 batch 154/188  Train Loss: 0.038, Acc: 0.980\n",
      "epoch: 283/300 batch 155/188  Train Loss: 0.026, Acc: 0.988\n",
      "epoch: 283/300 batch 156/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 283/300 batch 157/188  Train Loss: 0.045, Acc: 0.980\n",
      "epoch: 283/300 batch 158/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 283/300 batch 159/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 283/300 batch 160/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 283/300 batch 161/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 283/300 batch 162/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 283/300 batch 163/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 283/300 batch 164/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 283/300 batch 165/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 283/300 batch 166/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 283/300 batch 167/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 283/300 batch 168/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 283/300 batch 169/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 283/300 batch 170/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 283/300 batch 171/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 283/300 batch 172/188  Train Loss: 0.063, Acc: 0.977\n",
      "epoch: 283/300 batch 173/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 283/300 batch 174/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 283/300 batch 175/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 283/300 batch 176/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 283/300 batch 177/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 283/300 batch 178/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 283/300 batch 179/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 283/300 batch 180/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 283/300 batch 181/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 283/300 batch 182/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 283/300 batch 183/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 283/300 batch 184/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 283/300 batch 185/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 283/300 batch 186/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 283/300 batch 187/188  Train Loss: 0.035, Acc: 0.984\n",
      "Train Loss: 0.032538, Acc: 0.993\n",
      "Val Loss: 0.057298, Acc: 0.983\n",
      "epoch: 284/300 batch   0/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 284/300 batch   1/188  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 284/300 batch   2/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 284/300 batch   3/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 284/300 batch   4/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 284/300 batch   5/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 284/300 batch   6/188  Train Loss: 0.042, Acc: 0.996\n",
      "epoch: 284/300 batch   7/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 284/300 batch   8/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 284/300 batch   9/188  Train Loss: 0.033, Acc: 0.984\n",
      "epoch: 284/300 batch  10/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 284/300 batch  11/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 284/300 batch  12/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 284/300 batch  13/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 284/300 batch  14/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 284/300 batch  15/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 284/300 batch  16/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 284/300 batch  17/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 284/300 batch  18/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 284/300 batch  19/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 284/300 batch  20/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 284/300 batch  21/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 284/300 batch  22/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 284/300 batch  23/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 284/300 batch  24/188  Train Loss: 0.054, Acc: 0.980\n",
      "epoch: 284/300 batch  25/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 284/300 batch  26/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 284/300 batch  27/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 284/300 batch  28/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 284/300 batch  29/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 284/300 batch  30/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 284/300 batch  31/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 284/300 batch  32/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 284/300 batch  33/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 284/300 batch  34/188  Train Loss: 0.042, Acc: 0.996\n",
      "epoch: 284/300 batch  35/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 284/300 batch  36/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 284/300 batch  37/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 284/300 batch  38/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 284/300 batch  39/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 284/300 batch  40/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 284/300 batch  41/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 284/300 batch  42/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 284/300 batch  43/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 284/300 batch  44/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 284/300 batch  45/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 284/300 batch  46/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 284/300 batch  47/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 284/300 batch  48/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 284/300 batch  49/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 284/300 batch  50/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 284/300 batch  51/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 284/300 batch  52/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 284/300 batch  53/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 284/300 batch  54/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 284/300 batch  55/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 284/300 batch  56/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 284/300 batch  57/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 284/300 batch  58/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 284/300 batch  59/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 284/300 batch  60/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 284/300 batch  61/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 284/300 batch  62/188  Train Loss: 0.066, Acc: 0.977\n",
      "epoch: 284/300 batch  63/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 284/300 batch  64/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 284/300 batch  65/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 284/300 batch  66/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 284/300 batch  67/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 284/300 batch  68/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 284/300 batch  69/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 284/300 batch  70/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 284/300 batch  71/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 284/300 batch  72/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 284/300 batch  73/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 284/300 batch  74/188  Train Loss: 0.028, Acc: 0.984\n",
      "epoch: 284/300 batch  75/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 284/300 batch  76/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 284/300 batch  77/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 284/300 batch  78/188  Train Loss: 0.047, Acc: 0.980\n",
      "epoch: 284/300 batch  79/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 284/300 batch  80/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 284/300 batch  81/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 284/300 batch  82/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 284/300 batch  83/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 284/300 batch  84/188  Train Loss: 0.050, Acc: 0.980\n",
      "epoch: 284/300 batch  85/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 284/300 batch  86/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 284/300 batch  87/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 284/300 batch  88/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 284/300 batch  89/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 284/300 batch  90/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 284/300 batch  91/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 284/300 batch  92/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 284/300 batch  93/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 284/300 batch  94/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 284/300 batch  95/188  Train Loss: 0.033, Acc: 0.984\n",
      "epoch: 284/300 batch  96/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 284/300 batch  97/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 284/300 batch  98/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 284/300 batch  99/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 284/300 batch 100/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 284/300 batch 101/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 284/300 batch 102/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 284/300 batch 103/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 284/300 batch 104/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 284/300 batch 105/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 284/300 batch 106/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 284/300 batch 107/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 284/300 batch 108/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 284/300 batch 109/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 284/300 batch 110/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 284/300 batch 111/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 284/300 batch 112/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 284/300 batch 113/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 284/300 batch 114/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 284/300 batch 115/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 284/300 batch 116/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 284/300 batch 117/188  Train Loss: 0.042, Acc: 0.996\n",
      "epoch: 284/300 batch 118/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 284/300 batch 119/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 284/300 batch 120/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 284/300 batch 121/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 284/300 batch 122/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 284/300 batch 123/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 284/300 batch 124/188  Train Loss: 0.058, Acc: 0.992\n",
      "epoch: 284/300 batch 125/188  Train Loss: 0.053, Acc: 0.992\n",
      "epoch: 284/300 batch 126/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 284/300 batch 127/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 284/300 batch 128/188  Train Loss: 0.053, Acc: 0.980\n",
      "epoch: 284/300 batch 129/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 284/300 batch 130/188  Train Loss: 0.033, Acc: 1.000\n",
      "epoch: 284/300 batch 131/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 284/300 batch 132/188  Train Loss: 0.052, Acc: 0.977\n",
      "epoch: 284/300 batch 133/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 284/300 batch 134/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 284/300 batch 135/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 284/300 batch 136/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 284/300 batch 137/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 284/300 batch 138/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 284/300 batch 139/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 284/300 batch 140/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 284/300 batch 141/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 284/300 batch 142/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 284/300 batch 143/188  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 284/300 batch 144/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 284/300 batch 145/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 284/300 batch 146/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 284/300 batch 147/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 284/300 batch 148/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 284/300 batch 149/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 284/300 batch 150/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 284/300 batch 151/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 284/300 batch 152/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 284/300 batch 153/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 284/300 batch 154/188  Train Loss: 0.014, Acc: 0.996\n",
      "epoch: 284/300 batch 155/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 284/300 batch 156/188  Train Loss: 0.043, Acc: 0.996\n",
      "epoch: 284/300 batch 157/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 284/300 batch 158/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 284/300 batch 159/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 284/300 batch 160/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 284/300 batch 161/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 284/300 batch 162/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 284/300 batch 163/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 284/300 batch 164/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 284/300 batch 165/188  Train Loss: 0.027, Acc: 0.988\n",
      "epoch: 284/300 batch 166/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 284/300 batch 167/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 284/300 batch 168/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 284/300 batch 169/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 284/300 batch 170/188  Train Loss: 0.041, Acc: 0.980\n",
      "epoch: 284/300 batch 171/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 284/300 batch 172/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 284/300 batch 173/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 284/300 batch 174/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 284/300 batch 175/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 284/300 batch 176/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 284/300 batch 177/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 284/300 batch 178/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 284/300 batch 179/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 284/300 batch 180/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 284/300 batch 181/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 284/300 batch 182/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 284/300 batch 183/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 284/300 batch 184/188  Train Loss: 0.063, Acc: 0.984\n",
      "epoch: 284/300 batch 185/188  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 284/300 batch 186/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 284/300 batch 187/188  Train Loss: 0.028, Acc: 1.000\n",
      "Train Loss: 0.032444, Acc: 0.993\n",
      "Val Loss: 0.057307, Acc: 0.984\n",
      "epoch: 285/300 batch   0/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 285/300 batch   1/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 285/300 batch   2/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 285/300 batch   3/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 285/300 batch   4/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 285/300 batch   5/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 285/300 batch   6/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 285/300 batch   7/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 285/300 batch   8/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 285/300 batch   9/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 285/300 batch  10/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 285/300 batch  11/188  Train Loss: 0.027, Acc: 0.988\n",
      "epoch: 285/300 batch  12/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 285/300 batch  13/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 285/300 batch  14/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 285/300 batch  15/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 285/300 batch  16/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 285/300 batch  17/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 285/300 batch  18/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 285/300 batch  19/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 285/300 batch  20/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 285/300 batch  21/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 285/300 batch  22/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 285/300 batch  23/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 285/300 batch  24/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 285/300 batch  25/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 285/300 batch  26/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 285/300 batch  27/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 285/300 batch  28/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 285/300 batch  29/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 285/300 batch  30/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 285/300 batch  31/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 285/300 batch  32/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 285/300 batch  33/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 285/300 batch  34/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 285/300 batch  35/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 285/300 batch  36/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 285/300 batch  37/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 285/300 batch  38/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 285/300 batch  39/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 285/300 batch  40/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 285/300 batch  41/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 285/300 batch  42/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 285/300 batch  43/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 285/300 batch  44/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 285/300 batch  45/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 285/300 batch  46/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 285/300 batch  47/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 285/300 batch  48/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 285/300 batch  49/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 285/300 batch  50/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 285/300 batch  51/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 285/300 batch  52/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 285/300 batch  53/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 285/300 batch  54/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 285/300 batch  55/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 285/300 batch  56/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 285/300 batch  57/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 285/300 batch  58/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 285/300 batch  59/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 285/300 batch  60/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 285/300 batch  61/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 285/300 batch  62/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 285/300 batch  63/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 285/300 batch  64/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 285/300 batch  65/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 285/300 batch  66/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 285/300 batch  67/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 285/300 batch  68/188  Train Loss: 0.057, Acc: 0.980\n",
      "epoch: 285/300 batch  69/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 285/300 batch  70/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 285/300 batch  71/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 285/300 batch  72/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 285/300 batch  73/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 285/300 batch  74/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 285/300 batch  75/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 285/300 batch  76/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 285/300 batch  77/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 285/300 batch  78/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 285/300 batch  79/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 285/300 batch  80/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 285/300 batch  81/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 285/300 batch  82/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 285/300 batch  83/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 285/300 batch  84/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 285/300 batch  85/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 285/300 batch  86/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 285/300 batch  87/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 285/300 batch  88/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 285/300 batch  89/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 285/300 batch  90/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 285/300 batch  91/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 285/300 batch  92/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 285/300 batch  93/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 285/300 batch  94/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 285/300 batch  95/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 285/300 batch  96/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 285/300 batch  97/188  Train Loss: 0.028, Acc: 0.984\n",
      "epoch: 285/300 batch  98/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 285/300 batch  99/188  Train Loss: 0.067, Acc: 0.984\n",
      "epoch: 285/300 batch 100/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 285/300 batch 101/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 285/300 batch 102/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 285/300 batch 103/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 285/300 batch 104/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 285/300 batch 105/188  Train Loss: 0.066, Acc: 0.980\n",
      "epoch: 285/300 batch 106/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 285/300 batch 107/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 285/300 batch 108/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 285/300 batch 109/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 285/300 batch 110/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 285/300 batch 111/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 285/300 batch 112/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 285/300 batch 113/188  Train Loss: 0.061, Acc: 0.980\n",
      "epoch: 285/300 batch 114/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 285/300 batch 115/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 285/300 batch 116/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 285/300 batch 117/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 285/300 batch 118/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 285/300 batch 119/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 285/300 batch 120/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 285/300 batch 121/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 285/300 batch 122/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 285/300 batch 123/188  Train Loss: 0.052, Acc: 0.992\n",
      "epoch: 285/300 batch 124/188  Train Loss: 0.044, Acc: 0.980\n",
      "epoch: 285/300 batch 125/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 285/300 batch 126/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 285/300 batch 127/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 285/300 batch 128/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 285/300 batch 129/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 285/300 batch 130/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 285/300 batch 131/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 285/300 batch 132/188  Train Loss: 0.016, Acc: 0.996\n",
      "epoch: 285/300 batch 133/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 285/300 batch 134/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 285/300 batch 135/188  Train Loss: 0.080, Acc: 0.984\n",
      "epoch: 285/300 batch 136/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 285/300 batch 137/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 285/300 batch 138/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 285/300 batch 139/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 285/300 batch 140/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 285/300 batch 141/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 285/300 batch 142/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 285/300 batch 143/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 285/300 batch 144/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 285/300 batch 145/188  Train Loss: 0.062, Acc: 0.984\n",
      "epoch: 285/300 batch 146/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 285/300 batch 147/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 285/300 batch 148/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 285/300 batch 149/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 285/300 batch 150/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 285/300 batch 151/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 285/300 batch 152/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 285/300 batch 153/188  Train Loss: 0.027, Acc: 0.988\n",
      "epoch: 285/300 batch 154/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 285/300 batch 155/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 285/300 batch 156/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 285/300 batch 157/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 285/300 batch 158/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 285/300 batch 159/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 285/300 batch 160/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 285/300 batch 161/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 285/300 batch 162/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 285/300 batch 163/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 285/300 batch 164/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 285/300 batch 165/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 285/300 batch 166/188  Train Loss: 0.033, Acc: 0.984\n",
      "epoch: 285/300 batch 167/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 285/300 batch 168/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 285/300 batch 169/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 285/300 batch 170/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 285/300 batch 171/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 285/300 batch 172/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 285/300 batch 173/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 285/300 batch 174/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 285/300 batch 175/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 285/300 batch 176/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 285/300 batch 177/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 285/300 batch 178/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 285/300 batch 179/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 285/300 batch 180/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 285/300 batch 181/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 285/300 batch 182/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 285/300 batch 183/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 285/300 batch 184/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 285/300 batch 185/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 285/300 batch 186/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 285/300 batch 187/188  Train Loss: 0.026, Acc: 1.000\n",
      "Train Loss: 0.032522, Acc: 0.993\n",
      "Val Loss: 0.057410, Acc: 0.984\n",
      "epoch: 286/300 batch   0/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 286/300 batch   1/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 286/300 batch   2/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 286/300 batch   3/188  Train Loss: 0.035, Acc: 0.980\n",
      "epoch: 286/300 batch   4/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 286/300 batch   5/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 286/300 batch   6/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 286/300 batch   7/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 286/300 batch   8/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 286/300 batch   9/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 286/300 batch  10/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 286/300 batch  11/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 286/300 batch  12/188  Train Loss: 0.044, Acc: 0.996\n",
      "epoch: 286/300 batch  13/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 286/300 batch  14/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 286/300 batch  15/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 286/300 batch  16/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 286/300 batch  17/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 286/300 batch  18/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 286/300 batch  19/188  Train Loss: 0.058, Acc: 0.988\n",
      "epoch: 286/300 batch  20/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 286/300 batch  21/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 286/300 batch  22/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 286/300 batch  23/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 286/300 batch  24/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 286/300 batch  25/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 286/300 batch  26/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 286/300 batch  27/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 286/300 batch  28/188  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 286/300 batch  29/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 286/300 batch  30/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 286/300 batch  31/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 286/300 batch  32/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 286/300 batch  33/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 286/300 batch  34/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 286/300 batch  35/188  Train Loss: 0.059, Acc: 0.984\n",
      "epoch: 286/300 batch  36/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 286/300 batch  37/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 286/300 batch  38/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 286/300 batch  39/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 286/300 batch  40/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 286/300 batch  41/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 286/300 batch  42/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 286/300 batch  43/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 286/300 batch  44/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 286/300 batch  45/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 286/300 batch  46/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 286/300 batch  47/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 286/300 batch  48/188  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 286/300 batch  49/188  Train Loss: 0.027, Acc: 0.988\n",
      "epoch: 286/300 batch  50/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 286/300 batch  51/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 286/300 batch  52/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 286/300 batch  53/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 286/300 batch  54/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 286/300 batch  55/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 286/300 batch  56/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 286/300 batch  57/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 286/300 batch  58/188  Train Loss: 0.051, Acc: 0.980\n",
      "epoch: 286/300 batch  59/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 286/300 batch  60/188  Train Loss: 0.027, Acc: 0.988\n",
      "epoch: 286/300 batch  61/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 286/300 batch  62/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 286/300 batch  63/188  Train Loss: 0.049, Acc: 0.980\n",
      "epoch: 286/300 batch  64/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 286/300 batch  65/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 286/300 batch  66/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 286/300 batch  67/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 286/300 batch  68/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 286/300 batch  69/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 286/300 batch  70/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 286/300 batch  71/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 286/300 batch  72/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 286/300 batch  73/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 286/300 batch  74/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 286/300 batch  75/188  Train Loss: 0.062, Acc: 0.977\n",
      "epoch: 286/300 batch  76/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 286/300 batch  77/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 286/300 batch  78/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 286/300 batch  79/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 286/300 batch  80/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 286/300 batch  81/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 286/300 batch  82/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 286/300 batch  83/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 286/300 batch  84/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 286/300 batch  85/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 286/300 batch  86/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 286/300 batch  87/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 286/300 batch  88/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 286/300 batch  89/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 286/300 batch  90/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 286/300 batch  91/188  Train Loss: 0.063, Acc: 0.992\n",
      "epoch: 286/300 batch  92/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 286/300 batch  93/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 286/300 batch  94/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 286/300 batch  95/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 286/300 batch  96/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 286/300 batch  97/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 286/300 batch  98/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 286/300 batch  99/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 286/300 batch 100/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 286/300 batch 101/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 286/300 batch 102/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 286/300 batch 103/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 286/300 batch 104/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 286/300 batch 105/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 286/300 batch 106/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 286/300 batch 107/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 286/300 batch 108/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 286/300 batch 109/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 286/300 batch 110/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 286/300 batch 111/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 286/300 batch 112/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 286/300 batch 113/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 286/300 batch 114/188  Train Loss: 0.053, Acc: 0.992\n",
      "epoch: 286/300 batch 115/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 286/300 batch 116/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 286/300 batch 117/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 286/300 batch 118/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 286/300 batch 119/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 286/300 batch 120/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 286/300 batch 121/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 286/300 batch 122/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 286/300 batch 123/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 286/300 batch 124/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 286/300 batch 125/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 286/300 batch 126/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 286/300 batch 127/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 286/300 batch 128/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 286/300 batch 129/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 286/300 batch 130/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 286/300 batch 131/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 286/300 batch 132/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 286/300 batch 133/188  Train Loss: 0.053, Acc: 0.980\n",
      "epoch: 286/300 batch 134/188  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 286/300 batch 135/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 286/300 batch 136/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 286/300 batch 137/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 286/300 batch 138/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 286/300 batch 139/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 286/300 batch 140/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 286/300 batch 141/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 286/300 batch 142/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 286/300 batch 143/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 286/300 batch 144/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 286/300 batch 145/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 286/300 batch 146/188  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 286/300 batch 147/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 286/300 batch 148/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 286/300 batch 149/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 286/300 batch 150/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 286/300 batch 151/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 286/300 batch 152/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 286/300 batch 153/188  Train Loss: 0.056, Acc: 0.988\n",
      "epoch: 286/300 batch 154/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 286/300 batch 155/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 286/300 batch 156/188  Train Loss: 0.072, Acc: 0.977\n",
      "epoch: 286/300 batch 157/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 286/300 batch 158/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 286/300 batch 159/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 286/300 batch 160/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 286/300 batch 161/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 286/300 batch 162/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 286/300 batch 163/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 286/300 batch 164/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 286/300 batch 165/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 286/300 batch 166/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 286/300 batch 167/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 286/300 batch 168/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 286/300 batch 169/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 286/300 batch 170/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 286/300 batch 171/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 286/300 batch 172/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 286/300 batch 173/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 286/300 batch 174/188  Train Loss: 0.033, Acc: 0.984\n",
      "epoch: 286/300 batch 175/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 286/300 batch 176/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 286/300 batch 177/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 286/300 batch 178/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 286/300 batch 179/188  Train Loss: 0.032, Acc: 0.984\n",
      "epoch: 286/300 batch 180/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 286/300 batch 181/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 286/300 batch 182/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 286/300 batch 183/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 286/300 batch 184/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 286/300 batch 185/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 286/300 batch 186/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 286/300 batch 187/188  Train Loss: 0.036, Acc: 0.992\n",
      "Train Loss: 0.032524, Acc: 0.993\n",
      "Val Loss: 0.057330, Acc: 0.983\n",
      "epoch: 287/300 batch   0/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 287/300 batch   1/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 287/300 batch   2/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 287/300 batch   3/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 287/300 batch   4/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 287/300 batch   5/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 287/300 batch   6/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 287/300 batch   7/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 287/300 batch   8/188  Train Loss: 0.052, Acc: 0.992\n",
      "epoch: 287/300 batch   9/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 287/300 batch  10/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 287/300 batch  11/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 287/300 batch  12/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 287/300 batch  13/188  Train Loss: 0.043, Acc: 0.996\n",
      "epoch: 287/300 batch  14/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 287/300 batch  15/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 287/300 batch  16/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 287/300 batch  17/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 287/300 batch  18/188  Train Loss: 0.054, Acc: 0.977\n",
      "epoch: 287/300 batch  19/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 287/300 batch  20/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 287/300 batch  21/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 287/300 batch  22/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 287/300 batch  23/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 287/300 batch  24/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 287/300 batch  25/188  Train Loss: 0.069, Acc: 0.977\n",
      "epoch: 287/300 batch  26/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 287/300 batch  27/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 287/300 batch  28/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 287/300 batch  29/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 287/300 batch  30/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 287/300 batch  31/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 287/300 batch  32/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 287/300 batch  33/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 287/300 batch  34/188  Train Loss: 0.057, Acc: 0.992\n",
      "epoch: 287/300 batch  35/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 287/300 batch  36/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 287/300 batch  37/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 287/300 batch  38/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 287/300 batch  39/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 287/300 batch  40/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 287/300 batch  41/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 287/300 batch  42/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 287/300 batch  43/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 287/300 batch  44/188  Train Loss: 0.051, Acc: 0.980\n",
      "epoch: 287/300 batch  45/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 287/300 batch  46/188  Train Loss: 0.042, Acc: 0.996\n",
      "epoch: 287/300 batch  47/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 287/300 batch  48/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 287/300 batch  49/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 287/300 batch  50/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 287/300 batch  51/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 287/300 batch  52/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 287/300 batch  53/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 287/300 batch  54/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 287/300 batch  55/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 287/300 batch  56/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 287/300 batch  57/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 287/300 batch  58/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 287/300 batch  59/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 287/300 batch  60/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 287/300 batch  61/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 287/300 batch  62/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 287/300 batch  63/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 287/300 batch  64/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 287/300 batch  65/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 287/300 batch  66/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 287/300 batch  67/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 287/300 batch  68/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 287/300 batch  69/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 287/300 batch  70/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 287/300 batch  71/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 287/300 batch  72/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 287/300 batch  73/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 287/300 batch  74/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 287/300 batch  75/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 287/300 batch  76/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 287/300 batch  77/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 287/300 batch  78/188  Train Loss: 0.059, Acc: 0.984\n",
      "epoch: 287/300 batch  79/188  Train Loss: 0.030, Acc: 0.984\n",
      "epoch: 287/300 batch  80/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 287/300 batch  81/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 287/300 batch  82/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 287/300 batch  83/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 287/300 batch  84/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 287/300 batch  85/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 287/300 batch  86/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 287/300 batch  87/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 287/300 batch  88/188  Train Loss: 0.046, Acc: 0.996\n",
      "epoch: 287/300 batch  89/188  Train Loss: 0.049, Acc: 0.980\n",
      "epoch: 287/300 batch  90/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 287/300 batch  91/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 287/300 batch  92/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 287/300 batch  93/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 287/300 batch  94/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 287/300 batch  95/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 287/300 batch  96/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 287/300 batch  97/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 287/300 batch  98/188  Train Loss: 0.064, Acc: 0.988\n",
      "epoch: 287/300 batch  99/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 287/300 batch 100/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 287/300 batch 101/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 287/300 batch 102/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 287/300 batch 103/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 287/300 batch 104/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 287/300 batch 105/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 287/300 batch 106/188  Train Loss: 0.034, Acc: 0.984\n",
      "epoch: 287/300 batch 107/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 287/300 batch 108/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 287/300 batch 109/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 287/300 batch 110/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 287/300 batch 111/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 287/300 batch 112/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 287/300 batch 113/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 287/300 batch 114/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 287/300 batch 115/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 287/300 batch 116/188  Train Loss: 0.059, Acc: 0.988\n",
      "epoch: 287/300 batch 117/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 287/300 batch 118/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 287/300 batch 119/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 287/300 batch 120/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 287/300 batch 121/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 287/300 batch 122/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 287/300 batch 123/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 287/300 batch 124/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 287/300 batch 125/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 287/300 batch 126/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 287/300 batch 127/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 287/300 batch 128/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 287/300 batch 129/188  Train Loss: 0.031, Acc: 1.000\n",
      "epoch: 287/300 batch 130/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 287/300 batch 131/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 287/300 batch 132/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 287/300 batch 133/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 287/300 batch 134/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 287/300 batch 135/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 287/300 batch 136/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 287/300 batch 137/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 287/300 batch 138/188  Train Loss: 0.046, Acc: 0.980\n",
      "epoch: 287/300 batch 139/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 287/300 batch 140/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 287/300 batch 141/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 287/300 batch 142/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 287/300 batch 143/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 287/300 batch 144/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 287/300 batch 145/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 287/300 batch 146/188  Train Loss: 0.024, Acc: 0.988\n",
      "epoch: 287/300 batch 147/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 287/300 batch 148/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 287/300 batch 149/188  Train Loss: 0.062, Acc: 0.980\n",
      "epoch: 287/300 batch 150/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 287/300 batch 151/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 287/300 batch 152/188  Train Loss: 0.051, Acc: 0.992\n",
      "epoch: 287/300 batch 153/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 287/300 batch 154/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 287/300 batch 155/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 287/300 batch 156/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 287/300 batch 157/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 287/300 batch 158/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 287/300 batch 159/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 287/300 batch 160/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 287/300 batch 161/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 287/300 batch 162/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 287/300 batch 163/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 287/300 batch 164/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 287/300 batch 165/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 287/300 batch 166/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 287/300 batch 167/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 287/300 batch 168/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 287/300 batch 169/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 287/300 batch 170/188  Train Loss: 0.016, Acc: 0.996\n",
      "epoch: 287/300 batch 171/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 287/300 batch 172/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 287/300 batch 173/188  Train Loss: 0.042, Acc: 0.980\n",
      "epoch: 287/300 batch 174/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 287/300 batch 175/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 287/300 batch 176/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 287/300 batch 177/188  Train Loss: 0.031, Acc: 1.000\n",
      "epoch: 287/300 batch 178/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 287/300 batch 179/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 287/300 batch 180/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 287/300 batch 181/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 287/300 batch 182/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 287/300 batch 183/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 287/300 batch 184/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 287/300 batch 185/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 287/300 batch 186/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 287/300 batch 187/188  Train Loss: 0.032, Acc: 0.992\n",
      "Train Loss: 0.032502, Acc: 0.993\n",
      "Val Loss: 0.057298, Acc: 0.983\n",
      "epoch: 288/300 batch   0/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 288/300 batch   1/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 288/300 batch   2/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 288/300 batch   3/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 288/300 batch   4/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 288/300 batch   5/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 288/300 batch   6/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 288/300 batch   7/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 288/300 batch   8/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 288/300 batch   9/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 288/300 batch  10/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 288/300 batch  11/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 288/300 batch  12/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 288/300 batch  13/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 288/300 batch  14/188  Train Loss: 0.026, Acc: 0.988\n",
      "epoch: 288/300 batch  15/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 288/300 batch  16/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 288/300 batch  17/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 288/300 batch  18/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 288/300 batch  19/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 288/300 batch  20/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 288/300 batch  21/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 288/300 batch  22/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 288/300 batch  23/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 288/300 batch  24/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 288/300 batch  25/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 288/300 batch  26/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 288/300 batch  27/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 288/300 batch  28/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 288/300 batch  29/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 288/300 batch  30/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 288/300 batch  31/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 288/300 batch  32/188  Train Loss: 0.051, Acc: 0.992\n",
      "epoch: 288/300 batch  33/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 288/300 batch  34/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 288/300 batch  35/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 288/300 batch  36/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 288/300 batch  37/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 288/300 batch  38/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 288/300 batch  39/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 288/300 batch  40/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 288/300 batch  41/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 288/300 batch  42/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 288/300 batch  43/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 288/300 batch  44/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 288/300 batch  45/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 288/300 batch  46/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 288/300 batch  47/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 288/300 batch  48/188  Train Loss: 0.045, Acc: 0.980\n",
      "epoch: 288/300 batch  49/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 288/300 batch  50/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 288/300 batch  51/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 288/300 batch  52/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 288/300 batch  53/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 288/300 batch  54/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 288/300 batch  55/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 288/300 batch  56/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 288/300 batch  57/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 288/300 batch  58/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 288/300 batch  59/188  Train Loss: 0.067, Acc: 0.988\n",
      "epoch: 288/300 batch  60/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 288/300 batch  61/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 288/300 batch  62/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 288/300 batch  63/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 288/300 batch  64/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 288/300 batch  65/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 288/300 batch  66/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 288/300 batch  67/188  Train Loss: 0.027, Acc: 0.988\n",
      "epoch: 288/300 batch  68/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 288/300 batch  69/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 288/300 batch  70/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 288/300 batch  71/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 288/300 batch  72/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 288/300 batch  73/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 288/300 batch  74/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 288/300 batch  75/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 288/300 batch  76/188  Train Loss: 0.051, Acc: 0.980\n",
      "epoch: 288/300 batch  77/188  Train Loss: 0.064, Acc: 0.988\n",
      "epoch: 288/300 batch  78/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 288/300 batch  79/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 288/300 batch  80/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 288/300 batch  81/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 288/300 batch  82/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 288/300 batch  83/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 288/300 batch  84/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 288/300 batch  85/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 288/300 batch  86/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 288/300 batch  87/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 288/300 batch  88/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 288/300 batch  89/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 288/300 batch  90/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 288/300 batch  91/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 288/300 batch  92/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 288/300 batch  93/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 288/300 batch  94/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 288/300 batch  95/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 288/300 batch  96/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 288/300 batch  97/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 288/300 batch  98/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 288/300 batch  99/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 288/300 batch 100/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 288/300 batch 101/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 288/300 batch 102/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 288/300 batch 103/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 288/300 batch 104/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 288/300 batch 105/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 288/300 batch 106/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 288/300 batch 107/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 288/300 batch 108/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 288/300 batch 109/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 288/300 batch 110/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 288/300 batch 111/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 288/300 batch 112/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 288/300 batch 113/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 288/300 batch 114/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 288/300 batch 115/188  Train Loss: 0.061, Acc: 0.973\n",
      "epoch: 288/300 batch 116/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 288/300 batch 117/188  Train Loss: 0.060, Acc: 0.980\n",
      "epoch: 288/300 batch 118/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 288/300 batch 119/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 288/300 batch 120/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 288/300 batch 121/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 288/300 batch 122/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 288/300 batch 123/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 288/300 batch 124/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 288/300 batch 125/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 288/300 batch 126/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 288/300 batch 127/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 288/300 batch 128/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 288/300 batch 129/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 288/300 batch 130/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 288/300 batch 131/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 288/300 batch 132/188  Train Loss: 0.032, Acc: 0.984\n",
      "epoch: 288/300 batch 133/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 288/300 batch 134/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 288/300 batch 135/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 288/300 batch 136/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 288/300 batch 137/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 288/300 batch 138/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 288/300 batch 139/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 288/300 batch 140/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 288/300 batch 141/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 288/300 batch 142/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 288/300 batch 143/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 288/300 batch 144/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 288/300 batch 145/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 288/300 batch 146/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 288/300 batch 147/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 288/300 batch 148/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 288/300 batch 149/188  Train Loss: 0.034, Acc: 0.984\n",
      "epoch: 288/300 batch 150/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 288/300 batch 151/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 288/300 batch 152/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 288/300 batch 153/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 288/300 batch 154/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 288/300 batch 155/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 288/300 batch 156/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 288/300 batch 157/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 288/300 batch 158/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 288/300 batch 159/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 288/300 batch 160/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 288/300 batch 161/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 288/300 batch 162/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 288/300 batch 163/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 288/300 batch 164/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 288/300 batch 165/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 288/300 batch 166/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 288/300 batch 167/188  Train Loss: 0.069, Acc: 0.977\n",
      "epoch: 288/300 batch 168/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 288/300 batch 169/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 288/300 batch 170/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 288/300 batch 171/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 288/300 batch 172/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 288/300 batch 173/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 288/300 batch 174/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 288/300 batch 175/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 288/300 batch 176/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 288/300 batch 177/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 288/300 batch 178/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 288/300 batch 179/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 288/300 batch 180/188  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 288/300 batch 181/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 288/300 batch 182/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 288/300 batch 183/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 288/300 batch 184/188  Train Loss: 0.046, Acc: 0.980\n",
      "epoch: 288/300 batch 185/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 288/300 batch 186/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 288/300 batch 187/188  Train Loss: 0.046, Acc: 0.992\n",
      "Train Loss: 0.032603, Acc: 0.993\n",
      "Val Loss: 0.057558, Acc: 0.983\n",
      "epoch: 289/300 batch   0/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 289/300 batch   1/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 289/300 batch   2/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 289/300 batch   3/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 289/300 batch   4/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 289/300 batch   5/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 289/300 batch   6/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 289/300 batch   7/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 289/300 batch   8/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 289/300 batch   9/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 289/300 batch  10/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 289/300 batch  11/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 289/300 batch  12/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 289/300 batch  13/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 289/300 batch  14/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 289/300 batch  15/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 289/300 batch  16/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 289/300 batch  17/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 289/300 batch  18/188  Train Loss: 0.052, Acc: 0.980\n",
      "epoch: 289/300 batch  19/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 289/300 batch  20/188  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 289/300 batch  21/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 289/300 batch  22/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 289/300 batch  23/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 289/300 batch  24/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 289/300 batch  25/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 289/300 batch  26/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 289/300 batch  27/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 289/300 batch  28/188  Train Loss: 0.056, Acc: 0.992\n",
      "epoch: 289/300 batch  29/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 289/300 batch  30/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 289/300 batch  31/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 289/300 batch  32/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 289/300 batch  33/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 289/300 batch  34/188  Train Loss: 0.048, Acc: 0.980\n",
      "epoch: 289/300 batch  35/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 289/300 batch  36/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 289/300 batch  37/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 289/300 batch  38/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 289/300 batch  39/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 289/300 batch  40/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 289/300 batch  41/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 289/300 batch  42/188  Train Loss: 0.046, Acc: 0.977\n",
      "epoch: 289/300 batch  43/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 289/300 batch  44/188  Train Loss: 0.053, Acc: 0.992\n",
      "epoch: 289/300 batch  45/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 289/300 batch  46/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 289/300 batch  47/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 289/300 batch  48/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 289/300 batch  49/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 289/300 batch  50/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 289/300 batch  51/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 289/300 batch  52/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 289/300 batch  53/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 289/300 batch  54/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 289/300 batch  55/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 289/300 batch  56/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 289/300 batch  57/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 289/300 batch  58/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 289/300 batch  59/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 289/300 batch  60/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 289/300 batch  61/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 289/300 batch  62/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 289/300 batch  63/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 289/300 batch  64/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 289/300 batch  65/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 289/300 batch  66/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 289/300 batch  67/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 289/300 batch  68/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 289/300 batch  69/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 289/300 batch  70/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 289/300 batch  71/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 289/300 batch  72/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 289/300 batch  73/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 289/300 batch  74/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 289/300 batch  75/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 289/300 batch  76/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 289/300 batch  77/188  Train Loss: 0.032, Acc: 1.000\n",
      "epoch: 289/300 batch  78/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 289/300 batch  79/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 289/300 batch  80/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 289/300 batch  81/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 289/300 batch  82/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 289/300 batch  83/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 289/300 batch  84/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 289/300 batch  85/188  Train Loss: 0.056, Acc: 0.980\n",
      "epoch: 289/300 batch  86/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 289/300 batch  87/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 289/300 batch  88/188  Train Loss: 0.063, Acc: 0.992\n",
      "epoch: 289/300 batch  89/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 289/300 batch  90/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 289/300 batch  91/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 289/300 batch  92/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 289/300 batch  93/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 289/300 batch  94/188  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 289/300 batch  95/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 289/300 batch  96/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 289/300 batch  97/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 289/300 batch  98/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 289/300 batch  99/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 289/300 batch 100/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 289/300 batch 101/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 289/300 batch 102/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 289/300 batch 103/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 289/300 batch 104/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 289/300 batch 105/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 289/300 batch 106/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 289/300 batch 107/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 289/300 batch 108/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 289/300 batch 109/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 289/300 batch 110/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 289/300 batch 111/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 289/300 batch 112/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 289/300 batch 113/188  Train Loss: 0.041, Acc: 0.980\n",
      "epoch: 289/300 batch 114/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 289/300 batch 115/188  Train Loss: 0.042, Acc: 0.996\n",
      "epoch: 289/300 batch 116/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 289/300 batch 117/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 289/300 batch 118/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 289/300 batch 119/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 289/300 batch 120/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 289/300 batch 121/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 289/300 batch 122/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 289/300 batch 123/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 289/300 batch 124/188  Train Loss: 0.060, Acc: 0.980\n",
      "epoch: 289/300 batch 125/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 289/300 batch 126/188  Train Loss: 0.042, Acc: 0.977\n",
      "epoch: 289/300 batch 127/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 289/300 batch 128/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 289/300 batch 129/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 289/300 batch 130/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 289/300 batch 131/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 289/300 batch 132/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 289/300 batch 133/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 289/300 batch 134/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 289/300 batch 135/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 289/300 batch 136/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 289/300 batch 137/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 289/300 batch 138/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 289/300 batch 139/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 289/300 batch 140/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 289/300 batch 141/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 289/300 batch 142/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 289/300 batch 143/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 289/300 batch 144/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 289/300 batch 145/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 289/300 batch 146/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 289/300 batch 147/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 289/300 batch 148/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 289/300 batch 149/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 289/300 batch 150/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 289/300 batch 151/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 289/300 batch 152/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 289/300 batch 153/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 289/300 batch 154/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 289/300 batch 155/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 289/300 batch 156/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 289/300 batch 157/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 289/300 batch 158/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 289/300 batch 159/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 289/300 batch 160/188  Train Loss: 0.044, Acc: 0.980\n",
      "epoch: 289/300 batch 161/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 289/300 batch 162/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 289/300 batch 163/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 289/300 batch 164/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 289/300 batch 165/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 289/300 batch 166/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 289/300 batch 167/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 289/300 batch 168/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 289/300 batch 169/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 289/300 batch 170/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 289/300 batch 171/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 289/300 batch 172/188  Train Loss: 0.022, Acc: 0.988\n",
      "epoch: 289/300 batch 173/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 289/300 batch 174/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 289/300 batch 175/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 289/300 batch 176/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 289/300 batch 177/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 289/300 batch 178/188  Train Loss: 0.016, Acc: 0.996\n",
      "epoch: 289/300 batch 179/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 289/300 batch 180/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 289/300 batch 181/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 289/300 batch 182/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 289/300 batch 183/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 289/300 batch 184/188  Train Loss: 0.064, Acc: 0.984\n",
      "epoch: 289/300 batch 185/188  Train Loss: 0.031, Acc: 1.000\n",
      "epoch: 289/300 batch 186/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 289/300 batch 187/188  Train Loss: 0.058, Acc: 0.984\n",
      "Train Loss: 0.032543, Acc: 0.993\n",
      "Val Loss: 0.057223, Acc: 0.984\n",
      "epoch: 290/300 batch   0/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 290/300 batch   1/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 290/300 batch   2/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 290/300 batch   3/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 290/300 batch   4/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 290/300 batch   5/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 290/300 batch   6/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 290/300 batch   7/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 290/300 batch   8/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 290/300 batch   9/188  Train Loss: 0.041, Acc: 0.980\n",
      "epoch: 290/300 batch  10/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 290/300 batch  11/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 290/300 batch  12/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 290/300 batch  13/188  Train Loss: 0.049, Acc: 0.973\n",
      "epoch: 290/300 batch  14/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 290/300 batch  15/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 290/300 batch  16/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 290/300 batch  17/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 290/300 batch  18/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 290/300 batch  19/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 290/300 batch  20/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 290/300 batch  21/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 290/300 batch  22/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 290/300 batch  23/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 290/300 batch  24/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 290/300 batch  25/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 290/300 batch  26/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 290/300 batch  27/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 290/300 batch  28/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 290/300 batch  29/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 290/300 batch  30/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 290/300 batch  31/188  Train Loss: 0.026, Acc: 0.988\n",
      "epoch: 290/300 batch  32/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 290/300 batch  33/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 290/300 batch  34/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 290/300 batch  35/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 290/300 batch  36/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 290/300 batch  37/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 290/300 batch  38/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 290/300 batch  39/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 290/300 batch  40/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 290/300 batch  41/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 290/300 batch  42/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 290/300 batch  43/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 290/300 batch  44/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 290/300 batch  45/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 290/300 batch  46/188  Train Loss: 0.058, Acc: 0.988\n",
      "epoch: 290/300 batch  47/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 290/300 batch  48/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 290/300 batch  49/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 290/300 batch  50/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 290/300 batch  51/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 290/300 batch  52/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 290/300 batch  53/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 290/300 batch  54/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 290/300 batch  55/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 290/300 batch  56/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 290/300 batch  57/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 290/300 batch  58/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 290/300 batch  59/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 290/300 batch  60/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 290/300 batch  61/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 290/300 batch  62/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 290/300 batch  63/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 290/300 batch  64/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 290/300 batch  65/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 290/300 batch  66/188  Train Loss: 0.062, Acc: 0.984\n",
      "epoch: 290/300 batch  67/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 290/300 batch  68/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 290/300 batch  69/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 290/300 batch  70/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 290/300 batch  71/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 290/300 batch  72/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 290/300 batch  73/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 290/300 batch  74/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 290/300 batch  75/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 290/300 batch  76/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 290/300 batch  77/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 290/300 batch  78/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 290/300 batch  79/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 290/300 batch  80/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 290/300 batch  81/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 290/300 batch  82/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 290/300 batch  83/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 290/300 batch  84/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 290/300 batch  85/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 290/300 batch  86/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 290/300 batch  87/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 290/300 batch  88/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 290/300 batch  89/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 290/300 batch  90/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 290/300 batch  91/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 290/300 batch  92/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 290/300 batch  93/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 290/300 batch  94/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 290/300 batch  95/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 290/300 batch  96/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 290/300 batch  97/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 290/300 batch  98/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 290/300 batch  99/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 290/300 batch 100/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 290/300 batch 101/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 290/300 batch 102/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 290/300 batch 103/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 290/300 batch 104/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 290/300 batch 105/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 290/300 batch 106/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 290/300 batch 107/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 290/300 batch 108/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 290/300 batch 109/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 290/300 batch 110/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 290/300 batch 111/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 290/300 batch 112/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 290/300 batch 113/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 290/300 batch 114/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 290/300 batch 115/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 290/300 batch 116/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 290/300 batch 117/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 290/300 batch 118/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 290/300 batch 119/188  Train Loss: 0.041, Acc: 0.980\n",
      "epoch: 290/300 batch 120/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 290/300 batch 121/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 290/300 batch 122/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 290/300 batch 123/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 290/300 batch 124/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 290/300 batch 125/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 290/300 batch 126/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 290/300 batch 127/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 290/300 batch 128/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 290/300 batch 129/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 290/300 batch 130/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 290/300 batch 131/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 290/300 batch 132/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 290/300 batch 133/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 290/300 batch 134/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 290/300 batch 135/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 290/300 batch 136/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 290/300 batch 137/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 290/300 batch 138/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 290/300 batch 139/188  Train Loss: 0.052, Acc: 0.992\n",
      "epoch: 290/300 batch 140/188  Train Loss: 0.060, Acc: 0.980\n",
      "epoch: 290/300 batch 141/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 290/300 batch 142/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 290/300 batch 143/188  Train Loss: 0.056, Acc: 0.977\n",
      "epoch: 290/300 batch 144/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 290/300 batch 145/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 290/300 batch 146/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 290/300 batch 147/188  Train Loss: 0.063, Acc: 0.980\n",
      "epoch: 290/300 batch 148/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 290/300 batch 149/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 290/300 batch 150/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 290/300 batch 151/188  Train Loss: 0.054, Acc: 0.996\n",
      "epoch: 290/300 batch 152/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 290/300 batch 153/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 290/300 batch 154/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 290/300 batch 155/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 290/300 batch 156/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 290/300 batch 157/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 290/300 batch 158/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 290/300 batch 159/188  Train Loss: 0.048, Acc: 0.977\n",
      "epoch: 290/300 batch 160/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 290/300 batch 161/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 290/300 batch 162/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 290/300 batch 163/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 290/300 batch 164/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 290/300 batch 165/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 290/300 batch 166/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 290/300 batch 167/188  Train Loss: 0.064, Acc: 0.984\n",
      "epoch: 290/300 batch 168/188  Train Loss: 0.042, Acc: 0.996\n",
      "epoch: 290/300 batch 169/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 290/300 batch 170/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 290/300 batch 171/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 290/300 batch 172/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 290/300 batch 173/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 290/300 batch 174/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 290/300 batch 175/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 290/300 batch 176/188  Train Loss: 0.043, Acc: 0.996\n",
      "epoch: 290/300 batch 177/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 290/300 batch 178/188  Train Loss: 0.052, Acc: 0.977\n",
      "epoch: 290/300 batch 179/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 290/300 batch 180/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 290/300 batch 181/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 290/300 batch 182/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 290/300 batch 183/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 290/300 batch 184/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 290/300 batch 185/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 290/300 batch 186/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 290/300 batch 187/188  Train Loss: 0.036, Acc: 0.992\n",
      "Train Loss: 0.032511, Acc: 0.993\n",
      "Val Loss: 0.057406, Acc: 0.984\n",
      "epoch: 291/300 batch   0/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 291/300 batch   1/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 291/300 batch   2/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 291/300 batch   3/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 291/300 batch   4/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 291/300 batch   5/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 291/300 batch   6/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 291/300 batch   7/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 291/300 batch   8/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 291/300 batch   9/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 291/300 batch  10/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 291/300 batch  11/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 291/300 batch  12/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 291/300 batch  13/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 291/300 batch  14/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 291/300 batch  15/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 291/300 batch  16/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 291/300 batch  17/188  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 291/300 batch  18/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 291/300 batch  19/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 291/300 batch  20/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 291/300 batch  21/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 291/300 batch  22/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 291/300 batch  23/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 291/300 batch  24/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 291/300 batch  25/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 291/300 batch  26/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 291/300 batch  27/188  Train Loss: 0.038, Acc: 0.980\n",
      "epoch: 291/300 batch  28/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 291/300 batch  29/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 291/300 batch  30/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 291/300 batch  31/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 291/300 batch  32/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 291/300 batch  33/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 291/300 batch  34/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 291/300 batch  35/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 291/300 batch  36/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 291/300 batch  37/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 291/300 batch  38/188  Train Loss: 0.045, Acc: 0.996\n",
      "epoch: 291/300 batch  39/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 291/300 batch  40/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 291/300 batch  41/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 291/300 batch  42/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 291/300 batch  43/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 291/300 batch  44/188  Train Loss: 0.027, Acc: 0.988\n",
      "epoch: 291/300 batch  45/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 291/300 batch  46/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 291/300 batch  47/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 291/300 batch  48/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 291/300 batch  49/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 291/300 batch  50/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 291/300 batch  51/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 291/300 batch  52/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 291/300 batch  53/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 291/300 batch  54/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 291/300 batch  55/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 291/300 batch  56/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 291/300 batch  57/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 291/300 batch  58/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 291/300 batch  59/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 291/300 batch  60/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 291/300 batch  61/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 291/300 batch  62/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 291/300 batch  63/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 291/300 batch  64/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 291/300 batch  65/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 291/300 batch  66/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 291/300 batch  67/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 291/300 batch  68/188  Train Loss: 0.060, Acc: 0.988\n",
      "epoch: 291/300 batch  69/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 291/300 batch  70/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 291/300 batch  71/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 291/300 batch  72/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 291/300 batch  73/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 291/300 batch  74/188  Train Loss: 0.074, Acc: 0.969\n",
      "epoch: 291/300 batch  75/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 291/300 batch  76/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 291/300 batch  77/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 291/300 batch  78/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 291/300 batch  79/188  Train Loss: 0.056, Acc: 0.969\n",
      "epoch: 291/300 batch  80/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 291/300 batch  81/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 291/300 batch  82/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 291/300 batch  83/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 291/300 batch  84/188  Train Loss: 0.059, Acc: 0.984\n",
      "epoch: 291/300 batch  85/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 291/300 batch  86/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 291/300 batch  87/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 291/300 batch  88/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 291/300 batch  89/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 291/300 batch  90/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 291/300 batch  91/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 291/300 batch  92/188  Train Loss: 0.031, Acc: 1.000\n",
      "epoch: 291/300 batch  93/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 291/300 batch  94/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 291/300 batch  95/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 291/300 batch  96/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 291/300 batch  97/188  Train Loss: 0.052, Acc: 0.992\n",
      "epoch: 291/300 batch  98/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 291/300 batch  99/188  Train Loss: 0.043, Acc: 0.980\n",
      "epoch: 291/300 batch 100/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 291/300 batch 101/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 291/300 batch 102/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 291/300 batch 103/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 291/300 batch 104/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 291/300 batch 105/188  Train Loss: 0.043, Acc: 0.996\n",
      "epoch: 291/300 batch 106/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 291/300 batch 107/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 291/300 batch 108/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 291/300 batch 109/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 291/300 batch 110/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 291/300 batch 111/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 291/300 batch 112/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 291/300 batch 113/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 291/300 batch 114/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 291/300 batch 115/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 291/300 batch 116/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 291/300 batch 117/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 291/300 batch 118/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 291/300 batch 119/188  Train Loss: 0.045, Acc: 0.996\n",
      "epoch: 291/300 batch 120/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 291/300 batch 121/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 291/300 batch 122/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 291/300 batch 123/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 291/300 batch 124/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 291/300 batch 125/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 291/300 batch 126/188  Train Loss: 0.025, Acc: 0.988\n",
      "epoch: 291/300 batch 127/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 291/300 batch 128/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 291/300 batch 129/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 291/300 batch 130/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 291/300 batch 131/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 291/300 batch 132/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 291/300 batch 133/188  Train Loss: 0.052, Acc: 0.977\n",
      "epoch: 291/300 batch 134/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 291/300 batch 135/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 291/300 batch 136/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 291/300 batch 137/188  Train Loss: 0.062, Acc: 0.984\n",
      "epoch: 291/300 batch 138/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 291/300 batch 139/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 291/300 batch 140/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 291/300 batch 141/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 291/300 batch 142/188  Train Loss: 0.045, Acc: 0.996\n",
      "epoch: 291/300 batch 143/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 291/300 batch 144/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 291/300 batch 145/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 291/300 batch 146/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 291/300 batch 147/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 291/300 batch 148/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 291/300 batch 149/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 291/300 batch 150/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 291/300 batch 151/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 291/300 batch 152/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 291/300 batch 153/188  Train Loss: 0.034, Acc: 0.984\n",
      "epoch: 291/300 batch 154/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 291/300 batch 155/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 291/300 batch 156/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 291/300 batch 157/188  Train Loss: 0.034, Acc: 0.984\n",
      "epoch: 291/300 batch 158/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 291/300 batch 159/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 291/300 batch 160/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 291/300 batch 161/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 291/300 batch 162/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 291/300 batch 163/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 291/300 batch 164/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 291/300 batch 165/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 291/300 batch 166/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 291/300 batch 167/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 291/300 batch 168/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 291/300 batch 169/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 291/300 batch 170/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 291/300 batch 171/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 291/300 batch 172/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 291/300 batch 173/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 291/300 batch 174/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 291/300 batch 175/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 291/300 batch 176/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 291/300 batch 177/188  Train Loss: 0.071, Acc: 0.988\n",
      "epoch: 291/300 batch 178/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 291/300 batch 179/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 291/300 batch 180/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 291/300 batch 181/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 291/300 batch 182/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 291/300 batch 183/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 291/300 batch 184/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 291/300 batch 185/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 291/300 batch 186/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 291/300 batch 187/188  Train Loss: 0.027, Acc: 1.000\n",
      "Train Loss: 0.032475, Acc: 0.993\n",
      "Val Loss: 0.057616, Acc: 0.984\n",
      "epoch: 292/300 batch   0/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 292/300 batch   1/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 292/300 batch   2/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 292/300 batch   3/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 292/300 batch   4/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 292/300 batch   5/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 292/300 batch   6/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 292/300 batch   7/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 292/300 batch   8/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 292/300 batch   9/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 292/300 batch  10/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 292/300 batch  11/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 292/300 batch  12/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 292/300 batch  13/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 292/300 batch  14/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 292/300 batch  15/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 292/300 batch  16/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 292/300 batch  17/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 292/300 batch  18/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 292/300 batch  19/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 292/300 batch  20/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 292/300 batch  21/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 292/300 batch  22/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 292/300 batch  23/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 292/300 batch  24/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 292/300 batch  25/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 292/300 batch  26/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 292/300 batch  27/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 292/300 batch  28/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 292/300 batch  29/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 292/300 batch  30/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 292/300 batch  31/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 292/300 batch  32/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 292/300 batch  33/188  Train Loss: 0.065, Acc: 0.977\n",
      "epoch: 292/300 batch  34/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 292/300 batch  35/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 292/300 batch  36/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 292/300 batch  37/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 292/300 batch  38/188  Train Loss: 0.042, Acc: 0.980\n",
      "epoch: 292/300 batch  39/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 292/300 batch  40/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 292/300 batch  41/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 292/300 batch  42/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 292/300 batch  43/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 292/300 batch  44/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 292/300 batch  45/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 292/300 batch  46/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 292/300 batch  47/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 292/300 batch  48/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 292/300 batch  49/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 292/300 batch  50/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 292/300 batch  51/188  Train Loss: 0.044, Acc: 0.980\n",
      "epoch: 292/300 batch  52/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 292/300 batch  53/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 292/300 batch  54/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 292/300 batch  55/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 292/300 batch  56/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 292/300 batch  57/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 292/300 batch  58/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 292/300 batch  59/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 292/300 batch  60/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 292/300 batch  61/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 292/300 batch  62/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 292/300 batch  63/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 292/300 batch  64/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 292/300 batch  65/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 292/300 batch  66/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 292/300 batch  67/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 292/300 batch  68/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 292/300 batch  69/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 292/300 batch  70/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 292/300 batch  71/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 292/300 batch  72/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 292/300 batch  73/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 292/300 batch  74/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 292/300 batch  75/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 292/300 batch  76/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 292/300 batch  77/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 292/300 batch  78/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 292/300 batch  79/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 292/300 batch  80/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 292/300 batch  81/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 292/300 batch  82/188  Train Loss: 0.060, Acc: 0.977\n",
      "epoch: 292/300 batch  83/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 292/300 batch  84/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 292/300 batch  85/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 292/300 batch  86/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 292/300 batch  87/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 292/300 batch  88/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 292/300 batch  89/188  Train Loss: 0.040, Acc: 0.980\n",
      "epoch: 292/300 batch  90/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 292/300 batch  91/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 292/300 batch  92/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 292/300 batch  93/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 292/300 batch  94/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 292/300 batch  95/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 292/300 batch  96/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 292/300 batch  97/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 292/300 batch  98/188  Train Loss: 0.075, Acc: 0.988\n",
      "epoch: 292/300 batch  99/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 292/300 batch 100/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 292/300 batch 101/188  Train Loss: 0.024, Acc: 0.988\n",
      "epoch: 292/300 batch 102/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 292/300 batch 103/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 292/300 batch 104/188  Train Loss: 0.064, Acc: 0.988\n",
      "epoch: 292/300 batch 105/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 292/300 batch 106/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 292/300 batch 107/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 292/300 batch 108/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 292/300 batch 109/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 292/300 batch 110/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 292/300 batch 111/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 292/300 batch 112/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 292/300 batch 113/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 292/300 batch 114/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 292/300 batch 115/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 292/300 batch 116/188  Train Loss: 0.047, Acc: 0.977\n",
      "epoch: 292/300 batch 117/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 292/300 batch 118/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 292/300 batch 119/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 292/300 batch 120/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 292/300 batch 121/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 292/300 batch 122/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 292/300 batch 123/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 292/300 batch 124/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 292/300 batch 125/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 292/300 batch 126/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 292/300 batch 127/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 292/300 batch 128/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 292/300 batch 129/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 292/300 batch 130/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 292/300 batch 131/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 292/300 batch 132/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 292/300 batch 133/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 292/300 batch 134/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 292/300 batch 135/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 292/300 batch 136/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 292/300 batch 137/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 292/300 batch 138/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 292/300 batch 139/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 292/300 batch 140/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 292/300 batch 141/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 292/300 batch 142/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 292/300 batch 143/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 292/300 batch 144/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 292/300 batch 145/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 292/300 batch 146/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 292/300 batch 147/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 292/300 batch 148/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 292/300 batch 149/188  Train Loss: 0.033, Acc: 0.984\n",
      "epoch: 292/300 batch 150/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 292/300 batch 151/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 292/300 batch 152/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 292/300 batch 153/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 292/300 batch 154/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 292/300 batch 155/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 292/300 batch 156/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 292/300 batch 157/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 292/300 batch 158/188  Train Loss: 0.052, Acc: 0.992\n",
      "epoch: 292/300 batch 159/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 292/300 batch 160/188  Train Loss: 0.044, Acc: 0.980\n",
      "epoch: 292/300 batch 161/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 292/300 batch 162/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 292/300 batch 163/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 292/300 batch 164/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 292/300 batch 165/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 292/300 batch 166/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 292/300 batch 167/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 292/300 batch 168/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 292/300 batch 169/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 292/300 batch 170/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 292/300 batch 171/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 292/300 batch 172/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 292/300 batch 173/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 292/300 batch 174/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 292/300 batch 175/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 292/300 batch 176/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 292/300 batch 177/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 292/300 batch 178/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 292/300 batch 179/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 292/300 batch 180/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 292/300 batch 181/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 292/300 batch 182/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 292/300 batch 183/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 292/300 batch 184/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 292/300 batch 185/188  Train Loss: 0.061, Acc: 0.988\n",
      "epoch: 292/300 batch 186/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 292/300 batch 187/188  Train Loss: 0.039, Acc: 0.984\n",
      "Train Loss: 0.032523, Acc: 0.993\n",
      "Val Loss: 0.057326, Acc: 0.983\n",
      "epoch: 293/300 batch   0/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 293/300 batch   1/188  Train Loss: 0.064, Acc: 0.977\n",
      "epoch: 293/300 batch   2/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 293/300 batch   3/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 293/300 batch   4/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 293/300 batch   5/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 293/300 batch   6/188  Train Loss: 0.056, Acc: 0.988\n",
      "epoch: 293/300 batch   7/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 293/300 batch   8/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 293/300 batch   9/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 293/300 batch  10/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 293/300 batch  11/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 293/300 batch  12/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 293/300 batch  13/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 293/300 batch  14/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 293/300 batch  15/188  Train Loss: 0.047, Acc: 0.977\n",
      "epoch: 293/300 batch  16/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 293/300 batch  17/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 293/300 batch  18/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 293/300 batch  19/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 293/300 batch  20/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 293/300 batch  21/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 293/300 batch  22/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 293/300 batch  23/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 293/300 batch  24/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 293/300 batch  25/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 293/300 batch  26/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 293/300 batch  27/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 293/300 batch  28/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 293/300 batch  29/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 293/300 batch  30/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 293/300 batch  31/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 293/300 batch  32/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 293/300 batch  33/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 293/300 batch  34/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 293/300 batch  35/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 293/300 batch  36/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 293/300 batch  37/188  Train Loss: 0.083, Acc: 0.988\n",
      "epoch: 293/300 batch  38/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 293/300 batch  39/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 293/300 batch  40/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 293/300 batch  41/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 293/300 batch  42/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 293/300 batch  43/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 293/300 batch  44/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 293/300 batch  45/188  Train Loss: 0.043, Acc: 0.996\n",
      "epoch: 293/300 batch  46/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 293/300 batch  47/188  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 293/300 batch  48/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 293/300 batch  49/188  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 293/300 batch  50/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 293/300 batch  51/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 293/300 batch  52/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 293/300 batch  53/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 293/300 batch  54/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 293/300 batch  55/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 293/300 batch  56/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 293/300 batch  57/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 293/300 batch  58/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 293/300 batch  59/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 293/300 batch  60/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 293/300 batch  61/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 293/300 batch  62/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 293/300 batch  63/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 293/300 batch  64/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 293/300 batch  65/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 293/300 batch  66/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 293/300 batch  67/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 293/300 batch  68/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 293/300 batch  69/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 293/300 batch  70/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 293/300 batch  71/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 293/300 batch  72/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 293/300 batch  73/188  Train Loss: 0.048, Acc: 0.980\n",
      "epoch: 293/300 batch  74/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 293/300 batch  75/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 293/300 batch  76/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 293/300 batch  77/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 293/300 batch  78/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 293/300 batch  79/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 293/300 batch  80/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 293/300 batch  81/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 293/300 batch  82/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 293/300 batch  83/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 293/300 batch  84/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 293/300 batch  85/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 293/300 batch  86/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 293/300 batch  87/188  Train Loss: 0.031, Acc: 0.984\n",
      "epoch: 293/300 batch  88/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 293/300 batch  89/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 293/300 batch  90/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 293/300 batch  91/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 293/300 batch  92/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 293/300 batch  93/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 293/300 batch  94/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 293/300 batch  95/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 293/300 batch  96/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 293/300 batch  97/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 293/300 batch  98/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 293/300 batch  99/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 293/300 batch 100/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 293/300 batch 101/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 293/300 batch 102/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 293/300 batch 103/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 293/300 batch 104/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 293/300 batch 105/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 293/300 batch 106/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 293/300 batch 107/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 293/300 batch 108/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 293/300 batch 109/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 293/300 batch 110/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 293/300 batch 111/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 293/300 batch 112/188  Train Loss: 0.035, Acc: 1.000\n",
      "epoch: 293/300 batch 113/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 293/300 batch 114/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 293/300 batch 115/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 293/300 batch 116/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 293/300 batch 117/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 293/300 batch 118/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 293/300 batch 119/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 293/300 batch 120/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 293/300 batch 121/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 293/300 batch 122/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 293/300 batch 123/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 293/300 batch 124/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 293/300 batch 125/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 293/300 batch 126/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 293/300 batch 127/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 293/300 batch 128/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 293/300 batch 129/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 293/300 batch 130/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 293/300 batch 131/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 293/300 batch 132/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 293/300 batch 133/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 293/300 batch 134/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 293/300 batch 135/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 293/300 batch 136/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 293/300 batch 137/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 293/300 batch 138/188  Train Loss: 0.046, Acc: 0.996\n",
      "epoch: 293/300 batch 139/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 293/300 batch 140/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 293/300 batch 141/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 293/300 batch 142/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 293/300 batch 143/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 293/300 batch 144/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 293/300 batch 145/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 293/300 batch 146/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 293/300 batch 147/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 293/300 batch 148/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 293/300 batch 149/188  Train Loss: 0.056, Acc: 0.988\n",
      "epoch: 293/300 batch 150/188  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 293/300 batch 151/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 293/300 batch 152/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 293/300 batch 153/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 293/300 batch 154/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 293/300 batch 155/188  Train Loss: 0.056, Acc: 0.977\n",
      "epoch: 293/300 batch 156/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 293/300 batch 157/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 293/300 batch 158/188  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 293/300 batch 159/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 293/300 batch 160/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 293/300 batch 161/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 293/300 batch 162/188  Train Loss: 0.065, Acc: 0.980\n",
      "epoch: 293/300 batch 163/188  Train Loss: 0.033, Acc: 1.000\n",
      "epoch: 293/300 batch 164/188  Train Loss: 0.054, Acc: 0.992\n",
      "epoch: 293/300 batch 165/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 293/300 batch 166/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 293/300 batch 167/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 293/300 batch 168/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 293/300 batch 169/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 293/300 batch 170/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 293/300 batch 171/188  Train Loss: 0.016, Acc: 0.996\n",
      "epoch: 293/300 batch 172/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 293/300 batch 173/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 293/300 batch 174/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 293/300 batch 175/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 293/300 batch 176/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 293/300 batch 177/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 293/300 batch 178/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 293/300 batch 179/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 293/300 batch 180/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 293/300 batch 181/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 293/300 batch 182/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 293/300 batch 183/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 293/300 batch 184/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 293/300 batch 185/188  Train Loss: 0.051, Acc: 0.980\n",
      "epoch: 293/300 batch 186/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 293/300 batch 187/188  Train Loss: 0.031, Acc: 0.984\n",
      "Train Loss: 0.032424, Acc: 0.993\n",
      "Val Loss: 0.057688, Acc: 0.983\n",
      "epoch: 294/300 batch   0/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 294/300 batch   1/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 294/300 batch   2/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 294/300 batch   3/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 294/300 batch   4/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 294/300 batch   5/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 294/300 batch   6/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 294/300 batch   7/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 294/300 batch   8/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 294/300 batch   9/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 294/300 batch  10/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 294/300 batch  11/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 294/300 batch  12/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 294/300 batch  13/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 294/300 batch  14/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 294/300 batch  15/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 294/300 batch  16/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 294/300 batch  17/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 294/300 batch  18/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 294/300 batch  19/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 294/300 batch  20/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 294/300 batch  21/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 294/300 batch  22/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 294/300 batch  23/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 294/300 batch  24/188  Train Loss: 0.073, Acc: 0.965\n",
      "epoch: 294/300 batch  25/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 294/300 batch  26/188  Train Loss: 0.015, Acc: 0.996\n",
      "epoch: 294/300 batch  27/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 294/300 batch  28/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 294/300 batch  29/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 294/300 batch  30/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 294/300 batch  31/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 294/300 batch  32/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 294/300 batch  33/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 294/300 batch  34/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 294/300 batch  35/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 294/300 batch  36/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 294/300 batch  37/188  Train Loss: 0.080, Acc: 0.988\n",
      "epoch: 294/300 batch  38/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 294/300 batch  39/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 294/300 batch  40/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 294/300 batch  41/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 294/300 batch  42/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 294/300 batch  43/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 294/300 batch  44/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 294/300 batch  45/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 294/300 batch  46/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 294/300 batch  47/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 294/300 batch  48/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 294/300 batch  49/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 294/300 batch  50/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 294/300 batch  51/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 294/300 batch  52/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 294/300 batch  53/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 294/300 batch  54/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 294/300 batch  55/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 294/300 batch  56/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 294/300 batch  57/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 294/300 batch  58/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 294/300 batch  59/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 294/300 batch  60/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 294/300 batch  61/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 294/300 batch  62/188  Train Loss: 0.060, Acc: 0.988\n",
      "epoch: 294/300 batch  63/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 294/300 batch  64/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 294/300 batch  65/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 294/300 batch  66/188  Train Loss: 0.064, Acc: 0.988\n",
      "epoch: 294/300 batch  67/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 294/300 batch  68/188  Train Loss: 0.026, Acc: 0.988\n",
      "epoch: 294/300 batch  69/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 294/300 batch  70/188  Train Loss: 0.026, Acc: 0.988\n",
      "epoch: 294/300 batch  71/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 294/300 batch  72/188  Train Loss: 0.066, Acc: 0.988\n",
      "epoch: 294/300 batch  73/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 294/300 batch  74/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 294/300 batch  75/188  Train Loss: 0.063, Acc: 0.984\n",
      "epoch: 294/300 batch  76/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 294/300 batch  77/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 294/300 batch  78/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 294/300 batch  79/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 294/300 batch  80/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 294/300 batch  81/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 294/300 batch  82/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 294/300 batch  83/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 294/300 batch  84/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 294/300 batch  85/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 294/300 batch  86/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 294/300 batch  87/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 294/300 batch  88/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 294/300 batch  89/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 294/300 batch  90/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 294/300 batch  91/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 294/300 batch  92/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 294/300 batch  93/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 294/300 batch  94/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 294/300 batch  95/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 294/300 batch  96/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 294/300 batch  97/188  Train Loss: 0.060, Acc: 0.980\n",
      "epoch: 294/300 batch  98/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 294/300 batch  99/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 294/300 batch 100/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 294/300 batch 101/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 294/300 batch 102/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 294/300 batch 103/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 294/300 batch 104/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 294/300 batch 105/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 294/300 batch 106/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 294/300 batch 107/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 294/300 batch 108/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 294/300 batch 109/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 294/300 batch 110/188  Train Loss: 0.068, Acc: 0.984\n",
      "epoch: 294/300 batch 111/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 294/300 batch 112/188  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 294/300 batch 113/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 294/300 batch 114/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 294/300 batch 115/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 294/300 batch 116/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 294/300 batch 117/188  Train Loss: 0.034, Acc: 0.984\n",
      "epoch: 294/300 batch 118/188  Train Loss: 0.030, Acc: 0.984\n",
      "epoch: 294/300 batch 119/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 294/300 batch 120/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 294/300 batch 121/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 294/300 batch 122/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 294/300 batch 123/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 294/300 batch 124/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 294/300 batch 125/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 294/300 batch 126/188  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 294/300 batch 127/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 294/300 batch 128/188  Train Loss: 0.049, Acc: 0.977\n",
      "epoch: 294/300 batch 129/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 294/300 batch 130/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 294/300 batch 131/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 294/300 batch 132/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 294/300 batch 133/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 294/300 batch 134/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 294/300 batch 135/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 294/300 batch 136/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 294/300 batch 137/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 294/300 batch 138/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 294/300 batch 139/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 294/300 batch 140/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 294/300 batch 141/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 294/300 batch 142/188  Train Loss: 0.034, Acc: 0.984\n",
      "epoch: 294/300 batch 143/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 294/300 batch 144/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 294/300 batch 145/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 294/300 batch 146/188  Train Loss: 0.045, Acc: 0.996\n",
      "epoch: 294/300 batch 147/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 294/300 batch 148/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 294/300 batch 149/188  Train Loss: 0.051, Acc: 0.980\n",
      "epoch: 294/300 batch 150/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 294/300 batch 151/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 294/300 batch 152/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 294/300 batch 153/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 294/300 batch 154/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 294/300 batch 155/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 294/300 batch 156/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 294/300 batch 157/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 294/300 batch 158/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 294/300 batch 159/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 294/300 batch 160/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 294/300 batch 161/188  Train Loss: 0.043, Acc: 0.996\n",
      "epoch: 294/300 batch 162/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 294/300 batch 163/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 294/300 batch 164/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 294/300 batch 165/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 294/300 batch 166/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 294/300 batch 167/188  Train Loss: 0.049, Acc: 0.980\n",
      "epoch: 294/300 batch 168/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 294/300 batch 169/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 294/300 batch 170/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 294/300 batch 171/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 294/300 batch 172/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 294/300 batch 173/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 294/300 batch 174/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 294/300 batch 175/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 294/300 batch 176/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 294/300 batch 177/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 294/300 batch 178/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 294/300 batch 179/188  Train Loss: 0.052, Acc: 0.980\n",
      "epoch: 294/300 batch 180/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 294/300 batch 181/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 294/300 batch 182/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 294/300 batch 183/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 294/300 batch 184/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 294/300 batch 185/188  Train Loss: 0.046, Acc: 0.980\n",
      "epoch: 294/300 batch 186/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 294/300 batch 187/188  Train Loss: 0.038, Acc: 0.992\n",
      "Train Loss: 0.032495, Acc: 0.993\n",
      "Val Loss: 0.057684, Acc: 0.983\n",
      "epoch: 295/300 batch   0/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 295/300 batch   1/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 295/300 batch   2/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 295/300 batch   3/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 295/300 batch   4/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 295/300 batch   5/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 295/300 batch   6/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 295/300 batch   7/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 295/300 batch   8/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 295/300 batch   9/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 295/300 batch  10/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 295/300 batch  11/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 295/300 batch  12/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 295/300 batch  13/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 295/300 batch  14/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 295/300 batch  15/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 295/300 batch  16/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 295/300 batch  17/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 295/300 batch  18/188  Train Loss: 0.041, Acc: 0.996\n",
      "epoch: 295/300 batch  19/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 295/300 batch  20/188  Train Loss: 0.043, Acc: 0.996\n",
      "epoch: 295/300 batch  21/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 295/300 batch  22/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 295/300 batch  23/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 295/300 batch  24/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 295/300 batch  25/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 295/300 batch  26/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 295/300 batch  27/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 295/300 batch  28/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 295/300 batch  29/188  Train Loss: 0.066, Acc: 0.977\n",
      "epoch: 295/300 batch  30/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 295/300 batch  31/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 295/300 batch  32/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 295/300 batch  33/188  Train Loss: 0.033, Acc: 1.000\n",
      "epoch: 295/300 batch  34/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 295/300 batch  35/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 295/300 batch  36/188  Train Loss: 0.050, Acc: 0.996\n",
      "epoch: 295/300 batch  37/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 295/300 batch  38/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 295/300 batch  39/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 295/300 batch  40/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 295/300 batch  41/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 295/300 batch  42/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 295/300 batch  43/188  Train Loss: 0.053, Acc: 0.973\n",
      "epoch: 295/300 batch  44/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 295/300 batch  45/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 295/300 batch  46/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 295/300 batch  47/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 295/300 batch  48/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 295/300 batch  49/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 295/300 batch  50/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 295/300 batch  51/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 295/300 batch  52/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 295/300 batch  53/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 295/300 batch  54/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 295/300 batch  55/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 295/300 batch  56/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 295/300 batch  57/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 295/300 batch  58/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 295/300 batch  59/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 295/300 batch  60/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 295/300 batch  61/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 295/300 batch  62/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 295/300 batch  63/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 295/300 batch  64/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 295/300 batch  65/188  Train Loss: 0.034, Acc: 0.980\n",
      "epoch: 295/300 batch  66/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 295/300 batch  67/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 295/300 batch  68/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 295/300 batch  69/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 295/300 batch  70/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 295/300 batch  71/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 295/300 batch  72/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 295/300 batch  73/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 295/300 batch  74/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 295/300 batch  75/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 295/300 batch  76/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 295/300 batch  77/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 295/300 batch  78/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 295/300 batch  79/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 295/300 batch  80/188  Train Loss: 0.063, Acc: 0.992\n",
      "epoch: 295/300 batch  81/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 295/300 batch  82/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 295/300 batch  83/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 295/300 batch  84/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 295/300 batch  85/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 295/300 batch  86/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 295/300 batch  87/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 295/300 batch  88/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 295/300 batch  89/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 295/300 batch  90/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 295/300 batch  91/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 295/300 batch  92/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 295/300 batch  93/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 295/300 batch  94/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 295/300 batch  95/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 295/300 batch  96/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 295/300 batch  97/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 295/300 batch  98/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 295/300 batch  99/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 295/300 batch 100/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 295/300 batch 101/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 295/300 batch 102/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 295/300 batch 103/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 295/300 batch 104/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 295/300 batch 105/188  Train Loss: 0.031, Acc: 1.000\n",
      "epoch: 295/300 batch 106/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 295/300 batch 107/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 295/300 batch 108/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 295/300 batch 109/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 295/300 batch 110/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 295/300 batch 111/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 295/300 batch 112/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 295/300 batch 113/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 295/300 batch 114/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 295/300 batch 115/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 295/300 batch 116/188  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 295/300 batch 117/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 295/300 batch 118/188  Train Loss: 0.061, Acc: 0.977\n",
      "epoch: 295/300 batch 119/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 295/300 batch 120/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 295/300 batch 121/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 295/300 batch 122/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 295/300 batch 123/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 295/300 batch 124/188  Train Loss: 0.024, Acc: 0.988\n",
      "epoch: 295/300 batch 125/188  Train Loss: 0.027, Acc: 0.988\n",
      "epoch: 295/300 batch 126/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 295/300 batch 127/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 295/300 batch 128/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 295/300 batch 129/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 295/300 batch 130/188  Train Loss: 0.051, Acc: 0.988\n",
      "epoch: 295/300 batch 131/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 295/300 batch 132/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 295/300 batch 133/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 295/300 batch 134/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 295/300 batch 135/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 295/300 batch 136/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 295/300 batch 137/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 295/300 batch 138/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 295/300 batch 139/188  Train Loss: 0.024, Acc: 0.988\n",
      "epoch: 295/300 batch 140/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 295/300 batch 141/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 295/300 batch 142/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 295/300 batch 143/188  Train Loss: 0.026, Acc: 0.988\n",
      "epoch: 295/300 batch 144/188  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 295/300 batch 145/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 295/300 batch 146/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 295/300 batch 147/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 295/300 batch 148/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 295/300 batch 149/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 295/300 batch 150/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 295/300 batch 151/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 295/300 batch 152/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 295/300 batch 153/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 295/300 batch 154/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 295/300 batch 155/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 295/300 batch 156/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 295/300 batch 157/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 295/300 batch 158/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 295/300 batch 159/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 295/300 batch 160/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 295/300 batch 161/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 295/300 batch 162/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 295/300 batch 163/188  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 295/300 batch 164/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 295/300 batch 165/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 295/300 batch 166/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 295/300 batch 167/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 295/300 batch 168/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 295/300 batch 169/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 295/300 batch 170/188  Train Loss: 0.063, Acc: 0.992\n",
      "epoch: 295/300 batch 171/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 295/300 batch 172/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 295/300 batch 173/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 295/300 batch 174/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 295/300 batch 175/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 295/300 batch 176/188  Train Loss: 0.060, Acc: 0.977\n",
      "epoch: 295/300 batch 177/188  Train Loss: 0.056, Acc: 0.980\n",
      "epoch: 295/300 batch 178/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 295/300 batch 179/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 295/300 batch 180/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 295/300 batch 181/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 295/300 batch 182/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 295/300 batch 183/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 295/300 batch 184/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 295/300 batch 185/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 295/300 batch 186/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 295/300 batch 187/188  Train Loss: 0.028, Acc: 0.992\n",
      "Train Loss: 0.032488, Acc: 0.993\n",
      "Val Loss: 0.058023, Acc: 0.983\n",
      "epoch: 296/300 batch   0/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 296/300 batch   1/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 296/300 batch   2/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 296/300 batch   3/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 296/300 batch   4/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 296/300 batch   5/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 296/300 batch   6/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 296/300 batch   7/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 296/300 batch   8/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 296/300 batch   9/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 296/300 batch  10/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 296/300 batch  11/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 296/300 batch  12/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 296/300 batch  13/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 296/300 batch  14/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 296/300 batch  15/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 296/300 batch  16/188  Train Loss: 0.056, Acc: 0.980\n",
      "epoch: 296/300 batch  17/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 296/300 batch  18/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 296/300 batch  19/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 296/300 batch  20/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 296/300 batch  21/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 296/300 batch  22/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 296/300 batch  23/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 296/300 batch  24/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 296/300 batch  25/188  Train Loss: 0.053, Acc: 0.992\n",
      "epoch: 296/300 batch  26/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 296/300 batch  27/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 296/300 batch  28/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 296/300 batch  29/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 296/300 batch  30/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 296/300 batch  31/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 296/300 batch  32/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 296/300 batch  33/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 296/300 batch  34/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 296/300 batch  35/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 296/300 batch  36/188  Train Loss: 0.012, Acc: 0.996\n",
      "epoch: 296/300 batch  37/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 296/300 batch  38/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 296/300 batch  39/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 296/300 batch  40/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 296/300 batch  41/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 296/300 batch  42/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 296/300 batch  43/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 296/300 batch  44/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 296/300 batch  45/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 296/300 batch  46/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 296/300 batch  47/188  Train Loss: 0.026, Acc: 0.988\n",
      "epoch: 296/300 batch  48/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 296/300 batch  49/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 296/300 batch  50/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 296/300 batch  51/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 296/300 batch  52/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 296/300 batch  53/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 296/300 batch  54/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 296/300 batch  55/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 296/300 batch  56/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 296/300 batch  57/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 296/300 batch  58/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 296/300 batch  59/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 296/300 batch  60/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 296/300 batch  61/188  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 296/300 batch  62/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 296/300 batch  63/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 296/300 batch  64/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 296/300 batch  65/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 296/300 batch  66/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 296/300 batch  67/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 296/300 batch  68/188  Train Loss: 0.074, Acc: 0.980\n",
      "epoch: 296/300 batch  69/188  Train Loss: 0.047, Acc: 0.980\n",
      "epoch: 296/300 batch  70/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 296/300 batch  71/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 296/300 batch  72/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 296/300 batch  73/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 296/300 batch  74/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 296/300 batch  75/188  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 296/300 batch  76/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 296/300 batch  77/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 296/300 batch  78/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 296/300 batch  79/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 296/300 batch  80/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 296/300 batch  81/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 296/300 batch  82/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 296/300 batch  83/188  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 296/300 batch  84/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 296/300 batch  85/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 296/300 batch  86/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 296/300 batch  87/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 296/300 batch  88/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 296/300 batch  89/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 296/300 batch  90/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 296/300 batch  91/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 296/300 batch  92/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 296/300 batch  93/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 296/300 batch  94/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 296/300 batch  95/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 296/300 batch  96/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 296/300 batch  97/188  Train Loss: 0.063, Acc: 0.996\n",
      "epoch: 296/300 batch  98/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 296/300 batch  99/188  Train Loss: 0.056, Acc: 0.992\n",
      "epoch: 296/300 batch 100/188  Train Loss: 0.026, Acc: 0.988\n",
      "epoch: 296/300 batch 101/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 296/300 batch 102/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 296/300 batch 103/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 296/300 batch 104/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 296/300 batch 105/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 296/300 batch 106/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 296/300 batch 107/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 296/300 batch 108/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 296/300 batch 109/188  Train Loss: 0.033, Acc: 0.984\n",
      "epoch: 296/300 batch 110/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 296/300 batch 111/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 296/300 batch 112/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 296/300 batch 113/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 296/300 batch 114/188  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 296/300 batch 115/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 296/300 batch 116/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 296/300 batch 117/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 296/300 batch 118/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 296/300 batch 119/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 296/300 batch 120/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 296/300 batch 121/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 296/300 batch 122/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 296/300 batch 123/188  Train Loss: 0.045, Acc: 0.980\n",
      "epoch: 296/300 batch 124/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 296/300 batch 125/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 296/300 batch 126/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 296/300 batch 127/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 296/300 batch 128/188  Train Loss: 0.022, Acc: 0.988\n",
      "epoch: 296/300 batch 129/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 296/300 batch 130/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 296/300 batch 131/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 296/300 batch 132/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 296/300 batch 133/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 296/300 batch 134/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 296/300 batch 135/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 296/300 batch 136/188  Train Loss: 0.048, Acc: 0.980\n",
      "epoch: 296/300 batch 137/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 296/300 batch 138/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 296/300 batch 139/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 296/300 batch 140/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 296/300 batch 141/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 296/300 batch 142/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 296/300 batch 143/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 296/300 batch 144/188  Train Loss: 0.049, Acc: 0.988\n",
      "epoch: 296/300 batch 145/188  Train Loss: 0.063, Acc: 0.980\n",
      "epoch: 296/300 batch 146/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 296/300 batch 147/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 296/300 batch 148/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 296/300 batch 149/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 296/300 batch 150/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 296/300 batch 151/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 296/300 batch 152/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 296/300 batch 153/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 296/300 batch 154/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 296/300 batch 155/188  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 296/300 batch 156/188  Train Loss: 0.059, Acc: 0.980\n",
      "epoch: 296/300 batch 157/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 296/300 batch 158/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 296/300 batch 159/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 296/300 batch 160/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 296/300 batch 161/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 296/300 batch 162/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 296/300 batch 163/188  Train Loss: 0.042, Acc: 0.980\n",
      "epoch: 296/300 batch 164/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 296/300 batch 165/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 296/300 batch 166/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 296/300 batch 167/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 296/300 batch 168/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 296/300 batch 169/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 296/300 batch 170/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 296/300 batch 171/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 296/300 batch 172/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 296/300 batch 173/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 296/300 batch 174/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 296/300 batch 175/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 296/300 batch 176/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 296/300 batch 177/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 296/300 batch 178/188  Train Loss: 0.016, Acc: 0.996\n",
      "epoch: 296/300 batch 179/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 296/300 batch 180/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 296/300 batch 181/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 296/300 batch 182/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 296/300 batch 183/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 296/300 batch 184/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 296/300 batch 185/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 296/300 batch 186/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 296/300 batch 187/188  Train Loss: 0.036, Acc: 0.992\n",
      "Train Loss: 0.032471, Acc: 0.993\n",
      "Val Loss: 0.057553, Acc: 0.984\n",
      "epoch: 297/300 batch   0/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 297/300 batch   1/188  Train Loss: 0.027, Acc: 0.988\n",
      "epoch: 297/300 batch   2/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 297/300 batch   3/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 297/300 batch   4/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 297/300 batch   5/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 297/300 batch   6/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 297/300 batch   7/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 297/300 batch   8/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 297/300 batch   9/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 297/300 batch  10/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 297/300 batch  11/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 297/300 batch  12/188  Train Loss: 0.051, Acc: 0.992\n",
      "epoch: 297/300 batch  13/188  Train Loss: 0.053, Acc: 0.988\n",
      "epoch: 297/300 batch  14/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 297/300 batch  15/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 297/300 batch  16/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 297/300 batch  17/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 297/300 batch  18/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 297/300 batch  19/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 297/300 batch  20/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 297/300 batch  21/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 297/300 batch  22/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 297/300 batch  23/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 297/300 batch  24/188  Train Loss: 0.017, Acc: 0.996\n",
      "epoch: 297/300 batch  25/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 297/300 batch  26/188  Train Loss: 0.043, Acc: 0.980\n",
      "epoch: 297/300 batch  27/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 297/300 batch  28/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 297/300 batch  29/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 297/300 batch  30/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 297/300 batch  31/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 297/300 batch  32/188  Train Loss: 0.075, Acc: 0.973\n",
      "epoch: 297/300 batch  33/188  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 297/300 batch  34/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 297/300 batch  35/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 297/300 batch  36/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 297/300 batch  37/188  Train Loss: 0.062, Acc: 0.992\n",
      "epoch: 297/300 batch  38/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 297/300 batch  39/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 297/300 batch  40/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 297/300 batch  41/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 297/300 batch  42/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 297/300 batch  43/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 297/300 batch  44/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 297/300 batch  45/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 297/300 batch  46/188  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 297/300 batch  47/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 297/300 batch  48/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 297/300 batch  49/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 297/300 batch  50/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 297/300 batch  51/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 297/300 batch  52/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 297/300 batch  53/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 297/300 batch  54/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 297/300 batch  55/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 297/300 batch  56/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 297/300 batch  57/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 297/300 batch  58/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 297/300 batch  59/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 297/300 batch  60/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 297/300 batch  61/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 297/300 batch  62/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 297/300 batch  63/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 297/300 batch  64/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 297/300 batch  65/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 297/300 batch  66/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 297/300 batch  67/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 297/300 batch  68/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 297/300 batch  69/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 297/300 batch  70/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 297/300 batch  71/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 297/300 batch  72/188  Train Loss: 0.064, Acc: 0.984\n",
      "epoch: 297/300 batch  73/188  Train Loss: 0.068, Acc: 0.969\n",
      "epoch: 297/300 batch  74/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 297/300 batch  75/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 297/300 batch  76/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 297/300 batch  77/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 297/300 batch  78/188  Train Loss: 0.063, Acc: 0.984\n",
      "epoch: 297/300 batch  79/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 297/300 batch  80/188  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 297/300 batch  81/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 297/300 batch  82/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 297/300 batch  83/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 297/300 batch  84/188  Train Loss: 0.033, Acc: 1.000\n",
      "epoch: 297/300 batch  85/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 297/300 batch  86/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 297/300 batch  87/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 297/300 batch  88/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 297/300 batch  89/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 297/300 batch  90/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 297/300 batch  91/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 297/300 batch  92/188  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 297/300 batch  93/188  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 297/300 batch  94/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 297/300 batch  95/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 297/300 batch  96/188  Train Loss: 0.053, Acc: 0.992\n",
      "epoch: 297/300 batch  97/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 297/300 batch  98/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 297/300 batch  99/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 297/300 batch 100/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 297/300 batch 101/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 297/300 batch 102/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 297/300 batch 103/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 297/300 batch 104/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 297/300 batch 105/188  Train Loss: 0.012, Acc: 0.996\n",
      "epoch: 297/300 batch 106/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 297/300 batch 107/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 297/300 batch 108/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 297/300 batch 109/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 297/300 batch 110/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 297/300 batch 111/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 297/300 batch 112/188  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 297/300 batch 113/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 297/300 batch 114/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 297/300 batch 115/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 297/300 batch 116/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 297/300 batch 117/188  Train Loss: 0.055, Acc: 0.980\n",
      "epoch: 297/300 batch 118/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 297/300 batch 119/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 297/300 batch 120/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 297/300 batch 121/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 297/300 batch 122/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 297/300 batch 123/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 297/300 batch 124/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 297/300 batch 125/188  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 297/300 batch 126/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 297/300 batch 127/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 297/300 batch 128/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 297/300 batch 129/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 297/300 batch 130/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 297/300 batch 131/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 297/300 batch 132/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 297/300 batch 133/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 297/300 batch 134/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 297/300 batch 135/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 297/300 batch 136/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 297/300 batch 137/188  Train Loss: 0.052, Acc: 0.973\n",
      "epoch: 297/300 batch 138/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 297/300 batch 139/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 297/300 batch 140/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 297/300 batch 141/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 297/300 batch 142/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 297/300 batch 143/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 297/300 batch 144/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 297/300 batch 145/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 297/300 batch 146/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 297/300 batch 147/188  Train Loss: 0.034, Acc: 0.984\n",
      "epoch: 297/300 batch 148/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 297/300 batch 149/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 297/300 batch 150/188  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 297/300 batch 151/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 297/300 batch 152/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 297/300 batch 153/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 297/300 batch 154/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 297/300 batch 155/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 297/300 batch 156/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 297/300 batch 157/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 297/300 batch 158/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 297/300 batch 159/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 297/300 batch 160/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 297/300 batch 161/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 297/300 batch 162/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 297/300 batch 163/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 297/300 batch 164/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 297/300 batch 165/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 297/300 batch 166/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 297/300 batch 167/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 297/300 batch 168/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 297/300 batch 169/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 297/300 batch 170/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 297/300 batch 171/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 297/300 batch 172/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 297/300 batch 173/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 297/300 batch 174/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 297/300 batch 175/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 297/300 batch 176/188  Train Loss: 0.060, Acc: 0.984\n",
      "epoch: 297/300 batch 177/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 297/300 batch 178/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 297/300 batch 179/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 297/300 batch 180/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 297/300 batch 181/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 297/300 batch 182/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 297/300 batch 183/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 297/300 batch 184/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 297/300 batch 185/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 297/300 batch 186/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 297/300 batch 187/188  Train Loss: 0.052, Acc: 0.984\n",
      "Train Loss: 0.032503, Acc: 0.993\n",
      "Val Loss: 0.057373, Acc: 0.984\n",
      "epoch: 298/300 batch   0/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 298/300 batch   1/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 298/300 batch   2/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 298/300 batch   3/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 298/300 batch   4/188  Train Loss: 0.069, Acc: 0.980\n",
      "epoch: 298/300 batch   5/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 298/300 batch   6/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 298/300 batch   7/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 298/300 batch   8/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 298/300 batch   9/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 298/300 batch  10/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 298/300 batch  11/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 298/300 batch  12/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 298/300 batch  13/188  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 298/300 batch  14/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 298/300 batch  15/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 298/300 batch  16/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 298/300 batch  17/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 298/300 batch  18/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 298/300 batch  19/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 298/300 batch  20/188  Train Loss: 0.053, Acc: 0.992\n",
      "epoch: 298/300 batch  21/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 298/300 batch  22/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 298/300 batch  23/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 298/300 batch  24/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 298/300 batch  25/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 298/300 batch  26/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 298/300 batch  27/188  Train Loss: 0.043, Acc: 0.996\n",
      "epoch: 298/300 batch  28/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 298/300 batch  29/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 298/300 batch  30/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 298/300 batch  31/188  Train Loss: 0.033, Acc: 1.000\n",
      "epoch: 298/300 batch  32/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 298/300 batch  33/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 298/300 batch  34/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 298/300 batch  35/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 298/300 batch  36/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 298/300 batch  37/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 298/300 batch  38/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 298/300 batch  39/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 298/300 batch  40/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 298/300 batch  41/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 298/300 batch  42/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 298/300 batch  43/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 298/300 batch  44/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 298/300 batch  45/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 298/300 batch  46/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 298/300 batch  47/188  Train Loss: 0.054, Acc: 0.988\n",
      "epoch: 298/300 batch  48/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 298/300 batch  49/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 298/300 batch  50/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 298/300 batch  51/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 298/300 batch  52/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 298/300 batch  53/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 298/300 batch  54/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 298/300 batch  55/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 298/300 batch  56/188  Train Loss: 0.030, Acc: 0.988\n",
      "epoch: 298/300 batch  57/188  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 298/300 batch  58/188  Train Loss: 0.027, Acc: 0.988\n",
      "epoch: 298/300 batch  59/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 298/300 batch  60/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 298/300 batch  61/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 298/300 batch  62/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 298/300 batch  63/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 298/300 batch  64/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 298/300 batch  65/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 298/300 batch  66/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 298/300 batch  67/188  Train Loss: 0.054, Acc: 0.980\n",
      "epoch: 298/300 batch  68/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 298/300 batch  69/188  Train Loss: 0.063, Acc: 0.977\n",
      "epoch: 298/300 batch  70/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 298/300 batch  71/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 298/300 batch  72/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 298/300 batch  73/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 298/300 batch  74/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 298/300 batch  75/188  Train Loss: 0.060, Acc: 0.988\n",
      "epoch: 298/300 batch  76/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 298/300 batch  77/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 298/300 batch  78/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 298/300 batch  79/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 298/300 batch  80/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 298/300 batch  81/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 298/300 batch  82/188  Train Loss: 0.029, Acc: 0.984\n",
      "epoch: 298/300 batch  83/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 298/300 batch  84/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 298/300 batch  85/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 298/300 batch  86/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 298/300 batch  87/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 298/300 batch  88/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 298/300 batch  89/188  Train Loss: 0.069, Acc: 0.988\n",
      "epoch: 298/300 batch  90/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 298/300 batch  91/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 298/300 batch  92/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 298/300 batch  93/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 298/300 batch  94/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 298/300 batch  95/188  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 298/300 batch  96/188  Train Loss: 0.066, Acc: 0.988\n",
      "epoch: 298/300 batch  97/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 298/300 batch  98/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 298/300 batch  99/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 298/300 batch 100/188  Train Loss: 0.027, Acc: 0.988\n",
      "epoch: 298/300 batch 101/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 298/300 batch 102/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 298/300 batch 103/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 298/300 batch 104/188  Train Loss: 0.034, Acc: 0.984\n",
      "epoch: 298/300 batch 105/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 298/300 batch 106/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 298/300 batch 107/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 298/300 batch 108/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 298/300 batch 109/188  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 298/300 batch 110/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 298/300 batch 111/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 298/300 batch 112/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 298/300 batch 113/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 298/300 batch 114/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 298/300 batch 115/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 298/300 batch 116/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 298/300 batch 117/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 298/300 batch 118/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 298/300 batch 119/188  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 298/300 batch 120/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 298/300 batch 121/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 298/300 batch 122/188  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 298/300 batch 123/188  Train Loss: 0.039, Acc: 0.988\n",
      "epoch: 298/300 batch 124/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 298/300 batch 125/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 298/300 batch 126/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 298/300 batch 127/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 298/300 batch 128/188  Train Loss: 0.026, Acc: 0.988\n",
      "epoch: 298/300 batch 129/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 298/300 batch 130/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 298/300 batch 131/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 298/300 batch 132/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 298/300 batch 133/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 298/300 batch 134/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 298/300 batch 135/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 298/300 batch 136/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 298/300 batch 137/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 298/300 batch 138/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 298/300 batch 139/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 298/300 batch 140/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 298/300 batch 141/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 298/300 batch 142/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 298/300 batch 143/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 298/300 batch 144/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 298/300 batch 145/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 298/300 batch 146/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 298/300 batch 147/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 298/300 batch 148/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 298/300 batch 149/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 298/300 batch 150/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 298/300 batch 151/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 298/300 batch 152/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 298/300 batch 153/188  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 298/300 batch 154/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 298/300 batch 155/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 298/300 batch 156/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 298/300 batch 157/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 298/300 batch 158/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 298/300 batch 159/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 298/300 batch 160/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 298/300 batch 161/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 298/300 batch 162/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 298/300 batch 163/188  Train Loss: 0.024, Acc: 0.988\n",
      "epoch: 298/300 batch 164/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 298/300 batch 165/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 298/300 batch 166/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 298/300 batch 167/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 298/300 batch 168/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 298/300 batch 169/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 298/300 batch 170/188  Train Loss: 0.034, Acc: 0.984\n",
      "epoch: 298/300 batch 171/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 298/300 batch 172/188  Train Loss: 0.067, Acc: 0.996\n",
      "epoch: 298/300 batch 173/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 298/300 batch 174/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 298/300 batch 175/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 298/300 batch 176/188  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 298/300 batch 177/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 298/300 batch 178/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 298/300 batch 179/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 298/300 batch 180/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 298/300 batch 181/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 298/300 batch 182/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 298/300 batch 183/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 298/300 batch 184/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 298/300 batch 185/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 298/300 batch 186/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 298/300 batch 187/188  Train Loss: 0.028, Acc: 0.984\n",
      "Train Loss: 0.032408, Acc: 0.993\n",
      "Val Loss: 0.057076, Acc: 0.984\n",
      "epoch: 299/300 batch   0/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 299/300 batch   1/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 299/300 batch   2/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 299/300 batch   3/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 299/300 batch   4/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 299/300 batch   5/188  Train Loss: 0.040, Acc: 0.996\n",
      "epoch: 299/300 batch   6/188  Train Loss: 0.041, Acc: 0.980\n",
      "epoch: 299/300 batch   7/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 299/300 batch   8/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 299/300 batch   9/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 299/300 batch  10/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 299/300 batch  11/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 299/300 batch  12/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 299/300 batch  13/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 299/300 batch  14/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 299/300 batch  15/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 299/300 batch  16/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 299/300 batch  17/188  Train Loss: 0.084, Acc: 0.988\n",
      "epoch: 299/300 batch  18/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 299/300 batch  19/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 299/300 batch  20/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 299/300 batch  21/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 299/300 batch  22/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 299/300 batch  23/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 299/300 batch  24/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 299/300 batch  25/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 299/300 batch  26/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 299/300 batch  27/188  Train Loss: 0.015, Acc: 0.996\n",
      "epoch: 299/300 batch  28/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 299/300 batch  29/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 299/300 batch  30/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 299/300 batch  31/188  Train Loss: 0.046, Acc: 0.988\n",
      "epoch: 299/300 batch  32/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 299/300 batch  33/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 299/300 batch  34/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 299/300 batch  35/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 299/300 batch  36/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 299/300 batch  37/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 299/300 batch  38/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 299/300 batch  39/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 299/300 batch  40/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 299/300 batch  41/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 299/300 batch  42/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 299/300 batch  43/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 299/300 batch  44/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 299/300 batch  45/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 299/300 batch  46/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 299/300 batch  47/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 299/300 batch  48/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 299/300 batch  49/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 299/300 batch  50/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 299/300 batch  51/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 299/300 batch  52/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 299/300 batch  53/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 299/300 batch  54/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 299/300 batch  55/188  Train Loss: 0.056, Acc: 0.988\n",
      "epoch: 299/300 batch  56/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 299/300 batch  57/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 299/300 batch  58/188  Train Loss: 0.075, Acc: 0.980\n",
      "epoch: 299/300 batch  59/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 299/300 batch  60/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 299/300 batch  61/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 299/300 batch  62/188  Train Loss: 0.051, Acc: 0.992\n",
      "epoch: 299/300 batch  63/188  Train Loss: 0.047, Acc: 0.996\n",
      "epoch: 299/300 batch  64/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 299/300 batch  65/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 299/300 batch  66/188  Train Loss: 0.018, Acc: 0.996\n",
      "epoch: 299/300 batch  67/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 299/300 batch  68/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 299/300 batch  69/188  Train Loss: 0.051, Acc: 0.980\n",
      "epoch: 299/300 batch  70/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 299/300 batch  71/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 299/300 batch  72/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 299/300 batch  73/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 299/300 batch  74/188  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 299/300 batch  75/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 299/300 batch  76/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 299/300 batch  77/188  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 299/300 batch  78/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 299/300 batch  79/188  Train Loss: 0.016, Acc: 0.996\n",
      "epoch: 299/300 batch  80/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 299/300 batch  81/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 299/300 batch  82/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 299/300 batch  83/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 299/300 batch  84/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 299/300 batch  85/188  Train Loss: 0.055, Acc: 0.992\n",
      "epoch: 299/300 batch  86/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 299/300 batch  87/188  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 299/300 batch  88/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 299/300 batch  89/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 299/300 batch  90/188  Train Loss: 0.023, Acc: 0.988\n",
      "epoch: 299/300 batch  91/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 299/300 batch  92/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 299/300 batch  93/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 299/300 batch  94/188  Train Loss: 0.061, Acc: 0.980\n",
      "epoch: 299/300 batch  95/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 299/300 batch  96/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 299/300 batch  97/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 299/300 batch  98/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 299/300 batch  99/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 299/300 batch 100/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 299/300 batch 101/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 299/300 batch 102/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 299/300 batch 103/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 299/300 batch 104/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 299/300 batch 105/188  Train Loss: 0.056, Acc: 0.977\n",
      "epoch: 299/300 batch 106/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 299/300 batch 107/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 299/300 batch 108/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 299/300 batch 109/188  Train Loss: 0.043, Acc: 0.980\n",
      "epoch: 299/300 batch 110/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 299/300 batch 111/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 299/300 batch 112/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 299/300 batch 113/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 299/300 batch 114/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 299/300 batch 115/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 299/300 batch 116/188  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 299/300 batch 117/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 299/300 batch 118/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 299/300 batch 119/188  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 299/300 batch 120/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 299/300 batch 121/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 299/300 batch 122/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 299/300 batch 123/188  Train Loss: 0.061, Acc: 0.977\n",
      "epoch: 299/300 batch 124/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 299/300 batch 125/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 299/300 batch 126/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 299/300 batch 127/188  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 299/300 batch 128/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 299/300 batch 129/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 299/300 batch 130/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 299/300 batch 131/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 299/300 batch 132/188  Train Loss: 0.057, Acc: 0.980\n",
      "epoch: 299/300 batch 133/188  Train Loss: 0.052, Acc: 0.988\n",
      "epoch: 299/300 batch 134/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 299/300 batch 135/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 299/300 batch 136/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 299/300 batch 137/188  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 299/300 batch 138/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 299/300 batch 139/188  Train Loss: 0.020, Acc: 0.996\n",
      "epoch: 299/300 batch 140/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 299/300 batch 141/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 299/300 batch 142/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 299/300 batch 143/188  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 299/300 batch 144/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 299/300 batch 145/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 299/300 batch 146/188  Train Loss: 0.032, Acc: 0.984\n",
      "epoch: 299/300 batch 147/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 299/300 batch 148/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 299/300 batch 149/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 299/300 batch 150/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 299/300 batch 151/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 299/300 batch 152/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 299/300 batch 153/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 299/300 batch 154/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 299/300 batch 155/188  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 299/300 batch 156/188  Train Loss: 0.053, Acc: 0.977\n",
      "epoch: 299/300 batch 157/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 299/300 batch 158/188  Train Loss: 0.050, Acc: 0.988\n",
      "epoch: 299/300 batch 159/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 299/300 batch 160/188  Train Loss: 0.055, Acc: 0.988\n",
      "epoch: 299/300 batch 161/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 299/300 batch 162/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 299/300 batch 163/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 299/300 batch 164/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 299/300 batch 165/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 299/300 batch 166/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 299/300 batch 167/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 299/300 batch 168/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 299/300 batch 169/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 299/300 batch 170/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 299/300 batch 171/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 299/300 batch 172/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 299/300 batch 173/188  Train Loss: 0.031, Acc: 0.988\n",
      "epoch: 299/300 batch 174/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 299/300 batch 175/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 299/300 batch 176/188  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 299/300 batch 177/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 299/300 batch 178/188  Train Loss: 0.057, Acc: 0.977\n",
      "epoch: 299/300 batch 179/188  Train Loss: 0.039, Acc: 0.996\n",
      "epoch: 299/300 batch 180/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 299/300 batch 181/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 299/300 batch 182/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 299/300 batch 183/188  Train Loss: 0.042, Acc: 0.996\n",
      "epoch: 299/300 batch 184/188  Train Loss: 0.060, Acc: 0.980\n",
      "epoch: 299/300 batch 185/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 299/300 batch 186/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 299/300 batch 187/188  Train Loss: 0.039, Acc: 0.992\n",
      "Train Loss: 0.032486, Acc: 0.993\n",
      "Val Loss: 0.057791, Acc: 0.983\n",
      "epoch: 300/300 batch   0/188  Train Loss: 0.043, Acc: 0.980\n",
      "epoch: 300/300 batch   1/188  Train Loss: 0.032, Acc: 0.988\n",
      "epoch: 300/300 batch   2/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 300/300 batch   3/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 300/300 batch   4/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 300/300 batch   5/188  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 300/300 batch   6/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 300/300 batch   7/188  Train Loss: 0.043, Acc: 0.988\n",
      "epoch: 300/300 batch   8/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 300/300 batch   9/188  Train Loss: 0.063, Acc: 0.988\n",
      "epoch: 300/300 batch  10/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 300/300 batch  11/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 300/300 batch  12/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 300/300 batch  13/188  Train Loss: 0.034, Acc: 0.984\n",
      "epoch: 300/300 batch  14/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 300/300 batch  15/188  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 300/300 batch  16/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 300/300 batch  17/188  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 300/300 batch  18/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 300/300 batch  19/188  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 300/300 batch  20/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 300/300 batch  21/188  Train Loss: 0.031, Acc: 0.996\n",
      "epoch: 300/300 batch  22/188  Train Loss: 0.054, Acc: 0.980\n",
      "epoch: 300/300 batch  23/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 300/300 batch  24/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 300/300 batch  25/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 300/300 batch  26/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 300/300 batch  27/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 300/300 batch  28/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 300/300 batch  29/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 300/300 batch  30/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 300/300 batch  31/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 300/300 batch  32/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 300/300 batch  33/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 300/300 batch  34/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 300/300 batch  35/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 300/300 batch  36/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 300/300 batch  37/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 300/300 batch  38/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 300/300 batch  39/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 300/300 batch  40/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 300/300 batch  41/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 300/300 batch  42/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 300/300 batch  43/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 300/300 batch  44/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 300/300 batch  45/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 300/300 batch  46/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 300/300 batch  47/188  Train Loss: 0.046, Acc: 0.977\n",
      "epoch: 300/300 batch  48/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 300/300 batch  49/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 300/300 batch  50/188  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 300/300 batch  51/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 300/300 batch  52/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 300/300 batch  53/188  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 300/300 batch  54/188  Train Loss: 0.062, Acc: 0.988\n",
      "epoch: 300/300 batch  55/188  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 300/300 batch  56/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 300/300 batch  57/188  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 300/300 batch  58/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 300/300 batch  59/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 300/300 batch  60/188  Train Loss: 0.021, Acc: 0.996\n",
      "epoch: 300/300 batch  61/188  Train Loss: 0.066, Acc: 0.980\n",
      "epoch: 300/300 batch  62/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 300/300 batch  63/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 300/300 batch  64/188  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 300/300 batch  65/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 300/300 batch  66/188  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 300/300 batch  67/188  Train Loss: 0.036, Acc: 0.988\n",
      "epoch: 300/300 batch  68/188  Train Loss: 0.036, Acc: 0.996\n",
      "epoch: 300/300 batch  69/188  Train Loss: 0.067, Acc: 0.980\n",
      "epoch: 300/300 batch  70/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 300/300 batch  71/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 300/300 batch  72/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 300/300 batch  73/188  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 300/300 batch  74/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 300/300 batch  75/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 300/300 batch  76/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 300/300 batch  77/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 300/300 batch  78/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 300/300 batch  79/188  Train Loss: 0.046, Acc: 0.996\n",
      "epoch: 300/300 batch  80/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 300/300 batch  81/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 300/300 batch  82/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 300/300 batch  83/188  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 300/300 batch  84/188  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 300/300 batch  85/188  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 300/300 batch  86/188  Train Loss: 0.083, Acc: 0.984\n",
      "epoch: 300/300 batch  87/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 300/300 batch  88/188  Train Loss: 0.035, Acc: 0.996\n",
      "epoch: 300/300 batch  89/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 300/300 batch  90/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 300/300 batch  91/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 300/300 batch  92/188  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 300/300 batch  93/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 300/300 batch  94/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 300/300 batch  95/188  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 300/300 batch  96/188  Train Loss: 0.074, Acc: 0.977\n",
      "epoch: 300/300 batch  97/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 300/300 batch  98/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 300/300 batch  99/188  Train Loss: 0.033, Acc: 0.984\n",
      "epoch: 300/300 batch 100/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 300/300 batch 101/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 300/300 batch 102/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 300/300 batch 103/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 300/300 batch 104/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 300/300 batch 105/188  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 300/300 batch 106/188  Train Loss: 0.030, Acc: 1.000\n",
      "epoch: 300/300 batch 107/188  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 300/300 batch 108/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 300/300 batch 109/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 300/300 batch 110/188  Train Loss: 0.022, Acc: 0.996\n",
      "epoch: 300/300 batch 111/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 300/300 batch 112/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 300/300 batch 113/188  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 300/300 batch 114/188  Train Loss: 0.034, Acc: 0.988\n",
      "epoch: 300/300 batch 115/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 300/300 batch 116/188  Train Loss: 0.033, Acc: 0.996\n",
      "epoch: 300/300 batch 117/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 300/300 batch 118/188  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 300/300 batch 119/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 300/300 batch 120/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 300/300 batch 121/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 300/300 batch 122/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 300/300 batch 123/188  Train Loss: 0.038, Acc: 0.988\n",
      "epoch: 300/300 batch 124/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 300/300 batch 125/188  Train Loss: 0.016, Acc: 0.996\n",
      "epoch: 300/300 batch 126/188  Train Loss: 0.047, Acc: 0.969\n",
      "epoch: 300/300 batch 127/188  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 300/300 batch 128/188  Train Loss: 0.026, Acc: 0.996\n",
      "epoch: 300/300 batch 129/188  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 300/300 batch 130/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 300/300 batch 131/188  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 300/300 batch 132/188  Train Loss: 0.037, Acc: 0.996\n",
      "epoch: 300/300 batch 133/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 300/300 batch 134/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 300/300 batch 135/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 300/300 batch 136/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 300/300 batch 137/188  Train Loss: 0.038, Acc: 0.996\n",
      "epoch: 300/300 batch 138/188  Train Loss: 0.045, Acc: 0.988\n",
      "epoch: 300/300 batch 139/188  Train Loss: 0.024, Acc: 0.996\n",
      "epoch: 300/300 batch 140/188  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 300/300 batch 141/188  Train Loss: 0.048, Acc: 0.988\n",
      "epoch: 300/300 batch 142/188  Train Loss: 0.033, Acc: 1.000\n",
      "epoch: 300/300 batch 143/188  Train Loss: 0.028, Acc: 0.988\n",
      "epoch: 300/300 batch 144/188  Train Loss: 0.042, Acc: 0.988\n",
      "epoch: 300/300 batch 145/188  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 300/300 batch 146/188  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 300/300 batch 147/188  Train Loss: 0.044, Acc: 0.988\n",
      "epoch: 300/300 batch 148/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 300/300 batch 149/188  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 300/300 batch 150/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 300/300 batch 151/188  Train Loss: 0.025, Acc: 0.996\n",
      "epoch: 300/300 batch 152/188  Train Loss: 0.032, Acc: 0.996\n",
      "epoch: 300/300 batch 153/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 300/300 batch 154/188  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 300/300 batch 155/188  Train Loss: 0.034, Acc: 0.996\n",
      "epoch: 300/300 batch 156/188  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 300/300 batch 157/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 300/300 batch 158/188  Train Loss: 0.037, Acc: 0.988\n",
      "epoch: 300/300 batch 159/188  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 300/300 batch 160/188  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 300/300 batch 161/188  Train Loss: 0.029, Acc: 0.988\n",
      "epoch: 300/300 batch 162/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 300/300 batch 163/188  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 300/300 batch 164/188  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 300/300 batch 165/188  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 300/300 batch 166/188  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 300/300 batch 167/188  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 300/300 batch 168/188  Train Loss: 0.029, Acc: 0.996\n",
      "epoch: 300/300 batch 169/188  Train Loss: 0.023, Acc: 0.996\n",
      "epoch: 300/300 batch 170/188  Train Loss: 0.040, Acc: 0.988\n",
      "epoch: 300/300 batch 171/188  Train Loss: 0.019, Acc: 0.996\n",
      "epoch: 300/300 batch 172/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 300/300 batch 173/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 300/300 batch 174/188  Train Loss: 0.033, Acc: 0.988\n",
      "epoch: 300/300 batch 175/188  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 300/300 batch 176/188  Train Loss: 0.035, Acc: 0.988\n",
      "epoch: 300/300 batch 177/188  Train Loss: 0.030, Acc: 0.996\n",
      "epoch: 300/300 batch 178/188  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 300/300 batch 179/188  Train Loss: 0.028, Acc: 0.996\n",
      "epoch: 300/300 batch 180/188  Train Loss: 0.047, Acc: 0.988\n",
      "epoch: 300/300 batch 181/188  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 300/300 batch 182/188  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 300/300 batch 183/188  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 300/300 batch 184/188  Train Loss: 0.027, Acc: 0.996\n",
      "epoch: 300/300 batch 185/188  Train Loss: 0.041, Acc: 0.988\n",
      "epoch: 300/300 batch 186/188  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 300/300 batch 187/188  Train Loss: 0.053, Acc: 0.984\n",
      "Train Loss: 0.032524, Acc: 0.993\n",
      "Val Loss: 0.057630, Acc: 0.983\n"
     ]
    }
   ],
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
